\documentclass[a4paper,12pt,twoside]{book}

%%% Packages %%%
\usepackage[cm,headings]{fullpage}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{gensymb}
\usepackage{url}
\usepackage{csquotes}
\usepackage{enumitem}
\usepackage{setspace}
\usepackage{longtable}

%%% Settings %%%
\pagestyle{headings}
\setlength{\parindent}{0pt}
\raggedbottom
\frenchspacing
\urlstyle{same}
\MakeOuterQuote{"}
\setlist{nolistsep}
\setlist[itemize]{leftmargin=*}
\setlist[enumerate]{leftmargin=*}
\setcounter{tocdepth}{3}
\setcounter{secnumdepth}{3}
\renewcommand{\arraystretch}{1.5}

%%% Format %%%
\renewcommand\thechapter{\Roman{chapter}}
\renewcommand\thesection{\arabic{section}}
\renewcommand\theequation{\arabic{equation}}
\renewcommand\thefootnote{\arabic{footnote}}
\let\Chaptermark\chaptermark
\def\chaptermark#1{\def\Chaptername{#1}\Chaptermark{#1}}
\let\Sectionmark\sectionmark
\def\sectionmark#1{\def\Sectionname{#1}\Sectionmark{#1}}

%%% Title %%%
\title{\Huge{The Book of Statistical Proofs}}
\author{DOI: 10.5281/zenodo.4305950 \\ \url{https://statproofbook.github.io/} \\ StatProofBook@gmail.com}
\date{2022-01-05, 11:55}

\begin{document}


%%% Title %%%
\maketitle

%%% Contents %%%
\pagebreak
\pagenumbering{roman}
\tableofcontents

%%% Text %%%
\newpage
\pagenumbering{arabic}


% Chapter 1 %
\chapter{General Theorems} \label{sec:General Theorems} \newpage

\pagebreak
\section{Probability theory}

\subsection{Random experiments}

\subsubsection[\textit{Random experiment}]{Random experiment} \label{sec:rexp}
\setcounter{equation}{0}

\textbf{Definition:} A random experiment is any repeatable procedure that results in one ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) out of a well-defined set of possible outcomes.

\begin{itemize}

\item The set of possible outcomes is called sample space ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:samp-spc}).

\item A set of zero or more outcomes is called a random event ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:reve}).

\item A function that maps from events to probabilities is called a probability function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist}).

\end{itemize}

Together, sample space ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:samp-spc}), event space ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:eve-spc}) and probability function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-spc}) characterize a random experiment.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Experiment (probability theory)"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-11-19; URL: \url{https://en.wikipedia.org/wiki/Experiment_(probability_theory)}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D109 | shortcut: rexp | author: JoramSoch | date: 2020-11-19, 04:10.
\vspace{1em}



\subsubsection[\textit{Sample space}]{Sample space} \label{sec:samp-spc}
\setcounter{equation}{0}

\textbf{Definition:} Given a random experiment ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rexp}), the set of all possible outcomes from this experiment is called the sample space of the experiment. A sample space is usually denoted as $\Omega$ and specified using set notation.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Sample space"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-11-26; URL: \url{https://en.wikipedia.org/wiki/Sample_space}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D165 | shortcut: samp-spc | author: JoramSoch | date: 2021-11-26, 14:13.
\vspace{1em}



\subsubsection[\textit{Event space}]{Event space} \label{sec:eve-spc}
\setcounter{equation}{0}

\textbf{Definition:} Given a random experiment ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rexp}), an event space $\mathcal{E}$ is any set of events, where an event ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:reve}) is any set of zero or more elements from the sample space ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:samp-spc}) $\Omega$ of this experiment.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Event (probability theory)"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-11-26; URL: \url{https://en.wikipedia.org/wiki/Event_(probability_theory)}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D166 | shortcut: eve-spc | author: JoramSoch | date: 2021-11-26, 14:26.
\vspace{1em}



\subsubsection[\textit{Probability space}]{Probability space} \label{sec:prob-spc}
\setcounter{equation}{0}

\textbf{Definition:} Given a random experiment ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rexp}), a probability space $(\Omega, \mathcal{E}, P)$ is a triple consisting of

\begin{itemize}

\item the sample space ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:samp-spc}) $\Omega$, i.e. the set of all possible outcomes from this experiment;

\item an event space ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:eve-spc}) $\mathcal{E} \subseteq 2^\Omega$, i.e. a set of subsets from the sample space, called events ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:reve});

\item a probability measure ($\rightarrow$ Definition "prob-meas") $P: \; \mathcal{E} \rightarrow [0,1]$, i.e. a function mapping from the event space ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:eve-spc}) to the real numbers, observing the axioms of probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-ax}).

\end{itemize}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Probability space"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-11-26; URL: \url{https://en.wikipedia.org/wiki/Probability_space#Definition}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D167 | shortcut: prob-spc | author: JoramSoch | date: 2021-11-26, 14:30.
\vspace{1em}



\subsection{Random variables}

\subsubsection[\textit{Random event}]{Random event} \label{sec:reve}
\setcounter{equation}{0}

\textbf{Definition:} A random event $E$ is the outcome of a random experiment ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rexp}) which can be described by a statement that is either true or false.

\begin{itemize}

\item If the statement is true, the event is said to take place, denoted as $E$.

\item If the statement is false, the complement of $E$ occurs, denoted as $\overline{E}$.

\end{itemize}

In other words, a random event is a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with two possible values (true and false, or 1 and 0). A random experiment ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rexp}) with two possible outcomes is called a Bernoulli trial ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:bern}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Event (probability theory)"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-11-19; URL: \url{https://en.wikipedia.org/wiki/Event_(probability_theory)}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D110 | shortcut: reve | author: JoramSoch | date: 2020-11-19, 04:33.
\vspace{1em}



\subsubsection[\textit{Random variable}]{Random variable} \label{sec:rvar}
\setcounter{equation}{0}

\textbf{Definition:} A random variable may be understood

\begin{itemize}

\item informally, as a real number $X \in \mathbb{R}$ whose value is the outcome of a random experiment ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rexp});

\item formally, as a measurable function ($\rightarrow$ Definition "meas-fct") $X$ defined on a probability space ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-spc}) $(\Omega, \mathcal{E}, P)$ that maps from a sample space ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:samp-spc}) $\Omega$ to the real numbers $\mathbb{R}$ using an event space ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:eve-spc}) $\mathcal{E}$ and a probability function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist}) $P$;

\item more broadly, as any random quantity $X$ such as a random event ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:reve}), a random scalar ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}), a random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}) or a random matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rmat}).

\end{itemize}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Random variable"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-05-27; URL: \url{https://en.wikipedia.org/wiki/Random_variable#Definition}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D65 | shortcut: rvar | author: JoramSoch | date: 2020-05-27, 22:36.
\vspace{1em}



\subsubsection[\textit{Random vector}]{Random vector} \label{sec:rvec}
\setcounter{equation}{0}

\textbf{Definition:} A random vector, also called "multivariate random variable", is an $n$-dimensional column vector $X \in \mathbb{R}^{n \times 1}$ whose entries are random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Multivariate random variable"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-05-27; URL: \url{https://en.wikipedia.org/wiki/Multivariate_random_variable}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D66 | shortcut: rvec | author: JoramSoch | date: 2020-05-27, 22:44.
\vspace{1em}



\subsubsection[\textit{Random matrix}]{Random matrix} \label{sec:rmat}
\setcounter{equation}{0}

\textbf{Definition:} A random matrix, also called "matrix-valued random variable", is an $n \times p$ matrix $X \in \mathbb{R}^{n \times p}$ whose entries are random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}). Equivalently, a random matrix is an $n \times p$ matrix whose columns are $n$-dimensional random vectors ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Random matrix"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-05-27; URL: \url{https://en.wikipedia.org/wiki/Random_matrix}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D67 | shortcut: rmat | author: JoramSoch | date: 2020-05-27, 22:48.
\vspace{1em}



\subsubsection[\textit{Constant}]{Constant} \label{sec:const}
\setcounter{equation}{0}

\textbf{Definition:} A constant is a quantity which does not change and thus always has the same value. From a statistical perspective, a constant is a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) which is equal to its expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean})

\begin{equation} \label{eq:const-EX}
X = \mathrm{E}(X)
\end{equation}

or equivalently, whose variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) is zero

\begin{equation} \label{eq:const-VarX}
\mathrm{Var}(X) = 0 \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item ProofWiki (2020): "Definition: Constant"; in: \textit{ProofWiki}, retrieved on 2020-09-09; URL: \url{https://proofwiki.org/wiki/Definition:Constant#Definition}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D96 | shortcut: const | author: JoramSoch | date: 2020-09-09, 01:30.
\vspace{1em}



\subsubsection[\textit{Discrete vs. continuous}]{Discrete vs. continuous} \label{sec:rvar-disc}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with possible outcomes $\mathcal{X}$. Then,

\begin{itemize}

\item $X$ is called a discrete random variable, if $\mathcal{X}$ is either a finite set or a countably infinite set; in this case, $X$ can be described by a probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf});

\item $X$ is called a continuous random variable, if $\mathcal{X}$ is an uncountably infinite set; if it is absolutely continuous, $X$ can be described by a probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}).

\end{itemize}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Random variable"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-10-29; URL: \url{https://en.wikipedia.org/wiki/Random_variable#Standard_case}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D105 | shortcut: rvar-disc | author: JoramSoch | date: 2020-10-29, 04:44.
\vspace{1em}



\subsubsection[\textit{Univariate vs. multivariate}]{Univariate vs. multivariate} \label{sec:rvar-uni}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with possible outcomes $\mathcal{X}$. Then,

\begin{itemize}

\item $X$ is called a two-valued random variable or random event ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:reve}), if $\mathcal{X}$ has exactly two elements, e.g. $\mathcal{X} = \left\lbrace E, \overline{E} \right\rbrace$ or $\mathcal{X} = \left\lbrace \mathrm{true}, \mathrm{false} \right\rbrace$ or $\mathcal{X} = \left\lbrace 1, 0 \right\rbrace$;

\item $X$ is called a univariate random variable or random scalar ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}), if $\mathcal{X}$ is one-dimensional, i.e. (a subset of) the real numbers $\mathbb{R}$;

\item $X$ is called a multivariate random variable or random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}), if $\mathcal{X}$ is multi-dimensional, e.g. (a subset of) the $n$-dimensional Euclidean space $\mathbb{R}^n$;

\item $X$ is called a matrix-valued random variable or random matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rmat}), if $\mathcal{X}$ is (a subset of) the set of $n \times p$ real matrices $\mathbb{R}^{n \times p}$.

\end{itemize}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Multivariate random variable"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-11-06; URL: \url{https://en.wikipedia.org/wiki/Multivariate_random_variable}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D106 | shortcut: rvar-uni | author: JoramSoch | date: 2020-11-06, 03:47.
\vspace{1em}



\subsection{Probability}

\subsubsection[\textit{Probability}]{Probability} \label{sec:prob}
\setcounter{equation}{0}

\textbf{Definition:} Let $E$ be a statement about an arbitrary event such as the outcome of a random experiment ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rexp}). Then, $p(E)$ is called the probability of $E$ and may be interpreted as

\begin{itemize}

\item (objectivist interpretation of probability:) some physical state of affairs, e.g. the relative frequency of occurrence of $E$, when repeating the experiment ("Frequentist probability"); or

\item (subjectivist interpretation of probability:) a degree of belief in $E$, e.g. the price at which someone would buy or sell a bet that pays 1 unit of utility if $E$ and 0 if not $E$ ("Bayesian probability").

\end{itemize}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Probability"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-05-10; URL: \url{https://en.wikipedia.org/wiki/Probability#Interpretations}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D48 | shortcut: prob | author: JoramSoch | date: 2020-05-10, 19:41.
\vspace{1em}



\subsubsection[\textit{Joint probability}]{Joint probability} \label{sec:prob-joint}
\setcounter{equation}{0}

\textbf{Definition:} Let $A$ and $B$ be two arbitrary statements about random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}), such as statements about the presence or absence of an event or about the value of a scalar, vector or matrix. Then, $p(A,B)$ is called the joint probability of $A$ and $B$ and is defined as the probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob}) that $A$ and $B$ are both true.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Joint probability distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-05-10; URL: \url{https://en.wikipedia.org/wiki/Joint_probability_distribution}.
\item Jason Browlee (2019): "A Gentle Introduction to Joint, Marginal, and Conditional Probability"; in: \textit{Machine Learning Mastery}, retrieved on 2021-08-01; URL: \url{https://machinelearningmastery.com/joint-marginal-and-conditional-probability-for-machine-learning/}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D49 | shortcut: prob-joint | author: JoramSoch | date: 2020-05-10, 19:49.
\vspace{1em}



\subsubsection[\textit{Marginal probability}]{Marginal probability} \label{sec:prob-marg}
\setcounter{equation}{0}

\textbf{Definition:} (law of marginal probability, also called "sum rule") Let $A$ and $X$ be two arbitrary statements about random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}), such as statements about the presence or absence of an event or about the value of a scalar, vector or matrix. Furthermore, assume a joint probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) distribution $p(A,X)$. Then, $p(A)$ is called the marginal probability of $A$ and,

1) if $X$ is a discrete ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar-disc}) random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with domain $\mathcal{X}$, is given by

\begin{equation} \label{eq:prob-marg-prob-marg-disc}
p(A) = \sum_{x \in \mathcal{X}} p(A,x) \; ;
\end{equation}

2) if $X$ is a continuous ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar-disc}) random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with domain $\mathcal{X}$, is given by

\begin{equation} \label{eq:prob-marg-prob-marg-cont}
p(A) = \int_{\mathcal{X}} p(A,x) \, \mathrm{d}x \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Marginal distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-05-10; URL: \url{https://en.wikipedia.org/wiki/Marginal_distribution#Definition}.
\item Jason Browlee (2019): "A Gentle Introduction to Joint, Marginal, and Conditional Probability"; in: \textit{Machine Learning Mastery}, retrieved on 2021-08-01; URL: \url{https://machinelearningmastery.com/joint-marginal-and-conditional-probability-for-machine-learning/}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D50 | shortcut: prob-marg | author: JoramSoch | date: 2020-05-10, 20:01.
\vspace{1em}



\subsubsection[\textit{Conditional probability}]{Conditional probability} \label{sec:prob-cond}
\setcounter{equation}{0}

\textbf{Definition:} (law of conditional probability, also called "product rule") Let $A$ and $B$ be two arbitrary statements about random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}), such as statements about the presence or absence of an event or about the value of a scalar, vector or matrix. Furthermore, assume a joint probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) distribution $p(A,B)$. Then, $p(A \vert B)$ is called the conditional probability that $A$ is true, given that $B$ is true, and is given by

\begin{equation} \label{eq:prob-cond-prob-cond}
p(A|B) = \frac{p(A,B)}{p(B)}
\end{equation}

where $p(B)$ is the marginal probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}) of $B$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Conditional probability"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-05-10; URL: \url{https://en.wikipedia.org/wiki/Conditional_probability#Definition}.
\item Jason Browlee (2019): "A Gentle Introduction to Joint, Marginal, and Conditional Probability"; in: \textit{Machine Learning Mastery}, retrieved on 2021-08-01; URL: \url{https://machinelearningmastery.com/joint-marginal-and-conditional-probability-for-machine-learning/}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D51 | shortcut: prob-cond | author: JoramSoch | date: 2020-05-10, 20:06.
\vspace{1em}



\subsubsection[\textit{Exceedance probability}]{Exceedance probability} \label{sec:prob-exc}
\setcounter{equation}{0}

\textbf{Definition:} Let $X = \left\lbrace X_1, \ldots, X_n \right\rbrace$ be a set of $n$ random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) which the joint probability distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-joint}) $p(X) = p(X_1, \ldots, X_n)$. Then, the exceedance probability for random variable $X_i$ is the probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob}) that $X_i$ is larger than all other random variables $X_j, \; j \neq i$:

\begin{equation} \label{eq:prob-exc-EP}
\begin{split}
\varphi(X_i) &= \mathrm{Pr}\left( \forall j \in \left\lbrace 1, \ldots, n | j \neq i \right\rbrace: \, X_i > X_j \right) \\
&= \mathrm{Pr}\left( \bigwedge_{j \neq i} X_i > X_j \right) \\
&= \mathrm{Pr}\left( X_i = \mathrm{max}(\left\lbrace X_1, \ldots, X_n \right\rbrace) \right) \\
&= \int_{X_i = \mathrm{max}(X)} p(X) \, \mathrm{d}X \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Stephan KE, Penny WD, Daunizeau J, Moran RJ, Friston KJ (2009): "Bayesian model selection for group studies"; in: \textit{NeuroImage}, vol. 46, pp. 1004â€“1017, eq. 16; URL: \url{https://www.sciencedirect.com/science/article/abs/pii/S1053811909002638}; DOI: 10.1016/j.neuroimage.2009.03.025.
\item Soch J, Allefeld C (2016): "Exceedance Probabilities for the Dirichlet Distribution"; in: \textit{arXiv stat.AP}, 1611.01439; URL: \url{https://arxiv.org/abs/1611.01439}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D103 | shortcut: prob-exc | author: JoramSoch | date: 2020-10-22, 04:36.
\vspace{1em}



\subsubsection[\textit{Statistical independence}]{Statistical independence} \label{sec:ind}
\setcounter{equation}{0}

\textbf{Definition:} Generally speaking, random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) are statistically independent, if their joint probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) can be expressed in terms of their marginal probabilities ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}).

\vspace{1em}
1) A set of discrete random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X_1, \ldots, X_n$ with possible values $\mathcal{X}_1, \ldots, \mathcal{X}_n$ is called statistically independent, if

\begin{equation} \label{eq:ind-disc-ind}
p(X_1 = x_1, \ldots, X_n = x_n) = \prod_{i=1}^{n} p(X_i = x_i) \quad \text{for all} \; x_i \in \mathcal{X}_i, \; i = 1, \ldots, n
\end{equation}

where $p(x_1, \ldots, x_n)$ are the joint probabilities ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) of $X_1, \ldots, X_n$ and $p(x_i)$ are the marginal probabilities ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}) of $X_i$.

\vspace{1em}
2) A set of continuous random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X_1, \ldots, X_n$ defined on the domains $\mathcal{X}_1, \ldots, \mathcal{X}_n$ is called statistically independent, if

\begin{equation} \label{eq:ind-cont-ind-F}
F_{X_1,\ldots,X_n}(x_1,\ldots,x_n) = \prod_{i=1}^{n} F_{X_i}(x_i) \quad \text{for all} \; x_i \in \mathcal{X}_i, \; i = 1, \ldots, n
\end{equation}

or equivalently, if the probability densities ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) exist, if

\begin{equation} \label{eq:ind-cont-ind-f}
f_{X_1,\ldots,X_n}(x_1,\ldots,x_n) = \prod_{i=1}^{n} f_{X_i}(x_i) \quad \text{for all} \; x_i \in \mathcal{X}_i, \; i = 1, \ldots, n
\end{equation}

where $F$ are the joint ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-joint}) or marginal ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-marg}) cumulative distribution functions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) and $f$ are the respective probability density functions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Independence (probability theory)"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-06-06; URL: \url{https://en.wikipedia.org/wiki/Independence_(probability_theory)#Definition}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D75 | shortcut: ind | author: JoramSoch | date: 2020-06-06, 07:16.
\vspace{1em}



\subsubsection[\textit{Conditional independence}]{Conditional independence} \label{sec:ind-cond}
\setcounter{equation}{0}

\textbf{Definition:} Generally speaking, random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) are conditionally independent given another random variable, if they are statistically independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}) in their conditional probability distributions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-cond}) given this random variable.

\vspace{1em}
1) A set of discrete random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar-disc}) $X_1, \ldots, X_n$ with possible values $\mathcal{X}_1, \ldots, \mathcal{X}_n$ is called conditionally independent given the random variable $Y$ with possible values $\mathcal{Y}$, if

\begin{equation} \label{eq:ind-cond-disc-ind}
p(X_1 = x_1, \ldots, X_n = x_n|Y = y) = \prod_{i=1}^{n} p(X_i = x_i|Y = y) \quad \text{for all} \; x_i \in \mathcal{X}_i \quad \text{and all} \; y \in \mathcal{Y}
\end{equation}

where $p(x_1, \ldots, x_n \vert y)$ are the joint (conditional) probabilities ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) of $X_1, \ldots, X_n$ given $Y$ and $p(x_i)$ are the marginal (conditional) probabilities ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}) of $X_i$ given $Y$.

\vspace{1em}
2) A set of continuous random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar-disc}) $X_1, \ldots, X_n$ with possible values $\mathcal{X}_1, \ldots, \mathcal{X}_n$ is called conditionally independent given the random variable $Y$ with possible values $\mathcal{Y}$, if

\begin{equation} \label{eq:ind-cond-cond-ind-F}
F_{X_1,\ldots,X_n|Y=y}(x_1,\ldots,x_n) = \prod_{i=1}^{n} F_{X_i|Y=y}(x_i) \quad \text{for all} \; x_i \in \mathcal{X}_i \quad \text{and all} \; y \in \mathcal{Y}
\end{equation}

or equivalently, if the probability densities ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) exist, if

\begin{equation} \label{eq:ind-cond-cont-ind-f}
f_{X_1,\ldots,X_n|Y=y}(x_1,\ldots,x_n) = \prod_{i=1}^{n} f_{X_i|Y=y}(x_i) \quad \text{for all} \; x_i \in \mathcal{X}_i \quad \text{and all} \; y \in \mathcal{Y}
\end{equation}

where $F$ are the joint (conditional) ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-joint}) or marginal (conditional) ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-marg}) cumulative distribution functions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) and $f$ are the respective probability density functions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Conditional independence"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-11-19; URL: \url{https://en.wikipedia.org/wiki/Conditional_independence#Conditional_independence_of_random_variables}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D112 | shortcut: ind-cond | author: JoramSoch | date: 2020-11-19, 05:40.
\vspace{1em}



\subsubsection[\textbf{Probability under independence}]{Probability under independence} \label{sec:prob-ind}
\setcounter{equation}{0}

\textbf{Theorem:} Let $A$ and $B$ be two statements about random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}). Then, if $A$ and $B$ are independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}), marginal ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}) and conditional ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-cond}) probabilities are equal:

\begin{equation} \label{eq:prob-ind-prob-ind}
\begin{split}
p(A) &= p(A|B) \\
p(B) &= p(B|A) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Proof:} If $A$ and $B$ are independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}), then the joint probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) is equal to the product of the marginal probabilities ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}):

\begin{equation} \label{eq:prob-ind-ind}
p(A,B) = p(A) \cdot p(B) \; .
\end{equation}

The law of conditional probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-cond}) states that

\begin{equation} \label{eq:prob-ind-prob-cond}
p(A|B) = \frac{p(A,B)}{p(B)} \; .
\end{equation}

Combining \eqref{eq:prob-ind-ind} and \eqref{eq:prob-ind-prob-cond}, we have:

\begin{equation} \label{eq:prob-ind-prob-ind-qed-A}
p(A|B) = \frac{p(A) \cdot p(B)}{p(B)} = p(A) \; .
\end{equation}

Equivalently, we can write:

\begin{equation} \label{eq:prob-ind-prob-ind-qed-B}
p(B|A) \overset{\eqref{eq:prob-ind-prob-cond}}{=} \frac{p(A,B)}{p(A)} \overset{\eqref{eq:prob-ind-ind}}{=} \frac{p(A) \cdot p(B)}{p(A)} = p(B) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Independence (probability theory)"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-07-23; URL: \url{https://en.wikipedia.org/wiki/Independence_(probability_theory)#Definition}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P241 | shortcut: prob-ind | author: JoramSoch | date: 2021-07-23, 16:05.
\vspace{1em}



\subsubsection[\textit{Mutual exclusivity}]{Mutual exclusivity} \label{sec:exc}
\setcounter{equation}{0}

\textbf{Definition:} Generally speaking, random events ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:reve}) are mutually exclusive, if they cannot occur together, such that their intersection is equal to the empty set ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:prob-emp}).

\vspace{1em}
More precisely, a set of statements $A_1, \ldots, A_n$ is called mutually exclusive, if

\begin{equation} \label{eq:exc-exc}
p(A_1, \ldots, A_n) = 0
\end{equation}

where $p(A_1, \ldots, A_n)$ is the joint probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) of the statements $A_1, \ldots, A_n$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Mutual exclusivity"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-07-23; URL: \url{https://en.wikipedia.org/wiki/Mutual_exclusivity#Probability}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D156 | shortcut: exc | author: JoramSoch | date: 2021-07-23, 16:32.
\vspace{1em}



\subsubsection[\textbf{Probability under exclusivity}]{Probability under exclusivity} \label{sec:prob-exc}
\setcounter{equation}{0}

\textbf{Theorem:} Let $A$ and $B$ be two statements about random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}). Then, if $A$ and $B$ are mutually exclusive ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:exc}), the probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob}) of their disjunction is equal to the sum of the marginal probabilities ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}):

\begin{equation} \label{eq:prob-exc-prob-exc}
p(A \vee B) = p(A) + p(B) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} If $A$ and $B$ are mutually exclusive ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:exc}), then their joint probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) is zero:

\begin{equation} \label{eq:prob-exc-exc}
p(A,B) = 0 \; .
\end{equation}

The addition law of probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}) states that

\begin{equation} \label{eq:prob-exc-prob-add-set}
p(A \cup B) = p(A) + p(B) - p(A \cap B)
\end{equation}

which, in logical rather than set-theoretic expression, becomes

\begin{equation} \label{eq:prob-exc-prob-add-log}
p(A \vee B) = p(A) + p(B) - p(A,B) \; .
\end{equation}

Because the union of mutually exclusive events is the empty set ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:exc}) and the probability of the empty set is zero ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:prob-emp}), the joint probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) term cancels out:

\begin{equation} \label{eq:prob-exc-prob-exc-qed}
p(A \vee B) = p(A) + p(B) - p(A,B) \overset{\eqref{eq:prob-exc-exc}}{=} p(A) + p(B) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Mutual exclusivity"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-07-23; URL: \url{https://en.wikipedia.org/wiki/Mutual_exclusivity#Probability}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P242 | shortcut: prob-exc | author: JoramSoch | date: 2021-07-23, 17:19.
\vspace{1em}



\subsection{Probability axioms}

\subsubsection[\textit{Axioms of probability}]{Axioms of probability} \label{sec:prob-ax}
\setcounter{equation}{0}

\textbf{Definition:} Let there be a sample space ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:samp-spc}) $\Omega$, an event space ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:eve-spc}) $\mathcal{E}$ and a probability measure ($\rightarrow$ Definition "prob-meas") $P$, such that $P(E)$ is the probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob}) of some event ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:reve}) $E \in \mathcal{E}$. Then, we introduce three axioms of probability:

\begin{itemize}

\item First axiom: The probability of an event is a non-negative real number:

\end{itemize}

\begin{equation} \label{eq:prob-ax-prob-ax1}
P(E) \in \mathbb{R}, \; P(E) \geq 0, \; \text{for all } E \in \mathcal{E} \; .
\end{equation}

\begin{itemize}

\item Second axiom: The probability that at least one elementary event in the sample space will occur is one:

\end{itemize}

\begin{equation} \label{eq:prob-ax-prob-ax2}
P(\Omega) = 1 \; .
\end{equation}

\begin{itemize}

\item Third axiom: The probability of any countable sequence of disjoint (i.e. mutually exclusive ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:exc})) events $E_1, E_2, E_3, \ldots$ is equal to the sum of the probabilities of the individual events:

\end{itemize}

\begin{equation} \label{eq:prob-ax-prob-ax3}
P\left(\bigcup_{i=1}^\infty E_i \right) = \sum_{i=1}^\infty P(E_i) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item A.N. Kolmogorov (1950): "Elementary Theory of Probability"; in: \textit{Foundations of the Theory of Probability}, p. 2; URL: \url{https://archive.org/details/foundationsofthe00kolm/page/2/mode/2up}.
\item Alan Stuart \& J. Keith Ord (1994): "Probability and Statistical Inference"; in: \textit{Kendall's Advanced Theory of Statistics, Vol. 1: Distribution Theory}, ch. 8.6, p. 288, eqs. 8.2-8.4; URL: \url{https://www.wiley.com/en-us/Kendall%27s+Advanced+Theory+of+Statistics%2C+3+Volumes%2C+Set%2C+6th+Edition-p-9780470669549}.
\item Wikipedia (2021): "Probability axioms"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-07-30; URL: \url{https://en.wikipedia.org/wiki/Probability_axioms#Axioms}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D158 | shortcut: prob-ax | author: JoramSoch | date: 2021-07-30, 11:11.
\vspace{1em}



\subsubsection[\textbf{Monotonicity of probability}]{Monotonicity of probability} \label{sec:prob-mon}
\setcounter{equation}{0}

\textbf{Theorem:} Probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob}) is monotonic, i.e. if $A$ is a subset of or equal to  $B$, then the probability of $A$ is smaller than or equal to $B$:

\begin{equation} \label{eq:prob-mon-prob-mon}
A \subseteq B \quad \Rightarrow \quad P(A) \leq P(B) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} Set $E_1 = A$, $E_2 = B \setminus A$ and $E_i = \emptyset$ for $i \geq 3$. Then, the sets $E_i$ are pairwise disjoint and $E_1 \cup E_2 \cup \ldots = B$, because $A \subseteq B$. Thus, from the third axiom of probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-ax}), we have:

\begin{equation} \label{eq:prob-mon-pB}
P(B) = P(A) + P(B \setminus A) + \sum_{i=3}^\infty P(E_i) \; .
\end{equation}

Since, by the first axiom of probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-ax}), the right-hand side is a series of non-negative numbers converging to $P(B)$ on the left-hand side, it follows that

\begin{equation} \label{eq:prob-mon-prob-mon-qed}
P(A) \leq P(B) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item A.N. Kolmogorov (1950): "Elementary Theory of Probability"; in: \textit{Foundations of the Theory of Probability}, p. 6; URL: \url{https://archive.org/details/foundationsofthe00kolm/page/6/mode/2up}.
\item Alan Stuart \& J. Keith Ord (1994): "Probability and Statistical Inference"; in: \textit{Kendall's Advanced Theory of Statistics, Vol. 1: Distribution Theory}, pp. 288-289; URL: \url{https://www.wiley.com/en-us/Kendall%27s+Advanced+Theory+of+Statistics%2C+3+Volumes%2C+Set%2C+6th+Edition-p-9780470669549}.
\item Wikipedia (2021): "Probability axioms"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-07-30; URL: \url{https://en.wikipedia.org/wiki/Probability_axioms#Monotonicity}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P243 | shortcut: prob-mon | author: JoramSoch | date: 2021-07-30, 11:37.
\vspace{1em}



\subsubsection[\textbf{Probability of the empty set}]{Probability of the empty set} \label{sec:prob-emp}
\setcounter{equation}{0}

\textbf{Theorem:} The probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob}) of the empty set is zero:

\begin{equation} \label{eq:prob-emp-prob-emp}
P(\emptyset) = 0 \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} Assume that the probability of the empty set is not zero, i.e. $P(\emptyset) > 0$. Then, in an equation derived when proving that probability is monotonic ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:prob-mon}),

\begin{equation} \label{eq:prob-emp-pB}
P(B) = P(A) + P(B \setminus A) + \sum_{i=3}^\infty P(E_i) \quad \text{where} \quad E_i = \emptyset \quad \text{for} \quad i \geq 3 \; ,
\end{equation}

the right-hand side would be infinite. However, by the first axiom of probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-ax}), the left-hand side must be finite. This is a contradiction. Therefore, $P(\emptyset) = 0$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item A.N. Kolmogorov (1950): "Elementary Theory of Probability"; in: \textit{Foundations of the Theory of Probability}, p. 6, eq. 3; URL: \url{https://archive.org/details/foundationsofthe00kolm/page/6/mode/2up}.
\item Alan Stuart \& J. Keith Ord (1994): "Probability and Statistical Inference"; in: \textit{Kendall's Advanced Theory of Statistics, Vol. 1: Distribution Theory}, ch. 8.6, p. 288, eq. (b); URL: \url{https://www.wiley.com/en-us/Kendall%27s+Advanced+Theory+of+Statistics%2C+3+Volumes%2C+Set%2C+6th+Edition-p-9780470669549}.
\item Wikipedia (2021): "Probability axioms"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-07-30; URL: \url{https://en.wikipedia.org/wiki/Probability_axioms#The_probability_of_the_empty_set}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P244 | shortcut: prob-emp | author: JoramSoch | date: 2021-07-30, 11:58.
\vspace{1em}



\subsubsection[\textbf{Probability of the complement}]{Probability of the complement} \label{sec:prob-comp}
\setcounter{equation}{0}

\textbf{Theorem:} The probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob}) of a complement of a set is one minus the probability of this set:

\begin{equation} \label{eq:prob-comp-prob-comp}
P(A^\mathrm{c}) = 1 - P(A)
\end{equation}

where $A^\mathrm{c} = \Omega \setminus A$ and $\Omega$ is the sample space ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:samp-spc}).


\vspace{1em}
\textbf{Proof:} Since $A$ and $A^\mathrm{c}$ are mutually exclusive ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:exc}) and $A \cup A^\mathrm{c} = \Omega$, the third axiom of probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-ax}) implies:

\begin{equation} \label{eq:prob-comp-pAAc}
\begin{split}
P(A \cup A^\mathrm{c}) &= P(A) + P(A^\mathrm{c}) \\
P(\Omega) &= P(A) + P(A^\mathrm{c}) \\
P(A^\mathrm{c}) &= P(\Omega) - P(A) \; .
\end{split}
\end{equation}

The second axiom of probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-ax}) states that $P(\Omega) =1$, such that we obtain:

\begin{equation} \label{eq:prob-comp-prob-comp-qed}
P(A^\mathrm{c}) = 1 - P(A) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item A.N. Kolmogorov (1950): "Elementary Theory of Probability"; in: \textit{Foundations of the Theory of Probability}, p. 6, eq. 2; URL: \url{https://archive.org/details/foundationsofthe00kolm/page/6/mode/2up}.
\item Alan Stuart \& J. Keith Ord (1994): "Probability and Statistical Inference"; in: \textit{Kendall's Advanced Theory of Statistics, Vol. 1: Distribution Theory}, ch. 8.6, p. 288, eq. (c); URL: \url{https://www.wiley.com/en-us/Kendall%27s+Advanced+Theory+of+Statistics%2C+3+Volumes%2C+Set%2C+6th+Edition-p-9780470669549}.
\item Wikipedia (2021): "Probability axioms"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-07-30; URL: \url{https://en.wikipedia.org/wiki/Probability_axioms#The_complement_rule}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P245 | shortcut: prob-comp | author: JoramSoch | date: 2021-07-30, 12:14.
\vspace{1em}



\subsubsection[\textbf{Range of probability}]{Range of probability} \label{sec:prob-range}
\setcounter{equation}{0}

\textbf{Theorem:} The probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob}) of an event is bounded between 0 and 1:

\begin{equation} \label{eq:prob-range-prob-range}
0 \leq P(E) \leq 1 \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} From the first axiom of probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-ax}), we have:

\begin{equation} \label{eq:prob-range-pEg0}
P(E) \geq 0 \; .
\end{equation}

By combining the first axiom of probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-ax}) and the probability of the complement ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:prob-comp}), we obtain:

\begin{equation} \label{eq:prob-range-pEl1}
\begin{split}
1- P(E) = P(E^\mathrm{c}) &\geq 0 \\
1- P(E) &\geq 0 \\
P(E) &\leq 1 \; .
\end{split}
\end{equation}

Together, \eqref{eq:prob-range-pEg0} and \eqref{eq:prob-range-pEl1} imply that

\begin{equation} \label{eq:prob-range-prob-range-qed}
0 \leq P(E) \leq 1 \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item A.N. Kolmogorov (1950): "Elementary Theory of Probability"; in: \textit{Foundations of the Theory of Probability}, p. 6; URL: \url{https://archive.org/details/foundationsofthe00kolm/page/6/mode/2up}.
\item Alan Stuart \& J. Keith Ord (1994): "Probability and Statistical Inference"; in: \textit{Kendall's Advanced Theory of Statistics, Vol. 1: Distribution Theory}, pp. 288-289; URL: \url{https://www.wiley.com/en-us/Kendall%27s+Advanced+Theory+of+Statistics%2C+3+Volumes%2C+Set%2C+6th+Edition-p-9780470669549}.
\item Wikipedia (2021): "Probability axioms"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-07-30; URL: \url{https://en.wikipedia.org/wiki/Probability_axioms#The_numeric_bound}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P246 | shortcut: prob-range | author: JoramSoch | date: 2021-07-30, 12:25.
\vspace{1em}



\subsubsection[\textbf{Addition law of probability}]{Addition law of probability} \label{sec:prob-add}
\setcounter{equation}{0}

\textbf{Theorem:} The probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob}) of the union of $A$ and $B$ is the sum of the probabilities of $A$ and $B$ minus the probability of the intersection of $A$ and $B$:

\begin{equation} \label{eq:prob-add-prob-add}
P(A \cup B) = P(A) + P(B) - P(A \cap B) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} Let $E_1 = A$ and $E_2 = B \setminus A$, such that $E_1 \cup E_2 = A \cup B$. Then, by the third axiom of probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-ax}), we have:

\begin{equation} \label{eq:prob-add-pAoB}
\begin{split}
P(A \cup B) &= P(A) + P(B \setminus A) \\
P(A \cup B) &= P(A) + P(B \setminus [A \cap B]) \; .
\end{split}
\end{equation}

Then, let $E_1 = B \setminus [A \cap B]$ and $E_2 = A \cap B$, such that $E_1 \cup E_2 = B$. Again, from the third axiom of probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-ax}), we obtain:

\begin{equation} \label{eq:prob-add-pB}
\begin{split}
P(B) &= P(B \setminus [A \cap B]) + P(A \cap B) \\
P(B \setminus [A \cap B]) &= P(B) - P(A \cap B) \; .
\end{split}
\end{equation}

Plugging \eqref{eq:prob-add-pB} into \eqref{eq:prob-add-pAoB}, we finally get:

\begin{equation} \label{eq:prob-add-prob-add-qed}
P(A \cup B) = P(A) + P(B) - P(A \cap B) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item A.N. Kolmogorov (1950): "Elementary Theory of Probability"; in: \textit{Foundations of the Theory of Probability}, p. 2; URL: \url{https://archive.org/details/foundationsofthe00kolm/page/2/mode/2up}.
\item Alan Stuart \& J. Keith Ord (1994): "Probability and Statistical Inference"; in: \textit{Kendall's Advanced Theory of Statistics, Vol. 1: Distribution Theory}, ch. 8.6, p. 288, eq. (a); URL: \url{https://www.wiley.com/en-us/Kendall%27s+Advanced+Theory+of+Statistics%2C+3+Volumes%2C+Set%2C+6th+Edition-p-9780470669549}.
\item Wikipedia (2021): "Probability axioms"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-07-30; URL: \url{https://en.wikipedia.org/wiki/Probability_axioms#Further_consequences}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P247 | shortcut: prob-add | author: JoramSoch | date: 2021-07-30, 12:45.
\vspace{1em}



\subsubsection[\textbf{Law of total probability}]{Law of total probability} \label{sec:prob-tot}
\setcounter{equation}{0}

\textbf{Theorem:} Let $A$ be a subset of sample space ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:samp-spc}) $\Omega$ and let $B_1, \ldots, B_n$ be finite or countably infinite partition of $\Omega$, such that $B_i \cap B_j = \emptyset$ for all $i \neq j$ and $\cup_i \, B_i = \Omega$. Then, the probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob}) of the event $A$ is

\begin{equation} \label{eq:prob-tot-prob-tot}
P(A) = \sum_i P(A \cap B_i) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} Because all $B_i$ are disjoint, sets $(A \cap B_i)$ are also disjoint:

\begin{equation} \label{eq:prob-tot-B-disjoint}
B_i \cap B_j = \emptyset \quad \Rightarrow \quad (A \cap B_i) \cap (A \cap B_j) = A \cap (B_i \cap B_j) = A \cap \emptyset = \emptyset \; .
\end{equation}

Because the $B_i$ are exhaustive, the sets $(A \cap B_i)$ are also exhaustive:

\begin{equation} \label{eq:prob-tot-B-exhaustive}
\cup_i \, B_i = \Omega \quad \Rightarrow \quad \cup_i \, (A \cap B_i) = A \cap \left( \cup_i \, B_i \right) = A \cap \Omega = A \; .
\end{equation}

Thus, the third axiom of probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-ax}) implies that

\begin{equation} \label{eq:prob-tot-prob-tot-qed}
P(A) = \sum_i P(A \cap B_i) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Alan Stuart \& J. Keith Ord (1994): "Probability and Statistical Inference"; in: \textit{Kendall's Advanced Theory of Statistics, Vol. 1: Distribution Theory}, p. 288, eq. (d); p. 289, eq. 8.7; URL: \url{https://www.wiley.com/en-us/Kendall%27s+Advanced+Theory+of+Statistics%2C+3+Volumes%2C+Set%2C+6th+Edition-p-9780470669549}.
\item Alan Stuart \& J. Keith Ord (1994): "Probability and Statistical Inference"; in: \textit{Kendall's Advanced Theory of Statistics, Vol. 1: Distribution Theory}, ch. 8.6, p. 289, eq. 8.7; URL: \url{https://www.wiley.com/en-us/Kendall%27s+Advanced+Theory+of+Statistics%2C+3+Volumes%2C+Set%2C+6th+Edition-p-9780470669549}.
\item Wikipedia (2021): "Law of total probability"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-08-08; URL: \url{https://en.wikipedia.org/wiki/Law_of_total_probability#Statement}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P248 | shortcut: prob-tot | author: JoramSoch | date: 2021-08-08, 03:56.
\vspace{1em}



\subsubsection[\textbf{Probability of exhaustive events}]{Probability of exhaustive events} \label{sec:prob-exh}
\setcounter{equation}{0}

\textbf{Theorem:} Let $B_1, \ldots, B_n$ be mutually exclusive and collectively exhaustive subsets of a sample space ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:samp-spc}) $\Omega$. Then, their total probability ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:prob-tot}) is one:

\begin{equation} \label{eq:prob-exh-prob-exh}
\sum_i P(B_i) = 1 \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} Because all $B_i$ are mutually exclusive, we have:

\begin{equation} \label{eq:prob-exh-B-exclusive}
B_i \cap B_j = \emptyset \quad \text{for all} \quad i \neq j \; .
\end{equation}

Because the $B_i$ are collectively exhaustive, we have:

\begin{equation} \label{eq:prob-exh-B-exhaustive}
\cup_i \, B_i = \Omega \; .
\end{equation}

Thus, the third axiom of probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-ax}) implies that

\begin{equation} \label{eq:prob-exh-prob-exh-s1}
\sum_i P(B_i) = P(\Omega) \; .
\end{equation}

and the second axiom of probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-ax}) implies that

\begin{equation} \label{eq:prob-exh-prob-exh-s2}
\sum_i P(B_i) = 1 \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Alan Stuart \& J. Keith Ord (1994): "Probability and Statistical Inference"; in: \textit{Kendall's Advanced Theory of Statistics, Vol. 1: Distribution Theory}, pp. 288-289; URL: \url{https://www.wiley.com/en-us/Kendall%27s+Advanced+Theory+of+Statistics%2C+3+Volumes%2C+Set%2C+6th+Edition-p-9780470669549}.
\item Wikipedia (2021): "Probability axioms"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-08-08; URL: \url{https://en.wikipedia.org/wiki/Probability_axioms#Axioms}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P249 | shortcut: prob-exh | author: JoramSoch | date: 2021-08-08, 04:10.
\vspace{1em}



\subsection{Probability distributions}

\subsubsection[\textit{Probability distribution}]{Probability distribution} \label{sec:dist}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with the set of possible outcomes $\mathcal{X}$. Then, a probability distribution of $X$ is a mathematical function that gives the probabilities ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob}) of occurrence of all possible outcomes $x \in \mathcal{X}$ of this random variable.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Probability distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-05-17; URL: \url{https://en.wikipedia.org/wiki/Probability_distribution}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D55 | shortcut: dist | author: JoramSoch | date: 2020-05-17, 20:23.
\vspace{1em}



\subsubsection[\textit{Joint distribution}]{Joint distribution} \label{sec:dist-joint}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ and $Y$ be random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with sets of possible outcomes $\mathcal{X}$ and $\mathcal{Y}$. Then, a joint distribution of $X$ and $Y$ is a probability distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist}) that specifies the probability of the event that $X = x$ and $Y = y$ for each possible combination of $x \in \mathcal{X}$ and $y \in \mathcal{Y}$.

\begin{itemize}

\item The joint distribution of two scalar random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) is called a bivariate distribution.

\item The joint distribution of a random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}) is called a multivariate distribution.

\item The joint distribution of a random matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rmat}) is called a matrix-variate distribution.

\end{itemize}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Joint probability distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-05-17; URL: \url{https://en.wikipedia.org/wiki/Joint_probability_distribution}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D56 | shortcut: dist-joint | author: JoramSoch | date: 2020-05-17, 20:43.
\vspace{1em}



\subsubsection[\textit{Marginal distribution}]{Marginal distribution} \label{sec:dist-marg}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ and $Y$ be random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with sets of possible outcomes $\mathcal{X}$ and $\mathcal{Y}$. Then, the marginal distribution of $X$ is a probability distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist}) that specifies the probability of the event that $X = x$ irrespective of the value of $Y$ for each possible value $x \in \mathcal{X}$. The marginal distribution can be obtained from the joint distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-joint}) of $X$ and $Y$ using the law of marginal probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Marginal distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-05-17; URL: \url{https://en.wikipedia.org/wiki/Marginal_distribution}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D57 | shortcut: dist-marg | author: JoramSoch | date: 2020-05-17, 21:02.
\vspace{1em}



\subsubsection[\textit{Conditional distribution}]{Conditional distribution} \label{sec:dist-cond}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ and $Y$ be random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with sets of possible outcomes $\mathcal{X}$ and $\mathcal{Y}$. Then, the conditional distribution of $X$ given that $Y$ is a probability distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist}) that specifies the probability of the event that $X = x$ given that $Y = y$ for each possible combination of $x \in \mathcal{X}$ and $y \in \mathcal{Y}$. The conditional distribution of $X$ can be obtained from the joint distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-joint}) of $X$ and $Y$ and the marginal distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-marg}) of $Y$ using the law of conditional probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-cond}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Conditional probability distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-05-17; URL: \url{https://en.wikipedia.org/wiki/Conditional_probability_distribution}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D58 | shortcut: dist-cond | author: JoramSoch | date: 2020-05-17, 21:25.
\vspace{1em}



\subsubsection[\textit{Sampling distribution}]{Sampling distribution} \label{sec:dist-samp}
\setcounter{equation}{0}

\textbf{Definition:} Let there be a random sample ($\rightarrow$ Definition "samp") with finite sample size ($\rightarrow$ Definition "samp-size"). Then, the probability distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist}) of a given statistic ($\rightarrow$ Definition "stat") computed from this sample, e.g. a test statistic ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:tstat}), is called a sampling distribution.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Sampling distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-03-31; URL: \url{https://en.wikipedia.org/wiki/Sampling_distribution}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D140 | shortcut: dist-samp | author: JoramSoch | date: 2021-03-31, 09:43.
\vspace{1em}



\subsection{Probability functions}

\subsubsection[\textit{Probability mass function}]{Probability mass function} \label{sec:pmf}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a discrete ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar-disc}) random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with possible outcomes $\mathcal{X}$. Then, $f_X(x): \mathbb{R} \to [0,1]$ is the probability mass function (PMF) of $X$, if

\begin{equation} \label{eq:pmf-pmf-def-s0}
f_X(x) = 0
\end{equation}

for all $x \notin \mathcal{X}$,

\begin{equation} \label{eq:pmf-pmf-def-s1}
\mathrm{Pr}(X = x) = f_X(x)
\end{equation}

for all $x \in \mathcal{X}$ and

\begin{equation} \label{eq:pmf-pmf-def-s2}
\sum_{x \in \mathcal{X}} f_X(x) = 1 \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Probability mass function"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-02-13; URL: \url{https://en.wikipedia.org/wiki/Probability_mass_function}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D9 | shortcut: pmf | author: JoramSoch | date: 2020-02-13, 19:09.
\vspace{1em}



\subsubsection[\textbf{Probability mass function of sum of independents}]{Probability mass function of sum of independents} \label{sec:pmf-sumind}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ and $Y$ be two independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}) discrete ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar-disc}) random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with possible values $\mathcal{X}$ and $\mathcal{Y}$ and let $Z = X + Y$. Then, the probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) of $Z$ is given by

\begin{equation} \label{eq:pmf-sumind-pmf-sumind}
\begin{split}
f_Z(z) &= \sum_{y \in \mathcal{Y}} f_X(z-y) f_Y(y)  \\
\text{or} \quad f_Z(z) &= \sum_{x \in \mathcal{X}} f_Y(z-x) f_X(x)
\end{split}
\end{equation}

where $f_X(x)$, $f_Y(y)$ and $f_Z(z)$ are the probability mass functions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) of $X$, $Y$ and $Z$.


\vspace{1em}
\textbf{Proof:} Using the definition of the probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) and the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}), the first equation can be derived as follows:

\begin{equation} \label{eq:pmf-sumind-pmf-sumind-qed}
\begin{split}
f_Z(z) &= \mathrm{Pr}(Z = z) \\
&= \mathrm{Pr}(X + Y = z) \\
&= \mathrm{Pr}(X = z - Y) \\
&= \mathrm{E} \left[ \mathrm{Pr}(X = z - Y \vert Y = y) \right] \\
&= \mathrm{E} \left[ \mathrm{Pr}(X = z - Y) \right] \\
&= \mathrm{E} \left[ f_X(z-Y) \right] \\
&= \sum_{y \in \mathcal{Y}} f_X(z-y) f_Y(y) \; .
\end{split}
\end{equation}

Note that the third-last transition is justified by the fact that $X$ and $Y$ are independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}), such that conditional probabilities are equal to marginal probabilities ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:prob-ind}). The second equation can be derived by switching $X$ and $Y$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Taboga, Marco (2017): "Sums of independent random variables"; in: \textit{Lectures on probability and mathematical statistics}, retrieved on 2021-08-30; URL: \url{https://www.statlect.com/fundamentals-of-probability/sums-of-independent-random-variables}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P257 | shortcut: pmf-sumind | author: JoramSoch | date: 2021-08-30, 09:14.
\vspace{1em}



\subsubsection[\textbf{Probability mass function of strictly increasing function}]{Probability mass function of strictly increasing function} \label{sec:pmf-sifct}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a discrete ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar-disc}) random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with possible outcomes $\mathcal{X}$ and let $g(x)$ be a strictly increasing function on the support of $X$. Then, the probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) of $Y = g(X)$ is given by

\begin{equation} \label{eq:pmf-sifct-pmf-sifct}
f_Y(y) = \left\{
\begin{array}{rl}
f_X(g^{-1}(y)) \; , & \text{if} \; y \in \mathcal{Y} \\
0 \; , & \text{if} \; y \notin \mathcal{Y}
\end{array}
\right.
\end{equation}

where $g^{-1}(y)$ is the inverse function of $g(x)$ and $\mathcal{Y}$ is the set of possible outcomes of $Y$:

\begin{equation} \label{eq:pmf-sifct-Y-range}
\mathcal{Y} = \left\lbrace y = g(x): x \in \mathcal{X} \right\rbrace \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} Because a strictly increasing function is invertible, the probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) of $Y$ can be derived as follows:

\begin{equation} \label{eq:pmf-sifct-pmf-sifct-qed}
\begin{split}
f_Y(y) &= \mathrm{Pr}(Y = y) \\
&= \mathrm{Pr}(g(X) = y) \\
&= \mathrm{Pr}(X = g^{-1}(y)) \\
&= f_X(g^{-1}(y)) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Taboga, Marco (2017): "Functions of random variables and their distribution"; in: \textit{Lectures on probability and mathematical statistics}, retrieved on 2020-10-29; URL: \url{https://www.statlect.com/fundamentals-of-probability/functions-of-random-variables-and-their-distribution#hid3}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P184 | shortcut: pmf-sifct | author: JoramSoch | date: 2020-10-29, 05:55.
\vspace{1em}



\subsubsection[\textbf{Probability mass function of strictly decreasing function}]{Probability mass function of strictly decreasing function} \label{sec:pmf-sdfct}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a discrete ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar-disc}) random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with possible outcomes $\mathcal{X}$ and let $g(x)$ be a strictly decreasing function on the support of $X$. Then, the probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) of $Y = g(X)$ is given by

\begin{equation} \label{eq:pmf-sdfct-pmf-sdfct}
f_Y(y) = \left\{
\begin{array}{rl}
f_X(g^{-1}(y)) \; , & \text{if} \; y \in \mathcal{Y} \\
0 \; , & \text{if} \; y \notin \mathcal{Y}
\end{array}
\right.
\end{equation}

where $g^{-1}(y)$ is the inverse function of $g(x)$ and $\mathcal{Y}$ is the set of possible outcomes of $Y$:

\begin{equation} \label{eq:pmf-sdfct-Y-range}
\mathcal{Y} = \left\lbrace y = g(x): x \in \mathcal{X} \right\rbrace \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} Because a strictly decreasing function is invertible, the probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) of $Y$ can be derived as follows:

\begin{equation} \label{eq:pmf-sdfct-pmf-sdfct-qed}
\begin{split}
f_Y(y) &= \mathrm{Pr}(Y = y) \\
&= \mathrm{Pr}(g(X) = y) \\
&= \mathrm{Pr}(X = g^{-1}(y)) \\
&= f_X(g^{-1}(y)) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Taboga, Marco (2017): "Functions of random variables and their distribution"; in: \textit{Lectures on probability and mathematical statistics}, retrieved on 2020-11-06; URL: \url{https://www.statlect.com/fundamentals-of-probability/functions-of-random-variables-and-their-distribution#hid6}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P187 | shortcut: pmf-sdfct | author: JoramSoch | date: 2020-11-06, 04:21.
\vspace{1em}



\subsubsection[\textbf{Probability mass function of invertible function}]{Probability mass function of invertible function} \label{sec:pmf-invfct}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be an $n \times 1$ random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}) of discrete random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar-disc}) with possible outcomes $\mathcal{X}$ and let $g: \; \mathbb{R}^n \rightarrow \mathbb{R}^n$ be an invertible function on the support of $X$. Then, the probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) of $Y = g(X)$ is given by

\begin{equation} \label{eq:pmf-invfct-pmf-invfct}
f_Y(y) = \left\{
\begin{array}{rl}
f_X(g^{-1}(y)) \; , & \text{if} \; y \in \mathcal{Y} \\
0 \; , & \text{if} \; y \notin \mathcal{Y}
\end{array}
\right.
\end{equation}

where $g^{-1}(y)$ is the inverse function of $g(x)$ and $\mathcal{Y}$ is the set of possible outcomes of $Y$:

\begin{equation} \label{eq:pmf-invfct-Y-range}
\mathcal{Y} = \left\lbrace y = g(x): x \in \mathcal{X} \right\rbrace \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} Because an invertible function is a one-to-one mapping, the probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) of $Y$ can be derived as follows:

\begin{equation} \label{eq:pmf-invfct-pmf-invfct-qed}
\begin{split}
f_Y(y) &= \mathrm{Pr}(Y = y) \\
&= \mathrm{Pr}(g(X) = y) \\
&= \mathrm{Pr}(X = g^{-1}(y)) \\
&= f_X(g^{-1}(y)) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Taboga, Marco (2017): "Functions of random vectors and their distribution"; in: \textit{Lectures on probability and mathematical statistics}, retrieved on 2021-08-30; URL: \url{https://www.statlect.com/fundamentals-of-probability/functions-of-random-vectors}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P253 | shortcut: pmf-invfct | author: JoramSoch | date: 2021-08-30, 05:13.
\vspace{1em}



\subsubsection[\textit{Probability density function}]{Probability density function} \label{sec:pdf}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a continuous ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar-disc}) random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with possible outcomes $\mathcal{X}$. Then, $f_X(x): \mathbb{R} \to \mathbb{R}$ is the probability density function (PDF) of $X$, if

\begin{equation} \label{eq:pdf-pdf-def-s0}
f_X(x) \geq 0
\end{equation}

for all $x \in \mathbb{R}$,

\begin{equation} \label{eq:pdf-pdf-def-s1}
\mathrm{Pr}(X \in A) = \int_{A} f_X(x) \, \mathrm{d}x
\end{equation}

for any $A \subset \mathcal{X}$ and

\begin{equation} \label{eq:pdf-pdf-def-s2}
\int_{\mathcal{X}} f_X(x) \, \mathrm{d}x = 1 \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Probability density function"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-02-13; URL: \url{https://en.wikipedia.org/wiki/Probability_density_function}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D10 | shortcut: pdf | author: JoramSoch | date: 2020-02-13, 19:26.
\vspace{1em}



\subsubsection[\textbf{Probability density function of sum of independents}]{Probability density function of sum of independents} \label{sec:pdf-sumind}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ and $Y$ be two independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}) continuous ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar-disc}) random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with possible values $\mathcal{X}$ and $\mathcal{Y}$ and let $Z = X + Y$. Then, the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $Z$ is given by

\begin{equation} \label{eq:pdf-sumind-pdf-sumind}
\begin{split}
f_Z(z) &= \int_{-\infty}^{+\infty} f_X(z-y) f_Y(y) \, \mathrm{d}y \\
\text{or} \quad f_Z(z) &= \int_{-\infty}^{+\infty} f_Y(z-x) f_X(x) \, \mathrm{d}x
\end{split}
\end{equation}

where $f_X(x)$, $f_Y(y)$ and $f_Z(z)$ are the probability density functions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $X$, $Y$ and $Z$.


\vspace{1em}
\textbf{Proof:} The cumulative distribution function of a sum of independent random variables ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:cdf-sumind}) is

\begin{equation} \label{eq:pdf-sumind-cdf-sumind}
F_Z(z) = \mathrm{E}\left[ F_X(z-Y) \right] \; .
\end{equation}

The probability density function is the first derivative of the cumulative distribution function ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:pdf-cdf}), such that

\begin{equation} \label{eq:pdf-sumind-pdf-sumind-qed}
\begin{split}
f_Z(z) &= \frac{\mathrm{d}}{\mathrm{d}z} F_Z(z) \\
&= \frac{\mathrm{d}}{\mathrm{d}z} \mathrm{E}\left[ F_X(z-Y) \right] \\
&= \mathrm{E}\left[ \frac{\mathrm{d}}{\mathrm{d}z} F_X(z-Y) \right] \\
&= \mathrm{E}\left[ f_X(z-Y) \right] \\
&= \int_{-\infty}^{+\infty} f_X(z-y) f_Y(y) \, \mathrm{d}y \; .
\end{split}
\end{equation}

The second equation can be derived by switching $X$ and $Y$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Taboga, Marco (2017): "Sums of independent random variables"; in: \textit{Lectures on probability and mathematical statistics}, retrieved on 2021-08-30; URL: \url{https://www.statlect.com/fundamentals-of-probability/sums-of-independent-random-variables}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P258 | shortcut: pdf-sumind | author: JoramSoch | date: 2021-08-30, 09:31.
\vspace{1em}



\subsubsection[\textbf{Probability density function of strictly increasing function}]{Probability density function of strictly increasing function} \label{sec:pdf-sifct}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a continuous ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar-disc}) random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with possible outcomes $\mathcal{X}$ and let $g(x)$ be a strictly increasing function on the support of $X$. Then, the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $Y = g(X)$ is given by

\begin{equation} \label{eq:pdf-sifct-pdf-sifct}
f_Y(y) = \left\{
\begin{array}{rl}
f_X(g^{-1}(y)) \, \frac{\mathrm{d}g^{-1}(y)}{\mathrm{d}y} \; , & \text{if} \; y \in \mathcal{Y} \\
0 \; , & \text{if} \; y \notin \mathcal{Y}
\end{array}
\right.
\end{equation}

where $g^{-1}(y)$ is the inverse function of $g(x)$ and $\mathcal{Y}$ is the set of possible outcomes of $Y$:

\begin{equation} \label{eq:pdf-sifct-Y-range}
\mathcal{Y} = \left\lbrace y = g(x): x \in \mathcal{X} \right\rbrace \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The cumulative distribution function of a strictly increasing function ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:cdf-sifct}) is

\begin{equation} \label{eq:pdf-sifct-cdf-sifct}
F_Y(y) = \left\{
\begin{array}{rl}
0 \; , & \text{if} \; y < \mathrm{min}(\mathcal{Y}) \\
F_X(g^{-1}(y)) \; , & \text{if} \; y \in \mathcal{Y} \\
1 \; , & \text{if} \; y > \mathrm{max}(\mathcal{Y})
\end{array}
\right.
\end{equation}

Because the probability density function is the first derivative of the cumulative distribution function ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:pdf-cdf})

\begin{equation} \label{eq:pdf-sifct-pdf-cdf}
f_X(x) = \frac{\mathrm{d}F_X(x)}{\mathrm{d}x} \; ,
\end{equation}

the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $Y$ can be derived as follows:

1) If $y$ does not belong to the support of $Y$, $F_Y(y)$ is constant, such that

\begin{equation} \label{eq:pdf-sifct-pdf-sifct-p1}
f_Y(y) = 0, \quad \text{if} \quad y \notin \mathcal{Y} \; .
\end{equation}

2) If $y$ belongs to the support of $Y$, then $f_Y(y)$ can be derived using the chain rule:

\begin{equation} \label{eq:pdf-sifct-pdf-sifct-p2}
\begin{split}
f_Y(y) &\overset{\eqref{eq:pdf-sifct-pdf-cdf}}{=} \frac{\mathrm{d}}{\mathrm{d}y} F_Y(y) \\
&\overset{\eqref{eq:pdf-sifct-cdf-sifct}}{=} \frac{\mathrm{d}}{\mathrm{d}y} F_X(g^{-1}(y)) \\
&= f_X(g^{-1}(y)) \, \frac{\mathrm{d}g^{-1}(y)}{\mathrm{d}y} \; .
\end{split}
\end{equation}

Taking together \eqref{eq:pdf-sifct-pdf-sifct-p1} and \eqref{eq:pdf-sifct-pdf-sifct-p2}, eventually proves \eqref{eq:pdf-sifct-pdf-sifct}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Taboga, Marco (2017): "Functions of random variables and their distribution"; in: \textit{Lectures on probability and mathematical statistics}, retrieved on 2020-10-29; URL: \url{https://www.statlect.com/fundamentals-of-probability/functions-of-random-variables-and-their-distribution#hid4}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P185 | shortcut: pdf-sifct | author: JoramSoch | date: 2020-10-29, 06:21.
\vspace{1em}



\subsubsection[\textbf{Probability density function of strictly decreasing function}]{Probability density function of strictly decreasing function} \label{sec:pdf-sdfct}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a continuous ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar-disc}) random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with possible outcomes $\mathcal{X}$ and let $g(x)$ be a strictly decreasing function on the support of $X$. Then, the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $Y = g(X)$ is given by

\begin{equation} \label{eq:pdf-sdfct-pdf-sdfct}
f_Y(y) = \left\{
\begin{array}{rl}
-f_X(g^{-1}(y)) \, \frac{\mathrm{d}g^{-1}(y)}{\mathrm{d}y} \; , & \text{if} \; y \in \mathcal{Y} \\
0 \; , & \text{if} \; y \notin \mathcal{Y}
\end{array}
\right.
\end{equation}

where $g^{-1}(y)$ is the inverse function of $g(x)$ and $\mathcal{Y}$ is the set of possible outcomes of $Y$:

\begin{equation} \label{eq:pdf-sdfct-Y-range}
\mathcal{Y} = \left\lbrace y = g(x): x \in \mathcal{X} \right\rbrace \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The cumulative distribution function of a strictly decreasing function ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:cdf-sifct}) is

\begin{equation} \label{eq:pdf-sdfct-cdf-sdfct}
F_Y(y) = \left\{
\begin{array}{rl}
1 \; , & \text{if} \; y > \mathrm{max}(\mathcal{Y}) \\
1 - F_X(g^{-1}(y)) + \mathrm{Pr}(X = g^{-1}(y)) \; , & \text{if} \; y \in \mathcal{Y} \\
0 \; , & \text{if} \; y < \mathrm{min}(\mathcal{Y})
\end{array}
\right.
\end{equation}

Note that for continuous random variables, the probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of point events is

\begin{equation} \label{eq:pdf-sdfct-pdf-cont}
\mathrm{Pr}(X = a) = \int_a^a f_X(x) \, \mathrm{d}x = 0 \; .
\end{equation}

Because the probability density function is the first derivative of the cumulative distribution function ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:pdf-cdf})

\begin{equation} \label{eq:pdf-sdfct-pdf-cdf}
f_X(x) = \frac{\mathrm{d}F_X(x)}{\mathrm{d}x} \; ,
\end{equation}

the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $Y$ can be derived as follows:

1) If $y$ does not belong to the support of $Y$, $F_Y(y)$ is constant, such that

\begin{equation} \label{eq:pdf-sdfct-pdf-sdfct-p1}
f_Y(y) = 0, \quad \text{if} \quad y \notin \mathcal{Y} \; .
\end{equation}

2) If $y$ belongs to the support of $Y$, then $f_Y(y)$ can be derived using the chain rule:

\begin{equation} \label{eq:pdf-sdfct-pdf-sdfct-p2}
\begin{split}
f_Y(y) &\overset{\eqref{eq:pdf-sdfct-pdf-cdf}}{=} \frac{\mathrm{d}}{\mathrm{d}y} F_Y(y) \\
&\overset{\eqref{eq:pdf-sdfct-cdf-sdfct}}{=} \frac{\mathrm{d}}{\mathrm{d}y} \left[ 1 - F_X(g^{-1}(y)) + \mathrm{Pr}(X = g^{-1}(y)) \right] \\
&\overset{\eqref{eq:pdf-sdfct-pdf-cont}}{=} \frac{\mathrm{d}}{\mathrm{d}y} \left[ 1 - F_X(g^{-1}(y)) \right] \\
&= -\frac{\mathrm{d}}{\mathrm{d}y} F_X(g^{-1}(y)) \\
&= - f_X(g^{-1}(y)) \, \frac{\mathrm{d}g^{-1}(y)}{\mathrm{d}y} \; .
\end{split}
\end{equation}

Taking together \eqref{eq:pdf-sdfct-pdf-sdfct-p1} and \eqref{eq:pdf-sdfct-pdf-sdfct-p2}, eventually proves \eqref{eq:pdf-sdfct-pdf-sdfct}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Taboga, Marco (2017): "Functions of random variables and their distribution"; in: \textit{Lectures on probability and mathematical statistics}, retrieved on 2020-11-06; URL: \url{https://www.statlect.com/fundamentals-of-probability/functions-of-random-variables-and-their-distribution#hid7}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P188 | shortcut: pdf-sdfct | author: JoramSoch | date: 2020-11-06, 05:30.
\vspace{1em}



\subsubsection[\textbf{Probability density function of invertible function}]{Probability density function of invertible function} \label{sec:pdf-invfct}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be an $n \times 1$ random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}) of continuous random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar-disc}) with possible outcomes $\mathcal{X} \subseteq \mathbb{R}^n$ and let $g: \; \mathbb{R}^n \rightarrow \mathbb{R}^n$ be an invertible and differentiable function on the support of $X$. Then, the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $Y = g(X)$ is given by

\begin{equation} \label{eq:pdf-invfct-pdf-invfct}
f_Y(y) = \left\{
\begin{array}{rl}
f_X(g^{-1}(y)) \, \left| J_{g^{-1}}(y) \right| \; , & \text{if} \; y \in \mathcal{Y} \\
0 \; , & \text{if} \; y \notin \mathcal{Y}
\end{array}
\right. \; ,
\end{equation}

if the Jacobian determinant satisfies

\begin{equation} \label{eq:pdf-invfct-jac-det}
\left| J_{g^{-1}}(y) \right| \neq 0 \quad \text{for all} \quad y \in \mathcal{Y}
\end{equation}

where $g^{-1}(y)$ is the inverse function of $g(x)$, $J_{g^{-1}}(y)$ is the Jacobian matrix of $g^{-1}(y)$

\begin{equation} \label{eq:pdf-invfct-jac}
J_{g^{-1}}(y) = \left[ \begin{matrix}
\frac{\mathrm{d}x_1}{\mathrm{d}y_1} & \ldots & \frac{\mathrm{d}x_1}{\mathrm{d}y_n} \\
\vdots & \ddots & \vdots \\
\frac{\mathrm{d}x_n}{\mathrm{d}y_1} & \ldots & \frac{\mathrm{d}x_n}{\mathrm{d}y_n}
\end{matrix} \right] \; ,
\end{equation}

$\lvert J \rvert$ is the determinant of $J$ and $\mathcal{Y}$ is the set of possible outcomes of $Y$:

\begin{equation} \label{eq:pdf-invfct-Y-range}
\mathcal{Y} = \left\lbrace y = g(x): x \in \mathcal{X} \right\rbrace \; .
\end{equation}


\vspace{1em}
\textbf{Proof:}

1) First, we obtain the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) of $Y = g(X)$. The joint CDF ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf-joint}) is given by

\begin{equation} \label{eq:pdf-invfct-Y-cdf-s1}
\begin{split}
F_Y(y) &= \mathrm{Pr}(Y_1 \leq y_1, \ldots, Y_n \leq y_n) \\
&= \mathrm{Pr}(g_1(X) \leq y_1, \ldots, g_n(X) \leq y_n) \\
&= \int_{A(y)} f_X(x) \, \mathrm{d}x
\end{split}
\end{equation}

where $A(y)$ is the following subset of the $n$-dimensional Euclidean space:

\begin{equation} \label{eq:pdf-invfct-A-y}
A(y) = \left\lbrace x \in \mathbb{R}^n: g_j(x) \leq y_j \; \text{for all} \; j = 1, \ldots, n \right\rbrace
\end{equation}

and $g_j(X)$ is the function which returns the $j$-th element of $Y$, given a vector $X$.

\vspace{1em}
2) Next, we substitute $x = g^{-1}(y)$ into the integral which gives us

\begin{equation} \label{eq:pdf-invfct-Y-cdf-s2}
\begin{split}
F_Y(z) &= \int_{B(z)} f_X(g^{-1}(y)) \, \mathrm{d}g^{-1}(y) \\
&= \int_{-\infty}^{z_n} \ldots \int_{-\infty}^{z_1} f_X(g^{-1}(y)) \, \mathrm{d}g^{-1}(y) \; .
\end{split}
\end{equation}

where we have the modified the integration regime $B(z)$ which reads

\begin{equation} \label{eq:pdf-invfct-B-z}
B(z) = \left\lbrace y \in \mathbb{R}^n: y \leq z_j \; \text{for all} \; j = 1, \ldots, n \right\rbrace \; .
\end{equation}

\vspace{1em}
3) The formula for change of variables in multivariable calculus states that

\begin{equation} \label{eq:pdf-invfct-cov-multi}
y = f(x) \quad \Rightarrow \quad \mathrm{d}y = \left| J_f(x) \right| \, \mathrm{d}x \; .
\end{equation}

Applied to equation \eqref{eq:pdf-invfct-Y-cdf-s2}, this yields

\begin{equation} \label{eq:pdf-invfct-Y-cdf-s3}
\begin{split}
F_Y(z) &= \int_{-\infty}^{z_n} \ldots \int_{-\infty}^{z_1} f_X(g^{-1}(y)) \, \left| J_{g^{-1}}(y) \right| \, \mathrm{d}y \\
&= \int_{-\infty}^{z_n} \ldots \int_{-\infty}^{z_1} f_X(g^{-1}(y)) \, \left| J_{g^{-1}}(y) \right| \, \mathrm{d}y_1 \ldots \mathrm{d}y_n \; .
\end{split}
\end{equation}

\vspace{1em}
4) Finally, we obtain the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $Y = g(X)$. Because the PDF is the derivative of the CDF ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:pdf-cdf}), we can differentiate the joint CDF to get

\begin{equation} \label{eq:pdf-invfct-Y-cdf-s4}
\begin{split}
f_Y(z) &= \frac{\mathrm{d}^n}{\mathrm{d}z_1 \ldots \mathrm{d}z_n} \, F_Y(z) \\
&= \frac{\mathrm{d}^n}{\mathrm{d}z_1 \ldots \mathrm{d}z_n} \int_{-\infty}^{z_n} \ldots \int_{-\infty}^{z_1} f_X(g^{-1}(y)) \, \left| J_{g^{-1}}(y) \right| \, \mathrm{d}y_1 \ldots \mathrm{d}y_n \\
&= f_X(g^{-1}(z)) \, \left| J_{g^{-1}}(z) \right|
\end{split}
\end{equation}

which can also be written as

\begin{equation} \label{eq:pdf-invfct-pdf-invfct-qed}
f_Y(y) = f_X(g^{-1}(y)) \, \left| J_{g^{-1}}(y) \right| \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Taboga, Marco (2017): "Functions of random vectors and their distribution"; in: \textit{Lectures on probability and mathematical statistics}, retrieved on 2021-08-30; URL: \url{https://www.statlect.com/fundamentals-of-probability/functions-of-random-vectors}.
\item Lebanon, Guy (2017): "Functions of a Random Vector"; in: \textit{Probability: The Analysis of Data, Vol. 1}, retrieved on 2021-08-30; URL: \url{http://theanalysisofdata.com/probability/4_4.html}.
\item Poirier, Dale J. (1995): "Distributions of Functions of Random Variables"; in: \textit{Intermediate Statistics and Econometrics: A Comparative Approach}, ch. 4, pp. 149ff.; URL: \url{https://books.google.de/books?id=K52_YvD1YNwC&hl=de&source=gbs_navlinks_s}.
\item Devore, Jay L.; Berk, Kennth N. (2011): "Conditional Distributions"; in: \textit{Modern Mathematical Statistics with Applications}, ch. 5.2, pp. 253ff.; URL: \url{https://books.google.de/books?id=5PRLUho-YYgC&hl=de&source=gbs_navlinks_s}.
\item peek-a-boo (2019): "How to come up with the Jacobian in the change of variables formula"; in: \textit{StackExchange Mathematics}, retrieved on 2021-08-30; URL: \url{https://math.stackexchange.com/a/3239222}.
\item Bazett, Trefor (2019): "Change of Variables \& The Jacobian | Multi-variable Integration"; in: \textit{YouTube}, retrieved on 2021-08-30; URL: \url{https://www.youtube.com/watch?v=wUF-lyyWpUc}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P254 | shortcut: pdf-invfct | author: JoramSoch | date: 2021-08-30, 07:05.
\vspace{1em}



\subsubsection[\textbf{Probability density function of linear transformation}]{Probability density function of linear transformation} \label{sec:pdf-linfct}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be an $n \times 1$ random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}) of continuous random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar-disc}) with possible outcomes $\mathcal{X} \subseteq \mathbb{R}^n$ and let $Y = \Sigma X + \mu$ be a linear transformation of this random variable with constant ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:const}) $n \times 1$ vector $\mu$ and constant ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:const}) $n \times n$ matrix $\Sigma$. Then, the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $Y$ is

\begin{equation} \label{eq:pdf-linfct-pdf-linfct}
f_Y(y) = \left\{
\begin{array}{rl}
\frac{1}{\left| \Sigma \right|} f_X(\Sigma^{-1}(y-\mu)) \; , & \text{if} \; y \in \mathcal{Y} \\
0 \; , & \text{if} \; y \notin \mathcal{Y}
\end{array}
\right.
\end{equation}

where $\lvert \Sigma \rvert$ is the determinant of $\Sigma$ and $\mathcal{Y}$ is the set of possible outcomes of $Y$:

\begin{equation} \label{eq:pdf-linfct-Y-range}
\mathcal{Y} = \left\lbrace y = \Sigma x + \mu: x \in \mathcal{X} \right\rbrace \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} Because the linear function $g(X) = \Sigma X + \mu$ is invertible and differentiable, we can determine the probability density function of an invertible function of a continuous random vector ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:pdf-invfct}) using the relation

\begin{equation} \label{eq:pdf-linfct-pdf-invfct}
f_Y(y) = \left\{
\begin{array}{rl}
f_X(g^{-1}(y)) \, \left| J_{g^{-1}}(y) \right| \; , & \text{if} \; y \in \mathcal{Y} \\
0 \; , & \text{if} \; y \notin \mathcal{Y}
\end{array}
\right. \; .
\end{equation}

The inverse function is

\begin{equation} \label{eq:pdf-linfct-g-inv}
X = g^{-1}(Y) = \Sigma^{-1}(Y-\mu) = \Sigma^{-1} Y - \Sigma^{-1} \mu
\end{equation}

and the Jacobian matrix is

\begin{equation} \label{eq:pdf-linfct-J-g-inv}
J_{g^{-1}}(y) = \left[ \begin{matrix}
\frac{\mathrm{d}x_1}{\mathrm{d}y_1} & \ldots & \frac{\mathrm{d}x_1}{\mathrm{d}y_n} \\
\vdots & \ddots & \vdots \\
\frac{\mathrm{d}x_n}{\mathrm{d}y_1} & \ldots & \frac{\mathrm{d}x_n}{\mathrm{d}y_n}
\end{matrix} \right] = \Sigma^{-1} \; .
\end{equation}

Plugging \eqref{eq:pdf-linfct-g-inv} and \eqref{eq:pdf-linfct-J-g-inv} into \eqref{eq:pdf-linfct-pdf-invfct} and applying the determinant property $\lvert A^{-1} \rvert = \lvert A \rvert^{-1}$, we obtain

\begin{equation} \label{eq:pdf-linfct-pdf-linfct-qed}
f_Y(y) = \frac{1}{\left| \Sigma \right|} f_X(\Sigma^{-1}(y-\mu)) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Taboga, Marco (2017): "Functions of random vectors and their distribution"; in: \textit{Lectures on probability and mathematical statistics}, retrieved on 2021-08-30; URL: \url{https://www.statlect.com/fundamentals-of-probability/functions-of-random-vectors}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P255 | shortcut: pdf-linfct | author: JoramSoch | date: 2021-08-30, 07:46.
\vspace{1em}



\subsubsection[\textbf{Probability density function in terms of cumulative distribution function}]{Probability density function in terms of cumulative distribution function} \label{sec:pdf-cdf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a continuous ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar-disc}) random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}). Then, the probability distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $X$ is the first derivative of the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) of $X$:

\begin{equation} \label{eq:pdf-cdf-pdf-cdf}
f_X(x) = \frac{\mathrm{d}F_X(x)}{\mathrm{d}x} \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The cumulative distribution function in terms of the probability density function of a continuous random variable ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:cdf-pdf}) is given by:

\begin{equation} \label{eq:pdf-cdf-cdf-pdf}
F_X(x) = \int_{-\infty}^{x} f_X(t) \, \mathrm{d}t, \; x \in \mathbb{R} \; .
\end{equation}

Taking the derivative with respect to $x$, we have:

\begin{equation} \label{eq:pdf-cdf-ddx-cdf}
\frac{\mathrm{d}F_X(x)}{\mathrm{d}x} = \frac{\mathrm{d}}{\mathrm{d}x} \int_{-\infty}^{x} f_X(t) \, \mathrm{d}t \; .
\end{equation}

The fundamental theorem of calculus states that, if $f(x)$ is a continuous real-valued function defined on the interval $[a,b]$, then it holds that

\begin{equation} \label{eq:pdf-cdf-FToC-1st}
F(x) = \int_{a}^{x} f(t) \, \mathrm{d}t \quad \Rightarrow \quad F'(x) = f(x) \quad \text{for all} \quad x \in (a,b) \; .
\end{equation}

Applying \eqref{eq:pdf-cdf-FToC-1st} to \eqref{eq:pdf-cdf-cdf-pdf}, it follows that

\begin{equation} \label{eq:pdf-cdf-pdf-cdf-qed}
F_X(x) = \int_{-\infty}^{x} f_X(t) \, \mathrm{d}t \quad \Rightarrow \quad \frac{\mathrm{d}F_X(x)}{\mathrm{d}x} = f_X(x) \quad \text{for all} \quad x \in \mathbb{R} \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Fundamental theorem of calculus"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-11-12; URL: \url{https://en.wikipedia.org/wiki/Fundamental_theorem_of_calculus#Formal_statements}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P191 | shortcut: pdf-cdf | author: JoramSoch | date: 2020-11-12, 07:19.
\vspace{1em}



\subsubsection[\textit{Cumulative distribution function}]{Cumulative distribution function} \label{sec:cdf}
\setcounter{equation}{0}

\textbf{Definition:} The cumulative distribution function (CDF) of a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X$ at a given value $x$ is defined as the probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob}) that $X$ is smaller than $x$:

\begin{equation} \label{eq:cdf-cdf}
F_X(x) = \mathrm{Pr}(X \leq x) \; .
\end{equation}

\vspace{1em}
1) If $X$ is a discrete ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar-disc}) random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with possible outcomes $\mathcal{X}$ and the probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) $f_X(x)$, then the cumulative distribution function is the function ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:cdf-pmf}) $F_X(x): \mathbb{R} \to [0,1]$ with

\begin{equation} \label{eq:cdf-cdf-disc}
F_X(x) = \sum_{\overset{t \in \mathcal{X}}{t \leq x}} f_X(t) \; .
\end{equation}

\vspace{1em}
2) If $X$ is a continuous ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar-disc}) random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with possible outcomes $\mathcal{X}$ and the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) $f_X(x)$, then the cumulative distribution function is the function ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:cdf-pdf}) $F_X(x): \mathbb{R} \to [0,1]$ with

\begin{equation} \label{eq:cdf-cdf-cont}
F_X(x) = \int_{-\infty}^{x} f_X(t) \, \mathrm{d}t \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Cumulative distribution function"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-02-17; URL: \url{https://en.wikipedia.org/wiki/Cumulative_distribution_function#Definition}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D13 | shortcut: cdf | author: JoramSoch | date: 2020-02-17, 22:07.
\vspace{1em}



\subsubsection[\textbf{Cumulative distribution function of sum of independents}]{Cumulative distribution function of sum of independents} \label{sec:cdf-sumind}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ and $Y$ be two independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}) random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) and let $Z = X + Y$. Then, the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) of $Z$ is given by

\begin{equation} \label{eq:cdf-sumind-cdf-sumind}
\begin{split}
F_Z(z) &= \mathrm{E}\left[ F_X(z-Y) \right] \\
\text{or} \quad F_Z(z) &= \mathrm{E}\left[ F_Y(z-X) \right]
\end{split}
\end{equation}

where $F_X(x)$, $F_Y(y)$ and $F_Z(z)$ are the cumulative distribution functions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) of $X$, $Y$ and $Z$ and $\mathrm{E}\left[ \cdot \right]$ denotes the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}).


\vspace{1em}
\textbf{Proof:} Using the definition of the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}), the first equation can be derived as follows:

\begin{equation} \label{eq:cdf-sumind-cdf-sumind-qed}
\begin{split}
F_Z(z) &= \mathrm{Pr}(Z \leq z) \\
&= \mathrm{Pr}(X + Y \leq z) \\
&= \mathrm{Pr}(X \leq z - Y) \\
&= \mathrm{E} \left[ \mathrm{Pr}(X \leq z - Y \vert Y = y) \right] \\
&= \mathrm{E} \left[ \mathrm{Pr}(X \leq z - Y) \right] \\
&= \mathrm{E} \left[ F_X(z-Y) \right] \; .
\end{split}
\end{equation}

Note that the second-last transition is justified by the fact that $X$ and $Y$ are independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}), such that conditional probabilities are equal to marginal probabilities ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:prob-ind}). The second equation can be derived by switching $X$ and $Y$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Taboga, Marco (2017): "Sums of independent random variables"; in: \textit{Lectures on probability and mathematical statistics}, retrieved on 2021-08-30; URL: \url{https://www.statlect.com/fundamentals-of-probability/sums-of-independent-random-variables}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P256 | shortcut: cdf-sumind | author: JoramSoch | date: 2021-08-30, 08:53.
\vspace{1em}



\subsubsection[\textbf{Cumulative distribution function of strictly increasing function}]{Cumulative distribution function of strictly increasing function} \label{sec:cdf-sifct}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with possible outcomes $\mathcal{X}$ and let $g(x)$ be a strictly increasing function on the support of $X$. Then, the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) of $Y = g(X)$ is given by

\begin{equation} \label{eq:cdf-sifct-cdf-sifct}
F_Y(y) = \left\{
\begin{array}{rl}
0 \; , & \text{if} \; y < \mathrm{min}(\mathcal{Y}) \\
F_X(g^{-1}(y)) \; , & \text{if} \; y \in \mathcal{Y} \\
1 \; , & \text{if} \; y > \mathrm{max}(\mathcal{Y})
\end{array}
\right.
\end{equation}

where $g^{-1}(y)$ is the inverse function of $g(x)$ and $\mathcal{Y}$ is the set of possible outcomes of $Y$:

\begin{equation} \label{eq:cdf-sifct-Y-range}
\mathcal{Y} = \left\lbrace y = g(x): x \in \mathcal{X} \right\rbrace \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The support of $Y$ is determined by $g(x)$ and by the set of possible outcomes of $X$. Moreover, if $g(x)$ is strictly increasing, then $g^{-1}(y)$ is also strictly increasing. Therefore, the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) of $Y$ can be derived as follows:

1) If $y$ is lower than the lowest value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:min}) $Y$ can take, then $\mathrm{Pr}(Y \leq y) = 0$, so

\begin{equation} \label{eq:cdf-sifct-cdf-sifct-p1}
F_Y(y) = 0, \quad \text{if} \quad y < \mathrm{min}(\mathcal{Y}) \; .
\end{equation}

2) If $y$ belongs to the support of $Y$, then $F_Y(y)$ can be derived as follows:

\begin{equation} \label{eq:cdf-sifct-cdf-sifct-p2}
\begin{split}
F_Y(y) &= \mathrm{Pr}(Y \leq y) \\
&= \mathrm{Pr}(g(X) \leq y) \\
&= \mathrm{Pr}(X \leq g^{-1}(y)) \\
&= F_X(g^{-1}(y)) \; .
\end{split}
\end{equation}

3) If $y$ is higher than the highest value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:max}) $Y$ can take, then $\mathrm{Pr}(Y \leq y) = 1$, so

\begin{equation} \label{eq:cdf-sifct-cdf-sifct-p3}
F_Y(y) = 1, \quad \text{if} \quad y > \mathrm{max}(\mathcal{Y}) \; .
\end{equation}

Taking together \eqref{eq:cdf-sifct-cdf-sifct-p1}, \eqref{eq:cdf-sifct-cdf-sifct-p2}, \eqref{eq:cdf-sifct-cdf-sifct-p3}, eventually proves \eqref{eq:cdf-sifct-cdf-sifct}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Taboga, Marco (2017): "Functions of random variables and their distribution"; in: \textit{Lectures on probability and mathematical statistics}, retrieved on 2020-10-29; URL: \url{https://www.statlect.com/fundamentals-of-probability/functions-of-random-variables-and-their-distribution#hid2}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P183 | shortcut: cdf-sifct | author: JoramSoch | date: 2020-10-29, 05:35.
\vspace{1em}



\subsubsection[\textbf{Cumulative distribution function of strictly decreasing function}]{Cumulative distribution function of strictly decreasing function} \label{sec:cdf-sdfct}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with possible outcomes $\mathcal{X}$ and let $g(x)$ be a strictly decreasing function on the support of $X$. Then, the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) of $Y = g(X)$ is given by

\begin{equation} \label{eq:cdf-sdfct-cdf-sdfct}
F_Y(y) = \left\{
\begin{array}{rl}
1 \; , & \text{if} \; y > \mathrm{max}(\mathcal{Y}) \\
1 - F_X(g^{-1}(y)) + \mathrm{Pr}(X = g^{-1}(y)) \; , & \text{if} \; y \in \mathcal{Y} \\
0 \; , & \text{if} \; y < \mathrm{min}(\mathcal{Y})
\end{array}
\right.
\end{equation}

where $g^{-1}(y)$ is the inverse function of $g(x)$ and $\mathcal{Y}$ is the set of possible outcomes of $Y$:

\begin{equation} \label{eq:cdf-sdfct-Y-range}
\mathcal{Y} = \left\lbrace y = g(x): x \in \mathcal{X} \right\rbrace \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The support of $Y$ is determined by $g(x)$ and by the set of possible outcomes of $X$. Moreover, if $g(x)$ is strictly decreasing, then $g^{-1}(y)$ is also strictly decreasing. Therefore, the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) of $Y$ can be derived as follows:

1) If $y$ is higher than the highest value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:max}) $Y$ can take, then $\mathrm{Pr}(Y \leq y) = 1$, so

\begin{equation} \label{eq:cdf-sdfct-cdf-sdfct-p1}
F_Y(y) = 1, \quad \text{if} \quad y > \mathrm{max}(\mathcal{Y}) \; .
\end{equation}

2) If $y$ belongs to the support of $Y$, then $F_Y(y)$ can be derived as follows:

\begin{equation} \label{eq:cdf-sdfct-cdf-sdfct-p2}
\begin{split}
F_Y(y) &= \mathrm{Pr}(Y \leq y) \\
&= 1 - \mathrm{Pr}(Y > y) \\
&= 1 - \mathrm{Pr}(g(X) > y) \\
&= 1 - \mathrm{Pr}(X < g^{-1}(y)) \\
&= 1 - \mathrm{Pr}(X < g^{-1}(y)) - \mathrm{Pr}(X = g^{-1}(y)) + \mathrm{Pr}(X = g^{-1}(y)) \\
&= 1 - \left[ \mathrm{Pr}(X < g^{-1}(y)) + \mathrm{Pr}(X = g^{-1}(y)) \right] + \mathrm{Pr}(X = g^{-1}(y)) \\
&= 1 - \mathrm{Pr}(X \leq g^{-1}(y)) + \mathrm{Pr}(X = g^{-1}(y)) \\
&= 1 - F_X(g^{-1}(y)) + \mathrm{Pr}(X = g^{-1}(y)) \; .
\end{split}
\end{equation}

3) If $y$ is lower than the lowest value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:min}) $Y$ can take, then $\mathrm{Pr}(Y \leq y) = 0$, so

\begin{equation} \label{eq:cdf-sdfct-cdf-sdfct-p3}
F_Y(y) = 0, \quad \text{if} \quad y < \mathrm{min}(\mathcal{Y}) \; .
\end{equation}

Taking together \eqref{eq:cdf-sdfct-cdf-sdfct-p1}, \eqref{eq:cdf-sdfct-cdf-sdfct-p2}, \eqref{eq:cdf-sdfct-cdf-sdfct-p3}, eventually proves \eqref{eq:cdf-sdfct-cdf-sdfct}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Taboga, Marco (2017): "Functions of random variables and their distribution"; in: \textit{Lectures on probability and mathematical statistics}, retrieved on 2020-11-06; URL: \url{https://www.statlect.com/fundamentals-of-probability/functions-of-random-variables-and-their-distribution#hid5}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P186 | shortcut: cdf-sdfct | author: JoramSoch | date: 2020-11-06, 04:12.
\vspace{1em}



\subsubsection[\textbf{Cumulative distribution function of discrete random variable}]{Cumulative distribution function of discrete random variable} \label{sec:cdf-pmf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a discrete ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar-disc}) random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with possible values $\mathcal{X}$ and probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) $f_X(x)$. Then, the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) of $X$ is

\begin{equation} \label{eq:cdf-pmf-cdf-pmf}
F_X(x) = \sum_{\overset{t \in \mathcal{X}}{t \leq x}} f_X(t) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) of a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X$ is defined as the probability that $X$ is smaller than $x$:

\begin{equation} \label{eq:cdf-pmf-cdf}
F_X(x) = \mathrm{Pr}(X \leq x) \; .
\end{equation}

The probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) of a discrete ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar-disc}) random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X$ returns the probability that $X$ takes a particular value $x$:

\begin{equation} \label{eq:cdf-pmf-pmf}
f_X(x) = \mathrm{Pr}(X = x) \; .
\end{equation}

Taking these two definitions together, we have:

\begin{equation} \label{eq:cdf-pmf-cdf-pmf-qed}
\begin{split}
F_X(x) &\overset{\eqref{eq:cdf-pmf-cdf}}{=} \sum_{\overset{t \in \mathcal{X}}{t \leq x}} \mathrm{Pr}(X = t) \\
&\overset{\eqref{eq:cdf-pmf-pmf}}{=} \sum_{\overset{t \in \mathcal{X}}{t \leq x}} f_X(t) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P189 | shortcut: cdf-pmf | author: JoramSoch | date: 2020-11-12, 06:03.
\vspace{1em}



\subsubsection[\textbf{Cumulative distribution function of continuous random variable}]{Cumulative distribution function of continuous random variable} \label{sec:cdf-pdf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a continuous ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar-disc}) random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with possible values $\mathcal{X}$ and probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) $f_X(x)$. Then, the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) of $X$ is

\begin{equation} \label{eq:cdf-pdf-cdf-pdf}
F_X(x) = \int_{-\infty}^{x} f_X(t) \, \mathrm{d}t \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) of a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X$ is defined as the probability that $X$ is smaller than $x$:

\begin{equation} \label{eq:cdf-pdf-cdf}
F_X(x) = \mathrm{Pr}(X \leq x) \; .
\end{equation}

The probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of a continuous ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar-disc}) random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X$ can be used to calculate the probability that $X$ falls into a particular interval $A$:

\begin{equation} \label{eq:cdf-pdf-pdf}
\mathrm{Pr}(X \in A) = \int_{A} f_X(x) \, \mathrm{d}x \; .
\end{equation}

Taking these two definitions together, we have:

\begin{equation} \label{eq:cdf-pdf-cdf-pdf-qed}
\begin{split}
F_X(x) &\overset{\eqref{eq:cdf-pdf-cdf}}{=} \mathrm{Pr}(X \in (-\infty, x]) \\
&\overset{\eqref{eq:cdf-pdf-pdf}}{=} \int_{-\infty}^{x} f_X(t) \, \mathrm{d}t \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P190 | shortcut: cdf-pdf | author: JoramSoch | date: 2020-11-12, 06:33.
\vspace{1em}



\subsubsection[\textbf{Probability integral transform}]{Probability integral transform} \label{sec:cdf-pit}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a continuous ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar-disc}) random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with invertible ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:qf}) cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) $F_X(x)$. Then, the random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar})

\begin{equation} \label{eq:cdf-pit-cdf-pit}
Y = F_X(X)
\end{equation}

has a standard uniform distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:suni}).


\vspace{1em}
\textbf{Proof:} The cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) of $Y = F_X(X)$ can be derived as

\begin{equation} \label{eq:cdf-pit-cdf-pit-qed}
\begin{split}
F_Y(y) &= \mathrm{Pr}(Y \leq y) \\
&= \mathrm{Pr}(F_X(X) \leq y) \\
&= \mathrm{Pr}(X \leq F_X^{-1}(y)) \\
&= F_X(F_X^{-1}(y)) \\
&= y \\
\end{split}
\end{equation}

which is the cumulative distribution function of a continuous uniform distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:cuni-cdf}) with $a = 0$ and $b = 1$, i.e. the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) of the standard uniform distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:suni}) $\mathcal{U}(0,1)$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Probability integral transform"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-04-07; URL: \url{https://en.wikipedia.org/wiki/Probability_integral_transform#Proof}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P220 | shortcut: cdf-pit | author: JoramSoch | date: 2021-04-07, 08:47.
\vspace{1em}



\subsubsection[\textbf{Inverse transformation method}]{Inverse transformation method} \label{sec:cdf-itm}
\setcounter{equation}{0}

\textbf{Theorem:} Let $U$ be a continuous ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar-disc}) random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) having a standard uniform distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:suni}). Then, the random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar})

\begin{equation} \label{eq:cdf-itm-cdf-itm}
X = F_X^{-1}(U)
\end{equation}

has a probability distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist}) characterized by the invertible ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:qf}) cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) $F_X(x)$.


\vspace{1em}
\textbf{Proof:} The cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) of the transformation $X = F_X^{-1}(U)$ can be derived as

\begin{equation} \label{eq:cdf-itm-cdf-itm-qed}
\begin{split}
&\hphantom{=} \;\; \mathrm{Pr}(X \leq x) \\
&= \mathrm{Pr}(F_X^{-1}(U) \leq x) \\
&= \mathrm{Pr}(U \leq F_X(x)) \\
&= F_X(x) \; ,
\end{split}
\end{equation}

because the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) of the standard uniform distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:suni}) $\mathcal{U}(0,1)$ is

\begin{equation} \label{eq:cdf-itm-suni-cdf}
U \sim \mathcal{U}(0,1) \quad \Rightarrow \quad F_U(u) = \mathrm{Pr}(U \leq u) = u \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Inverse transform sampling"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-04-07; URL: \url{https://en.wikipedia.org/wiki/Inverse_transform_sampling#Proof_of_correctness}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P221 | shortcut: cdf-itm | author: JoramSoch | date: 2021-04-07, 08:47.
\vspace{1em}



\subsubsection[\textbf{Distributional transformation}]{Distributional transformation} \label{sec:cdf-dt}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ and $Y$ be two continuous ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar-disc}) random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) $F_X(x)$ and invertible cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) $F_Y(y)$. Then, the random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar})

\begin{equation} \label{eq:cdf-dt-cdf-dt}
\tilde{X} = F_Y^{-1}(F_X(X))
\end{equation}

has the same probability distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist}) as $Y$.


\vspace{1em}
\textbf{Proof:} The cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) of the transformation $\tilde{X} = F_Y^{-1}(F_X(X))$ can be derived as

\begin{equation} \label{eq:cdf-dt-cdf-dt-qed}
\begin{split}
F_{\tilde{X}}(y) &= \mathrm{Pr}\left( \tilde{X} \leq y \right) \\
&= \mathrm{Pr}\left( F_Y^{-1}(F_X(X)) \leq y \right) \\
&= \mathrm{Pr}\left( F_X(X) \leq F_Y(y) \right) \\
&= \mathrm{Pr}\left( X \leq F_X^{-1}(F_Y(y)) \right) \\
&= F_X\left( F_X^{-1}(F_Y(y)) \right) \\
&= F_Y(y) \\
\end{split}
\end{equation}

which shows that $\tilde{X}$ and $Y$ have the same cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) and are thus identically distributed ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Soch, Joram (2020): "Distributional Transformation Improves Decoding Accuracy When Predicting Chronological Age From Structural MRI"; in: \textit{Frontiers in Psychiatry}, vol. 11, art. 604268; URL: \url{https://www.frontiersin.org/articles/10.3389/fpsyt.2020.604268/full}; DOI: 10.3389/fpsyt.2020.604268.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P222 | shortcut: cdf-dt | author: JoramSoch | date: 2021-04-07, 09:19.
\vspace{1em}



\subsubsection[\textit{Joint cumulative distribution function}]{Joint cumulative distribution function} \label{sec:cdf-joint}
\setcounter{equation}{0}

\textbf{Definition:} Let $X \in \mathbb{R}^{n \times 1}$ be an $n \times 1$ random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}). Then, the joint ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-joint}) cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) of $X$ is defined as the probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob}) that each entry $X_i$ is smaller than a specific value $x_i$ for $i = 1, \ldots, n$:

\begin{equation} \label{eq:cdf-joint-cdf-joint}
F_X(x) = \mathrm{Pr}(X_1 \leq x_1, \ldots, X_n \leq x_n) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Cumulative distribution function"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-04-07; URL: \url{https://en.wikipedia.org/wiki/Cumulative_distribution_function#Definition_for_more_than_two_random_variables}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D141 | shortcut: cdf-joint | author: JoramSoch | date: 2020-04-07, 08:17.
\vspace{1em}



\subsubsection[\textit{Quantile function}]{Quantile function} \label{sec:qf}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) (CDF) $F_X(x)$. Then, the function $Q_X(p): [0,1] \to \mathbb{R}$ which is the inverse CDF is the quantile function (QF) of $X$. More precisely, the QF is the function that, for a given quantile $p \in [0,1]$, returns the smallest $x$ for which $F_X(x) = p$:

\begin{equation} \label{eq:qf-qf}
Q_X(p) = \min \left\lbrace x \in \mathbb{R} \, \vert \, F_X(x) = p \right\rbrace \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Probability density function"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-02-17; URL: \url{https://en.wikipedia.org/wiki/Quantile_function#Definition}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D14 | shortcut: qf | author: JoramSoch | date: 2020-02-17, 22:18.
\vspace{1em}



\subsubsection[\textbf{Quantile function in terms of cumulative distribution function}]{Quantile function in terms of cumulative distribution function} \label{sec:qf-cdf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a continuous ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar-disc}) random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) $F_X(x)$. If the cumulative distribution function is strictly monotonically increasing, then the quantile function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:qf})  is identical to the inverse of $F_X(x)$:

\begin{equation} \label{eq:qf-cdf-qf-cdf}
Q_X(p) = F_X^{-1}(x) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The quantile function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:qf}) $Q_X(p)$ is defined as the function that, for a given quantile $p \in [0,1]$, returns the smallest $x$ for which $F_X(x) = p$:

\begin{equation} \label{eq:qf-cdf-qf}
Q_X(p) = \min \left\lbrace x \in \mathbb{R} \, \vert \, F_X(x) = p \right\rbrace \; .
\end{equation}

If $F_X(x)$ is continuous and strictly monotonically increasing, then there is exactly one $x$ for which $F_X(x) = p$ and $F_X(x)$ is an invertible function, such that

\begin{equation} \label{eq:qf-cdf-qf-cdf-qed}
Q_X(p) = F_X^{-1}(x) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Quantile function"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-11-12; URL: \url{https://en.wikipedia.org/wiki/Quantile_function#Definition}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P192 | shortcut: qf-cdf | author: JoramSoch | date: 2020-11-12, 07:48.
\vspace{1em}



\subsubsection[\textit{Characteristic function}]{Characteristic function} \label{sec:cf}
\setcounter{equation}{0}

\textbf{Definition:}

1) The characteristic function of a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X \in \mathbb{R}$ is

\begin{equation} \label{eq:cf-cf-var}
\varphi_X(t) = \mathrm{E} \left[ e^{itX} \right], \quad t \in \mathbb{R} \; .
\end{equation}

2) The characteristic function of a random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}) $X \in \mathbb{R}^n$ is

\begin{equation} \label{eq:cf-cf-vec}
\varphi_X(t) = \mathrm{E} \left[ e^{i t^\mathrm{T}X} \right], \quad t \in \mathbb{R}^n \; .
\end{equation}

3) The characteristic function of a random matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rmat}) $X \in \mathbb{R}^{n \times p}$ is

\begin{equation} \label{eq:cf-cf-mat}
\varphi_X(t) = \mathrm{E} \left[ e^{i \, \mathrm{tr} \left( t^\mathrm{T}X \right)} \right], \quad t \in \mathbb{R}^{n \times p} \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Characteristic function (probability theory)"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-09-22; URL: \url{https://en.wikipedia.org/wiki/Characteristic_function_(probability_theory)#Definition}.
\item Taboga, Marco (2017): "Joint characteristic function"; in: \textit{Lectures on probability and mathematical statistics}, retrieved on 2021-10-07; URL: \url{https://www.statlect.com/fundamentals-of-probability/joint-characteristic-function}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D159 | shortcut: cf | author: JoramSoch | date: 2021-09-22, 09:20.
\vspace{1em}



\subsubsection[\textbf{Characteristic function of arbitrary function}]{Characteristic function of arbitrary function} \label{sec:cf-fct}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) function $\mathrm{E}_X[\cdot]$. Then, the characteristic function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cf}) of $Y = g(X)$ is equal to

\begin{equation} \label{eq:cf-fct-cf-fct}
\varphi_Y(t) = \mathrm{E}_X \left[ \mathrm{exp}(it \, g(X)) \right] \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The characteristic function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cf}) is defined as

\begin{equation} \label{eq:cf-fct-cf}
\varphi_Y(t) = \mathrm{E} \left[ \mathrm{exp}(it \, Y) \right] \; .
\end{equation}

Due of the law of the unconscious statistician ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-lotus})

\begin{equation} \label{eq:cf-fct-mean-lotus}
\begin{split}
\mathrm{E}[g(X)] &= \sum_{x \in \mathcal{X}} g(x) f_X(x) \\
\mathrm{E}[g(X)] &= \int_{\mathcal{X}} g(x) f_X(x) \, \mathrm{d}x \; ,
\end{split}
\end{equation}

$Y = g(X)$ can simply be substituted into \eqref{eq:cf-fct-cf} to give

\begin{equation} \label{eq:cf-fct-cf-fct-qed}
\varphi_Y(t) = \mathrm{E}_X \left[ \mathrm{exp}(it \, g(X)) \right] \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Taboga, Marco (2017): "Functions of random vectors and their distribution"; in: \textit{Lectures on probability and mathematical statistics}, retrieved on 2021-09-22; URL: \url{https://www.statlect.com/fundamentals-of-probability/functions-of-random-vectors}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P259 | shortcut: cf-fct | author: JoramSoch | date: 2021-09-22, 09:12.
\vspace{1em}



\subsubsection[\textit{Moment-generating function}]{Moment-generating function} \label{sec:mgf}
\setcounter{equation}{0}

\textbf{Definition:}

1) The moment-generating function of a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X \in \mathbb{R}$ is

\begin{equation} \label{eq:mgf-mgf-var}
M_X(t) = \mathrm{E} \left[ e^{tX} \right], \quad t \in \mathbb{R} \; .
\end{equation}

2) The moment-generating function of a random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}) $X \in \mathbb{R}^n$ is

\begin{equation} \label{eq:mgf-mgf-vec}
M_X(t) = \mathrm{E} \left[ e^{t^\mathrm{T}X} \right], \quad t \in \mathbb{R}^n \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Moment-generating function"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-01-22; URL: \url{https://en.wikipedia.org/wiki/Moment-generating_function#Definition}.
\item Taboga, Marco (2017): "Joint moment generating function"; in: \textit{Lectures on probability and mathematical statistics}, retrieved on 2021-10-07; URL: \url{https://www.statlect.com/fundamentals-of-probability/joint-moment-generating-function}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D2 | shortcut: mgf | author: JoramSoch | date: 2020-01-22, 10:58.
\vspace{1em}



\subsubsection[\textbf{Moment-generating function of arbitrary function}]{Moment-generating function of arbitrary function} \label{sec:mgf-fct}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) function $\mathrm{E}_X[\cdot]$. Then, the moment-generating function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mgf}) of $Y = g(X)$ is equal to

\begin{equation} \label{eq:mgf-fct-mgf-fct}
M_Y(t) = \mathrm{E}_X \left[ \mathrm{exp}(t \, g(X)) \right] \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The moment-generating function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mgf}) is defined as

\begin{equation} \label{eq:mgf-fct-mgf}
M_Y(t) = \mathrm{E} \left[ \mathrm{exp}(t \, Y) \right] \; .
\end{equation}

Due of the law of the unconscious statistician ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-lotus})

\begin{equation} \label{eq:mgf-fct-mean-lotus}
\begin{split}
\mathrm{E}[g(X)] &= \sum_{x \in \mathcal{X}} g(x) f_X(x) \\
\mathrm{E}[g(X)] &= \int_{\mathcal{X}} g(x) f_X(x) \, \mathrm{d}x \; ,
\end{split}
\end{equation}

$Y = g(X)$ can simply be substituted into \eqref{eq:mgf-fct-mgf} to give

\begin{equation} \label{eq:mgf-fct-mgf-fct-qed}
M_Y(t) = \mathrm{E}_X \left[ \mathrm{exp}(t \, g(X)) \right] \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Taboga, Marco (2017): "Functions of random vectors and their distribution"; in: \textit{Lectures on probability and mathematical statistics}, retrieved on 2021-09-22; URL: \url{https://www.statlect.com/fundamentals-of-probability/functions-of-random-vectors}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P260 | shortcut: mgf-fct | author: JoramSoch | date: 2021-09-22, 09:00.
\vspace{1em}



\subsubsection[\textbf{Moment-generating function of linear transformation}]{Moment-generating function of linear transformation} \label{sec:mgf-ltt}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be an $n \times 1$ random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}) with the moment-generating function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mgf}) $M_X(t)$. Then, the moment-generating function of the linear transformation $Y = A X + b$ is given by

\begin{equation} \label{eq:mgf-ltt-mgf-ltt}
M_Y(t) = \exp \left[ t^\mathrm{T} b \right] \cdot M_X(At)
\end{equation}

where $A$ is an $m \times n$ matrix and $b$ is an $m \times 1$ vector.


\vspace{1em}
\textbf{Proof:} The moment-generating function of a random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mgf}) $X$ is

\begin{equation} \label{eq:mgf-ltt-mfg-vect}
M_X(t) = \mathrm{E} \left( \exp \left[ t^\mathrm{T} X \right] \right)
\end{equation}

and therefore the moment-generating function of the random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}) $Y$ is given by

\begin{equation} \label{eq:mgf-ltt-mgf-ltt-qed}
\begin{split}
M_Y(t) &= \mathrm{E} \left( \exp \left[ t^\mathrm{T} (AX + b) \right] \right) \\
&= \mathrm{E} \left( \exp \left[ t^\mathrm{T} A X \right] \cdot \exp \left[ t^\mathrm{T} b \right] \right) \\
&= \exp \left[ t^\mathrm{T} b \right] \cdot \mathrm{E} \left( \exp \left[ (A t)^\mathrm{T} X \right] \right) \\
&= \exp \left[ t^\mathrm{T} b \right] \cdot M_X(At) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item ProofWiki (2020): "Moment Generating Function of Linear Transformation of Random Variable"; in: \textit{ProofWiki}, retrieved on 2020-08-19; URL: \url{https://proofwiki.org/wiki/Moment_Generating_Function_of_Linear_Transformation_of_Random_Variable}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P154 | shortcut: mgf-ltt | author: JoramSoch | date: 2020-08-19, 08:09.
\vspace{1em}



\subsubsection[\textbf{Moment-generating function of linear combination}]{Moment-generating function of linear combination} \label{sec:mgf-lincomb}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X_1, \ldots, X_n$ be $n$ independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}) random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with moment-generating functions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mgf}) $M_{X_i}(t)$. Then, the moment-generating function of the linear combination $X = \sum_{i=1}^{n} a_i X_i$ is given by

\begin{equation} \label{eq:mgf-lincomb-mgf-lincomb}
M_X(t) = \prod_{i=1}^{n} M_{X_i}(a_i t)
\end{equation}

where $a_1, \ldots, a_n$ are $n$ real numbers.


\vspace{1em}
\textbf{Proof:} The moment-generating function of a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mgf}) $X_i$ is

\begin{equation} \label{eq:mgf-lincomb-mfg-vect}
M_{X_i}(t) = \mathrm{E} \left( \exp \left[ t X_i \right] \right)
\end{equation}

and therefore the moment-generating function of the linear combination $X$ is given by

\begin{equation} \label{eq:mgf-lincomb-mgf-lincomb-s1}
\begin{split}
M_X(t) &= \mathrm{E} \left( \exp \left[ t X \right] \right) \\
&= \mathrm{E} \left( \exp \left[ t \sum_{i=1}^{n} a_i X_i \right] \right) \\
&= \mathrm{E} \left( \prod_{i=1}^{n} \exp \left[ t \, a_i X_i \right] \right) \; .
\end{split}
\end{equation}

Because the expected value is multiplicative for independent random variables ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-mult}), we have

\begin{equation} \label{eq:mgf-lincomb-mgf-lincomb-s2}
\begin{split}
M_X(t) &= \prod_{i=1}^{n} \mathrm{E} \left( \exp \left[ (a_i t) X_i \right] \right) \\
&= \prod_{i=1}^{n} M_{X_i}(a_i t) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item ProofWiki (2020): "Moment Generating Function of Linear Combination of Independent Random Variables"; in: \textit{ProofWiki}, retrieved on 2020-08-19; URL: \url{https://proofwiki.org/wiki/Moment_Generating_Function_of_Linear_Combination_of_Independent_Random_Variables}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P155 | shortcut: mgf-lincomb | author: JoramSoch | date: 2020-08-19, 08:36.
\vspace{1em}



\subsubsection[\textit{Cumulant-generating function}]{Cumulant-generating function} \label{sec:cgf}
\setcounter{equation}{0}

\textbf{Definition:}

1) The cumulant-generating function of a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X \in \mathbb{R}$ is

\begin{equation} \label{eq:cgf-cgf-var}
K_X(t) = \log \mathrm{E} \left[ e^{tX} \right], \quad t \in \mathbb{R} \; .
\end{equation}

2) The cumulant-generating function of a random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}) $X \in \mathbb{R}^n$ is

\begin{equation} \label{eq:cgf-cgf-vec}
K_X(t) = \log \mathrm{E} \left[ e^{t^\mathrm{T}X} \right], \quad t \in \mathbb{R}^n \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Cumulant"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-05-31; URL: \url{https://en.wikipedia.org/wiki/Cumulant#Definition}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D68 | shortcut: cgf | author: JoramSoch | date: 2020-05-31, 23:46.
\vspace{1em}



\subsubsection[\textit{Probability-generating function}]{Probability-generating function} \label{sec:pgf}
\setcounter{equation}{0}

\textbf{Definition:}

1) If $X$ is a discrete random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) taking values in the non-negative integers $\left\lbrace 0, 1, \ldots \right\rbrace$, then the probability-generating function of $X$ is defined as

\begin{equation} \label{eq:pgf-pgf-var}
G_X(z) = \mathrm{E} \left[ z^X \right] = \sum_{x=0}^{\infty} p(x) \, z^x
\end{equation}

where $z \in \mathbb{C}$ and $p(x)$ is the probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) of $X$.

2) If $X$ is a discrete random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}) taking values in the $n$-dimensional integer lattice $x \in \left\lbrace 0, 1, \ldots \right\rbrace^n$, then the probability-generating function of $X$ is defined as

\begin{equation} \label{eq:pgf-cgf-vec}
G_X(z) = \mathrm{E} \left[ {z_1}^{X_1} \cdot \ldots \cdot {z_n}^{X_n} \right] = \sum_{x_1=0}^{\infty} \cdots \sum_{x_n=0}^{\infty} p(x_1,\ldots,x_n) \, {z_1}^{x_1} \cdot \ldots \cdot {z_n}^{x_n}
\end{equation}

where $z \in \mathbb{C}^n$ and $p(x)$ is the probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) of $X$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Probability-generating function"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-05-31; URL: \url{https://en.wikipedia.org/wiki/Probability-generating_function#Definition}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D69 | shortcut: pgf | author: JoramSoch | date: 2020-05-31, 23:59.
\vspace{1em}



\subsection{Expected value}

\subsubsection[\textit{Definition}]{Definition} \label{sec:mean}
\setcounter{equation}{0}

\textbf{Definition:}

1) The expected value (or, mean) of a discrete random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X$ with domain $\mathcal{X}$ is

\begin{equation} \label{eq:mean-mean-disc}
\mathrm{E}(X) = \sum_{x \in \mathcal{X}} x \cdot f_X(x)
\end{equation}

where $f_X(x)$ is the probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) of $X$.

\vspace{1em}
2) The expected value (or, mean) of a continuous random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X$ with domain $\mathcal{X}$ is

\begin{equation} \label{eq:mean-mean-cont}
\mathrm{E}(X) = \int_{\mathcal{X}} x \cdot f_X(x) \, \mathrm{d}x
\end{equation}

where $f_X(x)$ is the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $X$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Expected value"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-02-13; URL: \url{https://en.wikipedia.org/wiki/Expected_value#Definition}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D11 | shortcut: mean | author: JoramSoch | date: 2020-02-13, 19:38.
\vspace{1em}



\subsubsection[\textit{Sample mean}]{Sample mean} \label{sec:mean-samp}
\setcounter{equation}{0}

\textbf{Definition:} Let $x = \left\lbrace x_1, \ldots, x_n \right\rbrace$ be a sample ($\rightarrow$ Definition "samp") from a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X$. Then, the sample mean of $x$ is denoted as $\bar{x}$ and is given by

\begin{equation} \label{eq:mean-samp-mean-samp}
\bar{x} = \frac{1}{n} \sum_{i=1}^{n} x_i \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Sample mean and covariance"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-04-16; URL: \url{https://en.wikipedia.org/wiki/Sample_mean_and_covariance#Definition_of_the_sample_mean}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D142 | shortcut: mean-samp | author: JoramSoch | date: 2021-04-16, 11:53.
\vspace{1em}



\subsubsection[\textbf{Non-negative random variable}]{Non-negative random variable} \label{sec:mean-nnrvar}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a non-negative random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}). Then, the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of $X$ is

\begin{equation} \label{eq:mean-nnrvar-mean-cdf}
\mathrm{E}(X) = \int_{0}^{\infty} (1 - F_X(x)) \, \mathrm{d}x
\end{equation}

where $F_X(x)$ is the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) of $X$.


\vspace{1em}
\textbf{Proof:} Because the cumulative distribution function gives the probability of a random variable being smaller than a given value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}),

\begin{equation} \label{eq:mean-nnrvar-cdf-Pr-leq}
F_X(x) = \mathrm{Pr}(X \leq x) \; ,
\end{equation}

we have

\begin{equation} \label{eq:mean-nnrvar-cdf-Pr-geq}
1 - F_X(x) = \mathrm{Pr}(X > x) \; ,
\end{equation}

such that

\begin{equation} \label{eq:mean-nnrvar-mean-cdf-s1}
\int_{0}^{\infty} (1 - F_X(x)) \, \mathrm{d}x = \int_{0}^{\infty} \mathrm{Pr}(X > x) \, \mathrm{d}x
\end{equation}

which, using the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $X$, can be rewritten as

\begin{equation} \label{eq:mean-nnrvar-mean-cdf-s2}
\begin{split}
\int_{0}^{\infty} (1 - F_X(x)) \, \mathrm{d}x &= \int_{0}^{\infty} \int_{x}^{\infty} f_X(z) \, \mathrm{d}z \, \mathrm{d}x \\
&= \int_{0}^{\infty} \int_{0}^{z} f_X(z) \, \mathrm{d}x \, \mathrm{d}z \\
&= \int_{0}^{\infty} f_X(z) \int_{0}^{z} 1 \, \mathrm{d}x \, \mathrm{d}z \\
&= \int_{0}^{\infty} [x]_{0}^{z} \cdot f_X(z) \, \mathrm{d}z \\
&= \int_{0}^{\infty} z \cdot f_X(z) \, \mathrm{d}z \\
\end{split}
\end{equation}

and by applying the definition of the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}), we see that

\begin{equation} \label{eq:mean-nnrvar-mean-cdf-s3}
\int_{0}^{\infty} (1 - F_X(x)) \, \mathrm{d}x = \int_{0}^{\infty} z \cdot f_X(z) \, \mathrm{d}z = \mathrm{E}(X)
\end{equation}

which proves the identity given above.



\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Kemp, Graham (2014): "Expected value of a non-negative random variable"; in: \textit{StackExchange Mathematics}, retrieved on 2020-05-18; URL: \url{https://math.stackexchange.com/questions/958472/expected-value-of-a-non-negative-random-variable}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P103 | shortcut: mean-nnrvar | author: JoramSoch | date: 2020-05-18, 23:54.
\vspace{1em}



\subsubsection[\textbf{Non-negativity}]{Non-negativity} \label{sec:mean-nonneg}
\setcounter{equation}{0}

\textbf{Theorem:} If a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) is strictly non-negative, its expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) is also non-negative, i.e.

\begin{equation} \label{eq:mean-nonneg-mean-nonneg}
\mathrm{E}(X) \geq 0, \quad \text{if} \quad X \geq 0 \; .
\end{equation}


\vspace{1em}
\textbf{Proof:}

1) If $X \geq 0$ is a discrete random variable, then, because the probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) is always non-negative, all the addends in

\begin{equation} \label{eq:mean-nonneg-mean-disc}
\mathrm{E}(X) = \sum_{x \in \mathcal{X}} x \cdot f_X(x)
\end{equation}

are non-negative, thus the entire sum must be non-negative.

\vspace{1em}
2) If $X \geq 0$ is a continuous random variable, then, because the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) is always non-negative, the integrand in

\begin{equation} \label{eq:mean-nonneg-mean-cont}
\mathrm{E}(X) = \int_{\mathcal{X}} x \cdot f_X(x) \, \mathrm{d}x
\end{equation}

is strictly non-negative, thus the term on the right-hand side is a Lebesgue integral, so that the result on the left-hand side must be non-negative.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Expected value"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-02-13; URL: \url{https://en.wikipedia.org/wiki/Expected_value#Basic_properties}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P52 | shortcut: mean-nonneg | author: JoramSoch | date: 2020-02-13, 20:14.
\vspace{1em}



\subsubsection[\textbf{Linearity}]{Linearity} \label{sec:mean-lin}
\setcounter{equation}{0}

\textbf{Theorem:} The expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) is a linear operator, i.e.

\begin{equation} \label{eq:mean-lin-mean-lin}
\begin{split}
\mathrm{E}(X + Y) &= \mathrm{E}(X) + \mathrm{E}(Y) \\
\mathrm{E}(a\,X) &= a\,\mathrm{E}(X)
\end{split}
\end{equation}

for random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X$ and $Y$ and a constant ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:const}) $a$.


\vspace{1em}
\textbf{Proof:}

1) If $X$ and $Y$ are discrete random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar-disc}), the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) is

\begin{equation} \label{eq:mean-lin-mean-disc}
\mathrm{E}(X) = \sum_{x \in \mathcal{X}} x \cdot f_X(x)
\end{equation}

and the law of marginal probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}) states that

\begin{equation} \label{eq:mean-lin-lmp-disc}
p(x) = \sum_{y \in \mathcal{Y}} p(x,y) \; .
\end{equation}

Applying this, we have

\begin{equation} \label{eq:mean-lin-mean-lin-s1-disc}
\begin{split}
\mathrm{E}(X + Y) &= \sum_{x \in \mathcal{X}} \sum_{y \in \mathcal{Y}} (x+y) \cdot f_{X,Y}(x,y) \\
&= \sum_{x \in \mathcal{X}} \sum_{y \in \mathcal{Y}} x \cdot f_{X,Y}(x,y) + \sum_{x \in \mathcal{X}} \sum_{y \in \mathcal{Y}} y \cdot f_{X,Y}(x,y) \\
&= \sum_{x \in \mathcal{X}} x \sum_{y \in \mathcal{Y}} f_{X,Y}(x,y) + \sum_{y \in \mathcal{Y}} y \sum_{x \in \mathcal{X}} f_{X,Y}(x,y) \\
&\overset{\eqref{eq:mean-lin-lmp-disc}}{=} \sum_{x \in \mathcal{X}} x \cdot f_X(x) + \sum_{y \in \mathcal{Y}} y \cdot f_{Y}(y) \\
&\overset{\eqref{eq:mean-lin-mean-disc}}{=} \mathrm{E}(X) + \mathrm{E}(Y)
\end{split}
\end{equation}

as well as

\begin{equation} \label{eq:mean-lin-mean-lin-s2-disc}
\begin{split}
\mathrm{E}(a\,X) &= \sum_{x \in \mathcal{X}} a \, x \cdot f_X(x) \\
&= a \, \sum_{x \in \mathcal{X}} x \cdot f_X(x) \\
&\overset{\eqref{eq:mean-lin-mean-disc}}{=} a \, \mathrm{E}(X) \; .
\end{split}
\end{equation}

\vspace{1em}
2) If $X$ and $Y$ are continuous random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar-disc}), the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) is

\begin{equation} \label{eq:mean-lin-mean-cont}
\mathrm{E}(X) = \int_{\mathcal{X}} x \cdot f_X(x) \, \mathrm{d}x
\end{equation}

and the law of marginal probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}) states that

\begin{equation} \label{eq:mean-lin-lmp-cont}
p(x) = \int_{\mathcal{Y}} p(x,y) \, \mathrm{d}y \; .
\end{equation}

Applying this, we have

\begin{equation} \label{eq:mean-lin-mean-lin-s1-cont}
\begin{split}
\mathrm{E}(X + Y) &= \int_{\mathcal{X}} \int_{\mathcal{Y}} (x+y) \cdot f_{X,Y}(x,y) \, \mathrm{d}y \, \mathrm{d}x \\
&= \int_{\mathcal{X}} \int_{\mathcal{Y}} x \cdot f_{X,Y}(x,y) \, \mathrm{d}y \, \mathrm{d}x + \int_{\mathcal{X}} \int_{\mathcal{Y}} y \cdot f_{X,Y}(x,y) \, \mathrm{d}y \, \mathrm{d}x \\
&= \int_{\mathcal{X}} x \int_{\mathcal{Y}} f_{X,Y}(x,y) \, \mathrm{d}y \, \mathrm{d}x + \int_{\mathcal{Y}} y \int_{\mathcal{X}} f_{X,Y}(x,y) \, \mathrm{d}x \, \mathrm{d}y \\
&\overset{\eqref{eq:mean-lin-lmp-cont}}{=} \int_{\mathcal{X}} x \cdot f_X(x) \, \mathrm{d}x + \int_{\mathcal{Y}} y \cdot f_Y(y) \, \mathrm{d}y \\
&\overset{\eqref{eq:mean-lin-mean-cont}}{=} \mathrm{E}(X) + \mathrm{E}(Y)
\end{split}
\end{equation}

as well as

\begin{equation} \label{eq:mean-lin-mean-lin-s2-cont}
\begin{split}
\mathrm{E}(a\,X) &= \int_{\mathcal{X}} a \, x \cdot f_X(x) \, \mathrm{d}x \\
&= a \int_{\mathcal{X}} x \cdot f_X(x) \, \mathrm{d}x \\
&\overset{\eqref{eq:mean-lin-mean-cont}}{=} a \, \mathrm{E}(X) \; .
\end{split}
\end{equation}

\vspace{1em}
Collectively, this shows that both requirements for linearity are fulfilled for the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}), for discrete ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar-disc}) as well as for continuous ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar-disc}) random variables.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Expected value"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-02-13; URL: \url{https://en.wikipedia.org/wiki/Expected_value#Basic_properties}.
\item Michael B, Kuldeep Guha Mazumder, Geoff Pilling et al. (2020): "Linearity of Expectation"; in: \textit{brilliant.org}, retrieved on 2020-02-13; URL: \url{https://brilliant.org/wiki/linearity-of-expectation/}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P53 | shortcut: mean-lin | author: JoramSoch | date: 2020-02-13, 21:08.
\vspace{1em}



\subsubsection[\textbf{Monotonicity}]{Monotonicity} \label{sec:mean-mono}
\setcounter{equation}{0}

\textbf{Theorem:} The expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) is monotonic, i.e.

\begin{equation} \label{eq:mean-mono-mean-mono}
\mathrm{E}(X) \leq \mathrm{E}(Y), \quad \text{if} \quad X \leq Y \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} Let $Z = Y - X$. Due to the linearity of the expected value ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-lin}), we have

\begin{equation} \label{eq:mean-mono-mean-XYZ}
\mathrm{E}(Z) = \mathrm{E}(Y-X) = \mathrm{E}(Y) - \mathrm{E}(X) \; .
\end{equation}

With the non-negativity property of the expected value ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-nonneg}), it also holds that

\begin{equation} \label{eq:mean-mono-mean-Z}
Z \geq 0 \quad \Rightarrow \quad \mathrm{E}(Z) \geq 0 \; .
\end{equation}

Together with \eqref{eq:mean-mono-mean-XYZ}, this yields

\begin{equation} \label{eq:mean-mono-mean-mono-qed}
\mathrm{E}(Y) - \mathrm{E}(X) \geq 0 \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Expected value"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-02-17; URL: \url{https://en.wikipedia.org/wiki/Expected_value#Basic_properties}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P54 | shortcut: mean-mono | author: JoramSoch | date: 2020-02-17, 21:00.
\vspace{1em}



\subsubsection[\textbf{(Non-)Multiplicativity}]{(Non-)Multiplicativity} \label{sec:mean-mult}
\setcounter{equation}{0}

\textbf{Theorem:}

1) If two random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X$ and $Y$ are independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}), the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) is multiplicative, i.e.

\begin{equation} \label{eq:mean-mult-mean-mult}
\mathrm{E}(X\,Y) = \mathrm{E}(X) \, \mathrm{E}(Y) \; .
\end{equation}

2) If two random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X$ and $Y$ are dependent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}), the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) is not necessarily multiplicative, i.e. there exist $X$ and $Y$ such that

\begin{equation} \label{eq:mean-mult-mean-nonmult}
\mathrm{E}(X\,Y) \neq \mathrm{E}(X) \, \mathrm{E}(Y) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:}

1) If $X$ and $Y$ are independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}), it holds that

\begin{equation} \label{eq:mean-mult-ind}
p(x,y) = p(x) \, p(y) \quad \text{for all} \quad x \in \mathcal{X}, y \in \mathcal{Y} \; .
\end{equation}

Applying this to the expected value for discrete random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}), we have

\begin{equation} \label{eq:mean-mult-mean-mult-disc}
\begin{split}
\mathrm{E}(X\,Y) &= \sum_{x \in \mathcal{X}} \sum_{y \in \mathcal{Y}} (x \cdot y) \cdot f_{X,Y}(x,y) \\
&\overset{\eqref{eq:mean-mult-ind}}{=} \sum_{x \in \mathcal{X}} \sum_{y \in \mathcal{Y}} (x \cdot y) \cdot \left( f_X(x) \cdot f_Y(y) \right) \\
&= \sum_{x \in \mathcal{X}} x \cdot f_X(x) \, \sum_{y \in \mathcal{Y}} y \cdot f_Y(y) \\
&= \sum_{x \in \mathcal{X}} x \cdot f_X(x) \cdot \mathrm{E}(Y) \\
&= \mathrm{E}(X) \, \mathrm{E}(Y) \; . \\
\end{split}
\end{equation}

And applying it to the expected value for continuous random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}), we have

\begin{equation} \label{eq:mean-mult-mean-mult-cont}
\begin{split}
\mathrm{E}(X\,Y) &= \int_{\mathcal{X}} \int_{\mathcal{Y}} (x \cdot y) \cdot f_{X,Y}(x,y) \, \mathrm{d}y \, \mathrm{d}x \\
&\overset{\eqref{eq:mean-mult-ind}}{=} \int_{\mathcal{X}} \int_{\mathcal{Y}} (x \cdot y) \cdot \left( f_X(x) \cdot f_Y(y) \right) \, \mathrm{d}y \, \mathrm{d}x \\
&= \int_{\mathcal{X}} x \cdot f_X(x) \, \int_{\mathcal{Y}} y \cdot f_Y(y)  \, \mathrm{d}y \, \mathrm{d}x \\
&= \int_{\mathcal{X}} x \cdot f_X(x) \cdot \mathrm{E}(Y) \, \mathrm{d}x \\
&= \mathrm{E}(X) \, \mathrm{E}(Y) \; . \\
\end{split}
\end{equation}

\vspace{1em}
2) Let $X$ and $Y$ be Bernoulli random variables ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:bern}) with the following joint probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf})

\begin{equation} \label{eq:mean-mult-joint}
\begin{split}
p(X=0, Y=0) &= 1/2 \\
p(X=0, Y=1) &= 0 \\
p(X=1, Y=0) &= 0 \\
p(X=1, Y=1) &= 1/2
\end{split}
\end{equation}

and thus, the following marginal probabilities:

\begin{equation} \label{eq:mean-mult-marg}
\begin{split}
p(X=0) = p(X=1) &= 1/2 \\
p(Y=0) = p(Y=1) &= 1/2 \; .
\end{split}
\end{equation}

Then, $X$ and $Y$ are dependent, because

\begin{equation} \label{eq:mean-mult-dep}
p(X=0, Y=1) \overset{\eqref{eq:mean-mult-joint}}{=} 0 \neq \frac{1}{2} \cdot \frac{1}{2} \overset{\eqref{eq:mean-mult-marg}}{=} p(X=0) \, p(Y=1) \; ,
\end{equation}

and the expected value of their product is

\begin{equation} \label{eq:mean-mult-mean-prod}
\begin{split}
\mathrm{E}(X\,Y) &= \sum_{x \in \left\lbrace 0,1 \right\rbrace} \sum_{y \in \left\lbrace 0,1 \right\rbrace} (x \cdot y) \cdot p(x,y) \\
&= (1 \cdot 1) \cdot p(X=1, Y=1) \\
&\overset{\eqref{eq:mean-mult-joint}}{=} \frac{1}{2}
\end{split}
\end{equation}

while the product of their expected values is

\begin{equation} \label{eq:mean-mult-prod-mean}
\begin{split}
\mathrm{E}(X) \, \mathrm{E}(Y) &= \left( \sum_{x \in \left\lbrace 0,1 \right\rbrace} x \cdot p(x) \right) \cdot \left( \sum_{y \in \left\lbrace 0,1 \right\rbrace} y \cdot p(y) \right) \\
&= \left( 1 \cdot p(X=1) \right) \cdot \left( 1 \cdot p(Y=1) \right) \\
&\overset{\eqref{eq:mean-mult-marg}}{=} \frac{1}{4}
\end{split}
\end{equation}

and thus,

\begin{equation} \label{eq:mean-mult-mean-nonmult-qed}
\mathrm{E}(X\,Y) \neq \mathrm{E}(X) \, \mathrm{E}(Y) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Expected value"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-02-17; URL: \url{https://en.wikipedia.org/wiki/Expected_value#Basic_properties}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P55 | shortcut: mean-mult | author: JoramSoch | date: 2020-02-17, 21:51.
\vspace{1em}



\subsubsection[\textbf{Expectation of a trace}]{Expectation of a trace} \label{sec:mean-tr}
\setcounter{equation}{0}

\textbf{Theorem:} Let $A$ be an $n \times n$ random matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rmat}). Then, the expectation ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of the trace of $A$ is equal to the trace of the expectation ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of $A$:

\begin{equation} \label{eq:mean-tr-mean-tr}
\mathrm{E}\left[ \mathrm{tr}(A) \right] = \mathrm{tr}\left( \mathrm{E}[A] \right) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The trace of an $n \times n$ matrix $A$ is defined as:

\begin{equation} \label{eq:mean-tr-tr}
\mathrm{tr}(A) = \sum_{i=1}^{n} a_{ii} \; .
\end{equation}

Using this definition of the trace, the linearity of the expected value ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-lin}) and the expected value of a random matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean-rmat}), we have:

\begin{equation} \label{eq:mean-tr-mean-tr-qed}
\begin{split}
\mathrm{E}\left[ \mathrm{tr}(A) \right] &= \mathrm{E}\left[ \sum_{i=1}^{n} a_{ii} \right] \\
&= \sum_{i=1}^{n} \mathrm{E}\left[ a_{ii} \right] \\
&= \mathrm{tr}\left( \left[ \begin{matrix} \mathrm{E}[a_{11}] & \ldots & \mathrm{E}[a_{1n}] \\ \vdots & \ddots & \vdots \\ \mathrm{E}[a_{n1}] & \ldots & \mathrm{E}[a_{nn}] \end{matrix} \right] \right) \\
&= \mathrm{tr}\left( \mathrm{E}[A] \right) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item drerD (2018): "'Trace trick' for expectations of quadratic forms"; in: \textit{StackExchange Mathematics}, retrieved on 2021-12-07; URL: \url{https://math.stackexchange.com/a/3004034/480910}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P298 | shortcut: mean-tr | author: JoramSoch | date: 2021-12-07, 09:03.
\vspace{1em}



\subsubsection[\textbf{Expectation of a quadratic form}]{Expectation of a quadratic form} \label{sec:mean-qf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be an $n \times 1$ random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}) with mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) $\mu$ and covariance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cov}) $\Sigma$ and let $A$ be a symmetric $n \times n$ matrix. Then, the expectation of the quadratic form $X^\mathrm{T} A X$ is

\begin{equation} \label{eq:mean-qf-mean-qf}
\mathrm{E}\left[ X^\mathrm{T} A X \right] = \mu^\mathrm{T} A \mu + \mathrm{tr}(A \Sigma) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} Note that $X^\mathrm{T} A X$ is a $1 \times 1$ matrix. We can therefore write

\begin{equation} \label{eq:mean-qf-mean-qf-s1}
\mathrm{E}\left[ X^\mathrm{T} A X \right] =  \mathrm{E}\left[ \mathrm{tr} \left( X^\mathrm{T} A X \right) \right] \; .
\end{equation}

Using the trace property $\mathrm{tr}(ABC) = \mathrm{tr}(BCA)$, this becomes

\begin{equation} \label{eq:mean-qf-mean-qf-s2}
\mathrm{E}\left[ X^\mathrm{T} A X \right] =  \mathrm{E}\left[ \mathrm{tr} \left( A X X^\mathrm{T} \right) \right] \; .
\end{equation}

Because mean and trace are linear operators ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-tr}), we have

\begin{equation} \label{eq:mean-qf-mean-qf-s3}
\mathrm{E}\left[ X^\mathrm{T} A X \right] =  \mathrm{tr} \left( A \; \mathrm{E}\left[ X X^\mathrm{T} \right] \right) \; .
\end{equation}

Note that the covariance matrix can be partitioned into expected values ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:covmat-mean})

\begin{equation} \label{eq:mean-qf-covmat-mean}
\mathrm{Cov}(X,X) = \mathrm{E}(X X^\mathrm{T}) - \mathrm{E}(X) \mathrm{E}(X)^\mathrm{T} \; ,
\end{equation}

such that the expected value of the quadratic form becomes

\begin{equation} \label{eq:mean-qf-mean-qf-s4}
\mathrm{E}\left[ X^\mathrm{T} A X \right] =  \mathrm{tr} \left( A \left[ \mathrm{Cov}(X,X) + \mathrm{E}(X) \mathrm{E}(X)^\mathrm{T} \right] \right) \; .
\end{equation}

Finally, applying mean and covariance of $X$, we have

\begin{equation} \label{eq:mean-qf-mean-qf-s5}
\begin{split}
\mathrm{E}\left[ X^\mathrm{T} A X \right] &= \mathrm{tr} \left( A \left[ \Sigma + \mu \mu^\mathrm{T} \right] \right) \\
&= \mathrm{tr} \left( A \Sigma + A \mu \mu^\mathrm{T} \right) \\
&= \mathrm{tr}(A \Sigma) + \mathrm{tr}(A \mu \mu^\mathrm{T}) \\
&= \mathrm{tr}(A \Sigma) + \mathrm{tr}(\mu^\mathrm{T} A \mu) \\
&= \mu^\mathrm{T} A \mu + \mathrm{tr}(A \Sigma) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Kendrick, David (1981): "Expectation of a quadratic form"; in: \textit{Stochastic Control for Economic Models}, pp. 170-171.
\item Wikipedia (2020): "Multivariate random variable"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-07-13; URL: \url{https://en.wikipedia.org/wiki/Multivariate_random_variable#Expectation_of_a_quadratic_form}.
\item Halvorsen, Kjetil B. (2012): "Expected value and variance of trace function"; in: \textit{StackExchange CrossValidated}, retrieved on 2020-07-13; URL: \url{https://stats.stackexchange.com/questions/34477/expected-value-and-variance-of-trace-function}.
\item Sarwate, Dilip (2013): "Expected Value of Quadratic Form"; in: \textit{StackExchange CrossValidated}, retrieved on 2020-07-13; URL: \url{https://stats.stackexchange.com/questions/48066/expected-value-of-quadratic-form}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P131 | shortcut: mean-qf | author: JoramSoch | date: 2020-07-13, 21:59.
\vspace{1em}



\subsubsection[\textbf{Law of total expectation}]{Law of total expectation} \label{sec:mean-tot}
\setcounter{equation}{0}

\textbf{Theorem:} (law of total expectation, also called "law of iterated expectations") Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) $\mathrm{E}(X)$ and let $Y$ be any random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) defined on the same probability space ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-spc}). Then, the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of the conditional expectation ($\rightarrow$ Definition "mean-cond") of $X$ given $Y$ is the same as the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of $X$:

\begin{equation} \label{eq:mean-tot-mean-tot}
\mathrm{E}(X) = \mathrm{E}[\mathrm{E}(X \vert Y)] \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} Let $X$ and $Y$ be discrete random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar-disc}) with sets of possible outcomes $\mathcal{X}$ and $\mathcal{Y}$. Then, the expectation of the conditional expetectation can be rewritten as:

\begin{equation} \label{eq:mean-tot-mean-tot-s1}
\begin{split}
\mathrm{E}[\mathrm{E}(X \vert Y)] &= \mathrm{E}\left[ \sum_{x \in \mathcal{X}} x \cdot \mathrm{Pr}(X = x \vert Y) \right] \\
&= \sum_{y \in \mathcal{Y}} \left[ \sum_{x \in \mathcal{X}} x \cdot \mathrm{Pr}(X = x \vert Y = y) \right] \cdot \mathrm{Pr}(Y = y) \\
&= \sum_{x \in \mathcal{X}} \sum_{y \in \mathcal{Y}} x \cdot \mathrm{Pr}(X = x \vert Y = y) \cdot \mathrm{Pr}(Y = y) \; .
\end{split}
\end{equation}

Using the law of conditional probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-cond}), this becomes:

\begin{equation} \label{eq:mean-tot-mean-tot-s2}
\begin{split}
\mathrm{E}[\mathrm{E}(X \vert Y)] &= \sum_{x \in \mathcal{X}} \sum_{y \in \mathcal{Y}} x \cdot \mathrm{Pr}(X = x, Y = y) \\
&= \sum_{x \in \mathcal{X}} x \sum_{y \in \mathcal{Y}} \mathrm{Pr}(X = x, Y = y) \; .
\end{split}
\end{equation}

Using the law of marginal probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}), this becomes:

\begin{equation} \label{eq:mean-tot-mean-tot-s3}
\begin{split}
\mathrm{E}[\mathrm{E}(X \vert Y)] &= \sum_{x \in \mathcal{X}} x \cdot \mathrm{Pr}(X = x) \\
&= \mathrm{E}(X) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Law of total expectation"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-11-26; URL: \url{https://en.wikipedia.org/wiki/Law_of_total_expectation#Proof_in_the_finite_and_countable_cases}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P291 | shortcut: mean-tot | author: JoramSoch | date: 2021-11-26, 10:57.
\vspace{1em}



\subsubsection[\textbf{Law of the unconscious statistician}]{Law of the unconscious statistician} \label{sec:mean-lotus}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) and let $Y = g(X)$ be a function of this random variable.

1) If $X$ is a discrete random variable with possible outcomes $\mathcal{X}$ and probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) $f_X(x)$, the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of $g(X)$ is

\begin{equation} \label{eq:mean-lotus-mean-lotus-disc}
\mathrm{E}[g(X)] = \sum_{x \in \mathcal{X}} g(x) f_X(x) \; .
\end{equation}

2) If $X$ is a continuous random variable with possible outcomes $\mathcal{X}$ and probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) $f_X(x)$, the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of $g(X)$ is

\begin{equation} \label{eq:mean-lotus-mean-lotus-cont}
\mathrm{E}[g(X)] = \int_{\mathcal{X}} g(x) f_X(x) \, \mathrm{d}x \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} Suppose that $g$ is differentiable and that its inverse $g^{-1}$ is monotonic.

1) The expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of $Y = g(X)$ is defined as

\begin{equation} \label{eq:mean-lotus-mean-lotus-disc-s1}
\mathrm{E}[Y] = \sum_{y \in \mathcal{Y}} y \, f_Y(y) \; .
\end{equation}

Writing the probability mass function $f_Y(y)$ in terms of $y = g(x)$, we have:

\begin{equation} \label{eq:mean-lotus-mean-lotus-disc-s2}
\begin{split}
\mathrm{E}[g(X)] &= \sum_{y \in \mathcal{Y}} y \, \mathrm{Pr}(g(x) = y) \\
&= \sum_{y \in \mathcal{Y}} y \, \mathrm{Pr}(x = g^{-1}(y)) \\
&= \sum_{y \in \mathcal{Y}} y \sum_{x = g^{-1}(y)} f_X(x) \\
&= \sum_{y \in \mathcal{Y}} \sum_{x = g^{-1}(y)} y f_X(x) \\
&= \sum_{y \in \mathcal{Y}} \sum_{x = g^{-1}(y)} g(x) f_X(x) \; .
\end{split}
\end{equation}

Finally, noting that "for all $y$, then for all $x = g^{-1}(y)$" is equivalent to "for all $x$" if $g^{-1}$ is a monotonic function, we can conclude that

\begin{equation} \label{eq:mean-lotus-mean-lotus-disc-s3}
\mathrm{E}[g(X)] = \sum_{x \in \mathcal{X}} g(x) f_X(x) \; .
\end{equation}

\vspace{1em}
2) Let $y = g(x)$. The derivative of an inverse function is

\begin{equation} \label{eq:mean-lotus-der-inv}
\frac{\mathrm{d}}{\mathrm{d}y} (g^{-1}(y)) = \frac{1}{g'(g^{-1}(y))}
\end{equation}

Because $x = g^{-1}(y)$, this can be rearranged into

\begin{equation} \label{eq:mean-lotus-dx-dy}
\mathrm{d}x = \frac{1}{g'(g^{-1}(y))} \, \mathrm{d}y
\end{equation}

and subsitituing \eqref{eq:mean-lotus-dx-dy} into \eqref{eq:mean-lotus-mean-lotus-cont}, we get

\begin{equation} \label{eq:mean-lotus-mean-lotus-cont-s1}
\int_{\mathcal{X}} g(x) f_X(x) \, \mathrm{d}x = \int_{\mathcal{Y}} y \, f_X(g^{-1}(y)) \, \frac{1}{g'(g^{-1}(y))} \, \mathrm{d}y \; .
\end{equation}

Considering the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) of $Y$, one can deduce:

\begin{equation} \label{eq:mean-lotus-Y-cdf}
\begin{split}
F_Y(y) &= \mathrm{Pr}(Y \leq y) \\
&= \mathrm{Pr}(g(X) \leq y) \\
&= \mathrm{Pr}(X \leq g^{-1}(y)) \\
&= F_X(g^{-1}(y)) \; .
\end{split}
\end{equation}

Differentiating to get the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $Y$, the result is:

\begin{equation} \label{eq:mean-lotus-Y-pdf}
\begin{split}
f_Y(y) &= \frac{\mathrm{d}}{\mathrm{d}y} F_Y(y) \\
&\overset{\eqref{eq:mean-lotus-Y-cdf}}{=} \frac{\mathrm{d}}{\mathrm{d}y} F_X(g^{-1}(y)) \\
&= f_X(g^{-1}(y)) \, \frac{\mathrm{d}}{\mathrm{d}y} (g^{-1}(y)) \\
&\overset{\eqref{eq:mean-lotus-der-inv}}{=} f_X(g^{-1}(y)) \, \frac{1}{g'(g^{-1}(y))} \; .
\end{split}
\end{equation}

Finally, substituing \eqref{eq:mean-lotus-Y-pdf} into \eqref{eq:mean-lotus-mean-lotus-cont-s1}, we have:

\begin{equation} \label{eq:mean-lotus-mean-lotus-cont-s2}
\int_{\mathcal{X}} g(x) f_X(x) \, \mathrm{d}x = \int_{\mathcal{Y}} y \, f_Y(y) \, \mathrm{d}y = \mathrm{E}[Y] = \mathrm{E}[g(X)] \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Law of the unconscious statistician"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-07-22; URL: \url{https://en.wikipedia.org/wiki/Law_of_the_unconscious_statistician#Proof}.
\item Taboga, Marco (2017): "Transformation theorem"; in: \textit{Lectures on probability and mathematical statistics}, retrieved on 2021-09-22; URL: \url{https://www.statlect.com/glossary/transformation-theorem}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P138 | shortcut: mean-lotus | author: JoramSoch | date: 2020-07-22, 08:30.
\vspace{1em}



\subsubsection[\textit{Expected value of a random vector}]{Expected value of a random vector} \label{sec:mean-rvec}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be an $n \times 1$ random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}). Then, the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of $X$ is an $n \times 1$ vector whose entries correspond to the expected values of the entries of the random vector:

\begin{equation} \label{eq:mean-rvec-mean-rvec}
\mathrm{E}(X) = \mathrm{E}\left( \left[ \begin{array}{c} X_1 \\ \vdots \\ X_n \end{array} \right] \right) = \left[ \begin{array}{c} \mathrm{E}(X_1) \\ \vdots \\ \mathrm{E}(X_n) \end{array} \right] \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Taboga, Marco (2017): "Expected value"; in: \textit{Lectures on probability theory and mathematical statistics}, retrieved on 2021-07-08; URL: \url{https://www.statlect.com/fundamentals-of-probability/expected-value#hid12}.
\item Wikipedia (2021): "Multivariate random variable"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-07-08; URL: \url{https://en.wikipedia.org/wiki/Multivariate_random_variable#Expected_value}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D154 | shortcut: mean-rvec | author: JoramSoch | date: 2021-07-08, 08:34.
\vspace{1em}



\subsubsection[\textit{Expected value of a random matrix}]{Expected value of a random matrix} \label{sec:mean-rmat}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be an $n \times p$ random matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rmat}). Then, the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of $X$ is an $n \times p$ matrix whose entries correspond to the expected values of the entries of the random matrix:

\begin{equation} \label{eq:mean-rmat-mean-rmat}
\mathrm{E}(X) = \mathrm{E}\left( \left[ \begin{array}{ccc} X_{11} & \ldots & X_{1p} \\ \vdots & \ddots & \vdots \\ X_{n1} & \ldots & X_{np} \end{array} \right] \right) = \left[ \begin{array}{ccc} \mathrm{E}(X_{11}) & \ldots & \mathrm{E}(X_{1p}) \\ \vdots & \ddots & \vdots \\ \mathrm{E}(X_{n1}) & \ldots & \mathrm{E}(X_{np}) \end{array} \right] \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Taboga, Marco (2017): "Expected value"; in: \textit{Lectures on probability theory and mathematical statistics}, retrieved on 2021-07-08; URL: \url{https://www.statlect.com/fundamentals-of-probability/expected-value#hid13}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D155 | shortcut: mean-rmat | author: JoramSoch | date: 2021-07-08, 08:42.
\vspace{1em}



\subsection{Variance}

\subsubsection[\textit{Definition}]{Definition} \label{sec:var}
\setcounter{equation}{0}

\textbf{Definition:} The variance of a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X$ is defined as the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of the squared deviation from its expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}):

\begin{equation} \label{eq:var-var}
\mathrm{Var}(X) = \mathrm{E}\left[ (X-\mathrm{E}(X))^2 \right] \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Variance"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-02-13; URL: \url{https://en.wikipedia.org/wiki/Variance#Definition}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D12 | shortcut: var | author: JoramSoch | date: 2020-02-13, 19:55.
\vspace{1em}



\subsubsection[\textit{Sample variance}]{Sample variance} \label{sec:var-samp}
\setcounter{equation}{0}

\textbf{Definition:} Let $x = \left\lbrace x_1, \ldots, x_n \right\rbrace$ be a sample ($\rightarrow$ Definition "samp") from a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X$. Then, the sample variance of $x$ is given by

\begin{equation} \label{eq:var-samp-var-samp}
\hat{\sigma}^2 = \frac{1}{n} \sum_{i=1}^{n} (x_i - \bar{x})^2
\end{equation}

and the unbiased sample variance of $x$ is given by

\begin{equation} \label{eq:var-samp-var-samp-unb}
s^2 = \frac{1}{n-1} \sum_{i=1}^{n} (x_i - \bar{x})^2
\end{equation}

where $\bar{x}$ is the sample mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean-samp}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Variance"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-04-16; URL: \url{https://en.wikipedia.org/wiki/Variance#Sample_variance}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D143 | shortcut: var-samp | author: JoramSoch | date: 2021-04-16, 12:04.
\vspace{1em}



\subsubsection[\textbf{Partition into expected values}]{Partition into expected values} \label{sec:var-mean}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}). Then, the variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) of $X$ is equal to the mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of the square of $X$ minus the square of the mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of $X$:

\begin{equation} \label{eq:var-mean-var-mean}
\mathrm{Var}(X) = \mathrm{E}(X^2) - \mathrm{E}(X)^2 \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) of $X$ is defined as

\begin{equation} \label{eq:var-mean-var}
\mathrm{Var}(X) = \mathrm{E}\left[ \left( X - \mathrm{E}[X] \right)^2 \right]
\end{equation}

which, due to the linearity of the expected value ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-lin}), can be rewritten as

\begin{equation} \label{eq:var-mean-var-mean-qed}
\begin{split}
\mathrm{Var}(X) &= \mathrm{E}\left[ \left( X - \mathrm{E}[X] \right)^2 \right] \\
&= \mathrm{E}\left[ X^2 - 2 \, X \, \mathrm{E}(X) + \mathrm{E}(X)^2 \right] \\
&= \mathrm{E}(X^2) - 2 \, \mathrm{E}(X) \, \mathrm{E}(X) + \mathrm{E}(X)^2 \\
&= \mathrm{E}(X^2) - \mathrm{E}(X)^2 \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Variance"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-05-19; URL: \url{https://en.wikipedia.org/wiki/Variance#Definition}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P104 | shortcut: var-mean | author: JoramSoch | date: 2020-05-19, 00:17.
\vspace{1em}



\subsubsection[\textbf{Non-negativity}]{Non-negativity} \label{sec:var-nonneg}
\setcounter{equation}{0}

\textbf{Theorem:} The variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) is always non-negative, i.e.

\begin{equation} \label{eq:var-nonneg-var-nonneg}
\mathrm{Var}(X) \geq 0 \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) of a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) is defined as

\begin{equation} \label{eq:var-nonneg-var}
\mathrm{Var}(X) = \mathrm{E}\left[ (X-\mathrm{E}(X))^2 \right] \; .
\end{equation}

\vspace{1em}
1) If $X$ is a discrete random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}), then, because squares and probabilities are stricly non-negative, all the addends in

\begin{equation} \label{eq:var-nonneg-var-disc}
\mathrm{Var}(X) = \sum_{x \in \mathcal{X}} (x-\mathrm{E}(X))^2 \cdot f_X(x)
\end{equation}

are also non-negative, thus the entire sum must be non-negative.

\vspace{1em}
2) If $X$ is a continuous random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}), then, because squares and probability densities are strictly non-negative, the integrand in

\begin{equation} \label{eq:var-nonneg-var-cont}
\mathrm{Var}(X) = \int_{\mathcal{X}} (x-\mathrm{E}(X))^2 \cdot f_X(x) \, \mathrm{d}x
\end{equation}

is always non-negative, thus the term on the right-hand side is a Lebesgue integral, so that the result on the left-hand side must be non-negative.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Variance"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-06-06; URL: \url{https://en.wikipedia.org/wiki/Variance#Basic_properties}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P123 | shortcut: var-nonneg | author: JoramSoch | date: 2020-06-06, 07:29.
\vspace{1em}



\subsubsection[\textbf{Variance of a constant}]{Variance of a constant} \label{sec:var-const}
\setcounter{equation}{0}

\textbf{Theorem:} The variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) of a constant ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:const}) is zero

\begin{equation} \label{eq:var-const-var-const}
a = \text{const.} \quad \Rightarrow \quad \mathrm{Var}(a) = 0
\end{equation}

and if the variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) of $X$ is zero, then $X$ is a constant ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:const})

\begin{equation} \label{eq:var-const-var-zero}
\mathrm{Var}(X) = 0 \quad \Rightarrow \quad X = \text{const.}
\end{equation}


\vspace{1em}
\textbf{Proof:}

1) A constant ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:const}) is defined as a quantity that always has the same value. Thus, if understood as a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}), the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of a constant is equal to itself:

\begin{equation} \label{eq:var-const-mean-const}
\mathrm{E}(a) = a \; .
\end{equation}

Plugged into the formula of the variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}), we have

\begin{equation} \label{eq:var-const-var-const-s1}
\begin{split}
\mathrm{Var}(a) &= \mathrm{E}\left[ (a-\mathrm{E}(a))^2 \right] \\
&= \mathrm{E}\left[ (a-a)^2 \right] \\
&= \mathrm{E}(0) \; .
\end{split}
\end{equation}

Applied to the formula of the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}), this gives

\begin{equation} \label{eq:var-const-var-const-s2}
\mathrm{E}(0) = \sum_{x=0} x \cdot f_X(x) = 0 \cdot 1 = 0 \; .
\end{equation}

Together, \eqref{eq:var-const-var-const-s1} and \eqref{eq:var-const-var-const-s2} imply \eqref{eq:var-const-var-const}.

\vspace{1em}

2) The variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) is defined as

\begin{equation} \label{eq:var-const-var}
\mathrm{Var}(X) = \mathrm{E}\left[ (X-\mathrm{E}(X))^2 \right] \; .
\end{equation}

Because $(X-\mathrm{E}(X))^2$ is strictly non-negative ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-nonneg}), the only way for the variance to become zero is, if the squared deviation is always zero:

\begin{equation} \label{eq:var-const-sqr-dev-zero}
(X-\mathrm{E}(X))^2 = 0 \; .
\end{equation}

This, in turn, requires that $X$ is equal to its expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean})

\begin{equation} \label{eq:var-const-X-eq-E-X}
X = \mathrm{E}(X)
\end{equation}

which can only be the case, if $X$ always has the same value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:const}):

\begin{equation} \label{eq:var-const-X-const}
X = \text{const.}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Variance"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-06-27; URL: \url{https://en.wikipedia.org/wiki/Variance#Basic_properties}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P124 | shortcut: var-const | author: JoramSoch | date: 2020-06-27, 06:44.
\vspace{1em}



\subsubsection[\textbf{Invariance under addition}]{Invariance under addition} \label{sec:var-inv}
\setcounter{equation}{0}

\textbf{Theorem:} The variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) is invariant under addition of a constant ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:const}):

\begin{equation} \label{eq:var-inv-var-inv}
\mathrm{Var}(X+a) = \mathrm{Var}(X)
\end{equation}


\vspace{1em}
\textbf{Proof:} The variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) is defined in terms of the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) as

\begin{equation} \label{eq:var-inv-var}
\mathrm{Var}(X) = \mathrm{E}\left[ (X-\mathrm{E}(X))^2 \right] \; .
\end{equation}

Using this and the linearity of the expected value ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-lin}), we can derive \eqref{eq:var-inv-var-inv} as follows:

\begin{equation} \label{eq:var-inv-var-inv-qed}
\begin{split}
\mathrm{Var}(X+a) &\overset{\eqref{eq:var-inv-var}}{=} \mathrm{E}\left[ ((X+a)-\mathrm{E}(X+a))^2 \right] \\
&= \mathrm{E}\left[ (X + a - \mathrm{E}(X) - a)^2 \right] \\
&= \mathrm{E}\left[ (X-\mathrm{E}(X))^2 \right] \\
&\overset{\eqref{eq:var-inv-var}}{=} \mathrm{Var}(X) \; . \\
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Variance"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-07-07; URL: \url{https://en.wikipedia.org/wiki/Variance#Basic_properties}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P126 | shortcut: var-inv | author: JoramSoch | date: 2020-07-07, 05:23.
\vspace{1em}



\subsubsection[\textbf{Scaling upon multiplication}]{Scaling upon multiplication} \label{sec:var-scal}
\setcounter{equation}{0}

\textbf{Theorem:} The variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) scales upon multiplication with a constant ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:const}):

\begin{equation} \label{eq:var-scal-var-scal}
\mathrm{Var}(aX) = a^2 \, \mathrm{Var}(X)
\end{equation}


\vspace{1em}
\textbf{Proof:} The variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) is defined in terms of the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) as

\begin{equation} \label{eq:var-scal-var}
\mathrm{Var}(X) = \mathrm{E}\left[ (X-\mathrm{E}(X))^2 \right] \; .
\end{equation}

Using this and the linearity of the expected value ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-lin}), we can derive \eqref{eq:var-scal-var-scal} as follows:

\begin{equation} \label{eq:var-scal-var-scal-qed}
\begin{split}
\mathrm{Var}(aX) &\overset{\eqref{eq:var-scal-var}}{=} \mathrm{E}\left[ ((aX)-\mathrm{E}(aX))^2 \right] \\
&= \mathrm{E}\left[ (aX - a\mathrm{E}(X))^2 \right] \\
&= \mathrm{E}\left[ (a [X - \mathrm{E}(X)])^2 \right] \\
&= \mathrm{E}\left[ a^2 (X - \mathrm{E}(X))^2 \right] \\
&= a^2 \, \mathrm{E}\left[ (X - \mathrm{E}(X))^2 \right] \\
&\overset{\eqref{eq:var-scal-var}}{=} a^2 \, \mathrm{Var}(X) \; . \\
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Variance"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-07-07; URL: \url{https://en.wikipedia.org/wiki/Variance#Basic_properties}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P127 | shortcut: var-scal | author: JoramSoch | date: 2020-07-07, 05:38.
\vspace{1em}



\subsubsection[\textbf{Variance of a sum}]{Variance of a sum} \label{sec:var-sum}
\setcounter{equation}{0}

\textbf{Theorem:} The variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) of the sum of two random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) equals the sum of the variances of those random variables, plus two times their covariance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cov}):

\begin{equation} \label{eq:var-sum-var-sum}
\mathrm{Var}(X+Y) = \mathrm{Var}(X) + \mathrm{Var}(Y) + 2 \, \mathrm{Cov}(X,Y) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) is defined in terms of the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) as

\begin{equation} \label{eq:var-sum-var}
\mathrm{Var}(X) = \mathrm{E}\left[ (X-\mathrm{E}(X))^2 \right] \; .
\end{equation}

Using this and the linearity of the expected value ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-lin}), we can derive \eqref{eq:var-sum-var-sum} as follows:

\begin{equation} \label{eq:var-sum-var-sum-qed}
\begin{split}
\mathrm{Var}(X+Y) &\overset{\eqref{eq:var-sum-var}}{=} \mathrm{E}\left[ ((X+Y)-\mathrm{E}(X+Y))^2 \right] \\
&= \mathrm{E}\left[ ([X-\mathrm{E}(X)] + [Y-\mathrm{E}(Y)])^2 \right] \\
&= \mathrm{E}\left[ (X-\mathrm{E}(X))^2 + (Y-\mathrm{E}(Y))^2 + 2 \, (X-\mathrm{E}(X)) (Y-\mathrm{E}(Y)) \right] \\
&= \mathrm{E}\left[ (X-\mathrm{E}(X))^2 \right] + \mathrm{E}\left[ (Y-\mathrm{E}(Y))^2 \right] + \mathrm{E}\left[ 2 \, (X-\mathrm{E}(X)) (Y-\mathrm{E}(Y)) \right] \\
&\overset{\eqref{eq:var-sum-var}}{=} \mathrm{Var}(X) + \mathrm{Var}(Y) + 2 \, \mathrm{Cov}(X,Y) \; . \\
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Variance"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-07-07; URL: \url{https://en.wikipedia.org/wiki/Variance#Basic_properties}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P128 | shortcut: var-sum | author: JoramSoch | date: 2020-07-07, 06:10.
\vspace{1em}



\subsubsection[\textbf{Variance of linear combination}]{Variance of linear combination} \label{sec:var-lincomb}
\setcounter{equation}{0}

\textbf{Theorem:} The variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) of the linear combination of two random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) is a function of the variances as well as the covariance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cov}) of those random variables:

\begin{equation} \label{eq:var-lincomb-var-lincomb}
\mathrm{Var}(aX+bY) = a^2 \, \mathrm{Var}(X) + b^2 \, \mathrm{Var}(Y) + 2ab \, \mathrm{Cov}(X,Y) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) is defined in terms of the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) as

\begin{equation} \label{eq:var-lincomb-var}
\mathrm{Var}(X) = \mathrm{E}\left[ (X-\mathrm{E}(X))^2 \right] \; .
\end{equation}

Using this and the linearity of the expected value ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-lin}), we can derive \eqref{eq:var-lincomb-var-lincomb} as follows:

\begin{equation} \label{eq:var-lincomb-var-lincomb-qed}
\begin{split}
\mathrm{Var}(aX+bY) &\overset{\eqref{eq:var-lincomb-var}}{=} \mathrm{E}\left[ ((aX+bY)-\mathrm{E}(aX+bY))^2 \right] \\
&= \mathrm{E}\left[ (a [X-\mathrm{E}(X)] + b [Y-\mathrm{E}(Y)])^2 \right] \\
&= \mathrm{E}\left[ a^2 \, (X-\mathrm{E}(X))^2 + b^2 \, (Y-\mathrm{E}(Y))^2 + 2ab \, (X-\mathrm{E}(X)) (Y-\mathrm{E}(Y)) \right] \\
&= \mathrm{E}\left[ a^2 \, (X-\mathrm{E}(X))^2 \right] + \mathrm{E}\left[ b^2 \, (Y-\mathrm{E}(Y))^2 \right] + \mathrm{E}\left[ 2ab \, (X-\mathrm{E}(X)) (Y-\mathrm{E}(Y)) \right] \\
&\overset{\eqref{eq:var-lincomb-var}}{=} a^2 \, \mathrm{Var}(X) + b^2 \, \mathrm{Var}(Y) + 2ab \, \mathrm{Cov}(X,Y) \; . \\
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Variance"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-07-07; URL: \url{https://en.wikipedia.org/wiki/Variance#Basic_properties}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P129 | shortcut: var-lincomb | author: JoramSoch | date: 2020-07-07, 06:21.
\vspace{1em}



\subsubsection[\textbf{Additivity under independence}]{Additivity under independence} \label{sec:var-add}
\setcounter{equation}{0}

\textbf{Theorem:} The variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) is additive for independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}) random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}):

\begin{equation} \label{eq:var-add-var-add}
p(X,Y) = p(X) \, p(Y) \quad \Rightarrow \quad \mathrm{Var}(X+Y) = \mathrm{Var}(X) + \mathrm{Var}(Y) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The variance of the sum of two random variables ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:var-sum}) is given by

\begin{equation} \label{eq:var-add-var-sum}
\mathrm{Var}(X+Y) = \mathrm{Var}(X) + \mathrm{Var}(Y) + 2 \, \mathrm{Cov}(X,Y) \; .
\end{equation}

The covariance of independent random variables ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:cov-ind}) is zero:

\begin{equation} \label{eq:var-add-cov-ind}
p(X,Y) = p(X) \, p(Y) \quad \Rightarrow \quad \mathrm{Cov}(X,Y) = 0 \; .
\end{equation}

Combining \eqref{eq:var-add-var-sum} and \eqref{eq:var-add-cov-ind}, we have:

\begin{equation} \label{eq:var-add-var-add-qed}
\mathrm{Var}(X+Y) = \mathrm{Var}(X) + \mathrm{Var}(Y) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Variance"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-07-07; URL: \url{https://en.wikipedia.org/wiki/Variance#Basic_properties}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P130 | shortcut: var-add | author: JoramSoch | date: 2020-07-07, 06:52.
\vspace{1em}



\subsubsection[\textbf{Law of total variance}]{Law of total variance} \label{sec:var-tot}
\setcounter{equation}{0}

\textbf{Theorem:} (law of total variance, also called "conditional variance formula") Let $X$ and $Y$ be random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) defined on the same probability space ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-spc}) and assume that the variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) of $Y$ is finite. Then, the sum of the expectation ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of the conditional variance and the variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) of the conditional expectation of $Y$ given $X$ is equal to the variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) of $Y$:

\begin{equation} \label{eq:var-tot-var-tot}
\mathrm{Var}(Y) = \mathrm{E}[\mathrm{Var}(Y \vert X)] + \mathrm{Var}[\mathrm{E}(Y \vert X)] \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The variance can be decomposed into expected values ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:var-mean}) as follows:

\begin{equation} \label{eq:var-tot-var-tot-s1}
\mathrm{Var}(Y) = \mathrm{E}(Y^2) - \mathrm{E}(Y)^2 \; .
\end{equation}

This can be rearranged into:

\begin{equation} \label{eq:var-tot-var-tot-s2}
\mathrm{E}(Y^2) = \mathrm{Var}(Y) + \mathrm{E}(Y)^2 \; .
\end{equation}

Applying the law of total expectation ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-tot}), we have:

\begin{equation} \label{eq:var-tot-var-tot-s3}
\mathrm{E}(Y^2) = \mathrm{E}\left[ \mathrm{Var}(Y \vert X) + \mathrm{E}(Y \vert X)^2 \right] \; .
\end{equation}

Now subtract the second term from \eqref{eq:var-tot-var-tot-s1}:

\begin{equation} \label{eq:var-tot-var-tot-s4}
\mathrm{E}(Y^2) - \mathrm{E}(Y)^2 = \mathrm{E}\left[ \mathrm{Var}(Y \vert X) + \mathrm{E}(Y \vert X)^2 \right] - \mathrm{E}(Y)^2 \; .
\end{equation}

Again applying the law of total expectation ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-tot}), we have:

\begin{equation} \label{eq:var-tot-var-tot-s5}
\mathrm{E}(Y^2) - \mathrm{E}(Y)^2 = \mathrm{E}\left[ \mathrm{Var}(Y \vert X) + \mathrm{E}(Y \vert X)^2 \right] - \mathrm{E}\left[ \mathrm{E}(Y \vert X) \right]^2 \; .
\end{equation}

With the linearity of the expected value ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-lin}), the terms can be regrouped to give:

\begin{equation} \label{eq:var-tot-var-tot-s6}
\mathrm{E}(Y^2) - \mathrm{E}(Y)^2 = \mathrm{E}\left[ \mathrm{Var}(Y \vert X) \right] + \left( \mathrm{E}\left[ \mathrm{E}(Y \vert X)^2 \right] - \mathrm{E}\left[ \mathrm{E}(Y \vert X) \right]^2 \right) \; .
\end{equation}

Using the decomposition of variance into expected values ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:var-mean}), we finally have:

\begin{equation} \label{eq:var-tot-var-tot-s7}
\mathrm{Var}(Y) = \mathrm{E}[\mathrm{Var}(Y \vert X)] + \mathrm{Var}[\mathrm{E}(Y \vert X)] \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Law of total variance"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-11-26; URL: \url{https://en.wikipedia.org/wiki/Law_of_total_variance#Proof}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P292 | shortcut: var-tot | author: JoramSoch | date: 2021-11-26, 11:20.
\vspace{1em}



\subsubsection[\textit{Precision}]{Precision} \label{sec:prec}
\setcounter{equation}{0}

\textbf{Definition:} The precision of a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X$ is defined as the inverse of the variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}), i.e. one divided by the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of the squared deviation from its expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}):

\begin{equation} \label{eq:prec-prec}
\mathrm{Prec}(X) = \mathrm{Var}(X)^{-1} = \frac{1}{\mathrm{E}\left[ (X-\mathrm{E}(X))^2 \right]} \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Precision (statistics)"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-04-21; URL: \url{https://en.wikipedia.org/wiki/Precision_(statistics)}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D145 | shortcut: prec | author: JoramSoch | date: 2020-04-21, 07:04.
\vspace{1em}



\subsection{Covariance}

\subsubsection[\textit{Definition}]{Definition} \label{sec:cov}
\setcounter{equation}{0}

\textbf{Definition:} The covariance of two random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X$ and $Y$ is defined as the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of the product of their deviations from their individual expected values ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}):

\begin{equation} \label{eq:cov-cov}
\mathrm{Cov}(X,Y) = \mathrm{E}\left[ (X-\mathrm{E}[X]) (Y-\mathrm{E}[Y]) \right] \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Covariance"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-02-06; URL: \url{https://en.wikipedia.org/wiki/Covariance#Definition}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D70 | shortcut: cov | author: JoramSoch | date: 2020-06-02, 20:20.
\vspace{1em}



\subsubsection[\textit{Sample covariance}]{Sample covariance} \label{sec:cov-samp}
\setcounter{equation}{0}

\textbf{Definition:} Let $x = \left\lbrace x_1, \ldots, x_n \right\rbrace$ and $y = \left\lbrace y_1, \ldots, y_n \right\rbrace$ be samples ($\rightarrow$ Definition "samp") from random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X$ and $Y$. Then, the sample covariance of $x$ and $y$ is given by

\begin{equation} \label{eq:cov-samp-cov-samp}
\hat{\sigma}_{xy} = \frac{1}{n} \sum_{i=1}^{n} (x_i - \bar{x}) (y_i - \bar{y})
\end{equation}

and the unbiased sample covariance of $x$ and $y$ is given by

\begin{equation} \label{eq:cov-samp-cov-samp-unb}
s_{xy} = \frac{1}{n-1} \sum_{i=1}^{n} (x_i - \bar{x}) (y_i - \bar{y})
\end{equation}

where $\bar{x}$ and $\bar{y}$ are the sample means ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean-samp}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Covariance"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-05-20; URL: \url{https://en.wikipedia.org/wiki/Covariance#Calculating_the_sample_covariance}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D144 | shortcut: cov-samp | author: ciaranmci | date: 2021-04-21, 06:53.
\vspace{1em}



\subsubsection[\textbf{Partition into expected values}]{Partition into expected values} \label{sec:cov-mean}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ and $Y$ be random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}). Then, the covariance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cov}) of $X$ and $Y$ is equal to the mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of the product of $X$ and $Y$ minus the product of the means ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of $X$ and $Y$:

\begin{equation} \label{eq:cov-mean-cov-mean}
\mathrm{Cov}(X,Y) = \mathrm{E}(X Y) - \mathrm{E}(X) \mathrm{E}(Y) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The covariance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cov}) of $X$ and $Y$ is defined as

\begin{equation} \label{eq:cov-mean-cov}
\mathrm{Cov}(X,Y) = \mathrm{E}\left[ (X-\mathrm{E}[X]) (Y-\mathrm{E}[Y]) \right] \; .
\end{equation}

which, due to the linearity of the expected value ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-lin}), can be rewritten as

\begin{equation} \label{eq:cov-mean-cov-mean-qed}
\begin{split}
\mathrm{Cov}(X,Y) &= \mathrm{E}\left[ (X-\mathrm{E}[X]) (Y-\mathrm{E}[Y]) \right] \\
&= \mathrm{E}\left[ X Y - X \, \mathrm{E}(Y) - \mathrm{E}(X) \, Y + \mathrm{E}(X) \mathrm{E}(Y) \right] \\
&= \mathrm{E}(X Y) - \mathrm{E}(X) \mathrm{E}(Y) - \mathrm{E}(X) \mathrm{E}(Y) + \mathrm{E}(X) \mathrm{E}(Y) \\
&= \mathrm{E}(X Y) - \mathrm{E}(X) \mathrm{E}(Y) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Covariance"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-06-02; URL: \url{https://en.wikipedia.org/wiki/Covariance#Definition}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P118 | shortcut: cov-mean | author: JoramSoch | date: 2020-06-02, 20:50.
\vspace{1em}



\subsubsection[\textbf{Covariance under independence}]{Covariance under independence} \label{sec:cov-ind}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ and $Y$ be independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}) random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}). Then, the covariance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cov}) of $X$ and $Y$ is zero:

\begin{equation} \label{eq:cov-ind-cov-ind}
X, Y \; \text{independent} \quad \Rightarrow \quad \mathrm{Cov}(X,Y) = 0 \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The covariance can be expressed in terms of expected values ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:cov-mean}) as

\begin{equation} \label{eq:cov-ind-cov-mean}
\mathrm{Cov}(X,Y) = \mathrm{E}(X\,Y) - \mathrm{E}(X) \, \mathrm{E}(Y) \; .
\end{equation}

For independent random variables, the expected value of the product is equal to the product of the expected values ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-mult}):

\begin{equation} \label{eq:cov-ind-mean-mult}
\mathrm{E}(X\,Y) = \mathrm{E}(X) \, \mathrm{E}(Y) \; .
\end{equation}

Taking \eqref{eq:cov-ind-cov-mean} and \eqref{eq:cov-ind-mean-mult} together, we have

\begin{equation} \label{eq:cov-ind-cov-ind-qed}
\begin{split}
\mathrm{Cov}(X,Y) &\overset{\eqref{eq:cov-ind-cov-mean}}{=} \mathrm{E}(X\,Y) - \mathrm{E}(X) \, \mathrm{E}(Y) \\
&\overset{\eqref{eq:cov-ind-mean-mult}}{=} \mathrm{E}(X) \, \mathrm{E}(Y) - \mathrm{E}(X) \, \mathrm{E}(Y) \\
&= 0 \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Covariance"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-09-03; URL: \url{https://en.wikipedia.org/wiki/Covariance#Uncorrelatedness_and_independence}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P158 | shortcut: cov-ind | author: JoramSoch | date: 2020-09-03, 06:05.
\vspace{1em}



\subsubsection[\textbf{Relationship to correlation}]{Relationship to correlation} \label{sec:cov-corr}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ and $Y$ be random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}). Then, the covariance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cov}) of $X$ and $Y$ is equal to the product of their correlation ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:corr}) and the standard deviations ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:std}) of $X$ and $Y$:

\begin{equation} \label{eq:cov-corr-cov-corr}
\mathrm{Cov}(X,Y) = \sigma_X \, \mathrm{Corr}(X,Y) \, \sigma_Y \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The correlation ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:corr}) of $X$ and $Y$ is defined as

\begin{equation} \label{eq:cov-corr-corr}
\mathrm{Corr}(X,Y) = \frac{\mathrm{Cov}(X,Y)}{\sigma_X \sigma_Y} \; .
\end{equation}

which can be rearranged for the covariance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cov}) to give

\begin{equation} \label{eq:cov-corr-cov-corr-qed}
\mathrm{Cov}(X,Y) = \sigma_X \, \mathrm{Corr}(X,Y) \, \sigma_Y
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P119 | shortcut: cov-corr | author: JoramSoch | date: 2020-06-02, 21:00.
\vspace{1em}



\subsubsection[\textbf{Law of total covariance}]{Law of total covariance} \label{sec:cov-tot}
\setcounter{equation}{0}

\textbf{Theorem:} (law of total covariance, also called "conditional covariance formula") Let $X$, $Y$ and $Z$ be random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) defined on the same probability space ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-spc}) and assume that the covariance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cov}) of $X$ and $Y$ is finite. Then, the sum of the expectation ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of the conditional covariance and the covariance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cov}) of the conditional expectations of $X$ and $Y$ given $Z$ is equal to the covariance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cov}) of $X$ and $Y$:

\begin{equation} \label{eq:cov-tot-cov-tot}
\mathrm{Cov}(X,Y) = \mathrm{E}[\mathrm{Cov}(X,Y \vert Z)] + \mathrm{Cov}[\mathrm{E}(X \vert Z),\mathrm{E}(Y \vert Z)] \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The covariance can be decomposed into expected values ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:cov-mean}) as follows:

\begin{equation} \label{eq:cov-tot-cov-tot-s1}
\mathrm{Cov}(X,Y) = \mathrm{E}(XY) - \mathrm{E}(X) \mathrm{E}(Y) \; .
\end{equation}

Then, conditioning on $Z$ and applying the law of total expectation ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-tot}), we have:

\begin{equation} \label{eq:cov-tot-cov-tot-s2}
\mathrm{Cov}(X,Y) = \mathrm{E}\left[ \mathrm{E}(XY \vert Z) \right] - \mathrm{E}\left[ \mathrm{E}(X \vert Z ) \right] \mathrm{E}\left[ \mathrm{E}(Y \vert Z) \right] \; .
\end{equation}

Applying the decomposition of covariance into expected values ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:cov-mean}) to the first term gives:

\begin{equation} \label{eq:cov-tot-cov-tot-s3}
\mathrm{Cov}(X,Y) = \mathrm{E}\left[ \mathrm{Cov}(X,Y \vert Z) + \mathrm{E}(X \vert Z) \mathrm{E}(Y \vert Z) \right] - \mathrm{E}\left[ \mathrm{E}(X \vert Z ) \right] \mathrm{E}\left[ \mathrm{E}(Y \vert Z) \right] \; .
\end{equation}

With the linearity of the expected value ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-lin}), the terms can be regrouped to give:

\begin{equation} \label{eq:cov-tot-cov-tot-s4}
\mathrm{Cov}(X,Y) = \mathrm{E}\left[ \mathrm{Cov}(X,Y \vert Z) \right] + \left( \mathrm{E}\left[ \mathrm{E}(X \vert Z) \mathrm{E}(Y \vert Z) \right] - \mathrm{E}\left[ \mathrm{E}(X \vert Z ) \right] \mathrm{E}\left[ \mathrm{E}(Y \vert Z) \right] \right) \; .
\end{equation}

Once more using the decomposition of covariance into expected values ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:cov-mean}), we finally have:

\begin{equation} \label{eq:cov-tot-var-tot-s5}
\mathrm{Cov}(X,Y) = \mathrm{E}[\mathrm{Cov}(X,Y \vert Z)] + \mathrm{Cov}[\mathrm{E}(X \vert Z),\mathrm{E}(Y \vert Z)] \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Law of total covariance"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-11-26; URL: \url{https://en.wikipedia.org/wiki/Law_of_total_covariance#Proof}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P293 | shortcut: cov-tot | author: JoramSoch | date: 2021-11-26, 11:38.
\vspace{1em}



\subsubsection[\textit{Covariance matrix}]{Covariance matrix} \label{sec:covmat}
\setcounter{equation}{0}

\textbf{Definition:} Let $X = [X_1, \ldots, X_n]^\mathrm{T}$ be a random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}). Then, the covariance matrix of $X$ is defined as the $n \times n$ matrix in which the entry $(i,j)$ is the covariance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cov}) of $X_i$ and $X_j$:

\begin{equation} \label{eq:covmat-covmat}
\Sigma_{XX} =
\begin{bmatrix}
\mathrm{Cov}(X_1,X_1) & \ldots & \mathrm{Cov}(X_1,X_n) \\
\vdots & \ddots & \vdots \\
\mathrm{Cov}(X_n,X_1) & \ldots & \mathrm{Cov}(X_n,X_n)
\end{bmatrix} =
\begin{bmatrix}
\mathrm{E}\left[ (X_1-\mathrm{E}[X_1]) (X_1-\mathrm{E}[X_1]) \right] & \ldots & \mathrm{E}\left[ (X_1-\mathrm{E}[X_1]) (X_n-\mathrm{E}[X_n]) \right] \\
\vdots & \ddots & \vdots \\
\mathrm{E}\left[ (X_n-\mathrm{E}[X_n]) (X_1-\mathrm{E}[X_1]) \right] & \ldots & \mathrm{E}\left[ (X_n-\mathrm{E}[X_n]) (X_n-\mathrm{E}[X_n]) \right]
\end{bmatrix} \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Covariance matrix"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-06-06; URL: \url{https://en.wikipedia.org/wiki/Covariance_matrix#Definition}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D72 | shortcut: covmat | author: JoramSoch | date: 2020-06-06, 04:24.
\vspace{1em}



\subsubsection[\textit{Sample covariance matrix}]{Sample covariance matrix} \label{sec:covmat-samp}
\setcounter{equation}{0}

\textbf{Definition:} Let $x = \left\lbrace x_1, \ldots, x_n \right\rbrace$ be a sample ($\rightarrow$ Definition "samp") from a random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}) $X \in \mathbb{R}^{p \times 1}$. Then, the sample covariance matrix of $x$ is given by

\begin{equation} \label{eq:covmat-samp-covmat-samp}
\hat{\Sigma} = \frac{1}{n} \sum_{i=1}^{n} (x_i - \bar{x}) (x_i - \bar{x})^\mathrm{T}
\end{equation}

and the unbiased sample covariance matrix of $x$ is given by

\begin{equation} \label{eq:covmat-samp-covmat-samp-unb}
S = \frac{1}{n-1} \sum_{i=1}^{n} (x_i - \bar{x}) (x_i - \bar{x})^\mathrm{T}
\end{equation}

where $\bar{x}$ is the sample mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean-samp}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Sample mean and covariance"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-05-20; URL: \url{https://en.wikipedia.org/wiki/Sample_mean_and_covariance#Definition_of_sample_covariance}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D153 | shortcut: covmat-samp | author: JoramSoch | date: 2021-05-20, 07:46.
\vspace{1em}



\subsubsection[\textbf{Covariance matrix and expected values}]{Covariance matrix and expected values} \label{sec:covmat-mean}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}). Then, the covariance matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:covmat}) of $X$ is equal to the mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of the outer product of $X$ with itself minus the outer product of the mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of $X$ with itself:

\begin{equation} \label{eq:covmat-mean-covmat-mean}
\Sigma_{XX} = \mathrm{E}(X X^\mathrm{T}) - \mathrm{E}(X) \mathrm{E}(X)^\mathrm{T} \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The covariance matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:covmat}) of $X$ is defined as

\begin{equation} \label{eq:covmat-mean-covmat1}
\Sigma_{XX} =
\begin{bmatrix}
\mathrm{E}\left[ (X_1-\mathrm{E}[X_1]) (X_1-\mathrm{E}[X_1]) \right] & \ldots & \mathrm{E}\left[ (X_1-\mathrm{E}[X_1]) (X_n-\mathrm{E}[X_n]) \right] \\
\vdots & \ddots & \vdots \\
\mathrm{E}\left[ (X_n-\mathrm{E}[X_n]) (X_1-\mathrm{E}[X_1]) \right] & \ldots & \mathrm{E}\left[ (X_n-\mathrm{E}[X_n]) (X_n-\mathrm{E}[X_n]) \right]
\end{bmatrix}
\end{equation}

which can also be expressed using matrix multiplication as

\begin{equation} \label{eq:covmat-mean-covmat2}
\Sigma_{XX} = \mathrm{E}\left[ (X-\mathrm{E}[X]) (X-\mathrm{E}[X])^\mathrm{T} \right]
\end{equation}

Due to the linearity of the expected value ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-lin}), this can be rewritten as

\begin{equation} \label{eq:covmat-mean-covmat-mean-qed}
\begin{split}
\Sigma_{XX} &= \mathrm{E}\left[ (X-\mathrm{E}[X]) (X-\mathrm{E}[X])^\mathrm{T} \right] \\
&= \mathrm{E}\left[ X X^\mathrm{T} - X \, \mathrm{E}(X)^\mathrm{T} - \mathrm{E}(X) \, X^\mathrm{T} + \mathrm{E}(X) \mathrm{E}(X)^\mathrm{T} \right] \\
&= \mathrm{E}(X X^\mathrm{T}) - \mathrm{E}(X) \mathrm{E}(X)^\mathrm{T} - \mathrm{E}(X) \mathrm{E}(X)^\mathrm{T} + \mathrm{E}(X) \mathrm{E}(X)^\mathrm{T} \\
&= \mathrm{E}(X X^\mathrm{T}) - \mathrm{E}(X) \mathrm{E}(X)^\mathrm{T} \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Taboga, Marco (2010): "Covariance matrix"; in: \textit{Lectures on probability and statistics}, retrieved on 2020-06-06; URL: \url{https://www.statlect.com/fundamentals-of-probability/covariance-matrix}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P120 | shortcut: covmat-mean | author: JoramSoch | date: 2020-06-06, 05:31.
\vspace{1em}



\subsubsection[\textbf{Covariance matrix and correlation matrix}]{Covariance matrix and correlation matrix} \label{sec:covmat-corrmat}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}). Then, the covariance matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:covmat}) of $X$ can be expressed in terms of its correlation matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:corrmat}) as follows

\begin{equation} \label{eq:covmat-corrmat-covmat-corrmat}
\Sigma_{XX} = \mathrm{D}_X \cdot \mathrm{C}_{XX} \cdot \mathrm{D}_X \; ,
\end{equation}

where $\mathrm{D}_X$ is a diagonal matrix with the standard deviations ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:std}) of $X_1, \ldots, X_n$ as entries on the diagonal:

\begin{equation} \label{eq:covmat-corrmat-diagmat}
\mathrm{D}_X = \mathrm{diag}(\sigma_{X_1},\ldots,\sigma_{X_n}) =
\begin{bmatrix}
\sigma_{X_1} & \ldots & 0 \\
\vdots & \ddots & \vdots \\
0 & \ldots & \sigma_{X_n}
\end{bmatrix} \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} Reiterating \eqref{eq:covmat-corrmat-covmat-corrmat} and applying \eqref{eq:covmat-corrmat-diagmat}, we have:

\begin{equation} \label{eq:covmat-corrmat-covmat-corrmat-s1}
\Sigma_{XX} =
\begin{bmatrix}
\sigma_{X_1} & \ldots & 0 \\
\vdots & \ddots & \vdots \\
0 & \ldots & \sigma_{X_n}
\end{bmatrix} \cdot
\mathrm{C}_{XX} \cdot
\begin{bmatrix}
\sigma_{X_1} & \ldots & 0 \\
\vdots & \ddots & \vdots \\
0 & \ldots & \sigma_{X_n}
\end{bmatrix} \; .
\end{equation}

Together with the definition of the correlation matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:corrmat}), this gives

\begin{equation} \label{eq:covmat-corrmat-covmat-corrmat-s2}
\begin{split}
\Sigma_{XX} &=
\begin{bmatrix}
\sigma_{X_1} & \ldots & 0 \\
\vdots & \ddots & \vdots \\
0 & \ldots & \sigma_{X_n}
\end{bmatrix} \cdot
\begin{bmatrix}
\frac{\mathrm{E}\left[(X_1-\mathrm{E}[X_1]) (X_1-\mathrm{E}[X_1])\right]}{\sigma_{X_1} \, \sigma_{X_1}} & \ldots & \frac{\mathrm{E}\left[(X_1-\mathrm{E}[X_1]) (X_n-\mathrm{E}[X_n])\right]}{\sigma_{X_1} \, \sigma_{X_n}} \\
\vdots & \ddots & \vdots \\
\frac{\mathrm{E}\left[(X_n-\mathrm{E}[X_n]) (X_1-\mathrm{E}[X_1])\right]}{\sigma_{X_n} \, \sigma_{X_1}} & \ldots & \frac{\mathrm{E}\left[(X_n-\mathrm{E}[X_n]) (X_n-\mathrm{E}[X_n])\right]}{\sigma_{X_n} \, \sigma_{X_n}}
\end{bmatrix} \cdot
\begin{bmatrix}
\sigma_{X_1} & \ldots & 0 \\
\vdots & \ddots & \vdots \\
0 & \ldots & \sigma_{X_n}
\end{bmatrix} \\
&=
\begin{bmatrix}
\frac{\sigma_{X_1} \cdot \mathrm{E}\left[(X_1-\mathrm{E}[X_1]) (X_1-\mathrm{E}[X_1])\right]}{\sigma_{X_1} \, \sigma_{X_1}} & \ldots & \frac{\sigma_{X_1} \cdot \mathrm{E}\left[(X_1-\mathrm{E}[X_1]) (X_n-\mathrm{E}[X_n])\right]}{\sigma_{X_1} \, \sigma_{X_n}} \\
\vdots & \ddots & \vdots \\
\frac{\sigma_{X_n} \cdot \mathrm{E}\left[(X_n-\mathrm{E}[X_n]) (X_1-\mathrm{E}[X_1])\right]}{\sigma_{X_n} \, \sigma_{X_1}} & \ldots & \frac{\sigma_{X_n} \cdot \mathrm{E}\left[(X_n-\mathrm{E}[X_n]) (X_n-\mathrm{E}[X_n])\right]}{\sigma_{X_n} \, \sigma_{X_n}}
\end{bmatrix} \cdot
\begin{bmatrix}
\sigma_{X_1} & \ldots & 0 \\
\vdots & \ddots & \vdots \\
0 & \ldots & \sigma_{X_n}
\end{bmatrix} \\
&=
\begin{bmatrix}
\frac{\sigma_{X_1} \cdot \mathrm{E}\left[(X_1-\mathrm{E}[X_1]) (X_1-\mathrm{E}[X_1])\right] \cdot \sigma_{X_1}}{\sigma_{X_1} \, \sigma_{X_1}} & \ldots & \frac{\sigma_{X_1} \cdot \mathrm{E}\left[(X_1-\mathrm{E}[X_1]) (X_n-\mathrm{E}[X_n])\right] \cdot \sigma_{X_n}}{\sigma_{X_1} \, \sigma_{X_n}} \\
\vdots & \ddots & \vdots \\
\frac{\sigma_{X_n} \cdot \mathrm{E}\left[(X_n-\mathrm{E}[X_n]) (X_1-\mathrm{E}[X_1])\right] \cdot \sigma_{X_1}}{\sigma_{X_n} \, \sigma_{X_1}} & \ldots & \frac{\sigma_{X_n} \cdot \mathrm{E}\left[(X_n-\mathrm{E}[X_n]) (X_n-\mathrm{E}[X_n])\right] \cdot \sigma_{X_n}}{\sigma_{X_n} \, \sigma_{X_n}}
\end{bmatrix} \\
&=
\begin{bmatrix}
\mathrm{E}\left[ (X_1-\mathrm{E}[X_1]) (X_1-\mathrm{E}[X_1]) \right] & \ldots & \mathrm{E}\left[ (X_1-\mathrm{E}[X_1]) (X_n-\mathrm{E}[X_n]) \right] \\
\vdots & \ddots & \vdots \\
\mathrm{E}\left[ (X_n-\mathrm{E}[X_n]) (X_1-\mathrm{E}[X_1]) \right] & \ldots & \mathrm{E}\left[ (X_n-\mathrm{E}[X_n]) (X_n-\mathrm{E}[X_n]) \right]
\end{bmatrix}
\end{split}
\end{equation}

which is nothing else than the definition of the covariance matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:covmat}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Penny, William (2006): "The correlation matrix"; in: \textit{Mathematics for Brain Imaging}, ch. 1.4.5, p. 28, eq. 1.60; URL: \url{https://ueapsylabs.co.uk/sites/wpenny/mbi/mbi_course.pdf}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P121 | shortcut: covmat-corrmat | author: JoramSoch | date: 2020-06-06, 06:02.
\vspace{1em}



\subsubsection[\textit{Precision matrix}]{Precision matrix} \label{sec:precmat}
\setcounter{equation}{0}

\textbf{Definition:} Let $X = [X_1, \ldots, X_n]^\mathrm{T}$ be a random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}). Then, the precision matrix of $X$ is defined as the inverse of the covariance matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:covmat}) of $X$:

\begin{equation} \label{eq:precmat-corrmat}
\Lambda_{XX} = \Sigma_{XX}^{-1} =
\begin{bmatrix}
\mathrm{Cov}(X_1,X_1) & \ldots & \mathrm{Cov}(X_1,X_n) \\
\vdots & \ddots & \vdots \\
\mathrm{Cov}(X_n,X_1) & \ldots & \mathrm{Cov}(X_n,X_n)
\end{bmatrix}^{-1} \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Precision (statistics)"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-06-06; URL: \url{https://en.wikipedia.org/wiki/Precision_(statistics)}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D74 | shortcut: precmat | author: JoramSoch | date: 2020-06-06, 05:08.
\vspace{1em}



\subsubsection[\textbf{Precision matrix and correlation matrix}]{Precision matrix and correlation matrix} \label{sec:precmat-corrmat}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}). Then, the precision matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:precmat}) of $X$ can be expressed in terms of its correlation matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:corrmat}) as follows

\begin{equation} \label{eq:precmat-corrmat-precmat-corrmat}
\Lambda_{XX} = \mathrm{D}_X^{-1} \cdot \mathrm{C}_{XX}^{-1} \cdot \mathrm{D}_X^{-1} \; ,
\end{equation}

where $\mathrm{D}_X^{-1}$ is a diagonal matrix with the inverse standard deviations ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:std}) of $X_1, \ldots, X_n$ as entries on the diagonal:

\begin{equation} \label{eq:precmat-corrmat-invdiagmat}
\mathrm{D}_X^{-1} = \mathrm{diag}(1/\sigma_{X_1},\ldots,1/\sigma_{X_n}) =
\begin{bmatrix}
\frac{1}{\sigma_{X_1}} & \ldots & 0 \\
\vdots & \ddots & \vdots \\
0 & \ldots & \frac{1}{\sigma_{X_n}}
\end{bmatrix} \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The precision matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:precmat}) is defined as the inverse of the covariance matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:covmat})

\begin{equation} \label{eq:precmat-corrmat-precmat-covmat}
\Lambda_{XX} = \Sigma_{XX}^{-1}
\end{equation}

and the relation between covariance matrix and correlation matrix ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:covmat-corrmat}) is given by

\begin{equation} \label{eq:precmat-corrmat-covmat-corrmat}
\Sigma_{XX} = \mathrm{D}_X \cdot \mathrm{C}_{XX} \cdot \mathrm{D}_X
\end{equation}

where

\begin{equation} \label{eq:precmat-corrmat-diagmat}
\mathrm{D}_X = \mathrm{diag}(\sigma_{X_1},\ldots,\sigma_{X_n}) =
\begin{bmatrix}
\sigma_{X_1} & \ldots & 0 \\
\vdots & \ddots & \vdots \\
0 & \ldots & \sigma_{X_n}
\end{bmatrix} \; .
\end{equation}

Using the matrix product property

\begin{equation} \label{eq:precmat-corrmat-matprod-inv}
\left(A \cdot B \cdot C\right)^{-1} = C^{-1} \cdot B^{-1} \cdot A^{-1}
\end{equation}

and the diagonal matrix property

\begin{equation} \label{eq:precmat-corrmat-diagmat-inv}
\mathrm{diag}(a_1,\ldots,a_n)^{-1} =
\begin{bmatrix}
a_1 & \ldots & 0 \\
\vdots & \ddots & \vdots \\
0 & \ldots & a_n
\end{bmatrix}^{-1} =
\begin{bmatrix}
\frac{1}{a_1} & \ldots & 0 \\
\vdots & \ddots & \vdots \\
0 & \ldots & \frac{1}{a_n}
\end{bmatrix} =
\mathrm{diag}(1/a_1,\ldots,1/a_n) \; ,
\end{equation}

we obtain

\begin{equation} \label{eq:precmat-corrmat-precmat-corrmat-qed}
\begin{split}
\Lambda_{XX} &\overset{\eqref{eq:precmat-corrmat-precmat-covmat}}{=} \Sigma_{XX}^{-1} \\
&\overset{\eqref{eq:precmat-corrmat-covmat-corrmat}}{=} \left( \mathrm{D}_X \cdot \mathrm{C}_{XX} \cdot \mathrm{D}_X \right)^{-1} \\
&\overset{\eqref{eq:precmat-corrmat-matprod-inv}}{=} \mathrm{D}_X^{-1} \cdot \mathrm{C}_{XX}^{-1} \cdot \mathrm{D}_X^{-1} \\
&\overset{\eqref{eq:precmat-corrmat-diagmat-inv}}{=}
\begin{bmatrix}
\frac{1}{\sigma_{X_1}} & \ldots & 0 \\
\vdots & \ddots & \vdots \\
0 & \ldots & \frac{1}{\sigma_{X_n}}
\end{bmatrix} \cdot
\mathrm{C}_{XX}^{-1} \cdot
\begin{bmatrix}
\frac{1}{\sigma_{X_1}} & \ldots & 0 \\
\vdots & \ddots & \vdots \\
0 & \ldots & \frac{1}{\sigma_{X_n}}
\end{bmatrix}
\end{split}
\end{equation}

which conforms to equation \eqref{eq:precmat-corrmat-precmat-corrmat}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P122 | shortcut: precmat-corrmat | author: JoramSoch | date: 2020-06-06, 06:28.
\vspace{1em}



\subsection{Correlation}

\subsubsection[\textit{Definition}]{Definition} \label{sec:corr}
\setcounter{equation}{0}

\textbf{Definition:} The correlation of two random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X$ and $Y$, also called Pearson product-moment correlation coefficient (PPMCC), is defined as the ratio of the covariance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cov}) of $X$ and $Y$ relative to the product of their standard deviations ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:std}):

\begin{equation} \label{eq:corr-corr}
\mathrm{Corr}(X,Y) = \frac{\sigma_{XY}}{\sigma_X \sigma_Y} = \frac{\mathrm{Cov}(X,Y)}{\sqrt{\mathrm{Var}(X)} \sqrt{\mathrm{Var}(Y)}} = \frac{\mathrm{E}\left[ (X-\mathrm{E}[X]) (Y-\mathrm{E}[Y]) \right]}{\sqrt{\mathrm{E}\left[ (X-\mathrm{E}[X])^2 \right]} \sqrt{\mathrm{E}\left[ (Y-\mathrm{E}[Y])^2 \right]}} \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Correlation and dependence"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-02-06; URL: \url{https://en.wikipedia.org/wiki/Correlation_and_dependence#Pearson's_product-moment_coefficient}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D71 | shortcut: corr | author: JoramSoch | date: 2020-06-02, 20:34.
\vspace{1em}



\subsubsection[\textbf{Range}]{Range} \label{sec:corr-range}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ and $Y$ be two random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}). Then, the correlation of $X$ and $Y$ is between and including $-1$ and $+1$:

\begin{equation} \label{eq:corr-range-corr-range}
-1 \leq \mathrm{Corr}(X,Y) \leq +1 \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} Consider the variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) of $X$ plus or minus $Y$, each divided by their standard deviations ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:std}):

\begin{equation} \label{eq:corr-range-var-XY}
\mathrm{Var}\left( \frac{X}{\sigma_X} \pm \frac{Y}{\sigma_Y} \right) \; .
\end{equation}

Because the variance is non-negative ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:var-nonneg}), this term is larger than or equal to zero:

\begin{equation} \label{eq:corr-range-var-XY-0}
0 \leq \mathrm{Var}\left( \frac{X}{\sigma_X} \pm \frac{Y}{\sigma_Y} \right) \; .
\end{equation}

Using the variance of a linear combination ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:var-lincomb}), it can also be written as:

\begin{equation} \label{eq:corr-range-var-XY-s1}
\begin{split}
\mathrm{Var}\left( \frac{X}{\sigma_X} \pm \frac{Y}{\sigma_Y} \right) &= \mathrm{Var}\left( \frac{X}{\sigma_X} \right) + \mathrm{Var}\left( \frac{Y}{\sigma_Y} \right) \pm 2 \, \mathrm{Cov}\left( \frac{X}{\sigma_X}, \frac{Y}{\sigma_Y} \right) \\
&= \frac{1}{\sigma_X^2} \mathrm{Var}(X) + \frac{1}{\sigma_Y^2} \mathrm{Var}(Y) \pm 2 \, \frac{1}{\sigma_X \sigma_Y} \, \mathrm{Cov}(X,Y) \\
&= \frac{1}{\sigma_X^2} \sigma_X^2 + \frac{1}{\sigma_Y^2} \sigma_Y^2 \pm 2 \, \frac{1}{\sigma_X \sigma_Y} \, \sigma_{XY} \; .
\end{split}
\end{equation}

Using the relationship between covariance and correlation ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:cov-corr}), we have:

\begin{equation} \label{eq:corr-range-var-XY-s2}
\mathrm{Var}\left( \frac{X}{\sigma_X} \pm \frac{Y}{\sigma_Y} \right) = 1 + 1 + \pm 2 \, \mathrm{Corr}(X,Y) \; .
\end{equation}

Thus, the combination of \eqref{eq:corr-range-var-XY-0} with \eqref{eq:corr-range-var-XY-s2} yields

\begin{equation} \label{eq:corr-range-var-XY-ineq}
0 \leq 2 \pm 2 \, \mathrm{Corr}(X,Y)
\end{equation}

which is equivalent to

\begin{equation} \label{eq:corr-range-corr-range-qed}
-1 \leq \mathrm{Corr}(X,Y) \leq +1 \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Dor Leventer (2021): "How can I simply prove that the pearson correlation coefficient is between -1 and 1?"; in: \textit{StackExchange Mathematics}, retrieved on 2021-12-14; URL: \url{https://math.stackexchange.com/a/4260655/480910}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P300 | shortcut: corr-range | author: JoramSoch | date: 2021-12-14, 02:08.
\vspace{1em}



\subsubsection[\textit{Sample correlation coefficient}]{Sample correlation coefficient} \label{sec:corr-samp}
\setcounter{equation}{0}

\textbf{Definition:} Let $x = \left\lbrace x_1, \ldots, x_n \right\rbrace$ and $y = \left\lbrace y_1, \ldots, y_n \right\rbrace$ be samples ($\rightarrow$ Definition "samp") from random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X$ and $Y$. Then, the sample correlation coefficient of $x$ and $y$ is given by

\begin{equation} \label{eq:corr-samp-corr-samp}
r_{xy} = \frac{\sum_{i=1}^n (x_i-\bar{x}) (y_i-\bar{y})}{\sqrt{\sum_{i=1}^n (x_i-\bar{x})^2} \sqrt{\sum_{i=1}^n (y_i-\bar{y})^2}}
\end{equation}

where $\bar{x}$ and $\bar{y}$ are the sample means ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean-samp}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Pearson correlation coefficient"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-12-14; URL: \url{https://en.wikipedia.org/wiki/Pearson_correlation_coefficient#For_a_sample}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D168 | shortcut: corr-samp | author: JoramSoch | date: 2021-12-14, 07:23.
\vspace{1em}



\subsubsection[\textbf{Relationship to standard scores}]{Relationship to standard scores} \label{sec:corr-z}
\setcounter{equation}{0}

\textbf{Theorem:} Let $x = \left\lbrace x_1, \ldots, x_n \right\rbrace$ and $y = \left\lbrace y_1, \ldots, y_n \right\rbrace$ be samples ($\rightarrow$ Definition "samp") from random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X$ and $Y$. Then, the sample correlation coefficient ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:corr-samp}) $r_{xy}$ can be expressed in terms of the standard scores ($\rightarrow$ Definition "z") of $x$ and $y$:

\begin{equation} \label{eq:corr-z-corr-z}
r_{xy} = \frac{1}{n-1} \sum_{i=1}^n z_i^{(x)} \cdot z_i^{(y)} = \frac{1}{n-1} \sum_{i=1}^n \left( \frac{x_i-\bar{x}}{s_x} \right) \left( \frac{y_i-\bar{y}}{s_y} \right)
\end{equation}

where $\bar{x}$ and $\bar{y}$ are the sample means ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean-samp}) and $s_x$ and $s_y$ are the sample variances ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var-samp}).


\vspace{1em}
\textbf{Proof:} The sample correlation coefficient ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:corr-samp}) is defined as

\begin{equation} \label{eq:corr-z-corr-samp}
r_{xy} = \frac{\sum_{i=1}^n (x_i-\bar{x}) (y_i-\bar{y})}{\sqrt{\sum_{i=1}^n (x_i-\bar{x})^2} \sqrt{\sum_{i=1}^n (y_i-\bar{y})^2}} \; .
\end{equation}

Using the sample variances ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var-samp}) of $x$ and $y$, we can write:

\begin{equation} \label{eq:corr-z-corr-z-s1}
r_{xy} = \frac{\sum_{i=1}^n (x_i-\bar{x}) (y_i-\bar{y})}{\sqrt{(n-1) s_x^2} \sqrt{(n-1) s_y^2}} \; .
\end{equation}

Rearranging the terms, we arrive at:

\begin{equation} \label{eq:corr-z-corr-z-s2}
r_{xy} = \frac{1}{(n-1) \, s_x \, s_y} \sum_{i=1}^n (x_i-\bar{x}) (y_i-\bar{y}) \; .
\end{equation}

Further simplifying, the result is:

\begin{equation} \label{eq:corr-z-corr-z-s3}
r_{xy} = \frac{1}{n-1} \sum_{i=1}^n \left( \frac{x_i-\bar{x}}{s_x} \right) \left( \frac{y_i-\bar{y}}{s_y} \right) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Peason correlation coefficient"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-12-14; URL: \url{https://en.wikipedia.org/wiki/Pearson_correlation_coefficient#For_a_sample}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P299 | shortcut: corr-z | author: JoramSoch | date: 2021-12-14, 02:31.
\vspace{1em}



\subsubsection[\textit{Correlation matrix}]{Correlation matrix} \label{sec:corrmat}
\setcounter{equation}{0}

\textbf{Definition:} Let $X = [X_1, \ldots, X_n]^\mathrm{T}$ be a random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}). Then, the correlation matrix of $X$ is defined as the $n \times n$ matrix in which the entry $(i,j)$ is the correlation ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:corr}) of $X_i$ and $X_j$:

\begin{equation} \label{eq:corrmat-corrmat}
\mathrm{C}_{XX} =
\begin{bmatrix}
\mathrm{Corr}(X_1,X_1) & \ldots & \mathrm{Corr}(X_1,X_n) \\
\vdots & \ddots & \vdots \\
\mathrm{Corr}(X_n,X_1) & \ldots & \mathrm{Corr}(X_n,X_n)
\end{bmatrix} =
\begin{bmatrix}
\frac{\mathrm{E}\left[(X_1-\mathrm{E}[X_1]) (X_1-\mathrm{E}[X_1])\right]}{\sigma_{X_1} \, \sigma_{X_1}} & \ldots & \frac{\mathrm{E}\left[(X_1-\mathrm{E}[X_1]) (X_n-\mathrm{E}[X_n])\right]}{\sigma_{X_1} \, \sigma_{X_n}} \\
\vdots & \ddots & \vdots \\
\frac{\mathrm{E}\left[(X_n-\mathrm{E}[X_n]) (X_1-\mathrm{E}[X_1])\right]}{\sigma_{X_n} \, \sigma_{X_1}} & \ldots & \frac{\mathrm{E}\left[(X_n-\mathrm{E}[X_n]) (X_n-\mathrm{E}[X_n])\right]}{\sigma_{X_n} \, \sigma_{X_n}}
\end{bmatrix} \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Correlation and dependence"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-06-06; URL: \url{https://en.wikipedia.org/wiki/Correlation_and_dependence#Correlation_matrices}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D73 | shortcut: corrmat | author: JoramSoch | date: 2020-06-06, 04:56.
\vspace{1em}



\subsubsection[\textit{Sample correlation matrix}]{Sample correlation matrix} \label{sec:corrmat-samp}
\setcounter{equation}{0}

\textbf{Definition:} Let $x = \left\lbrace x_1, \ldots, x_n \right\rbrace$ be a sample ($\rightarrow$ Definition "samp") from a random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}) $X \in \mathbb{R}^{p \times 1}$. Then, the sample correlation matrix of $x$ is the matrix whose entries are the sample correlation coefficients ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:corr-samp}) between pairs of entries of $x_1, \ldots, x_n$:

\begin{equation} \label{eq:corrmat-samp-corrmat-samp-v1}
\mathrm{R}_{xx} =
\begin{bmatrix}
r_{x^{(1)},x^{(1)}} & \ldots & r_{x^{(1)},x^{(n)}} \\
\vdots & \ddots & \vdots \\
r_{x^{(n)},x^{(1)}} & \ldots & r_{x^{(n)},x^{(n)}}
\end{bmatrix}
\end{equation}

where the $r_{x^{(j)},x^{(k)}}$ is the sample correlation ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:corr-samp}) between the $j$-th and the $k$-th entry of $X$ given by

\begin{equation} \label{eq:corrmat-samp-corrmat-samp-v2}
r_{x^{(j)},x^{(k)}} = \frac{\sum_{i=1}^n (x_{ij}-\bar{x}^{(j)}) (x_{ik}-\bar{x}^{(k)})}{\sqrt{\sum_{i=1}^n (x_{ij}-\bar{x}^{(j)})^2} \sqrt{\sum_{i=1}^n (x_{ik}-\bar{x}^{(k)})^2}}
\end{equation}

in which $\bar{x}^{(j)}$ and $\bar{x}^{(k)}$ are the sample means ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean-samp})

\begin{equation} \label{eq:corrmat-samp-mean-samp}
\begin{split}
\bar{x}^{(j)} &= \frac{1}{n} \sum_{i=1}^n x_{ij} \\
\bar{x}^{(k)} &= \frac{1}{n} \sum_{i=1}^n x_{ik} \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D169 | shortcut: corrmat-samp | author: JoramSoch | date: 2021-12-14, 07:45.
\vspace{1em}



\subsection{Measures of central tendency}

\subsubsection[\textit{Median}]{Median} \label{sec:med}
\setcounter{equation}{0}

\textbf{Definition:} The median of a sample or random variable is the value separating the higher half from the lower half of its values.

\vspace{1em}
1) Let $x = \left\lbrace x_1, \ldots, x_n \right\rbrace$ be a sample ($\rightarrow$ Definition "samp") from a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X$. Then, the median of $x$ is

\begin{equation} \label{eq:med-med-samp}
\mathrm{median}(x) = \left\{
\begin{array}{cl}
x_{(n+1)/2} \; , & \text{if} \; n \; \text{is odd} \\
\frac{1}{2}(x_{n/2} + x_{n/2+1}) \; , & \text{if} \; n \; \text{is even} \; ,
\end{array}
\right.
\end{equation}

i.e. the median is the "middle" number when all numbers are sorted from smallest to largest.

\vspace{1em}
2) Let $X$ be a continuous random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) $F_X(x)$. Then, the median of $X$ is

\begin{equation} \label{eq:med-med-rvar}
\mathrm{median}(X) = x, \quad \mathrm{s.t.} \quad F_X(x) = \frac{1}{2} \; ,
\end{equation}

i.e. the median is the value at which the CDF is $1/2$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Median"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-10-15; URL: \url{https://en.wikipedia.org/wiki/Median}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D101 | shortcut: med | author: JoramSoch | date: 2020-10-15, 10:53.
\vspace{1em}



\subsubsection[\textit{Mode}]{Mode} \label{sec:mode}
\setcounter{equation}{0}

\textbf{Definition:} The mode of a sample or random variable is the value which occurs most often or with largest probability among all its values.

\vspace{1em}
1) Let $x = \left\lbrace x_1, \ldots, x_n \right\rbrace$ be a sample ($\rightarrow$ Definition "samp") from a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X$. Then, the mode of $x$ is the value which occurs most often in the list $x_1, \ldots, x_n$.

\vspace{1em}
2) Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) or probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) $f_X(x)$. Then, the mode of $X$ is the the value which maximizes the PMF or PDF:

\begin{equation} \label{eq:mode-mode-rvar}
\mathrm{mode}(X) = \operatorname*{arg\,max}_x f_X(x) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Mode (statistics)"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-10-15; URL: \url{https://en.wikipedia.org/wiki/Mode_(statistics)}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D102 | shortcut: mode | author: JoramSoch | date: 2020-10-15, 11:10.
\vspace{1em}



\subsection{Measures of statistical dispersion}

\subsubsection[\textit{Standard deviation}]{Standard deviation} \label{sec:std}
\setcounter{equation}{0}

\textbf{Definition:} The standard deviation $\sigma$ of a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X$ with expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) $\mu$ is defined as the square root of the variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}), i.e.

\begin{equation} \label{eq:std-std}
\sigma(X) = \sqrt{\mathrm{E}\left[ (X-\mu)^2 \right]} \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Standard deviation"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-09-03; URL: \url{https://en.wikipedia.org/wiki/Standard_deviation#Definition_of_population_values}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D94 | shortcut: std | author: JoramSoch | date: 2020-09-03, 05:43.
\vspace{1em}



\subsubsection[\textit{Full width at half maximum}]{Full width at half maximum} \label{sec:fwhm}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a continuous random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with a unimodal probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) $f_X(x)$ and mode ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mode}) $x_M$. Then, the full width at half maximum of $X$ is defined as

\begin{equation} \label{eq:fwhm-FWHM}
\mathrm{FHWM}(X) = \Delta x = x_2 - x_1
\end{equation}

where $x_1$ and $x_2$ are specified, such that

\begin{equation} \label{eq:fwhm-x12}
f_X(x_1) = f_X(x_2) = \frac{1}{2} f_X(x_M) \quad \text{and} \quad x_1 < x_M < x_2 \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Full width at half maximum"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-08-19; URL: \url{https://en.wikipedia.org/wiki/Full_width_at_half_maximum}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D91 | shortcut: fwhm | author: JoramSoch | date: 2020-08-19, 05:40.
\vspace{1em}



\subsection{Further summary statistics}

\subsubsection[\textit{Minimum}]{Minimum} \label{sec:min}
\setcounter{equation}{0}

\textbf{Definition:} The minimum of a sample or random variable is its lowest observed or possible value.

\vspace{1em}
1) Let $x = \left\lbrace x_1, \ldots, x_n \right\rbrace$ be a sample ($\rightarrow$ Definition "samp") from a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X$. Then, the minimum of $x$ is

\begin{equation} \label{eq:min-min-samp}
\mathrm{min}(x) = x_j, \quad \text{such that} \quad x_j \leq x_i \quad \text{for all} \quad i = 1, \ldots, n, \; i \neq j \; ,
\end{equation}

i.e. the minimum is the value which is smaller than or equal to all other observed values.

\vspace{1em}
2) Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with possible values $\mathcal{X}$. Then, the minimum of $X$ is

\begin{equation} \label{eq:min-min-rvar}
\mathrm{min}(X) = \tilde{x}, \quad \text{such that} \quad \tilde{x} < x \quad \text{for all} \quad x \in \mathcal{X}\setminus\left\lbrace \tilde{x} \right\rbrace \; ,
\end{equation}

i.e. the minimum is the value which is smaller than all other possible values.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Sample maximum and minimum"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-11-12; URL: \url{https://en.wikipedia.org/wiki/Sample_maximum_and_minimum}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D107 | shortcut: min | author: JoramSoch | date: 2020-11-12, 05:25.
\vspace{1em}



\subsubsection[\textit{Maximum}]{Maximum} \label{sec:max}
\setcounter{equation}{0}

\textbf{Definition:} The maximum of a sample or random variable is its highest observed or possible value.

\vspace{1em}
1) Let $x = \left\lbrace x_1, \ldots, x_n \right\rbrace$ be a sample ($\rightarrow$ Definition "samp") from a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X$. Then, the maximum of $x$ is

\begin{equation} \label{eq:max-max-samp}
\mathrm{max}(x) = x_j, \quad \text{such that} \quad x_j \geq x_i \quad \text{for all} \quad i = 1, \ldots, n, \; i \neq j \; ,
\end{equation}

i.e. the maximum is the value which is larger than or equal to all other observed values.

\vspace{1em}
2) Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with possible values $\mathcal{X}$. Then, the maximum of $X$ is

\begin{equation} \label{eq:max-max-rvar}
\mathrm{max}(X) = \tilde{x}, \quad \text{such that} \quad \tilde{x} > x \quad \text{for all} \quad x \in \mathcal{X}\setminus\left\lbrace \tilde{x} \right\rbrace \; ,
\end{equation}

i.e. the maximum is the value which is larger than all other possible values.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Sample maximum and minimum"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-11-12; URL: \url{https://en.wikipedia.org/wiki/Sample_maximum_and_minimum}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D108 | shortcut: max | author: JoramSoch | date: 2020-11-12, 05:33.
\vspace{1em}



\subsection{Further moments}

\subsubsection[\textit{Moment}]{Moment} \label{sec:mom}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}), let $c$ be a constant ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:const}) and let $n$ be a positive integer. Then, the $n$-th moment of $X$ about $c$ is defined as the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of the $n$-th power of $X$ minus $c$:

\begin{equation} \label{eq:mom-mom}
\mu_n(c) = \mathrm{E}[(X-c)^n] \; .
\end{equation}

The "$n$-th moment of $X$" may also refer to:

\begin{itemize}

\item the $n$-th raw moment ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mom-raw}) $\mu_n' = \mu_n(0)$;

\item the $n$-th central moment ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mom-cent}) $\mu_n = \mu_n(\mu)$;

\item the $n$-th standardized moment ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mom-stand}) $\mu_n^{*} = \mu_n/\sigma^n$.

\end{itemize}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Moment (mathematics)"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-08-19; URL: \url{https://en.wikipedia.org/wiki/Moment_(mathematics)#Significance_of_the_moments}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D90 | shortcut: mom | author: JoramSoch | date: 2020-08-19, 05:24.
\vspace{1em}



\subsubsection[\textbf{Moment in terms of moment-generating function}]{Moment in terms of moment-generating function} \label{sec:mom-mgf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a scalar random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with the moment-generating function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mgf}) $M_X(t)$. Then, the $n$-th raw moment ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mom-raw}) of $X$ can be calculated from the moment-generating function via

\begin{equation} \label{eq:mom-mgf-mom-mgf}
\mathrm{E}(X^n) = M_X^{(n)}(0)
\end{equation}

where $n$ is a positive integer and $M_X^{(n)}(t)$ is the $n$-th derivative of $M_X(t)$.


\vspace{1em}
\textbf{Proof:} Using the definition of the moment-generating function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mgf}), we can write:

\begin{equation} \label{eq:mom-mgf-mom-mgf-s1}
M_X^{(n)}(t) = \frac{\mathrm{d}^n}{\mathrm{d}t^n} \mathrm{E}(e^{tX}) \; .
\end{equation}

Using the power series expansion of the exponential function

\begin{equation} \label{eq:mom-mgf-exp-ps}
e^x = \sum_{n=0}^\infty \frac{x^n}{n!} \; ,
\end{equation}

equation \eqref{eq:mom-mgf-mom-mgf-s1} becomes

\begin{equation} \label{eq:mom-mgf-mom-mgf-s2}
M_X^{(n)}(t) = \frac{\mathrm{d}^n}{\mathrm{d}t^n} \mathrm{E}\left( \sum_{m=0}^\infty \frac{t^m X^m}{m!} \right) \; .
\end{equation}

Because the expected value is a linear operator ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-lin}), we have:

\begin{equation} \label{eq:mom-mgf-mom-mgf-s3}
\begin{split}
M_X^{(n)}(t) &= \frac{\mathrm{d}^n}{\mathrm{d}t^n} \sum_{m=0}^\infty \mathrm{E}\left( \frac{t^m X^m}{m!} \right) \\
&= \sum_{m=0}^\infty \frac{\mathrm{d}^n}{\mathrm{d}t^n} \frac{t^m}{m!} \mathrm{E}\left( X^m \right) \; .
\end{split}
\end{equation}

Using the $n$-th derivative of the $m$-th power

\begin{equation} \label{eq:mom-mgf-dndx-xm}
\frac{\mathrm{d}^n}{\mathrm{d}x^n} x^m = \left\{
\begin{array}{rl}
m^{\underline{n}} \, x^{m-n} \; , & \text{if} \; n \leq m \\
0 \; , & \text{if} \; n > m \; .
\end{array}
\right.
\end{equation}

with the falling factorial

\begin{equation} \label{eq:mom-mgf-fact-fall}
m^{\underline{n}} = \prod_{i=0}^{n-1} (m-i) = \frac{m!}{(m-n)!} \; ,
\end{equation}

equation \eqref{eq:mom-mgf-mom-mgf-s3} becomes

\begin{equation} \label{eq:mom-mgf-mom-mgf-s4}
\begin{split}
M_X^{(n)}(t) &= \sum_{m=n}^\infty \frac{m^{\underline{n}} \, t^{m-n}}{m!} \mathrm{E}\left( X^m \right) \\
&\overset{\eqref{eq:mom-mgf-fact-fall}}{=} \sum_{m=n}^\infty \frac{m! \, t^{m-n}}{(m-n)! \, m!} \mathrm{E}\left( X^m \right) \\
&= \sum_{m=n}^\infty \frac{t^{m-n}}{(m-n)!} \mathrm{E}\left( X^m \right) \\
&= \frac{t^{n-n}}{(n-n)!} \mathrm{E}\left( X^n \right) + \sum_{m=n+1}^\infty \frac{t^{m-n}}{(m-n)!} \mathrm{E}\left( X^m \right) \\
&= \frac{t^0}{0!} \, \mathrm{E}\left( X^n \right) + \sum_{m=n+1}^\infty \frac{t^{m-n}}{(m-n)!} \mathrm{E}\left( X^m \right) \\
&= \mathrm{E}\left( X^n \right) + \sum_{m=n+1}^\infty \frac{t^{m-n}}{(m-n)!} \mathrm{E}\left( X^m \right) \; .
\end{split}
\end{equation}

Setting $t = 0$ in \eqref{eq:mom-mgf-mom-mgf-s4} yields

\begin{equation} \label{eq:mom-mgf-mom-mgf-s5}
\begin{split}
M_X^{(n)}(0) &= \mathrm{E}\left( X^n \right) + \sum_{m=n+1}^\infty \frac{0^{m-n}}{(m-n)!} \mathrm{E}\left( X^m \right) \\
&= \mathrm{E}\left( X^n \right)
\end{split}
\end{equation}

which conforms to equation \eqref{eq:mom-mgf-mom-mgf}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item ProofWiki (2020): "Moment in terms of Moment Generating Function"; in: \textit{ProofWiki}, retrieved on 2020-08-19; URL: \url{https://proofwiki.org/wiki/Moment_in_terms_of_Moment_Generating_Function}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P153 | shortcut: mom-mgf | author: JoramSoch | date: 2020-08-19, 07:51.
\vspace{1em}



\subsubsection[\textit{Raw moment}]{Raw moment} \label{sec:mom-raw}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) and let $n$ be a positive integer. Then, the $n$-th raw moment of $X$, also called ($n$-th) "crude moment", is defined as the $n$-th moment ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mom}) of $X$ about the value 0:

\begin{equation} \label{eq:mom-raw-mom-raw}
\mu_n' = \mu_n(0) = \mathrm{E}[(X-0)^n] = \mathrm{E}[X^n] \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Moment (mathematics)"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-10-08; URL: \url{https://en.wikipedia.org/wiki/Moment_(mathematics)#Significance_of_the_moments}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D97 | shortcut: mom-raw | author: JoramSoch | date: 2020-10-08, 03:31.
\vspace{1em}



\subsubsection[\textbf{First raw moment is mean}]{First raw moment is mean} \label{sec:momraw-1st}
\setcounter{equation}{0}

\textbf{Theorem:} The first raw moment ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mom-raw}) equals the mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}), i.e.

\begin{equation} \label{eq:momraw-1st-momraw-1st}
\mu_1' = \mu \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The first raw moment ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mom-raw}) of a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X$ is defined as

\begin{equation} \label{eq:momraw-1st-momraw-1st-def}
\mu_1' = \mathrm{E}\left[ (X-0)^1 \right]
\end{equation}

which is equal to the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of $X$:

\begin{equation} \label{eq:momraw-1st-momraw-1st-qed}
\mu_1' = \mathrm{E}\left[ X \right] = \mu \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P171 | shortcut: momraw-1st | author: JoramSoch | date: 2020-10-08, 04:19.
\vspace{1em}



\subsubsection[\textbf{Second raw moment and variance}]{Second raw moment and variance} \label{sec:momraw-2nd}
\setcounter{equation}{0}

\textbf{Theorem:} The second raw moment ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mom-raw}) can be expressed as

\begin{equation} \label{eq:momraw-2nd-momraw-2nd}
\mu_2' = \mathrm{Var}(X) + \mathrm{E}(X)^2
\end{equation}

where $\mathrm{Var}(X)$ is the variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) of $X$ and $\mathrm{E}(X)$ is the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of $X$.


\vspace{1em}
\textbf{Proof:} The second raw moment ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mom-raw}) of a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X$ is defined as

\begin{equation} \label{eq:momraw-2nd-momraw-2nd-def}
\mu_2' = \mathrm{E}\left[ (X-0)^2 \right] \; .
\end{equation}

Using the partition of variance into expected values ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:var-mean})

\begin{equation} \label{eq:momraw-2nd-var-mean}
\mathrm{Var}(X) = \mathrm{E}(X^2) - \mathrm{E}(X)^2 \; ,
\end{equation}

the second raw moment can be rearranged into:

\begin{equation} \label{eq:momraw-2nd-momraw-2nd-qed}
\mu_2' \overset{\eqref{eq:momraw-2nd-momraw-2nd-def}}{=} \mathrm{E}(X^2) \overset{\eqref{eq:momraw-2nd-var-mean}}{=} \mathrm{Var}(X) + \mathrm{E}(X)^2 \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P172 | shortcut: momraw-2nd | author: JoramSoch | date: 2020-10-08, 05:05.
\vspace{1em}



\subsubsection[\textit{Central moment}]{Central moment} \label{sec:mom-cent}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) $\mu$ and let $n$ be a positive integer. Then, the $n$-th central moment of $X$ is defined as the $n$-th moment ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mom}) of $X$ about the value $\mu$:

\begin{equation} \label{eq:mom-cent-mom-cent}
\mu_n = \mathrm{E}[(X-\mu)^n] \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Moment (mathematics)"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-10-08; URL: \url{https://en.wikipedia.org/wiki/Moment_(mathematics)#Significance_of_the_moments}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D98 | shortcut: mom-cent | author: JoramSoch | date: 2020-10-08, 03:37.
\vspace{1em}



\subsubsection[\textbf{First central moment is zero}]{First central moment is zero} \label{sec:momcent-1st}
\setcounter{equation}{0}

\textbf{Theorem:} The first central moment ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mom-cent}) is zero, i.e.

\begin{equation} \label{eq:momcent-1st-momcent-1st}
\mu_1 = 0 \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The first central moment ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mom-cent}) of a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X$ with mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) $\mu$ is defined as

\begin{equation} \label{eq:momcent-1st-momcent-1st-def}
\mu_1 = \mathrm{E}\left[ (X-\mu)^1 \right] \; .
\end{equation}

Due to the linearity of the expected value ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-lin}) and by plugging in $\mu = \mathrm{E}(X)$, we have

\begin{equation} \label{eq:momcent-1st-momcent-1st-qed}
\begin{split}
\mu_1 &= \mathrm{E}\left[ X-\mu \right] \\
&= \mathrm{E}(X) - \mu \\
&= \mathrm{E}(X) - \mathrm{E}(X) \\
&= 0 \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item ProofWiki (2020): "First Central Moment is Zero"; in: \textit{ProofWiki}, retrieved on 2020-09-09; URL: \url{https://proofwiki.org/wiki/First_Central_Moment_is_Zero}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P167 | shortcut: momcent-1st | author: JoramSoch | date: 2020-09-09, 07:51.
\vspace{1em}



\subsubsection[\textbf{Second central moment is variance}]{Second central moment is variance} \label{sec:momcent-2nd}
\setcounter{equation}{0}

\textbf{Theorem:} The second central moment ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mom-cent}) equals the variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}), i.e.

\begin{equation} \label{eq:momcent-2nd-momcent-2nd}
\mu_2 = \mathrm{Var}(X) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The second central moment ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mom-cent}) of a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X$ with mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) $\mu$ is defined as

\begin{equation} \label{eq:momcent-2nd-momcent-2nd-def}
\mu_2 = \mathrm{E}\left[ (X-\mu)^2 \right]
\end{equation}

which is equivalent to the definition of the variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}):

\begin{equation} \label{eq:momcent-2nd-momraw-1st-qed}
\mu_2 = \mathrm{E}\left[ (X - \mathrm{E}(X))^2 \right] = \mathrm{Var}(X) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Moment (mathematics)"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-10-08; URL: \url{https://en.wikipedia.org/wiki/Moment_(mathematics)#Significance_of_the_moments}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P173 | shortcut: momcent-2nd | author: JoramSoch | date: 2020-10-08, 05:13.
\vspace{1em}



\subsubsection[\textit{Standardized moment}]{Standardized moment} \label{sec:mom-stand}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) $\mu$ and standard deviation ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:std}) $\sigma$ and let $n$ be a positive integer. Then, the $n$-th standardized moment of $X$ is defined as the $n$-th moment ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mom}) of $X$ about the value $\mu$, divided by the $n$-th power of $\sigma$:

\begin{equation} \label{eq:mom-stand-mom-stand}
\mu_n^{*} = \frac{\mu_n}{\sigma^n} =  \frac{\mathrm{E}[(X-\mu)^n]}{\sigma^n} \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Moment (mathematics)"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-10-08; URL: \url{https://en.wikipedia.org/wiki/Moment_(mathematics)#Standardized_moments}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D99 | shortcut: mom-stand | author: JoramSoch | date: 2020-10-08, 03:47.
\vspace{1em}



\pagebreak
\section{Information theory}

\subsection{Shannon entropy}

\subsubsection[\textit{Definition}]{Definition} \label{sec:ent}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a discrete random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with possible outcomes $\mathcal{X}$ and the (observed or assumed) probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) $p(x) = f_X(x)$. Then, the entropy (also referred to as "Shannon entropy") of $X$ is defined as

\begin{equation} \label{eq:ent-ent}
\mathrm{H}(X) = - \sum_{x \in \mathcal{X}} p(x) \cdot \log_b p(x)
\end{equation}

where $b$ is the base of the logarithm specifying in which unit the entropy is determined.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Shannon CE (1948): "A Mathematical Theory of Communication"; in: \textit{Bell System Technical Journal}, vol. 27, iss. 3, pp. 379-423; URL: \url{https://ieeexplore.ieee.org/document/6773024}; DOI: 10.1002/j.1538-7305.1948.tb01338.x.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D15 | shortcut: ent | author: JoramSoch | date: 2020-02-19, 17:36.
\vspace{1em}



\subsubsection[\textbf{Non-negativity}]{Non-negativity} \label{sec:ent-nonneg}
\setcounter{equation}{0}

\textbf{Theorem:} The entropy of a discrete random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) is a non-negative number:

\begin{equation} \label{eq:ent-nonneg-ent-nonneg}
\mathrm{H}(X) \geq 0 \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The entropy of a discrete random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ent}) is defined as

\begin{equation} \label{eq:ent-nonneg-ent}
\mathrm{H}(X) = - \sum_{x \in \mathcal{X}} p(x) \cdot \log_b p(x)
\end{equation}

The minus sign can be moved into the sum:

\begin{equation} \label{eq:ent-nonneg-ent-dev}
\mathrm{H}(X) = \sum_{x \in \mathcal{X}} \left[ p(x) \cdot \left( - \log_b p(x) \right) \right]
\end{equation}

Because the co-domain of probability mass functions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) is $[0,1]$, we can deduce:

\begin{equation} \label{eq:ent-nonneg-nonneg}
\begin{array}{rcccl}
0 &\leq &p(x) &\leq &1 \\
-\infty &\leq &\log_b p(x) &\leq &0 \\
0 &\leq &-\log_b p(x) &\leq &+\infty \\
0 &\leq &p(x) \cdot \left(-\log_b p(x)\right) &\leq &+\infty \; .
\end{array}
\end{equation}

By convention, $0 \cdot \log_b(0)$ is taken to be $0$ when calculating entropy, consistent with

\begin{equation} \label{eq:ent-nonneg-lim-0log0}
\lim_{p \to 0} \left[ p \log_b(p) \right] = 0 \; .
\end{equation}

Taking this together, each addend in \eqref{eq:ent-nonneg-ent-dev} is positive or zero and thus, the entire sum must also be non-negative.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Cover TM, Thomas JA (1991): "Elements of Information Theory", p. 15; URL: \url{https://www.wiley.com/en-us/Elements+of+Information+Theory%2C+2nd+Edition-p-9780471241959}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P57 | shortcut: ent-nonneg | author: JoramSoch | date: 2020-02-19, 19:10.
\vspace{1em}



\subsubsection[\textbf{Concavity}]{Concavity} \label{sec:ent-conc}
\setcounter{equation}{0}

\textbf{Theorem:} The entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ent}) is concave in the probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) $p$, i.e.

\begin{equation} \label{eq:ent-conc-ent-conc}
\mathrm{H}[\lambda p_1 + (1-\lambda) p_2] \geq \lambda \mathrm{H}[p_1] + (1-\lambda) \mathrm{H}[p_2]
\end{equation}

where $p_1$ and $p_2$ are probability mass functions and $0 \leq \lambda \leq 1$.


\vspace{1em}
\textbf{Proof:} Let $X$ be a discrete random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with possible outcomes $\mathcal{X}$ and let $u(x)$ be the probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) of a discrete uniform distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:duni}) on $X \in \mathcal{X}$. Then, the entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ent}) of an arbitrary probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) $p(x)$ can be rewritten as

\begin{equation} \label{eq:ent-conc-ent-kl}
\begin{split}
\mathrm{H}[p] &= - \sum_{x \in \mathcal{X}} p(x) \cdot \log p(x) \\
&= - \sum_{x \in \mathcal{X}} p(x) \cdot \log \frac{p(x)}{u(x)} u(x) \\
&= - \sum_{x \in \mathcal{X}} p(x) \cdot \log \frac{p(x)}{u(x)} - \sum_{x \in \mathcal{X}} p(x) \cdot \log u(x) \\
&= - \mathrm{KL}[p||u] - \log \frac{1}{|\mathcal{X}|} \sum_{x \in \mathcal{X}} p(x) \\
&= \log |\mathcal{X}| - \mathrm{KL}[p||u] \\
\log |\mathcal{X}| - \mathrm{H}[p] &= \mathrm{KL}[p||u]
\end{split}
\end{equation}

where we have applied the definition of the Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}), the probability mass function of the discrete uniform distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:duni-pmf}) and the total sum over the probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}).

Note that the KL divergence is convex ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:kl-conv}) in the pair of probability distributions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist}) $(p,q)$:

\begin{equation} \label{eq:ent-conc-kl-conv}
\mathrm{KL}[\lambda p_1 + (1-\lambda) p_2||\lambda q_1 + (1-\lambda) q_2] \leq \lambda \mathrm{KL}[p_1||q_1] + (1-\lambda) \mathrm{KL}[p_2||q_2]
\end{equation}

A special case of this is given by

\begin{equation} \label{eq:ent-conc-kl-conv-u}
\begin{split}
\mathrm{KL}[\lambda p_1 + (1-\lambda) p_2||\lambda u + (1-\lambda) u] &\leq \lambda \mathrm{KL}[p_1||u] + (1-\lambda) \mathrm{KL}[p_2||u] \\
\mathrm{KL}[\lambda p_1 + (1-\lambda) p_2||u] &\leq \lambda \mathrm{KL}[p_1||u] + (1-\lambda) \mathrm{KL}[p_2||u]
\end{split}
\end{equation}

and applying equation \eqref{eq:ent-conc-ent-kl}, we have

\begin{equation} \label{eq:ent-conc-ent-conc-qed}
\begin{split}
\log |\mathcal{X}| - \mathrm{H}[\lambda p_1 + (1-\lambda) p_2] &\leq \lambda \left( \log |\mathcal{X}| - \mathrm{H}[p_1] \right) + (1-\lambda) \left( \log |\mathcal{X}| - \mathrm{H}[p_2] \right) \\
\log |\mathcal{X}| - \mathrm{H}[\lambda p_1 + (1-\lambda) p_2] &\leq \log |\mathcal{X}| - \lambda \mathrm{H}[p_1] - (1-\lambda) \mathrm{H}[p_2] \\
- \mathrm{H}[\lambda p_1 + (1-\lambda) p_2] &\leq - \lambda \mathrm{H}[p_1] - (1-\lambda) \mathrm{H}[p_2] \\
\mathrm{H}[\lambda p_1 + (1-\lambda) p_2] &\geq \lambda \mathrm{H}[p_1] + (1-\lambda) \mathrm{H}[p_2]
\end{split}
\end{equation}

which is equivalent to \eqref{eq:ent-conc-ent-conc}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Entropy (information theory)"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-08-11; URL: \url{https://en.wikipedia.org/wiki/Entropy_(information_theory)#Further_properties}.
\item Cover TM, Thomas JA (1991): "Elements of Information Theory", p. 30; URL: \url{https://www.wiley.com/en-us/Elements+of+Information+Theory%2C+2nd+Edition-p-9780471241959}.
\item Xie, Yao (2012): "Chain Rules and Inequalities"; in: \textit{ECE587: Information Theory}, Lecture 3, Slide 25; URL: \url{https://www2.isye.gatech.edu/~yxie77/ece587/Lecture3.pdf}.
\item Goh, Siong Thye (2016): "Understanding the proof of the concavity of entropy"; in: \textit{StackExchange Mathematics}, retrieved on 2020-11-08; URL: \url{https://math.stackexchange.com/questions/2000194/understanding-the-proof-of-the-concavity-of-entropy}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P149 | shortcut: ent-conc | author: JoramSoch | date: 2020-08-11, 08:29.
\vspace{1em}



\subsubsection[\textit{Conditional entropy}]{Conditional entropy} \label{sec:ent-cond}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ and $Y$ be discrete random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with possible outcomes $\mathcal{X}$ and $\mathcal{Y}$ and probability mass functions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) $p(x)$ and $p(y)$. Then, the conditional entropy of $Y$ given $X$ or, entropy of $Y$ conditioned on $X$, is defined as

\begin{equation} \label{eq:ent-cond-ent-cond}
\mathrm{H}(Y|X) = \sum_{x \in \mathcal{X}} p(x) \cdot \mathrm{H}(Y|X=x)
\end{equation}

where $\mathrm{H}(Y \vert X=x)$ is the (marginal) entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ent}) of $Y$, evaluated at $x$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Cover TM, Thomas JA (1991): "Joint Entropy and Conditional Entropy"; in: \textit{Elements of Information Theory}, ch. 2.2, p. 15; URL: \url{https://www.wiley.com/en-us/Elements+of+Information+Theory%2C+2nd+Edition-p-9780471241959}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D17 | shortcut: ent-cond | author: JoramSoch | date: 2020-02-19, 18:08.
\vspace{1em}



\subsubsection[\textit{Joint entropy}]{Joint entropy} \label{sec:ent-joint}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ and $Y$ be discrete random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with possible outcomes $\mathcal{X}$ and $\mathcal{Y}$ and joint probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) $p(x,y)$. Then, the joint entropy of $X$ and $Y$ is defined as

\begin{equation} \label{eq:ent-joint-ent-joint}
\mathrm{H}(X,Y) = - \sum_{x \in \mathcal{X}} \sum_{y \in \mathcal{Y}} p(x,y) \cdot \log_b p(x,y)
\end{equation}

where $b$ is the base of the logarithm specifying in which unit the entropy is determined.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Cover TM, Thomas JA (1991): "Joint Entropy and Conditional Entropy"; in: \textit{Elements of Information Theory}, ch. 2.2, p. 16; URL: \url{https://www.wiley.com/en-us/Elements+of+Information+Theory%2C+2nd+Edition-p-9780471241959}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D18 | shortcut: ent-joint | author: JoramSoch | date: 2020-02-19, 18:18.
\vspace{1em}



\subsubsection[\textit{Cross-entropy}]{Cross-entropy} \label{sec:ent-cross}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a discrete random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with possible outcomes $\mathcal{X}$ and let $P$ and $Q$ be two probability distributions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist}) on $X$ with the probability mass functions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) $p(x)$ and $q(x)$. Then, the cross-entropy of $Q$ relative to $P$ is defined as

\begin{equation} \label{eq:ent-cross-ent-cross}
\mathrm{H}(P,Q) = - \sum_{x \in \mathcal{X}} p(x) \cdot \log_b q(x)
\end{equation}

where $b$ is the base of the logarithm specifying in which unit the cross-entropy is determined.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Cross entropy"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-07-28; URL: \url{https://en.wikipedia.org/wiki/Cross_entropy#Definition}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D85 | shortcut: ent-cross | author: JoramSoch | date: 2020-07-28, 02:51.
\vspace{1em}



\subsubsection[\textbf{Convexity of cross-entropy}]{Convexity of cross-entropy} \label{sec:entcross-conv}
\setcounter{equation}{0}

\textbf{Theorem:} The cross-entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ent-cross}) is convex in the probability distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist}) $q$, i.e.

\begin{equation} \label{eq:entcross-conv-ent-cross-conv}
\mathrm{H}[p,\lambda q_1 + (1-\lambda) q_2] \leq \lambda \mathrm{H}[p,q_1] + (1-\lambda) \mathrm{H}[p,q_2]
\end{equation}

where $p$ is a fixed and $q_1$ and $q_2$ are any two probability distributions and $0 \leq \lambda \leq 1$.


\vspace{1em}
\textbf{Proof:} The relationship between Kullback-Leibler divergence, entropy and cross-entropy ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:kl-ent}) is:

\begin{equation} \label{eq:entcross-conv-kl-ent}
\mathrm{KL}[P||Q] = \mathrm{H}(P,Q) - \mathrm{H}(P) \; .
\end{equation}

Note that the KL divergence is convex ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:kl-conv}) in the pair of probability distributions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist}) $(p,q)$:

\begin{equation} \label{eq:entcross-conv-kl-conv}
\mathrm{KL}[\lambda p_1 + (1-\lambda) p_2||\lambda q_1 + (1-\lambda) q_2] \leq \lambda \mathrm{KL}[p_1||q_1] + (1-\lambda) \mathrm{KL}[p_2||q_2]
\end{equation}

A special case of this is given by

\begin{equation} \label{eq:entcross-conv-kl-conv-p}
\begin{split}
\mathrm{KL}[\lambda p + (1-\lambda) p||\lambda q_1 + (1-\lambda) q_2] &\leq \lambda \mathrm{KL}[p||q_1] + (1-\lambda) \mathrm{KL}[p||q_2] \\
\mathrm{KL}[p||\lambda q_1 + (1-\lambda) q_2] &\leq \lambda \mathrm{KL}[p||q_1] + (1-\lambda) \mathrm{KL}[p||q_2]
\end{split}
\end{equation}

and applying equation \eqref{eq:entcross-conv-kl-ent}, we have

\begin{equation} \label{eq:entcross-conv-ent-cross-conv-qed}
\begin{split}
\mathrm{H}[p,\lambda q_1 + (1-\lambda) q_2] - \mathrm{H}[p] &\leq \lambda \left( \mathrm{H}[p,q_1] - \mathrm{H}[p] \right) + (1-\lambda) \left( \mathrm{H}[p,q_2] - \mathrm{H}[p] \right) \\
\mathrm{H}[p,\lambda q_1 + (1-\lambda) q_2] - \mathrm{H}[p] &\leq \lambda \mathrm{H}[p,q_1] + (1-\lambda) \mathrm{H}[p,q_2] - \mathrm{H}[p] \\
\mathrm{H}[p,\lambda q_1 + (1-\lambda) q_2] &\leq \lambda \mathrm{H}[p,q_1] + (1-\lambda) \mathrm{H}[p,q_2]
\end{split}
\end{equation}

which is equivalent to \eqref{eq:entcross-conv-ent-cross-conv}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Cross entropy"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-08-11; URL: \url{https://en.wikipedia.org/wiki/Cross_entropy#Definition}.
\item gunes (2019): "Convexity of cross entropy"; in: \textit{StackExchange CrossValidated}, retrieved on 2020-11-08; URL: \url{https://stats.stackexchange.com/questions/394463/convexity-of-cross-entropy}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P150 | shortcut: entcross-conv | author: JoramSoch | date: 2020-08-11, 09:16.
\vspace{1em}



\subsubsection[\textbf{Gibbs' inequality}]{Gibbs' inequality} \label{sec:gibbs-ineq}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a discrete random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) and consider two probability distributions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist}) with probability mass functions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) $p(x)$ and $q(x)$. Then, Gibbs' inequality states that the entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ent}) of $X$ according to $P$ is smaller than or equal to the cross-entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ent-cross}) of $P$ and $Q$:

\begin{equation} \label{eq:gibbs-ineq-Gibbs-ineq}
- \sum_{x \in \mathcal{X}} p(x) \, \log_b p(x) \leq - \sum_{x \in \mathcal{X}} p(x) \, \log_b q(x) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} Without loss of generality, we will use the natural logarithm, because a change in the base of the logarithm only implies multiplication by a constant:

\begin{equation} \label{eq:gibbs-ineq-log-ln}
\log_b a = \frac{\ln a}{\ln b} \; .
\end{equation}

Let $I$ be the of all $x$ for which $p(x)$ is non-zero. Then, proving \eqref{eq:gibbs-ineq-Gibbs-ineq} requires to show that

\begin{equation} \label{eq:gibbs-ineq-Gibbs-ineq-s1}
\sum_{x \in I} p(x) \, \ln \frac{p(x)}{q(x)} \geq 0 \; .
\end{equation}

Because $\ln x \leq x - 1$, i.e. $-\ln x \geq 1 - x$, for all $x > 0$, with equality only if $x = 1$, we can say about the left-hand side that

\begin{equation} \label{eq:gibbs-ineq-Gibbs-ineq-s2}
\begin{split}
\sum_{x \in I} p(x) \, \ln \frac{p(x)}{q(x)} &\geq \sum_{x \in I} p(x) \left( 1 - \frac{p(x)}{q(x)} \right) \\
&= \sum_{x \in I} p(x) - \sum_{x \in I} q(x) \; .
\end{split}
\end{equation}

Finally, since $p(x)$ and $q(x)$ are probability mass functions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}), we have

\begin{equation} \label{eq:gibbs-ineq-p-q-pmf}
\begin{split}
0 \leq p(x) \leq 1, \quad \sum_{x \in I} p(x) &= 1 \quad \text{and} \\
0 \leq q(x) \leq 1, \quad \sum_{x \in I} q(x) &\leq 1 \; ,
\end{split}
\end{equation}

such that it follows from \eqref{eq:gibbs-ineq-Gibbs-ineq-s2} that

\begin{equation} \label{eq:gibbs-ineq-Gibbs-ineq-s3}
\begin{split}
\sum_{x \in I} p(x) \, \ln \frac{p(x)}{q(x)} &\geq \sum_{x \in I} p(x) - \sum_{x \in I} q(x) \\
&= 1 - \sum_{x \in I} q(x) \geq 0 \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Gibbs' inequality"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-09-09; URL: \url{https://en.wikipedia.org/wiki/Gibbs%27_inequality#Proof}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P164 | shortcut: gibbs-ineq | author: JoramSoch | date: 2020-09-09, 02:18.
\vspace{1em}



\subsubsection[\textbf{Log sum inequality}]{Log sum inequality} \label{sec:logsum-ineq}
\setcounter{equation}{0}

\textbf{Theorem:} Let $a_1, \ldots, a_n$ and $b_1, \ldots, b_n$ be non-negative real numbers and define $a = \sum_{i=1}^{n} a_i$ and $b = \sum_{i=1}^{n} b_i$. Then, the log sum inequality states that

\begin{equation} \label{eq:logsum-ineq-logsum-ineq}
\sum_{i=1}^n a_i \, \log_c \frac{a_i}{b_i} \geq a \, \log_c \frac{a}{b} \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} Without loss of generality, we will use the natural logarithm, because a change in the base of the logarithm only implies multiplication by a constant:

\begin{equation} \label{eq:logsum-ineq-log-ln}
\log_c a = \frac{\ln a}{\ln c} \; .
\end{equation}

Let $f(x) = x \ln x$. Then, the left-hand side of \eqref{eq:logsum-ineq-logsum-ineq} can be rewritten as

\begin{equation} \label{eq:logsum-ineq-logsum-ineq-s2}
\begin{split}
\sum_{i=1}^n a_i \, \ln \frac{a_i}{b_i} &= \sum_{i=1}^n b_i \, f\left( \frac{a_i}{b_i} \right) \\
&= b \sum_{i=1}^n \frac{b_i}{b} \, f\left( \frac{a_i}{b_i} \right) \; .
\end{split}
\end{equation}

Because $f(x)$ is a convex function and

\begin{equation} \label{eq:logsum-ineq-sum-bi-b}
\begin{split}
\frac{b_i}{b} &\geq 0 \\
\sum_{i=1}^n \frac{b_i}{b} &= 1 \; ,
\end{split}
\end{equation}

applying Jensen's inequality yields

\begin{equation} \label{eq:logsum-ineq-logsum-ineq-s3}
\begin{split}
b \sum_{i=1}^n \frac{b_i}{b} \, f\left( \frac{a_i}{b_i} \right) &\geq b \, f\left( \sum_{i=1}^n \frac{b_i}{b} \frac{a_i}{b_i} \right) \\
&= b \, f\left( \frac{1}{b} \sum_{i=1}^n a_i \right) \\
&= b \, f\left( \frac{a}{b} \right) \\
&= a \, \ln \frac{a}{b} \; .
\end{split}
\end{equation}

Finally, combining \eqref{eq:logsum-ineq-logsum-ineq-s2} and \eqref{eq:logsum-ineq-logsum-ineq-s3}, this demonstrates \eqref{eq:logsum-ineq-logsum-ineq}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Log sum inequality"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-09-09; URL: \url{https://en.wikipedia.org/wiki/Log_sum_inequality#Proof}.
\item Wikipedia (2020): "Jensen's inequality"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-09-09; URL: \url{https://en.wikipedia.org/wiki/Jensen%27s_inequality#Statements}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P165 | shortcut: logsum-ineq | author: JoramSoch | date: 2020-09-09, 02:46.
\vspace{1em}



\subsection{Differential entropy}

\subsubsection[\textit{Definition}]{Definition} \label{sec:dent}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a continuous random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with possible outcomes $\mathcal{X}$ and the (estimated or assumed) probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) $p(x) = f_X(x)$. Then, the differential entropy (also referred to as "continuous entropy") of $X$ is defined as

\begin{equation} \label{eq:dent-dent}
\mathrm{h}(X) = - \int_{\mathcal{X}} p(x) \log_b p(x) \, \mathrm{d}x
\end{equation}

where $b$ is the base of the logarithm specifying in which unit the entropy is determined.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Cover TM, Thomas JA (1991): "Differential Entropy"; in: \textit{Elements of Information Theory}, ch. 8.1, p. 243; URL: \url{https://www.wiley.com/en-us/Elements+of+Information+Theory%2C+2nd+Edition-p-9780471241959}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D16 | shortcut: dent | author: JoramSoch | date: 2020-02-19, 17:53.
\vspace{1em}



\subsubsection[\textbf{Negativity}]{Negativity} \label{sec:dent-neg}
\setcounter{equation}{0}

\textbf{Theorem:} Unlike its discrete analogue ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:ent-nonneg}), the differential entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent}) can become negative.


\vspace{1em}
\textbf{Proof:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a continuous uniform distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:cuni}) with minimum $0$ and maximum $1/2$:

\begin{equation} \label{eq:dent-neg-X}
X \sim \mathcal{U}(0, 1/2) \; .
\end{equation}

Then, its probability density function ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:cuni-pdf}) is:

\begin{equation} \label{eq:dent-neg-X-pdf}
f_X(x) = 2 \quad \text{for} \quad 0 \leq x \leq \frac{1}{2} \; .
\end{equation}

Thus, the differential entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent}) follows as

\begin{equation} \label{eq:dent-neg-X-dent}
\begin{split}
\mathrm{h}(X) &= - \int_{\mathcal{X}} f_X(x) \log_b f_X(x) \, \mathrm{d}x \\
&= - \int_{0}^{\frac{1}{2}} 2 \, \log_b(2) \, \mathrm{d}x \\
&= -\log_b(2) \int_{0}^{\frac{1}{2}} 2 \, \mathrm{d}x \\
&= -\log_b(2) \left[ 2x \right]_{0}^{\frac{1}{2}} \\
&= -\log_b(2)
\end{split}
\end{equation}

which is negative for any base $b > 1$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Differential entropy"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-03-02; URL: \url{https://en.wikipedia.org/wiki/Differential_entropy#Definition}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P68 | shortcut: dent-neg | author: JoramSoch | date: 2020-03-02, 20:32.
\vspace{1em}



\subsubsection[\textbf{Invariance under addition}]{Invariance under addition} \label{sec:dent-inv}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a continuous ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar-disc}) random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}). Then, the differential entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent}) of $X$ remains constant under addition of a constant:

\begin{equation} \label{eq:dent-inv-dent-inv}
\mathrm{h}(X + c) = \mathrm{h}(X) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} By definition, the differential entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent}) of $X$ is

\begin{equation} \label{eq:dent-inv-X-dent}
\mathrm{h}(X) = - \int_{\mathcal{X}} p(x) \log p(x) \, \mathrm{d}x
\end{equation}

where $p(x) = f_X(x)$ is the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $X$.

Define the mappings between $X$ and $Y = X + c$ as

\begin{equation} \label{eq:dent-inv-X-Y}
Y = g(X) = X + c \quad \Leftrightarrow \quad X = g^{-1}(Y) = Y - c \; .
\end{equation}

Note that $g(X)$ is a strictly increasing function, such that the probability density function ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:pdf-sifct}) of $Y$ is

\begin{equation} \label{eq:dent-inv-Y-pdf}
f_Y(y) = f_X(g^{-1}(y)) \, \frac{\mathrm{d}g^{-1}(y)}{\mathrm{d}y} \overset{\eqref{eq:dent-inv-X-Y}}{=} f_X(y-c) \; .
\end{equation}

Writing down the differential entropy for $Y$, we have:

\begin{equation} \label{eq:dent-inv-Y-dent-s1}
\begin{split}
\mathrm{h}(Y) &= - \int_{\mathcal{Y}} f_Y(y) \log f_Y(y) \, \mathrm{d}y \\
&\overset{\eqref{eq:dent-inv-Y-pdf}}{=} - \int_{\mathcal{Y}} f_X(y-c) \log f_X(y-c) \, \mathrm{d}y
\end{split}
\end{equation}

Substituting $x = y - c$, such that $y = x + c$, this yields:

\begin{equation} \label{eq:dent-inv-Y-dent-s2}
\begin{split}
\mathrm{h}(Y) &= - \int_{\left\lbrace y-c \,|\, y \in {\mathcal{Y}} \right\rbrace} f_X(x+c-c) \log f_X(x+c-c) \, \mathrm{d}(x+c) \\
&= - \int_{\mathcal{X}} f_X(x) \log f_X(x) \, \mathrm{d}x \\
&\overset{\eqref{eq:dent-inv-X-dent}}{=} \mathrm{h}(X) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Differential entropy"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-02-12; URL: \url{https://en.wikipedia.org/wiki/Differential_entropy#Properties_of_differential_entropy}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P199 | shortcut: dent-inv | author: JoramSoch | date: 2020-12-02, 16:11.
\vspace{1em}



\subsubsection[\textbf{Addition upon multiplication}]{Addition upon multiplication} \label{sec:dent-add}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a continuous ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar-disc}) random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}). Then, the differential entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent}) of $X$ increases additively upon multiplication with a constant:

\begin{equation} \label{eq:dent-add-dent-add}
\mathrm{h}(aX) = \mathrm{h}(X) + \log |a| \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} By definition, the differential entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent}) of $X$ is

\begin{equation} \label{eq:dent-add-X-dent}
\mathrm{h}(X) = - \int_{\mathcal{X}} p(x) \log p(x) \, \mathrm{d}x
\end{equation}

where $p(x) = f_X(x)$ is the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $X$.

Define the mappings between $X$ and $Y = aX$ as

\begin{equation} \label{eq:dent-add-X-Y}
Y = g(X) = aX \quad \Leftrightarrow \quad X = g^{-1}(Y) = \frac{Y}{a} \; .
\end{equation}

If $a > 0$, then $g(X)$ is a strictly increasing function, such that the probability density function ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:pdf-sifct}) of $Y$ is

\begin{equation} \label{eq:dent-add-Y-pdf-c1}
f_Y(y) = f_X(g^{-1}(y)) \, \frac{\mathrm{d}g^{-1}(y)}{\mathrm{d}y} \overset{\eqref{eq:dent-add-X-Y}}{=} \frac{1}{a} \, f_X\left(\frac{y}{a}\right) \; ;
\end{equation}

if $a < 0$, then $g(X)$ is a strictly decreasing function, such that the probability density function ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:pdf-sdfct}) of $Y$ is

\begin{equation} \label{eq:dent-add-Y-pdf-c2}
f_Y(y) = - f_X(g^{-1}(y)) \, \frac{\mathrm{d}g^{-1}(y)}{\mathrm{d}y} \overset{\eqref{eq:dent-add-X-Y}}{=} -\frac{1}{a} \, f_X\left(\frac{y}{a}\right) \; ;
\end{equation}

thus, we can write

\begin{equation} \label{eq:dent-add-Y-pdf}
f_Y(y) = \frac{1}{|a|} \, f_X\left(\frac{y}{a}\right) \; .
\end{equation}

Writing down the differential entropy for $Y$, we have:

\begin{equation} \label{eq:dent-add-Y-dent-s1}
\begin{split}
\mathrm{h}(Y) &= - \int_{\mathcal{Y}} f_Y(y) \log f_Y(y) \, \mathrm{d}y \\
&\overset{\eqref{eq:dent-add-Y-pdf}}{=} - \int_{\mathcal{Y}} \frac{1}{|a|} \, f_X\left(\frac{y}{a}\right) \log \left[ \frac{1}{|a|} \, f_X\left(\frac{y}{a}\right) \right] \, \mathrm{d}y
\end{split}
\end{equation}

Substituting $x = y/a$, such that $y = ax$, this yields:

\begin{equation} \label{eq:dent-add-Y-dent-s2}
\begin{split}
\mathrm{h}(Y) &= - \int_{\left\lbrace y/a \,|\, y \in {\mathcal{Y}} \right\rbrace} \frac{1}{|a|} \, f_X\left(\frac{ax}{a}\right) \log \left[ \frac{1}{|a|} \, f_X\left(\frac{ax}{a}\right) \right] \, \mathrm{d}(ax) \\
&= - \int_{\mathcal{X}} f_X(x) \log \left[ \frac{1}{|a|} \, f_X(x) \right] \, \mathrm{d}x \\
&= - \int_{\mathcal{X}} f_X(x) \left[ \log f_X(x) - \log |a| \right] \, \mathrm{d}x \\
&= - \int_{\mathcal{X}} f_X(x) \log f_X(x) \, \mathrm{d}x + \log |a| \int_{\mathcal{X}} f_X(x) \, \mathrm{d}x \\
&\overset{\eqref{eq:dent-add-X-dent}}{=} \mathrm{h}(X) + \log |a| \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Differential entropy"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-02-12; URL: \url{https://en.wikipedia.org/wiki/Differential_entropy#Properties_of_differential_entropy}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P200 | shortcut: dent-add | author: JoramSoch | date: 2020-12-02, 16:39.
\vspace{1em}



\subsubsection[\textbf{Addition upon matrix multiplication}]{Addition upon matrix multiplication} \label{sec:dent-addvec}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a continuous ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar-disc}) random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}). Then, the differential entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent}) of $X$ increases additively when multiplied with an invertible matrix $A$:

\begin{equation} \label{eq:dent-addvec-dent-addvec}
\mathrm{h}(AX) = \mathrm{h}(X) + \log |A| \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} By definition, the differential entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent}) of $X$ is

\begin{equation} \label{eq:dent-addvec-X-dent}
\mathrm{h}(X) = - \int_{\mathcal{X}} f_X(x) \log f_X(x) \, \mathrm{d}x
\end{equation}

where $f_X(x)$ is the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $X$ and $\mathcal{X}$ is the set of possible values of $X$.

The probability density function of a linear function of a continuous random vector ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:pdf-linfct}) $Y = g(X) = \Sigma X + \mu$ is

\begin{equation} \label{eq:dent-addvec-pdf-linfct}
f_Y(y) = \left\{
\begin{array}{rl}
\frac{1}{\left| \Sigma \right|} f_X(\Sigma^{-1}(y-\mu)) \; , & \text{if} \; y \in \mathcal{Y} \\
0 \; , & \text{if} \; y \notin \mathcal{Y}
\end{array}
\right.
\end{equation}

where $\mathcal{Y} = \left\lbrace y = \Sigma x + \mu: x \in \mathcal{X} \right\rbrace$ is the set of possible outcomes of $Y$.

Therefore, with $Y = g(X) = AX$, i.e. $\Sigma = A$ and $\mu = 0_n$, the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $Y$ is given by

\begin{equation} \label{eq:dent-addvec-Y-pdf}
f_Y(y) = \left\{
\begin{array}{rl}
\frac{1}{\left| A \right|} f_X(A^{-1}y) \; , & \text{if} \; y \in \mathcal{Y} \\
0 \; , & \text{if} \; y \notin \mathcal{Y}
\end{array}
\right.
\end{equation}

where $\mathcal{Y} = \left\lbrace y = A x: x \in \mathcal{X} \right\rbrace$.

Thus, the differential entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent}) of $Y$ is

\begin{equation} \label{eq:dent-addvec-Y-dent-s1}
\begin{split}
\mathrm{h}(Y) &\overset{\eqref{eq:dent-addvec-X-dent}}{=} - \int_{\mathcal{Y}} f_Y(y) \log f_Y(y) \, \mathrm{d}y \\
&\overset{\eqref{eq:dent-addvec-Y-pdf}}{=} - \int_{\mathcal{Y}} \left[ \frac{1}{\left| A \right|} f_X(A^{-1}y) \right] \log \left[ \frac{1}{\left| A \right|} f_X(A^{-1}y) \right] \, \mathrm{d}y \; .
\end{split}
\end{equation}

Substituting $y = Ax$ into the integral, we obtain

\begin{equation} \label{eq:dent-addvec-Y-dent-s2}
\begin{split}
\mathrm{h}(Y) &= - \int_{\mathcal{X}} \left[ \frac{1}{\left| A \right|} f_X(A^{-1}Ax) \right] \log \left[ \frac{1}{\left| A \right|} f_X(A^{-1}Ax) \right] \, \mathrm{d}(Ax) \\
&= - \frac{1}{\left| A \right|} \int_{\mathcal{X}} f_X(x) \log \left[ \frac{1}{\left| A \right|} f_X(x) \right] \, \mathrm{d}(Ax) \; .
\end{split}
\end{equation}

Using the differential $\mathrm{d}(Ax) = \lvert A \rvert \mathrm{d}x$, this becomes

\begin{equation} \label{eq:dent-addvec-Y-dent-s3}
\begin{split}
\mathrm{h}(Y) &= - \frac{\left| A \right|}{\left| A \right|} \int_{\mathcal{X}} f_X(x) \log \left[ \frac{1}{\left| A \right|} f_X(x) \right] \, \mathrm{d}x \\
&= - \int_{\mathcal{X}} f_X(x) \log f_X(x) \, \mathrm{d}x - \int_{\mathcal{X}} f_X(x) \log \frac{1}{\left| A \right|} \, \mathrm{d}x \; .
\end{split}
\end{equation}

Finally, employing the fact ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) that $\int_{\mathcal{X}} f_X(x) \, \mathrm{d}x = 1$, we can derive the differential entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent}) of $Y$ as

\begin{equation} \label{eq:dent-addvec-Y-dent-s4}
\begin{split}
\mathrm{h}(Y) &= - \int_{\mathcal{X}} f_X(x) \log f_X(x) \, \mathrm{d}x + \log \left| A \right| \int_{\mathcal{X}} f_X(x) \, \mathrm{d}x \\
&\overset{\eqref{eq:dent-addvec-X-dent}}{=} \mathrm{h}(X) + \log |A| \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Differential entropy"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-10-07; URL: \url{https://en.wikipedia.org/wiki/Differential_entropy#Properties_of_differential_entropy}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P261 | shortcut: dent-addvec | author: JoramSoch | date: 2021-10-07, 09:10.
\vspace{1em}



\subsubsection[\textbf{Non-invariance and transformation}]{Non-invariance and transformation} \label{sec:dent-noninv}
\setcounter{equation}{0}

\textbf{Theorem:} The differential entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent}) is not invariant under change of variables, i.e. there exist random variables $X$ and $Y = g(X)$, such that

\begin{equation} \label{eq:dent-noninv-dent-noninv}
\mathrm{h}(Y) \neq \mathrm{h}(X) \; .
\end{equation}

In particular, for an invertible transformation $g: X \rightarrow Y$ from a random vector $X$ to another random vector of the same dimension $Y$, it holds that

\begin{equation} \label{eq:dent-noninv-dent-trans}
\mathrm{h}(Y) = \mathrm{h}(X) + \int_{\mathcal{X}} f_X(x) \log \left| J_g(x) \right| \, \mathrm{d}x \; .
\end{equation}

where $J_g(x)$ is the Jacobian matrix of the vector-valued function $g$ and $\mathcal{X}$ is the set of possible values of $X$.


\vspace{1em}
\textbf{Proof:} By definition, the differential entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent}) of $X$ is

\begin{equation} \label{eq:dent-noninv-X-dent}
\mathrm{h}(X) = - \int_{\mathcal{X}} f_X(x) \log f_X(x) \, \mathrm{d}x
\end{equation}

where $f_X(x)$ is the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $X$.

The probability density function of an invertible function of a continuous random vector ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:pdf-invfct}) $Y = g(X)$ is

\begin{equation} \label{eq:dent-noninv-pdf-invfct}
f_Y(y) = \left\{
\begin{array}{rl}
f_X(g^{-1}(y)) \, \left| J_{g^{-1}}(y) \right| \; , & \text{if} \; y \in \mathcal{Y} \\
0 \; , & \text{if} \; y \notin \mathcal{Y}
\end{array}
\right.
\end{equation}

where $\mathcal{Y} = \left\lbrace y = g(x): x \in \mathcal{X} \right\rbrace$ is the set of possible outcomes of $Y$ and $J_{g^{-1}}(y)$ is the Jacobian matrix of $g^{-1}(y)$

\begin{equation} \label{eq:dent-noninv-jac}
J_{g^{-1}}(y) = \left[ \begin{matrix}
\frac{\mathrm{d}x_1}{\mathrm{d}y_1} & \ldots & \frac{\mathrm{d}x_1}{\mathrm{d}y_n} \\
\vdots & \ddots & \vdots \\
\frac{\mathrm{d}x_n}{\mathrm{d}y_1} & \ldots & \frac{\mathrm{d}x_n}{\mathrm{d}y_n}
\end{matrix} \right] \; .
\end{equation}

Thus, the differential entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent}) of $Y$ is

\begin{equation} \label{eq:dent-noninv-Y-dent-s1}
\begin{split}
\mathrm{h}(Y) &\overset{\eqref{eq:dent-noninv-X-dent}}{=} - \int_{\mathcal{Y}} f_Y(y) \log f_Y(y) \, \mathrm{d}y \\
&\overset{\eqref{eq:dent-noninv-pdf-invfct}}{=} - \int_{\mathcal{Y}} \left[ f_X(g^{-1}(y)) \, \left| J_{g^{-1}}(y) \right| \right] \log \left[ f_X(g^{-1}(y)) \, \left| J_{g^{-1}}(y) \right| \right] \, \mathrm{d}y \; .
\end{split}
\end{equation}

Substituting $y = g(x)$ into the integral and applying $J_{f^{-1}}(y) = J_f^{-1}(x)$, we obtain

\begin{equation} \label{eq:dent-noninv-Y-dent-s2}
\begin{split}
\mathrm{h}(Y) &= - \int_{\mathcal{X}} \left[ f_X(g^{-1}(g(x))) \, \left| J_{g^{-1}}(y) \right| \right] \log \left[ f_X(g^{-1}(g(x))) \, \left| J_{g^{-1}}(y) \right| \right] \, \mathrm{d}[g(x)] \\
&= - \int_{\mathcal{X}} \left[ f_X(x) \, \left| J_g^{-1}(x) \right| \right] \log \left[ f_X(x) \, \left| J_g^{-1}(x) \right| \right] \, \mathrm{d}[g(x)] \; .
\end{split}
\end{equation}

Using the relations $y = f(x) \Rightarrow \mathrm{d}y = \lvert J_f(x) \rvert \, \mathrm{d}x$ and $\lvert A \rvert \lvert B \rvert = \lvert AB \rvert$, this becomes

\begin{equation} \label{eq:dent-noninv-Y-dent-s3}
\begin{split}
\mathrm{h}(Y) &= - \int_{\mathcal{X}} \left[ f_X(x) \, \left| J_g^{-1}(x) \right| \left| J_g(x) \right| \right] \log \left[ f_X(x) \, \left| J_g^{-1}(x) \right| \right] \, \mathrm{d}x \\
&= - \int_{\mathcal{X}} f_X(x) \log f_X(x) \, \mathrm{d}x - \int_{\mathcal{X}} f_X(x) \log \left| J_g^{-1}(x) \right| \, \mathrm{d}x \; .
\end{split}
\end{equation}

Finally, employing the fact ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) that $\int_{\mathcal{X}} f_X(x) \, \mathrm{d}x = 1$ and the determinant property $\lvert A^{-1} \rvert = 1/\lvert A \rvert$, we can derive the differential entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent}) of $Y$ as

\begin{equation} \label{eq:dent-noninv-Y-dent-s4}
\begin{split}
\mathrm{h}(Y) &= - \int_{\mathcal{X}} f_X(x) \log f_X(x) \, \mathrm{d}x - \int_{\mathcal{X}} f_X(x) \log \frac{1}{\left| J_g(x) \right|} \, \mathrm{d}x \\
&\overset{\eqref{eq:dent-noninv-X-dent}}{=} \mathrm{h}(X) + \int_{\mathcal{X}} f_X(x) \log \left| J_g(x) \right| \, \mathrm{d}x \; .
\end{split}
\end{equation}

Because there exist $X$ and $Y$, such that the integral term in \eqref{eq:dent-noninv-Y-dent-s4} is non-zero, this also demonstrates that there exist $X$ and $Y$, such that \eqref{eq:dent-noninv-dent-noninv} is fulfilled.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Differential entropy"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-10-07; URL: \url{https://en.wikipedia.org/wiki/Differential_entropy#Properties_of_differential_entropy}.
\item Bernhard (2016): "proof of upper bound on differential entropy of f(X)"; in: \textit{StackExchange Mathematics}, retrieved on 2021-10-07; URL: \url{https://math.stackexchange.com/a/1759531}.
\item peek-a-boo (2019): "How to come up with the Jacobian in the change of variables formula"; in: \textit{StackExchange Mathematics}, retrieved on 2021-08-30; URL: \url{https://math.stackexchange.com/a/3239222}.
\item Wikipedia (2021): "Jacobian matrix and determinant"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-10-07; URL: \url{https://en.wikipedia.org/wiki/Jacobian_matrix_and_determinant#Inverse}.
\item Wikipedia (2021): "Inverse function theorem"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-10-07; URL: \url{https://en.wikipedia.org/wiki/Inverse_function_theorem#Statement}.
\item Wikipedia (2021): "Determinant"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-10-07; URL: \url{https://en.wikipedia.org/wiki/Determinant#Properties_of_the_determinant}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P262 | shortcut: dent-noninv | author: JoramSoch | date: 2021-10-07, 10:39.
\vspace{1em}



\subsubsection[\textit{Conditional differential entropy}]{Conditional differential entropy} \label{sec:dent-cond}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ and $Y$ be continuous random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with possible outcomes $\mathcal{X}$ and $\mathcal{Y}$ and probability density functions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) $p(x)$ and $p(y)$. Then, the conditional differential entropy of $Y$ given $X$ or, differential entropy of $Y$ conditioned on $X$, is defined as

\begin{equation} \label{eq:dent-cond-dent-cond}
\mathrm{h}(Y|X) = \int_{x \in \mathcal{X}} p(x) \cdot \mathrm{h}(Y|X=x)
\end{equation}

where $\mathrm{h}(Y \vert X=x)$ is the (marginal) differential entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent}) of $Y$, evaluated at $x$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D34 | shortcut: dent-cond | author: JoramSoch | date: 2020-03-21, 12:27.
\vspace{1em}



\subsubsection[\textit{Joint differential entropy}]{Joint differential entropy} \label{sec:dent-joint}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ and $Y$ be continuous random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with possible outcomes $\mathcal{X}$ and $\mathcal{Y}$ and joint probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) $p(x,y)$. Then, the joint differential entropy of $X$ and $Y$ is defined as

\begin{equation} \label{eq:dent-joint-dent-joint}
\mathrm{h}(X,Y) = - \int_{x \in \mathcal{X}} \int_{y \in \mathcal{Y}} p(x,y) \cdot \log_b p(x,y) \, \mathrm{d}y \, \mathrm{d}x
\end{equation}

where $b$ is the base of the logarithm specifying in which unit the differential entropy is determined.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D35 | shortcut: dent-joint | author: JoramSoch | date: 2020-03-21, 12:37.
\vspace{1em}



\subsubsection[\textit{Differential cross-entropy}]{Differential cross-entropy} \label{sec:dent-cross}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a continuous random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with possible outcomes $\mathcal{X}$ and let $P$ and $Q$ be two probability distributions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist}) on $X$ with the probability density functions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) $p(x)$ and $q(x)$. Then, the differential cross-entropy of $Q$ relative to $P$ is defined as

\begin{equation} \label{eq:dent-cross-dent-cross}
\mathrm{h}(P,Q) = - \int_{\mathcal{X}} p(x) \log_b q(x) \, \mathrm{d}x
\end{equation}

where $b$ is the base of the logarithm specifying in which unit the differential cross-entropy is determined.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Cross entropy"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-07-28; URL: \url{https://en.wikipedia.org/wiki/Cross_entropy#Definition}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D86 | shortcut: dent-cross | author: JoramSoch | date: 2020-07-28, 03:03.
\vspace{1em}



\subsection{Discrete mutual information}

\subsubsection[\textit{Definition}]{Definition} \label{sec:mi}
\setcounter{equation}{0}

\textbf{Definition:}

1) The mutual information of two discrete random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X$ and $Y$ is defined as

\begin{equation} \label{eq:mi-mi-disc}
\mathrm{I}(X,Y) = - \sum_{x \in \mathcal{X}} \sum_{x \in \mathcal{Y}} p(x,y) \cdot \log \frac{p(x,y)}{p(x) \cdot p(y)}
\end{equation}

where $p(x)$ and $p(y)$ are the probability mass functions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) of $X$ and $Y$ and $p(x,y)$ is the joint probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) mass function of $X$ and $Y$.

2) The mutual information of two continuous random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X$ and $Y$ is defined as

\begin{equation} \label{eq:mi-mi-cont}
\mathrm{I}(X,Y) = - \int_{\mathcal{X}} \int_{\mathcal{Y}} p(x,y) \cdot \log \frac{p(x,y)}{p(x) \cdot p(y)} \, \mathrm{d}y \, \mathrm{d}x
\end{equation}

where $p(x)$ and $p(y)$ are the probability density functions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) of $X$ and $Y$ and $p(x,y)$ is the joint probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) density function of $X$ and $Y$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Cover TM, Thomas JA (1991): "Relative Entropy and Mutual Information"; in: \textit{Elements of Information Theory}, ch. 2.3/8.5, p. 20/251; URL: \url{https://www.wiley.com/en-us/Elements+of+Information+Theory%2C+2nd+Edition-p-9780471241959}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D19 | shortcut: mi | author: JoramSoch | date: 2020-02-19, 18:35.
\vspace{1em}



\subsubsection[\textbf{Relation to marginal and conditional entropy}]{Relation to marginal and conditional entropy} \label{sec:dmi-mce}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ and $Y$ be discrete random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with the joint probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) $p(x,y)$ for $x \in \mathcal{X}$ and $y \in \mathcal{Y}$. Then, the mutual information ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mi}) of $X$ and $Y$ can be expressed as

\begin{equation} \label{eq:dmi-mce-dmi-mce}
\begin{split}
\mathrm{I}(X,Y) &= \mathrm{H}(X) - \mathrm{H}(X|Y) \\
&= \mathrm{H}(Y) - \mathrm{H}(Y|X)
\end{split}
\end{equation}

where $\mathrm{H}(X)$ and $\mathrm{H}(Y)$ are the marginal entropies ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ent}) of $X$ and $Y$ and $\mathrm{H}(X \vert Y)$ and $\mathrm{H}(Y \vert X)$ are the conditional entropies ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ent-cond}).


\vspace{1em}
\textbf{Proof:} The mutual information ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mi}) of $X$ and $Y$ is defined as

\begin{equation} \label{eq:dmi-mce-MI}
\mathrm{I}(X,Y) = \sum_{x \in \mathcal{X}} \sum_{y \in \mathcal{Y}} p(x,y) \log \frac{p(x,y)}{p(x)\,p(y)} \; .
\end{equation}

Separating the logarithm, we have:

\begin{equation} \label{eq:dmi-mce-MI-s1}
\mathrm{I}(X,Y) = \sum_x \sum_y p(x,y) \log \frac{p(x,y)}{p(y)} - \sum_x \sum_y p(x,y) \log p(x) \; .
\end{equation}

Applying the law of conditional probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-cond}), i.e. $p(x,y) = p(x \vert y) \, p(y)$, we get:

\begin{equation} \label{eq:dmi-mce-MI-s2}
\mathrm{I}(X,Y) = \sum_x \sum_y p(x|y) \, p(y) \log p(x|y) - \sum_x \sum_y p(x,y) \log p(x) \; .
\end{equation}

Regrouping the variables, we have:

\begin{equation} \label{eq:dmi-mce-MI-s3}
\mathrm{I}(X,Y) = \sum_y p(y) \sum_x p(x|y) \log p(x|y) - \sum_x \left( \sum_y p(x,y) \right) \log p(x) \; .
\end{equation}

Applying the law of marginal probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}), i.e. $p(x) = \sum_y p(x,y)$, we get:

\begin{equation} \label{eq:dmi-mce-MI-s4}
\mathrm{I}(X,Y) = \sum_y p(y) \sum_x p(x|y) \log p(x|y) - \sum_x p(x) \log p(x) \; .
\end{equation}

Now considering the definitions of marginal ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ent}) and conditional ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ent-cond}) entropy

\begin{equation} \label{eq:dmi-mce-ME-CE}
\begin{split}
\mathrm{H}(X) &= - \sum_{x \in \mathcal{X}} p(x) \log p(x) \\
\mathrm{H}(X|Y) &= \sum_{y \in \mathcal{Y}} p(y) \, \mathrm{H}(X|Y=y) \; ,
\end{split}
\end{equation}

we can finally show:

\begin{equation} \label{eq:dmi-mce-MI-qed}
\begin{split}
\mathrm{I}(X,Y) &= - \mathrm{H}(X|Y) + \mathrm{H}(X) \\
&= \mathrm{H}(X) - \mathrm{H}(X|Y) \; .
\end{split}
\end{equation}

The conditioning of $X$ on $Y$ in this proof is without loss of generality. Thus, the proof for the expression using the reverse conditional entropy of $Y$ given $X$ is obtained by simply switching $x$ and $y$ in the derivation.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Mutual information"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-01-13; URL: \url{https://en.wikipedia.org/wiki/Mutual_information#Relation_to_conditional_and_joint_entropy}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P19 | shortcut: dmi-mce | author: JoramSoch | date: 2020-01-13, 18:20.
\vspace{1em}



\subsubsection[\textbf{Relation to marginal and joint entropy}]{Relation to marginal and joint entropy} \label{sec:dmi-mje}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ and $Y$ be discrete random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with the joint probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) $p(x,y)$ for $x \in \mathcal{X}$ and $y \in \mathcal{Y}$. Then, the mutual information ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mi}) of $X$ and $Y$ can be expressed as

\begin{equation} \label{eq:dmi-mje-dmi-mje}
\mathrm{I}(X,Y) = \mathrm{H}(X) + \mathrm{H}(Y) - \mathrm{H}(X,Y)
\end{equation}

where $\mathrm{H}(X)$ and $\mathrm{H}(Y)$ are the marginal entropies ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ent}) of $X$ and $Y$ and $\mathrm{H}(X,Y)$ is the joint entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ent-joint}).


\vspace{1em}
\textbf{Proof:} The mutual information ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mi}) of $X$ and $Y$ is defined as

\begin{equation} \label{eq:dmi-mje-MI}
\mathrm{I}(X,Y) = \sum_{x \in \mathcal{X}} \sum_{y \in \mathcal{Y}} p(x,y) \log \frac{p(x,y)}{p(x)\,p(y)} \; .
\end{equation}

Separating the logarithm, we have:

\begin{equation} \label{eq:dmi-mje-MI-s1}
\mathrm{I}(X,Y) = \sum_x \sum_y p(x,y) \log p(x,y) - \sum_x \sum_y p(x,y) \log p(x) - \sum_x \sum_y p(x,y) \log p(y) \; .
\end{equation}

Regrouping the variables, this reads:

\begin{equation} \label{eq:dmi-mje-MI-s2}
\mathrm{I}(X,Y) = \sum_x \sum_y p(x,y) \log p(x,y) - \sum_x \left( \sum_y p(x,y) \right) \log p(x) - \sum_y \left( \sum_x p(x,y) \right) \log p(y) \; .
\end{equation}

Applying the law of marginal probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}), i.e. $p(x) = \sum_y p(x,y)$, we get:

\begin{equation} \label{eq:dmi-mje-MI-s3}
\mathrm{I}(X,Y) = \sum_x \sum_y p(x,y) \log p(x,y) - \sum_x p(x) \log p(x) - \sum_y p(y) \log p(y) \; .
\end{equation}

Now considering the definitions of marginal ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ent}) and joint ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ent-joint}) entropy

\begin{equation} \label{eq:dmi-mje-ME-JE}
\begin{split}
\mathrm{H}(X) &= - \sum_{x \in \mathcal{X}} p(x) \log p(x) \\
\mathrm{H}(X,Y) &= - \sum_{x \in \mathcal{X}} \sum_{y \in \mathcal{Y}} p(x,y) \log p(x,y) \; ,
\end{split}
\end{equation}

we can finally show:

\begin{equation} \label{eq:dmi-mje-MI-qed}
\begin{split}
\mathrm{I}(X,Y) &= - \mathrm{H}(X,Y) + \mathrm{H}(X) + \mathrm{H}(Y) \\
&= \mathrm{H}(X) + \mathrm{H}(Y) - \mathrm{H}(X,Y) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Mutual information"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-01-13; URL: \url{https://en.wikipedia.org/wiki/Mutual_information#Relation_to_conditional_and_joint_entropy}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P20 | shortcut: dmi-mje | author: JoramSoch | date: 2020-01-13, 21:53.
\vspace{1em}



\subsubsection[\textbf{Relation to joint and conditional entropy}]{Relation to joint and conditional entropy} \label{sec:dmi-jce}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ and $Y$ be discrete random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with the joint probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) $p(x,y)$ for $x \in \mathcal{X}$ and $y \in \mathcal{Y}$. Then, the mutual information ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mi}) of $X$ and $Y$ can be expressed as

\begin{equation} \label{eq:dmi-jce-dmi-jce}
\mathrm{I}(X,Y) = \mathrm{H}(X,Y) - \mathrm{H}(X|Y) - \mathrm{H}(Y|X)
\end{equation}

where $\mathrm{H}(X,Y)$ is the joint entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ent-joint}) of $X$ and $Y$ and $\mathrm{H}(X \vert Y)$ and $\mathrm{H}(Y \vert X)$ are the conditional entropies ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ent-cond}).


\vspace{1em}
\textbf{Proof:} The existence of the joint probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) ensures that the mutual information ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mi}) is defined:

\begin{equation} \label{eq:dmi-jce-MI}
\mathrm{I}(X,Y) = \sum_{x \in \mathcal{X}} \sum_{y \in \mathcal{Y}} p(x,y) \log \frac{p(x,y)}{p(x)\,p(y)} \; .
\end{equation}

The relation of mutual information to conditional entropy ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:dmi-mce}) is:

\begin{equation} \label{eq:dmi-jce-dmi-mce1}
\mathrm{I}(X,Y) = \mathrm{H}(X) - \mathrm{H}(X|Y)
\end{equation}

\begin{equation} \label{eq:dmi-jce-dmi-mce2}
\mathrm{I}(X,Y) = \mathrm{H}(Y) - \mathrm{H}(Y|X)
\end{equation}

The relation of mutual information to joint entropy ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:dmi-mje}) is:

\begin{equation} \label{eq:dmi-jce-dmi-mje}
\mathrm{I}(X,Y) = \mathrm{H}(X) + \mathrm{H}(Y) - \mathrm{H}(X,Y) \; .
\end{equation}

It is true that

\begin{equation} \label{eq:dmi-jce-MI-s1}
\mathrm{I}(X,Y) = \mathrm{I}(X,Y) + \mathrm{I}(X,Y) - \mathrm{I}(X,Y) \; .
\end{equation}

Plugging in \eqref{eq:dmi-jce-dmi-mce1}, \eqref{eq:dmi-jce-dmi-mce2} and \eqref{eq:dmi-jce-dmi-mje} on the right-hand side, we have

\begin{equation} \label{eq:dmi-jce-MI-s2}
\begin{split}
\mathrm{I}(X,Y) &= \mathrm{H}(X) - \mathrm{H}(X|Y) + \mathrm{H}(Y) - \mathrm{H}(Y|X) - \mathrm{H}(X) - \mathrm{H}(Y) + \mathrm{H}(X,Y) \\
&= \mathrm{H}(X,Y) - \mathrm{H}(X|Y) - \mathrm{H}(Y|X)
\end{split}
\end{equation}

which proves the identity given above.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Mutual information"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-01-13; URL: \url{https://en.wikipedia.org/wiki/Mutual_information#Relation_to_conditional_and_joint_entropy}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P21 | shortcut: dmi-jce | author: JoramSoch | date: 2020-01-13, 22:17.
\vspace{1em}



\subsection{Continuous mutual information}

\subsubsection[\textit{Definition}]{Definition} \label{sec:mi}
\setcounter{equation}{0}

\textbf{Definition:}

1) The mutual information of two discrete random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X$ and $Y$ is defined as

\begin{equation} \label{eq:mi-mi-disc}
\mathrm{I}(X,Y) = - \sum_{x \in \mathcal{X}} \sum_{x \in \mathcal{Y}} p(x,y) \cdot \log \frac{p(x,y)}{p(x) \cdot p(y)}
\end{equation}

where $p(x)$ and $p(y)$ are the probability mass functions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) of $X$ and $Y$ and $p(x,y)$ is the joint probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) mass function of $X$ and $Y$.

2) The mutual information of two continuous random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X$ and $Y$ is defined as

\begin{equation} \label{eq:mi-mi-cont}
\mathrm{I}(X,Y) = - \int_{\mathcal{X}} \int_{\mathcal{Y}} p(x,y) \cdot \log \frac{p(x,y)}{p(x) \cdot p(y)} \, \mathrm{d}y \, \mathrm{d}x
\end{equation}

where $p(x)$ and $p(y)$ are the probability density functions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) of $X$ and $Y$ and $p(x,y)$ is the joint probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) density function of $X$ and $Y$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Cover TM, Thomas JA (1991): "Relative Entropy and Mutual Information"; in: \textit{Elements of Information Theory}, ch. 2.3/8.5, p. 20/251; URL: \url{https://www.wiley.com/en-us/Elements+of+Information+Theory%2C+2nd+Edition-p-9780471241959}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D19 | shortcut: mi | author: JoramSoch | date: 2020-02-19, 18:35.
\vspace{1em}



\subsubsection[\textbf{Relation to marginal and conditional differential entropy}]{Relation to marginal and conditional differential entropy} \label{sec:cmi-mcde}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ and $Y$ be continuous random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with the joint probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) $p(x,y)$ for $x \in \mathcal{X}$ and $y \in \mathcal{Y}$. Then, the mutual information ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mi}) of $X$ and $Y$ can be expressed as

\begin{equation} \label{eq:cmi-mcde-cmi-mcde}
\begin{split}
\mathrm{I}(X,Y) &= \mathrm{h}(X) - \mathrm{h}(X|Y) \\
&= \mathrm{h}(Y) - \mathrm{h}(Y|X)
\end{split}
\end{equation}

where $\mathrm{h}(X)$ and $\mathrm{h}(Y)$ are the marginal differential entropies ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent}) of $X$ and $Y$ and $\mathrm{h}(X \vert Y)$ and $\mathrm{h}(Y \vert X)$ are the conditional differential entropies ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent-cond}).


\vspace{1em}
\textbf{Proof:} The mutual information ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mi}) of $X$ and $Y$ is defined as

\begin{equation} \label{eq:cmi-mcde-MI}
\mathrm{I}(X,Y) = \int_{\mathcal{X}} \int_{\mathcal{Y}} p(x,y) \log \frac{p(x,y)}{p(x)\,p(y)} \, \mathrm{d}y \, \mathrm{d}x \; .
\end{equation}

Separating the logarithm, we have:

\begin{equation} \label{eq:cmi-mcde-MI-s1}
\mathrm{I}(X,Y) = \int_{\mathcal{X}} \int_{\mathcal{Y}} p(x,y) \log \frac{p(x,y)}{p(y)} \, \mathrm{d}y \, \mathrm{d}x - \int_{\mathcal{X}} \int_{\mathcal{Y}} p(x,y) \log p(x) \, \mathrm{d}x \, \mathrm{d}y \; .
\end{equation}

Applying the law of conditional probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-cond}), i.e. $p(x,y) = p(x \vert y) \, p(y)$, we get:

\begin{equation} \label{eq:cmi-mcde-MI-s2}
\mathrm{I}(X,Y) = \int_{\mathcal{X}} \int_{\mathcal{Y}} p(x|y) \, p(y) \log p(x|y) \, \mathrm{d}y \, \mathrm{d}x - \int_{\mathcal{X}} \int_{\mathcal{Y}} p(x,y) \log p(x) \, \mathrm{d}y \, \mathrm{d}x \; .
\end{equation}

Regrouping the variables, we have:

\begin{equation} \label{eq:cmi-mcde-MI-s3}
\mathrm{I}(X,Y) = \int_{\mathcal{Y}} p(y) \int_{\mathcal{X}} p(x|y) \log p(x|y) \, \mathrm{d}x \, \mathrm{d}y - \int_{\mathcal{X}} \left( \int_{\mathcal{Y}} p(x,y) \, \mathrm{d}y \right) \log p(x)\, \mathrm{d}x \; .
\end{equation}

Applying the law of marginal probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}), i.e. $p(x) = \int_{\mathcal{Y}} p(x,y) \, \mathrm{d}y$, we get:

\begin{equation} \label{eq:cmi-mcde-MI-s4}
\mathrm{I}(X,Y) = \int_{\mathcal{Y}} p(y) \int_{\mathcal{X}} p(x|y) \log p(x|y) \, \mathrm{d}x \, \mathrm{d}y - \int_{\mathcal{X}} p(x) \log p(x) \, \mathrm{d}x \; .
\end{equation}

Now considering the definitions of marginal ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent}) and conditional ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent-cond}) differential entropy

\begin{equation} \label{eq:cmi-mcde-MDE-CDE}
\begin{split}
\mathrm{h}(X) &= - \int_{\mathcal{X}} p(x) \log p(x) \, \mathrm{d}x \\
\mathrm{h}(X|Y) &= \int_{\mathcal{Y}} p(y) \, \mathrm{h}(X|Y=y) \, \mathrm{d}y \; ,
\end{split}
\end{equation}

we can finally show:

\begin{equation} \label{eq:cmi-mcde-MI-qed}
\mathrm{I}(X,Y) = - \mathrm{h}(X|Y) + \mathrm{h}(X) = \mathrm{h}(X) - \mathrm{h}(X|Y) \; .
\end{equation}

The conditioning of $X$ on $Y$ in this proof is without loss of generality. Thus, the proof for the expression using the reverse conditional differential entropy of $Y$ given $X$ is obtained by simply switching $x$ and $y$ in the derivation.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Mutual information"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-02-21; URL: \url{https://en.wikipedia.org/wiki/Mutual_information#Relation_to_conditional_and_joint_entropy}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P58 | shortcut: cmi-mcde | author: JoramSoch | date: 2020-02-21, 16:53.
\vspace{1em}



\subsubsection[\textbf{Relation to marginal and joint differential entropy}]{Relation to marginal and joint differential entropy} \label{sec:cmi-mjde}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ and $Y$ be continuous random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with the joint probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) $p(x,y)$ for $x \in \mathcal{X}$ and $y \in \mathcal{Y}$. Then, the mutual information ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mi}) of $X$ and $Y$ can be expressed as

\begin{equation} \label{eq:cmi-mjde-cmi-mjde}
\mathrm{I}(X,Y) = \mathrm{h}(X) + \mathrm{h}(Y) - \mathrm{h}(X,Y)
\end{equation}

where $\mathrm{h}(X)$ and $\mathrm{h}(Y)$ are the marginal differential entropies ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent}) of $X$ and $Y$ and $\mathrm{h}(X,Y)$ is the joint differential entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent-joint}).


\vspace{1em}
\textbf{Proof:} The mutual information ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mi}) of $X$ and $Y$ is defined as

\begin{equation} \label{eq:cmi-mjde-MI}
\mathrm{I}(X,Y) = \int_{\mathcal{X}} \int_{\mathcal{Y}} p(x,y) \log \frac{p(x,y)}{p(x)\,p(y)} \, \mathrm{d}y \, \mathrm{d}x \; .
\end{equation}

Separating the logarithm, we have:

\begin{equation} \label{eq:cmi-mjde-MI-s1}
\mathrm{I}(X,Y) = \int_{\mathcal{X}} \int_{\mathcal{Y}} p(x,y) \log p(x,y) \, \mathrm{d}y \, \mathrm{d}x - \int_{\mathcal{X}} \int_{\mathcal{Y}} p(x,y) \log p(x) \, \mathrm{d}y \, \mathrm{d}x - \int_{\mathcal{X}} \int_{\mathcal{Y}} p(x,y) \log p(y) \, \mathrm{d}y \, \mathrm{d}x \; .
\end{equation}

Regrouping the variables, this reads:

\begin{equation} \label{eq:cmi-mjde-MI-s2}
\mathrm{I}(X,Y) = \int_{\mathcal{X}} \int_{\mathcal{Y}} p(x,y) \log p(x,y) \, \mathrm{d}y \, \mathrm{d}x - \int_{\mathcal{X}} \left( \int_{\mathcal{Y}} p(x,y) \, \mathrm{d}y \right) \log p(x) \, \mathrm{d}x - \int_{\mathcal{Y}} \left( \int_{\mathcal{X}} p(x,y) \, \mathrm{d}x \right) \log p(y) \, \mathrm{d}y \; .
\end{equation}

Applying the law of marginal probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}), i.e. $p(x) = \int_{\mathcal{Y}} p(x,y)$, we get:

\begin{equation} \label{eq:cmi-mjde-MI-s3}
\mathrm{I}(X,Y) = \int_{\mathcal{X}} \int_{\mathcal{Y}} p(x,y) \log p(x,y) \, \mathrm{d}y \, \mathrm{d}x - \int_{\mathcal{X}} p(x) \log p(x) \, \mathrm{d}x - \int_{\mathcal{Y}} p(y) \log p(y) \, \mathrm{d}y \; .
\end{equation}

Now considering the definitions of marginal ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent}) and joint ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent-joint}) differential entropy

\begin{equation} \label{eq:cmi-mjde-MDE-JDE}
\begin{split}
\mathrm{h}(X) &= - \int_{\mathcal{X}} p(x) \log p(x) \, \mathrm{d}x \\
\mathrm{h}(X,Y) &= - \int_{\mathcal{X}} \int_{\mathcal{Y}} p(x,y) \log p(x,y) \, \mathrm{d}y \, \mathrm{d}x \; ,
\end{split}
\end{equation}

we can finally show:

\begin{equation} \label{eq:cmi-mjde-MI-qed}
\begin{split}
\mathrm{I}(X,Y) &= - \mathrm{h}(X,Y) + \mathrm{h}(X) + \mathrm{h}(Y) \\
&= \mathrm{h}(X) + \mathrm{h}(Y) - \mathrm{h}(X,Y) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Mutual information"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-02-21; URL: \url{https://en.wikipedia.org/wiki/Mutual_information#Relation_to_conditional_and_joint_entropy}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P59 | shortcut: cmi-mjde | author: JoramSoch | date: 2020-02-21, 17:13.
\vspace{1em}



\subsubsection[\textbf{Relation to joint and conditional differential entropy}]{Relation to joint and conditional differential entropy} \label{sec:cmi-jcde}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ and $Y$ be continuous random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with the joint probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) $p(x,y)$ for $x \in \mathcal{X}$ and $y \in \mathcal{Y}$. Then, the mutual information ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mi}) of $X$ and $Y$ can be expressed as

\begin{equation} \label{eq:cmi-jcde-dmi-jce}
\mathrm{I}(X,Y) = \mathrm{h}(X,Y) - \mathrm{h}(X|Y) - \mathrm{h}(Y|X)
\end{equation}

where $\mathrm{h}(X,Y)$ is the joint differential entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent-joint}) of $X$ and $Y$ and $\mathrm{h}(X \vert Y)$ and $\mathrm{h}(Y \vert X)$ are the conditional differential entropies ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent-cond}).


\vspace{1em}
\textbf{Proof:} The existence of the joint probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) ensures that the mutual information ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mi}) is defined:

\begin{equation} \label{eq:cmi-jcde-MI}
\mathrm{I}(X,Y) = \int_{\mathcal{X}} \int_{\mathcal{Y}} p(x,y) \log \frac{p(x,y)}{p(x)\,p(y)} \, \mathrm{d}y \, \mathrm{d}x \; .
\end{equation}

The relation of mutual information to conditional differential entropy ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:cmi-mcde}) is:

\begin{equation} \label{eq:cmi-jcde-cmi-mcde1}
\mathrm{I}(X,Y) = \mathrm{h}(X) - \mathrm{h}(X|Y)
\end{equation}

\begin{equation} \label{eq:cmi-jcde-cmi-mcde2}
\mathrm{I}(X,Y) = \mathrm{h}(Y) - \mathrm{h}(Y|X)
\end{equation}

The relation of mutual information to joint differential entropy ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:cmi-mjde}) is:

\begin{equation} \label{eq:cmi-jcde-cmi-mjde}
\mathrm{I}(X,Y) = \mathrm{h}(X) + \mathrm{h}(Y) - \mathrm{h}(X,Y) \; .
\end{equation}

It is true that

\begin{equation} \label{eq:cmi-jcde-MI-s1}
\mathrm{I}(X,Y) = \mathrm{I}(X,Y) + \mathrm{I}(X,Y) - \mathrm{I}(X,Y) \; .
\end{equation}

Plugging in \eqref{eq:cmi-jcde-cmi-mcde1}, \eqref{eq:cmi-jcde-cmi-mcde2} and \eqref{eq:cmi-jcde-cmi-mjde} on the right-hand side, we have

\begin{equation} \label{eq:cmi-jcde-MI-s2}
\begin{split}
\mathrm{I}(X,Y) &= \mathrm{h}(X) - \mathrm{h}(X|Y) + \mathrm{h}(Y) - \mathrm{h}(Y|X) - \mathrm{h}(X) - \mathrm{h}(Y) + \mathrm{h}(X,Y) \\
&= \mathrm{h}(X,Y) - \mathrm{h}(X|Y) - \mathrm{h}(Y|X)
\end{split}
\end{equation}

which proves the identity given above.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Mutual information"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-02-21; URL: \url{https://en.wikipedia.org/wiki/Mutual_information#Relation_to_conditional_and_joint_entropy}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P60 | shortcut: cmi-jcde | author: JoramSoch | date: 2020-02-21, 17:23.
\vspace{1em}



\subsection{Kullback-Leibler divergence}

\subsubsection[\textit{Definition}]{Definition} \label{sec:kl}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with possible outcomes $\mathcal{X}$ and let $P$ and $Q$ be two probability distributions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist}) on $X$.

1) The Kullback-Leibler divergence of $P$ from $Q$ for a discrete random variable $X$ is defined as

\begin{equation} \label{eq:kl-KL-disc}
\mathrm{KL}[P||Q] = \sum_{x \in \mathcal{X}} p(x) \cdot \log \frac{p(x)}{q(x)}
\end{equation}

where $p(x)$ and $q(x)$ are the probability mass functions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) of $P$ and $Q$.

2) The Kullback-Leibler divergence of $P$ from $Q$ for a continuous random variable $X$ is defined as

\begin{equation} \label{eq:kl-KL-cont}
\mathrm{KL}[P||Q] = \int_{\mathcal{X}} p(x) \cdot \log \frac{p(x)}{q(x)} \, \mathrm{d}x
\end{equation}

where $p(x)$ and $q(x)$ are the probability density functions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $P$ and $Q$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item MacKay, David J.C. (2003): "Probability, Entropy, and Inference"; in: \textit{Information Theory, Inference, and Learning Algorithms}, ch. 2.6, eq. 2.45, p. 34; URL: \url{https://www.inference.org.uk/itprnn/book.pdf}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D52 | shortcut: kl | author: JoramSoch | date: 2020-05-10, 20:20.
\vspace{1em}



\subsubsection[\textbf{Non-negativity}]{Non-negativity} \label{sec:kl-nonneg}
\setcounter{equation}{0}

\textbf{Theorem:} The Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) is always non-negative

\begin{equation} \label{eq:kl-nonneg-KL-nonneg}
\mathrm{KL}[P||Q] \geq 0
\end{equation}

with $\mathrm{KL}[P \vert \vert Q] = 0$, if and only if $P = Q$.


\vspace{1em}
\textbf{Proof:} The discrete Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) is defined as

\begin{equation} \label{eq:kl-nonneg-KL}
\mathrm{KL}[P||Q] = \sum_{x \in \mathcal{X}} p(x) \cdot \log \frac{p(x)}{q(x)}
\end{equation}

which can be reformulated into

\begin{equation} \label{eq:kl-nonneg-KL-dev}
\mathrm{KL}[P||Q] = \sum_{x \in \mathcal{X}} p(x) \cdot \log p(x) - \sum_{x \in \mathcal{X}} p(x) \cdot \log q(x) \; .
\end{equation}

Gibbs' inequality ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:gibbs-ineq}) states that the entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ent}) of a probability distribution is always less than or equal to the cross-entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ent-cross}) with another probability distribution â€“ with equality only if the distributions are identical â€“,

\begin{equation} \label{eq:kl-nonneg-Gibbs-ineq}
- \sum_{i=1}^n p(x_i) \, \log p(x_i) \leq - \sum_{i=1}^n p(x_i) \, \log q(x_i)
\end{equation}

which can be reformulated into

\begin{equation} \label{eq:kl-nonneg-Gibbs-ineq-dev}
\sum_{i=1}^n p(x_i) \, \log p(x_i) - \sum_{i=1}^n p(x_i) \, \log q(x_i) \geq 0 \; .
\end{equation}

Applying \eqref{eq:kl-nonneg-Gibbs-ineq-dev} to \eqref{eq:kl-nonneg-KL-dev}, this proves equation \eqref{eq:kl-nonneg-KL-nonneg}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Kullback-Leibler divergence"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-05-31; URL: \url{https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence#Properties}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P117 | shortcut: kl-nonneg | author: JoramSoch | date: 2020-05-31, 23:43.
\vspace{1em}



\subsubsection[\textbf{Non-negativity}]{Non-negativity} \label{sec:kl-nonneg2}
\setcounter{equation}{0}

\textbf{Theorem:} The Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) is always non-negative

\begin{equation} \label{eq:kl-nonneg2-KL-nonneg}
\mathrm{KL}[P||Q] \geq 0
\end{equation}

with $\mathrm{KL}[P \vert \vert Q] = 0$, if and only if $P = Q$.


\vspace{1em}
\textbf{Proof:} The discrete Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) is defined as

\begin{equation} \label{eq:kl-nonneg2-KL}
\mathrm{KL}[P||Q] = \sum_{x \in \mathcal{X}} p(x) \cdot \log \frac{p(x)}{q(x)} \; .
\end{equation}

The log sum inequality ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:logsum-ineq}) states that

\begin{equation} \label{eq:kl-nonneg2-logsum-ineq}
\sum_{i=1}^n a_i \, \log_c \frac{a_i}{b_i} \geq a \, \log_c \frac{a}{b} \; .
\end{equation}

where $a_1, \ldots, a_n$ and $b_1, \ldots, b_n$ be non-negative real numbers and $a = \sum_{i=1}^{n} a_i$ and $b = \sum_{i=1}^{n} b_i$. Because $p(x)$ and $q(x)$ are probability mass functions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}), such that

\begin{equation} \label{eq:kl-nonneg2-p-q-pmf}
\begin{split}
p(x) \geq 0, \quad \sum_{x \in \mathcal{X}} p(x) &= 1 \quad \text{and} \\
q(x) \geq 0, \quad \sum_{x \in \mathcal{X}} q(x) &= 1 \; ,
\end{split}
\end{equation}

theorem \eqref{eq:kl-nonneg2-KL-nonneg} is simply a special case of \eqref{eq:kl-nonneg2-logsum-ineq}, i.e.

\begin{equation} \label{eq:kl-nonneg2-KL-nonneg-qed}
\mathrm{KL}[P||Q] \overset{\eqref{eq:kl-nonneg2-KL}}{=} \sum_{x \in \mathcal{X}} p(x) \cdot \log \frac{p(x)}{q(x)} \overset{\eqref{eq:kl-nonneg2-logsum-ineq}}{\geq} 1 \, \log \frac{1}{1} = 0 \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Log sum inequality"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-09-09; URL: \url{https://en.wikipedia.org/wiki/Log_sum_inequality#Applications}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P166 | shortcut: kl-nonneg2 | author: JoramSoch | date: 2020-09-09, 07:02.
\vspace{1em}



\subsubsection[\textbf{Non-symmetry}]{Non-symmetry} \label{sec:kl-nonsymm}
\setcounter{equation}{0}

\textbf{Theorem:}  The Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) is non-symmetric, i.e.

\begin{equation} \label{eq:kl-nonsymm-KL-nonsymm}
\mathrm{KL}[P||Q] \neq \mathrm{KL}[Q||P]
\end{equation}

for some probability distributions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist}) $P$ and $Q$.


\vspace{1em}
\textbf{Proof:} Let $X \in \mathcal{X} = \left\lbrace 0, 1, 2 \right\rbrace$ be a discrete random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) and consider the two probability distributions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist})

\begin{equation} \label{eq:kl-nonsymm-P-Q}
\begin{split}
P : \, X &\sim \mathrm{Bin}(2, 0.5) \\
Q : \, X &\sim \mathcal{U}(0, 2)
\end{split}
\end{equation}

where $\mathrm{Bin}(n, p)$ indicates a binomial distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:bin}) and $\mathcal{U}(a, b)$ indicates a discrete uniform distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:duni}).

Then, the probability mass function of the binomial distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:bin-pmf}) entails that

\begin{equation} \label{eq:kl-nonsymm-p(x)}
p(x) = \left\{
\begin{array}{rl}
1/4 \; , & \text{if} \; x = 0 \\
1/2 \; , & \text{if} \; x = 1 \\
1/4 \; , & \text{if} \; x = 2
\end{array}
\right.
\end{equation}

and the probability mass function of the discrete uniform distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:duni-pmf}) entails that

\begin{equation} \label{eq:kl-nonsymm-q(x)}
q(x) = \frac{1}{3} \; ,
\end{equation}

such that the Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) of $P$ from $Q$ is

\begin{equation} \label{eq:kl-nonsymm-KL-P-Q}
\begin{split}
\mathrm{KL}[P||Q] &= \sum_{x \in \mathcal{X}} p(x) \cdot \log \frac{p(x)}{q(x)} \\
&= \frac{1}{4} \log \frac{3}{4} + \frac{1}{2} \log \frac{3}{2} + \frac{1}{4} \log \frac{3}{4} \\
&= \frac{1}{2} \log \frac{3}{4} + \frac{1}{2} \log \frac{3}{2} \\
&= \frac{1}{2} \left( \log \frac{3}{4} + \log \frac{3}{2} \right) \\
&= \frac{1}{2} \log \left( \frac{3}{4} \cdot \frac{3}{2} \right) \\
&= \frac{1}{2} \log \frac{9}{8} = 0.0589
\end{split}
\end{equation}

and the Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) of $Q$ from $P$ is

\begin{equation} \label{eq:kl-nonsymm-KL-Q-P}
\begin{split}
\mathrm{KL}[Q||P] &= \sum_{x \in \mathcal{X}} q(x) \cdot \log \frac{q(x)}{p(x)} \\
&= \frac{1}{3} \log \frac{4}{3} + \frac{1}{3} \log \frac{2}{3} + \frac{1}{3} \log \frac{4}{3} \\
&= \frac{1}{3} \left( \log \frac{4}{3} + \log \frac{2}{3} + \log \frac{4}{3} \right) \\
&= \frac{1}{3} \log \left( \frac{4}{3} \cdot \frac{2}{3} \cdot \frac{4}{3} \right) \\
&= \frac{1}{3} \log \frac{32}{27} = 0.0566
\end{split}
\end{equation}

which provides an example for

\begin{equation} \label{eq:kl-nonsymm-KL-nonsymm-qed}
\mathrm{KL}[P||Q] \neq \mathrm{KL}[Q||P]
\end{equation}

and thus proves the theorem.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Kullback, Solomon (1959): "Divergence"; in: \textit{Information Theory and Statistics}, ch. 1.3, pp. 6ff.; URL: \url{http://index-of.co.uk/Information-Theory/Information%20theory%20and%20statistics%20-%20Solomon%20Kullback.pdf}.
\item Wikipedia (2020): "Kullback-Leibler divergence"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-08-11; URL: \url{https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence#Basic_example}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P147 | shortcut: kl-nonsymm | author: JoramSoch | date: 2020-08-11, 06:57.
\vspace{1em}



\subsubsection[\textbf{Convexity}]{Convexity} \label{sec:kl-conv}
\setcounter{equation}{0}

\textbf{Theorem:}  The Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) is convex in the pair of probability distributions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist}) $(p,q)$, i.e.

\begin{equation} \label{eq:kl-conv-KL-conv}
\mathrm{KL}[\lambda p_1 + (1-\lambda) p_2||\lambda q_1 + (1-\lambda) q_2] \leq \lambda \mathrm{KL}[p_1||q_1] + (1-\lambda) \mathrm{KL}[p_2||q_2]
\end{equation}

where $(p_1,q_1)$ and $(p_2,q_2)$ are two pairs of probability distributions and $0 \leq \lambda \leq 1$.


\vspace{1em}
\textbf{Proof:} The Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) of $P$ from $Q$ is defined as

\begin{equation} \label{eq:kl-conv-KL}
\mathrm{KL}[P||Q] = \sum_{x \in \mathcal{X}} p(x) \cdot \log \frac{p(x)}{q(x)}
\end{equation}

and the log sum inequality ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:logsum-ineq}) states that

\begin{equation} \label{eq:kl-conv-logsum-ineq}
\sum_{i=1}^n a_i \log \frac{a_i}{b_i} \geq \left( \sum_{i=1}^n a_i \right) \log \frac{\sum_{i=1}^n a_i}{\sum_{i=1}^n b_i}
\end{equation}

where $a_1, \ldots, a_n$ and $b_1, \ldots, b_n$ are non-negative real numbers.

Thus, we can rewrite the KL divergence of the mixture distribution as

\begin{equation} \label{eq:kl-conv-KL-conv-qed}
\begin{split}
&\mathrm{KL}[\lambda p_1 + (1-\lambda) p_2||\lambda q_1 + (1-\lambda) q_2] \\
\overset{\eqref{eq:kl-conv-KL}}{=} &\sum_{x \in \mathcal{X}} \left[ \left[ \lambda p_1(x) + (1-\lambda) p_2(x) \right] \cdot \log \frac{\lambda p_1(x) + (1-\lambda) p_2(x)}{\lambda q_1(x) + (1-\lambda) q_2(x)} \right] \\
\overset{\eqref{eq:kl-conv-logsum-ineq}}{\leq} &\sum_{x \in \mathcal{X}} \left[ \lambda p_1(x) \cdot \log \frac{\lambda p_1(x)}{\lambda q_1(x)} + (1-\lambda) p_2(x) \cdot \log \frac{(1-\lambda) p_2(x)}{(1-\lambda) q_2(x)} \right] \\
= &\lambda \sum_{x \in \mathcal{X}} p_1(x) \cdot \log \frac{p_1(x)}{q_1(x)} + (1-\lambda) \sum_{x \in \mathcal{X}} p_2(x) \cdot \log \frac{p_2(x)}{q_2(x)} \\
\overset{\eqref{eq:kl-conv-KL}}{=} &\lambda \, \mathrm{KL}[p_1||q_1] + (1-\lambda) \, \mathrm{KL}[p_2||q_2]
\end{split}
\end{equation}

which is equivalent to \eqref{eq:kl-conv-KL-conv}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Kullback-Leibler divergence"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-08-11; URL: \url{https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence#Properties}.
\item Xie, Yao (2012): "Chain Rules and Inequalities"; in: \textit{ECE587: Information Theory}, Lecture 3, Slides 22/24; URL: \url{https://www2.isye.gatech.edu/~yxie77/ece587/Lecture3.pdf}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P148 | shortcut: kl-conv | author: JoramSoch | date: 2020-08-11, 07:30.
\vspace{1em}



\subsubsection[\textbf{Additivity for independent distributions}]{Additivity for independent distributions} \label{sec:kl-add}
\setcounter{equation}{0}

\textbf{Theorem:} The Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) is additive for independent distributions, i.e.

\begin{equation} \label{eq:kl-add-KL-add}
\mathrm{KL}[P||Q] = \mathrm{KL}[P_1||Q_1] + \mathrm{KL}[P_2||Q_2]
\end{equation}

where $P_1$ and $P_2$ are independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}) distributions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist}) with the joint distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-joint}) $P$, such that $p(x,y) = p_1(x) \, p_2(y)$, and equivalently for $Q_1$, $Q_2$ and $Q$.


\vspace{1em}
\textbf{Proof:} The continuous Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) is defined as

\begin{equation} \label{eq:kl-add-KL}
\mathrm{KL}[P||Q] = \int_{\mathcal{X}} p(x) \cdot \log \frac{p(x)}{q(x)} \, \mathrm{d}x
\end{equation}

which, applied to the joint distributions $P$ and $Q$, yields

\begin{equation} \label{eq:kl-add-KL-s1}
\mathrm{KL}[P||Q] = \int_{\mathcal{X}} \int_{\mathcal{Y}} p(x,y) \cdot \log \frac{p(x,y)}{q(x,y)} \, \mathrm{d}y \, \mathrm{d}x \; .
\end{equation}

Applying $p(x,y) = p_1(x) \, p_2(y)$ and $q(x,y) = q_1(x) \, q_2(y)$, we have

\begin{equation} \label{eq:kl-add-KL-s2}
\mathrm{KL}[P||Q] = \int_{\mathcal{X}} \int_{\mathcal{Y}} p_1(x) \, p_2(y) \cdot \log \frac{p_1(x) \, p_2(y)}{q_1(x) \, q_2(y)} \, \mathrm{d}y \, \mathrm{d}x \; .
\end{equation}

Now we can separate the logarithm and evaluate the integrals:

\begin{equation} \label{eq:kl-add-KL-qed}
\begin{split}
\mathrm{KL}[P||Q] &= \int_{\mathcal{X}} \int_{\mathcal{Y}} p_1(x) \, p_2(y) \cdot \left( \log \frac{p_1(x)}{q_1(x)} + \log \frac{p_2(y)}{q_2(y)} \right) \, \mathrm{d}y \, \mathrm{d}x \\
&= \int_{\mathcal{X}} \int_{\mathcal{Y}} p_1(x) \, p_2(y) \cdot \log \frac{p_1(x)}{q_1(x)} \, \mathrm{d}y \, \mathrm{d}x + \int_{\mathcal{X}} \int_{\mathcal{Y}} p_1(x) \, p_2(y) \cdot \log \frac{p_2(y)}{q_2(y)} \, \mathrm{d}y \, \mathrm{d}x \\
&= \int_{\mathcal{X}} p_1(x) \cdot \log \frac{p_1(x)}{q_1(x)} \int_{\mathcal{Y}} p_2(y) \, \mathrm{d}y \, \mathrm{d}x + \int_{\mathcal{Y}} p_2(y) \cdot \log \frac{p_2(y)}{q_2(y)} \int_{\mathcal{X}} p_1(x) \, \mathrm{d}x \, \mathrm{d}y \\
&= \int_{\mathcal{X}} p_1(x) \cdot \log \frac{p_1(x)}{q_1(x)} \, \mathrm{d}x + \int_{\mathcal{Y}} p_2(y) \cdot \log \frac{p_2(y)}{q_2(y)} \, \mathrm{d}y \\
&\overset{\eqref{eq:kl-add-KL}}{=} \mathrm{KL}[P_1||Q_1] + \mathrm{KL}[P_2||Q_2] \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Kullback-Leibler divergence"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-05-31; URL: \url{https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence#Properties}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P116 | shortcut: kl-add | author: JoramSoch | date: 2020-05-31, 23:26.
\vspace{1em}



\subsubsection[\textbf{Invariance under parameter transformation}]{Invariance under parameter transformation} \label{sec:kl-inv}
\setcounter{equation}{0}

\textbf{Theorem:} The Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) is invariant under parameter transformation, i.e.

\begin{equation} \label{eq:kl-inv-KL-inv}
\mathrm{KL}[p(x)||q(x)] = \mathrm{KL}[p(y)||q(y)]
\end{equation}

where $y(x) = mx + n$ is an affine transformation of $x$ and $p(x)$ and $q(x)$ are the probability density functions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of the probability distributions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist}) $P$ and $Q$ on the continuous random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X$.


\vspace{1em}
\textbf{Proof:} The continuous Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) (KL divergence) is defined as

\begin{equation} \label{eq:kl-inv-KL}
\mathrm{KL}[p(x)||q(x)] = \int_{a}^{b} p(x) \cdot \log \frac{p(x)}{q(x)} \, \mathrm{d}x
\end{equation}

where $a = \mathrm{min}(\mathcal{X})$ and $b = \mathrm{max}(\mathcal{X})$ are the lower and upper bound of the possible outcomes $\mathcal{X}$ of $X$.

Due to the identity of the differentials

\begin{equation} \label{eq:kl-inv-diff}
\begin{split}
p(x) \, \mathrm{d}x &= p(y) \, \mathrm{d}y \\
q(x) \, \mathrm{d}x &= q(y) \, \mathrm{d}y
\end{split}
\end{equation}

which can be rearranged into

\begin{equation} \label{eq:kl-inv-diff-dev}
\begin{split}
p(x) &= p(y) \, \frac{\mathrm{d}y}{\mathrm{d}x} \\
q(x) &= q(y) \, \frac{\mathrm{d}y}{\mathrm{d}x} \; ,
\end{split}
\end{equation}

the KL divergence can be evaluated as follows:

\begin{equation} \label{eq:kl-inv-MDE-DCE}
\begin{split}
\mathrm{KL}[p(x)||q(x)] &= \int_{a}^{b} p(x) \cdot \log \frac{p(x)}{q(x)} \, \mathrm{d}x \\
&= \int_{y(a)}^{y(b)} p(y) \, \frac{\mathrm{d}y}{\mathrm{d}x} \cdot \log \left( \frac{p(y) \, \frac{\mathrm{d}y}{\mathrm{d}x}}{q(y) \, \frac{\mathrm{d}y}{\mathrm{d}x}} \right) \, \mathrm{d}x \\
&= \int_{y(a)}^{y(b)} p(y) \cdot \log \frac{p(y)}{q(y)} \, \mathrm{d}y \\
&= \mathrm{KL}[p(y)||q(y)] \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Kullback-Leibler divergence"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-05-27; URL: \url{https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence#Properties}.
\item shimao (2018): "KL divergence invariant to affine transformation?"; in: \textit{StackExchange CrossValidated}, retrieved on 2020-05-28; URL: \url{https://stats.stackexchange.com/questions/341922/kl-divergence-invariant-to-affine-transformation}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P115 | shortcut: kl-inv | author: JoramSoch | date: 2020-05-28, 00:18.
\vspace{1em}



\subsubsection[\textbf{Relation to discrete entropy}]{Relation to discrete entropy} \label{sec:kl-ent}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a discrete random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with possible outcomes $\mathcal{X}$ and let $P$ and $Q$ be two probability distributions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist}) on $X$. Then, the Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) of $P$ from $Q$ can be expressed as

\begin{equation} \label{eq:kl-ent-kl-ent}
\mathrm{KL}[P||Q] = \mathrm{H}(P,Q) - \mathrm{H}(P)
\end{equation}

where $\mathrm{H}(P,Q)$ is the cross-entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ent-cross}) of $P$ and $Q$ and $\mathrm{H}(P)$ is the marginal entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ent}) of $P$.


\vspace{1em}
\textbf{Proof:} The discrete Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) is defined as

\begin{equation} \label{eq:kl-ent-KL}
\mathrm{KL}[P||Q] = \sum_{x \in \mathcal{X}} p(x) \cdot \log \frac{p(x)}{q(x)}
\end{equation}

where $p(x)$ and $q(x)$ are the probability mass functions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) of $P$ and $Q$.

Separating the logarithm, we have:

\begin{equation} \label{eq:kl-ent-KL-dev}
\mathrm{KL}[P||Q] = - \sum_{x \in \mathcal{X}} p(x) \, \log q(x) + \sum_{x \in \mathcal{X}} p(x) \, \log p(x) \; .
\end{equation}

Now considering the definitions of marginal entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ent}) and cross-entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ent-cross})

\begin{equation} \label{eq:kl-ent-ME-CE}
\begin{split}
\mathrm{H}(P) &= - \sum_{x \in \mathcal{X}} p(x) \, \log p(x) \\
\mathrm{H}(P,Q) &= - \sum_{x \in \mathcal{X}} p(x) \, \log q(x) \; ,
\end{split}
\end{equation}

we can finally show:

\begin{equation} \label{eq:kl-ent-KL-qed}
\mathrm{KL}[P||Q] = \mathrm{H}(P,Q) - \mathrm{H}(P) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Kullback-Leibler divergence"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-05-27; URL: \url{https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence#Motivation}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P113 | shortcut: kl-ent | author: JoramSoch | date: 2020-05-27, 23:20.
\vspace{1em}



\subsubsection[\textbf{Relation to differential entropy}]{Relation to differential entropy} \label{sec:kl-dent}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a continuous random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with possible outcomes $\mathcal{X}$ and let $P$ and $Q$ be two probability distributions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist}) on $X$. Then, the Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) of $P$ from $Q$ can be expressed as

\begin{equation} \label{eq:kl-dent-kl-dent}
\mathrm{KL}[P||Q] = \mathrm{h}(P,Q) - \mathrm{h}(P)
\end{equation}

where $\mathrm{h}(P,Q)$ is the differential cross-entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent-cross}) of $P$ and $Q$ and $\mathrm{h}(P)$ is the marginal differential entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent}) of $P$.


\vspace{1em}
\textbf{Proof:} The continuous Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) is defined as

\begin{equation} \label{eq:kl-dent-KL}
\mathrm{KL}[P||Q] = \int_{\mathcal{X}} p(x) \cdot \log \frac{p(x)}{q(x)} \, \mathrm{d}x
\end{equation}

where $p(x)$ and $q(x)$ are the probability density functions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $P$ and $Q$.

Separating the logarithm, we have:

\begin{equation} \label{eq:kl-dent-KL-dev}
\mathrm{KL}[P||Q] = - \int_{\mathcal{X}} p(x) \, \log q(x) \, \mathrm{d}x + \int_{\mathcal{X}} p(x) \, \log p(x) \, \mathrm{d}x \; .
\end{equation}

Now considering the definitions of marginal differential entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent}) and differential cross-entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent-cross})

\begin{equation} \label{eq:kl-dent-MDE-DCE}
\begin{split}
\mathrm{h}(P) &= - \int_{\mathcal{X}} p(x) \, \log p(x) \, \mathrm{d}x \\
\mathrm{h}(P,Q) &= - \int_{\mathcal{X}} p(x) \, \log q(x) \, \mathrm{d}x \; ,
\end{split}
\end{equation}

we can finally show:

\begin{equation} \label{eq:kl-dent-KL-qed}
\mathrm{KL}[P||Q] = \mathrm{h}(P,Q) - \mathrm{h}(P) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Kullback-Leibler divergence"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-05-27; URL: \url{https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence#Motivation}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P114 | shortcut: kl-dent | author: JoramSoch | date: 2020-05-27, 23:32.
\vspace{1em}



\pagebreak
\section{Estimation theory}

\subsection{Point estimates}

\subsubsection[\textbf{Partition of the mean squared error into bias and variance}]{Partition of the mean squared error into bias and variance} \label{sec:mse-bnv}
\setcounter{equation}{0}

\textbf{Theorem:} The mean squared error ($\rightarrow$ Definition "mse") can be partitioned into variance and squared bias

\begin{equation} \label{eq:mse-bnv-MSE}
\mathrm{MSE}(\hat{\theta}) = \mathrm{Var}(\hat{\theta}) + \mathrm{Bias}(\hat{\theta},\theta)^2
\end{equation}

where the variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) is given by

\begin{equation} \label{eq:mse-bnv-Var}
\mathrm{Var}(\hat{\theta}) = \mathbb{E}_{\hat{\theta}}\left[ \left( \hat{\theta} - \mathbb{E}_{\hat{\theta}}(\hat{\theta}) \right)^2 \right]
\end{equation}

and the bias ($\rightarrow$ Definition "bias") is given by

\begin{equation} \label{eq:mse-bnv-Bias}
\mathrm{Bias}(\hat{\theta},\theta) = \left( \mathbb{E}_{\hat{\theta}}(\hat{\theta}) - \theta \right) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The mean squared error (MSE) is defined as ($\rightarrow$ Definition "mse") the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of the squared deviation of the estimated value $\hat{\theta}$ from the true value $\theta$ of a parameter, over all values $\hat{\theta}$:

\begin{equation} \label{eq:mse-bnv-MSE-def}
\mathrm{MSE}(\hat{\theta}) = \mathbb{E}_{\hat{\theta}}\left[ \left( \hat{\theta} - \theta \right)^2 \right] \; .
\end{equation}

This formula can be evaluated in the following way:

\begin{equation} \label{eq:mse-bnv-MSE-ref1}
\begin{split}
\mathrm{MSE}(\hat{\theta}) &= \mathbb{E}_{\hat{\theta}}\left[ \left( \hat{\theta} - \theta \right)^2 \right] \\
&= \mathbb{E}_{\hat{\theta}}\left[ \left( \hat{\theta} - \mathbb{E}_{\hat{\theta}}(\hat{\theta}) + \mathbb{E}_{\hat{\theta}}(\hat{\theta}) - \theta \right)^2 \right] \\
&= \mathbb{E}_{\hat{\theta}}\left[ \left( \hat{\theta} - \mathbb{E}_{\hat{\theta}}(\hat{\theta}) \right)^2 + 2 \left( \hat{\theta} - \mathbb{E}_{\hat{\theta}}(\hat{\theta}) \right) \left( \mathbb{E}_{\hat{\theta}}(\hat{\theta}) - \theta \right) + \left( \mathbb{E}_{\hat{\theta}}(\hat{\theta}) - \theta \right)^2 \right] \\
&= \mathbb{E}_{\hat{\theta}}\left[ \left( \hat{\theta} - \mathbb{E}_{\hat{\theta}}(\hat{\theta}) \right)^2 \right] + \mathbb{E}_{\hat{\theta}}\left[ 2 \left( \hat{\theta} - \mathbb{E}_{\hat{\theta}}(\hat{\theta}) \right) \left( \mathbb{E}_{\hat{\theta}}(\hat{\theta}) - \theta \right) \right] + \mathbb{E}_{\hat{\theta}}\left[ \left( \mathbb{E}_{\hat{\theta}}(\hat{\theta}) - \theta \right)^2 \right] \; . \\
\end{split}
\end{equation}

Because $\mathbb{E}_{\hat{\theta}}(\hat{\theta}) - \theta$ is constant as a function of $\hat{\theta}$, we have:

\begin{equation} \label{eq:mse-bnv-MSE-ref2}
\begin{split}
\mathrm{MSE}(\hat{\theta}) &= \mathbb{E}_{\hat{\theta}}\left[ \left( \hat{\theta} - \mathbb{E}_{\hat{\theta}}(\hat{\theta}) \right)^2 \right] + 2  \left( \mathbb{E}_{\hat{\theta}}(\hat{\theta}) - \theta \right) \mathbb{E}_{\hat{\theta}}\left[ \hat{\theta} - \mathbb{E}_{\hat{\theta}}(\hat{\theta}) \right] + \left( \mathbb{E}_{\hat{\theta}}(\hat{\theta}) - \theta \right)^2 \\
&= \mathbb{E}_{\hat{\theta}}\left[ \left( \hat{\theta} - \mathbb{E}_{\hat{\theta}}(\hat{\theta}) \right)^2 \right] + 2  \left( \mathbb{E}_{\hat{\theta}}(\hat{\theta}) - \theta \right) \left( \mathbb{E}_{\hat{\theta}}(\hat{\theta}) - \mathbb{E}_{\hat{\theta}}(\hat{\theta}) \right) + \left( \mathbb{E}_{\hat{\theta}}(\hat{\theta}) - \theta \right)^2 \\
&= \mathbb{E}_{\hat{\theta}}\left[ \left( \hat{\theta} - \mathbb{E}_{\hat{\theta}}(\hat{\theta}) \right)^2 \right] + \left( \mathbb{E}_{\hat{\theta}}(\hat{\theta}) - \theta \right)^2 \; . \\
\end{split}
\end{equation}

This proofs the partition given by \eqref{eq:mse-bnv-MSE}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2019): "Mean squared error"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2019-11-27; URL: \url{https://en.wikipedia.org/wiki/Mean_squared_error#Proof_of_variance_and_bias_relationship}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P5 | shortcut: mse-bnv | author: JoramSoch | date: 2019-11-27, 14:26.
\vspace{1em}



\subsection{Interval estimates}

\subsubsection[\textbf{Construction of confidence intervals using Wilks' theorem}]{Construction of confidence intervals using Wilks' theorem} \label{sec:ci-wilks}
\setcounter{equation}{0}

\textbf{Theorem:} Let $m$ be a generative model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) for measured data $y$ with model parameters $\theta$, consisting of a parameter of interest $\phi$ and nuisance parameters $\lambda$:

\begin{equation} \label{eq:ci-wilks-mod-par}
m: p(y|\theta) = \mathcal{D}(y; \theta), \quad \theta = \left\lbrace \phi, \lambda \right\rbrace \; .
\end{equation}

Further, let $\hat{\theta}$ be an estimate of $\theta$, obtained using maximum-likelihood-estimation ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mle}):

\begin{equation} \label{eq:ci-wilks-theta-mle}
\hat{\theta} = \operatorname*{arg\,max}_{\theta} \log p(y|\theta), \quad \hat{\theta} = \left\lbrace \hat{\phi}, \hat{\lambda} \right\rbrace \; .
\end{equation}

Then, an asymptotic confidence interval ($\rightarrow$ Definition "ci") for $\theta$ is given by

\begin{equation} \label{eq:ci-wilks-ci-wilks}
\mathrm{CI}_{1-\alpha}(\hat{\phi}) = \left\lbrace \phi \, \vert \, \log p(y|\phi,\hat{\lambda}) \geq \log p(y|\hat{\phi},\hat{\lambda}) - \frac{1}{2} \chi^2_{1,1-\alpha} \right\rbrace
\end{equation}

where $1-\alpha$ is the confidence level and $\chi^2_{1,1-\alpha}$ is the $(1-\alpha)$-quantile of the chi-squared distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:chi2}) with 1 degree of freedom ($\rightarrow$ Definition "dof").


\vspace{1em}
\textbf{Proof:} The confidence interval ($\rightarrow$ Definition "ci") is defined as the interval that, under infinitely repeated random experiments ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rexp}), contains the true parameter value with a certain probability.

Let us define the likelihood ratio ($\rightarrow$ Definition "lr")

\begin{equation} \label{eq:ci-wilks-lr}
\Lambda(\phi) = \frac{p(y|\phi,\hat{\lambda})}{p(y|\hat{\phi},\hat{\lambda})}
\end{equation}

and compute the log-likelihood ratio ($\rightarrow$ Definition "llr")

\begin{equation} \label{eq:ci-wilks-llr}
\log \Lambda(\phi) = \log p(y|\phi,\hat{\lambda}) - \log p(y|\hat{\phi},\hat{\lambda}) \; .
\end{equation}

Wilks' theorem ($\rightarrow$ Proof "llr-wilks") states that, when comparing two statistical models with parameter spaces $\Theta_1$ and $\Theta_0 \subset \Theta_1$, as the sample size approaches infinity, the quantity calculated as $-2$ times the log-ratio of maximum likelihoods follows a chi-squared distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:chi2}), if the null hypothesis is true:

\begin{equation} \label{eq:ci-wilks-wilks}
H_0: \theta \in \Theta_0 \quad \Rightarrow \quad -2 \log \frac{\operatorname*{max}_{\theta \in \Theta_0} p(y|\theta)}{\operatorname*{max}_{\theta \in \Theta_1} p(y|\theta)} \sim \chi^2_{\Delta k}
\end{equation}

where $\Delta k$ is the difference in dimensionality between $\Theta_0$ and $\Theta_1$. Applied to our example in \eqref{eq:ci-wilks-llr}, we note that $\Theta_1 = \left\lbrace \phi, \hat{\phi} \right\rbrace$ and $\Theta_0 = \left\lbrace \phi \right\rbrace$, such that $\Delta k = 1$ and Wilks' theorem implies:

\begin{equation} \label{eq:ci-wilks-llr-wilks}
-2 \log \Lambda(\phi) \sim  \chi^2_1 \; .
\end{equation}

Using the quantile function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:qf}) $\chi^2_{k,p}$ of the chi-squared distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:chi2}), an $(1-\alpha)$-confidence interval is therefore given by all values $\phi$ that satisfy

\begin{equation} \label{eq:ci-wilks-llr-chi2}
-2 \log \Lambda(\phi) \leq \chi^2_{1,1-\alpha} \; .
\end{equation}

Applying \eqref{eq:ci-wilks-llr} and rearranging, we can evaluate

\begin{equation} \label{eq:ci-wilks-llr-chi2-dev}
\begin{split}
-2 \left[ \log p(y|\phi,\hat{\lambda}) - \log p(y|\hat{\phi},\hat{\lambda}) \right] &\leq \chi^2_{1,1-\alpha} \\
\log p(y|\phi,\hat{\lambda}) - \log p(y|\hat{\phi},\hat{\lambda}) &\geq -\frac{1}{2} \chi^2_{1,1-\alpha} \\
\log p(y|\phi,\hat{\lambda}) &\geq \log p(y|\hat{\phi},\hat{\lambda}) - \frac{1}{2} \chi^2_{1,1-\alpha}
\end{split}
\end{equation}

which is equivalent to the confidence interval given by \eqref{eq:ci-wilks-ci-wilks}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Confidence interval"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-02-19; URL: \url{https://en.wikipedia.org/wiki/Confidence_interval#Methods_of_derivation}.
\item Wikipedia (2020): "Likelihood-ratio test"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-02-19; URL: \url{https://en.wikipedia.org/wiki/Likelihood-ratio_test#Definition}.
\item Wikipedia (2020): "Wilks' theorem"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-02-19; URL: \url{https://en.wikipedia.org/wiki/Wilks%27_theorem}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P56 | shortcut: ci-wilks | author: JoramSoch | date: 2020-02-19, 17:15.
\vspace{1em}



\pagebreak
\section{Frequentist statistics}

\subsection{Likelihood theory}

\subsubsection[\textit{Likelihood function}]{Likelihood function} \label{sec:lf}
\setcounter{equation}{0}

\textbf{Definition:} Let there be a generative model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) $m$ describing measured data $y$ using model parameters $\theta$. Then, the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of the distribution of $y$ given $\theta$ is called the likelihood function of $m$:

\begin{equation} \label{eq:lf-lf}
\mathcal{L}_m(\theta) = p(y|\theta,m) = \mathcal{D}(y; \theta) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D28 | shortcut: lf | author: JoramSoch | date: 2020-03-03, 15:50.
\vspace{1em}



\subsubsection[\textit{Log-likelihood function}]{Log-likelihood function} \label{sec:llf}
\setcounter{equation}{0}

\textbf{Definition:} Let there be a generative model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) $m$ describing measured data $y$ using model parameters $\theta$. Then, the logarithm of the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of the distribution of $y$ given $\theta$ is called the log-likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) of $m$:

\begin{equation} \label{eq:llf-llf}
\mathrm{LL}_m(\theta) = \log p(y|\theta,m) = \log \mathcal{D}(y; \theta) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D59 | shortcut: llf | author: JoramSoch | date: 2020-05-17, 22:52.
\vspace{1em}



\subsubsection[\textit{Maximum likelihood estimation}]{Maximum likelihood estimation} \label{sec:mle}
\setcounter{equation}{0}

\textbf{Definition:} Let there be a generative model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) $m$ describing measured data $y$ using model parameters $\theta$. Then, the parameter values maximizing the likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) or log-likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:llf}) are called maximum likelihood estimates of $\theta$:

\begin{equation} \label{eq:mle-mle}
\hat{\theta} = \operatorname*{arg\,max}_\theta \mathcal{L}_m(\theta) = \operatorname*{arg\,max}_\theta \mathrm{LL}_m(\theta) \; .
\end{equation}

The process of calculating $\hat{\theta}$ is called "maximum likelihood estimation" and the functional form leading from $y$ to $\hat{\theta}$ given $m$ is called "maximum likelihood estimator". Maximum likelihood estimation, estimator and estimates may all be abbreviated as "MLE".


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D60 | shortcut: mle | author: JoramSoch | date: 2020-05-15, 23:05.
\vspace{1em}



\subsubsection[\textit{Maximum log-likelihood}]{Maximum log-likelihood} \label{sec:mll}
\setcounter{equation}{0}

\textbf{Definition:} Let there be a generative model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) $m$ describing measured data $y$ using model parameters $\theta$. Then, the maximum log-likelihood (MLL) of $m$ is the maximal value of the log-likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:llf}) of this model:

\begin{equation} \label{eq:mll-mll}
\mathrm{MLL}(m) = \operatorname*{max}_\theta \mathrm{LL}_m(\theta) \; .
\end{equation}

The maximum log-likelihood can be obtained by plugging the maximum likelihood estimates ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mle}) into the log-likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:llf}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D61 | shortcut: mll | author: JoramSoch | date: 2020-05-15, 23:13.
\vspace{1em}



\subsubsection[\textit{Method of moments}]{Method of moments} \label{sec:mome}
\setcounter{equation}{0}

\textbf{Definition:} Let measured data $y$ follow a probability distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist}) with probability mass ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) or probability density ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) $p(y \vert \theta)$ governed by unknown parameters $\theta_1, \ldots, \theta_k$. Then, method-of-moments estimation, also referred to as "method of moments" or "matching the moments", consists in

\vspace{1em}
1) expressing the first $k$ moments ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mom}) of $y$ in terms of $\theta$

\begin{equation} \label{eq:mome-mom}
\begin{split}
\mu_1 &= f_1(\theta_1, \ldots, \theta_k) \\
&\vdots \\
\mu_k &= f_k(\theta_1, \ldots, \theta_k) \; ,
\end{split}
\end{equation}

\vspace{1em}
2) calculating the first $k$ sample moments ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mom}) from $y$

\begin{equation} \label{eq:mome-mom-samp}
\hat{\mu}_1(y), \ldots, \hat{\mu}_k(y)
\end{equation}

\vspace{1em}
3) and solving the system of $k$ equations

\begin{equation} \label{eq:mome-mome}
\begin{split}
\hat{\mu}_1(y) &= f_1(\hat{\theta}_1, \ldots, \hat{\theta}_k) \\
&\vdots \\
\hat{\mu}_k(y) &= f_k(\hat{\theta}_1, \ldots, \hat{\theta}_k)
\end{split}
\end{equation}

for $\hat{\theta}_1, \ldots, \hat{\theta}_k$, which are subsequently refered to as "method-of-moments estimates".


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Method of moments (statistics)"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-04-29; URL: \url{https://en.wikipedia.org/wiki/Method_of_moments_(statistics)#Method}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D151 | shortcut: mome | author: JoramSoch | date: 2021-04-29, 07:51.
\vspace{1em}



\subsection{Statistical hypotheses}

\subsubsection[\textit{Statistical hypothesis}]{Statistical hypothesis} \label{sec:hyp}
\setcounter{equation}{0}

\textbf{Definition:} A statistical hypothesis is a statement about the parameters of a distribution describing a population from which observations can be sampled as measured data ($\rightarrow$ Definition "data").

More precisely, let $m$ be a generative model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) describing measured data $y$ in terms of a distribution $\mathcal{D}(\theta)$ with model parameters $\theta \in \Theta$. Then, a statistical hypothesis is formally specified as

\begin{equation} \label{eq:hyp-hyp}
H: \; \theta \in \Theta^{*} \quad \text{where} \quad \Theta^{*} \subset \Theta \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Statistical hypothesis testing"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-03-19; URL: \url{https://en.wikipedia.org/wiki/Statistical_hypothesis_testing#Definition_of_terms}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D127 | shortcut: hyp | author: JoramSoch | date: 2021-03-19, 14:18.
\vspace{1em}



\subsubsection[\textit{Simple vs. composite}]{Simple vs. composite} \label{sec:hyp-simp}
\setcounter{equation}{0}

\textbf{Definition:} Let $H$ be a statistical hypothesis ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:hyp}). Then,

\begin{itemize}

\item $H$ is called a simple hypothesis, if it completely specifies the population distribution; in this case, the sampling distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-samp}) of the test statistic ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:tstat}) is a function of sample size alone.

\item $H$ is called a composite hypothesis, if it does not completely specify the population distribution; for example, the hypothesis may only specify one parameter of the distribution and leave others unspecified.

\end{itemize}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Exclusion of the null hypothesis"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-03-19; URL: \url{https://en.wikipedia.org/wiki/Exclusion_of_the_null_hypothesis#Terminology}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D128 | shortcut: hyp-simp | author: JoramSoch | date: 2021-03-19, 14:24.
\vspace{1em}



\subsubsection[\textit{Point/exact vs. set/inexact}]{Point/exact vs. set/inexact} \label{sec:hyp-point}
\setcounter{equation}{0}

\textbf{Definition:} Let $H$ be a statistical hypothesis ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:hyp}). Then,

\begin{itemize}

\item $H$ is called a point hypothesis or exact hypothesis, if it specifies an exact parameter value:

\end{itemize}

\begin{equation} \label{eq:hyp-point-hyp-point}
H: \; \theta = \theta^{*} \; ;
\end{equation}

\begin{itemize}

\item $H$ is called a set hypothesis or inexact hypothesis, if it specifies a set of possible values with more than one element for the parameter value (e.g. a range or an interval):

\end{itemize}

\begin{equation} \label{eq:hyp-point-hyp-non-point}
H: \; \theta \in \Theta^{*} \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Exclusion of the null hypothesis"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-03-19; URL: \url{https://en.wikipedia.org/wiki/Exclusion_of_the_null_hypothesis#Terminology}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D129 | shortcut: hyp-point | author: JoramSoch | date: 2021-03-19, 14:28.
\vspace{1em}



\subsubsection[\textit{One-tailed vs. two-tailed}]{One-tailed vs. two-tailed} \label{sec:hyp-tail}
\setcounter{equation}{0}

\textbf{Definition:} Let $H_0$ be a point ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:hyp-point}) null hypothesis ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:h0})

\begin{equation} \label{eq:hyp-tail-h0-point}
H_0: \; \theta = \theta_0 \;
\end{equation}

and consider a set ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:hyp-point}) alternative hypothesis ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:h1}) $H_1$. Then,

\begin{itemize}

\item $H_1$ is called a left-sided one-tailed hypothesis, if $\theta$ is assumed to be smaller than $\theta_0$:

\end{itemize}

\begin{equation} \label{eq:hyp-tail-h1-tail1-left}
H_1: \; \theta < \theta_0 \; ;
\end{equation}

\begin{itemize}

\item $H_1$ is called a right-sided one-tailed hypothesis, if $\theta$ is assumed to be larger than $\theta_0$:

\end{itemize}

\begin{equation} \label{eq:hyp-tail-h1-tail1-right}
H_1: \; \theta > \theta_0 \; ;
\end{equation}

\begin{itemize}

\item $H_1$ is called a two-tailed hypothesis, if $\theta$ is assumed to be unequal to $\theta_0$:

\end{itemize}

\begin{equation} \label{eq:hyp-tail-h1-tail2}
H_1: \; \theta \neq \theta_0 \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "One- and two-tailed tests"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-03-31; URL: \url{https://en.wikipedia.org/wiki/One-_and_two-tailed_tests}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D138 | shortcut: hyp-tail | author: JoramSoch | date: 2021-03-31, 09:21.
\vspace{1em}



\subsection{Hypothesis testing}

\subsubsection[\textit{Statistical test}]{Statistical test} \label{sec:test}
\setcounter{equation}{0}

\textbf{Definition:} Let $y$ be a set of measured data ($\rightarrow$ Definition "data"). Then, a statistical hypothesis test consists of the following:

\begin{itemize}

\item an assumption about the distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist}) of the data, often expressed in terms of a statistical model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) $m$;

\item a null hypothesis ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:h0}) $H_0$ and an alternative hypothesis ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:h1}) $H_1$ which make specific statements about the distribution of the data; 

\item a test statistic ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:tstat}) $T(Y)$ which is a function of the data and whose distribution under the null hypothesis ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:h0}) is known;

\item a significance level ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:alpha}) $\alpha$ which imposes an upper bound on the probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob}) of rejecting $H_0$, given that $H_0$ is true.

\end{itemize}

Procedurally, the statistical hypothesis test works as follows:

\begin{itemize}

\item Given the null hypothesis $H_0$ and the significance level $\alpha$, a critical value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cval}) $t_\mathrm{crit}$ is determined which partitions the set of possible values of $T(Y)$ into "acceptance region" and "rejection region".

\item Then, the observed test statistic ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:tstat}) $t_\mathrm{obs} = T(y)$ is calculated from the actually measured data $y$. If it is in the rejection region, $H_0$ is rejected in favor of $H_1$. Otherwise, the test fails to reject $H_0$.

\end{itemize}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Statistical hypothesis testing"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-03-19; URL: \url{https://en.wikipedia.org/wiki/Statistical_hypothesis_testing#The_testing_process}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D130 | shortcut: test | author: JoramSoch | date: 2021-03-19, 14:36.
\vspace{1em}



\subsubsection[\textit{Null hypothesis}]{Null hypothesis} \label{sec:h0}
\setcounter{equation}{0}

\textbf{Definition:} The statement which is tested in a statistical hypothesis test ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:test}) is called the "null hypothesis", denoted as $H_0$. The test is designed to assess the strength of evidence against $H_0$ and possibly reject it. The opposite of $H_0$ is called the "alternative hypothesis ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:h1})". Usually, $H_0$ is a statement that a particular parameter is zero, that there is no effect of a particular treatment or that there is no difference between particular conditions.

More precisely, let $m$ be a generative model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) describing measured data $y$ using model parameters $\theta \in \Theta$. Then, a null hypothesis is formally specified as

\begin{equation} \label{eq:h0-h0}
H_0: \; \theta \in \Theta_0 \quad \text{where} \quad \Theta_0 \subset \Theta \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Exclusion of the null hypothesis"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-03-12; URL: \url{https://en.wikipedia.org/wiki/Exclusion_of_the_null_hypothesis#Basic_definitions}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D125 | shortcut: h0 | author: JoramSoch | date: 2021-03-12, 10:25.
\vspace{1em}



\subsubsection[\textit{Alternative hypothesis}]{Alternative hypothesis} \label{sec:h1}
\setcounter{equation}{0}

\textbf{Definition:} Let $H_0$ be a null hypothesis ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:h0}) of a statistical hypothesis test ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:test}). Then, the corresponding alternative hypothesis, denoted as $H_1$, is either the negation of $H_0$ or an interesting sub-case in the negation of $H_0$, depending on context. The test is designed to assess the strength of evidence against $H_0$ and possibly reject it in favor of $H_1$. Usually, $H_1$ is a statement that a particular parameter is non-zero, that there is an effect of a particular treatment or that there is a difference between particular conditions.

More precisely, let $m$ be a generative model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) describing measured data $y$ using model parameters $\theta \in \Theta$. Then, null and alternative hypothesis are formally specified as

\begin{equation} \label{eq:h1-h0}
\begin{split}
H_0&: \; \theta \in \Theta_0 \quad \text{where} \quad \Theta_0 \subset \Theta \\
H_1&: \; \theta \in \Theta_1 \quad \text{where} \quad \Theta_1 = \Theta \setminus \Theta_0 \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Exclusion of the null hypothesis"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-03-12; URL: \url{https://en.wikipedia.org/wiki/Exclusion_of_the_null_hypothesis#Basic_definitions}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D126 | shortcut: h1 | author: JoramSoch | date: 2021-03-12, 10:36.
\vspace{1em}



\subsubsection[\textit{One-tailed vs. two-tailed}]{One-tailed vs. two-tailed} \label{sec:test-tail}
\setcounter{equation}{0}

\textbf{Definition:} Let there be a statistical test ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:test}) of an alternative hypothesis ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:h1}) $H_1$ against a null hypothesis ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:h0}) $H_0$. Then,

\begin{itemize}

\item the test is called a one-tailed test, if $H_1$ is a one-tailed hypothesis ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:hyp-tail});

\item the test is called a two-tailed test, if $H_1$ is a two-tailed hypothesis ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:hyp-tail}).

\end{itemize}

The fact whether a test ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:test}) is one-tailed or two-tailed has consequences for the computation of critical value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cval}) and p-value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pval}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "One- and two-tailed tests"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-03-31; URL: \url{https://en.wikipedia.org/wiki/One-_and_two-tailed_tests}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D139 | shortcut: test-tail | author: JoramSoch | date: 2021-03-31, 09:32.
\vspace{1em}



\subsubsection[\textit{Test statistic}]{Test statistic} \label{sec:tstat}
\setcounter{equation}{0}

\textbf{Definition:} In a statistical hypothesis test ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:test}), the test statistic $T(Y)$ is a scalar function of the measured data ($\rightarrow$ Definition "data") $y$ whose distribution under the null hypothesis ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:h0}) $H_0$ can be established. Together with a significance level ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:alpha}) $\alpha$, this distribution implies a critical value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cval}) $t_\mathrm{crit}$ of the test statistic which determines whether the test rejects or fails to reject $H_0$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Statistical hypothesis testing"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-03-19; URL: \url{https://en.wikipedia.org/wiki/Statistical_hypothesis_testing#The_testing_process}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D131 | shortcut: tstat | author: JoramSoch | date: 2021-03-19, 14:40.
\vspace{1em}



\subsubsection[\textit{Size of a test}]{Size of a test} \label{sec:size}
\setcounter{equation}{0}

\textbf{Definition:} Let there be a statistical hypothesis test ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:test}) with null hypothesis ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:h0}) $H_0$. Then, the size of the test is the probability of a false-positive result or making a type I error, i.e. the probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob}) of rejecting the null hypothesis ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:h0}) $H_0$, given that $H_0$ is actually true.

For a simple null hypothesis ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:hyp-simp}), the size is determined by the following conditional probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-cond}):

\begin{equation} \label{eq:size-size-h0-simp}
\mathrm{Pr}(\text{test rejects } H_0 \vert H_0) \; .
\end{equation}

For a composite null hypothesis ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:hyp-simp}), the size is the supremum over all possible realizations of the null hypothesis ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:h0}):

\begin{equation} \label{eq:size-size-h0-comp}
\operatorname*{sup}_{h \in H_0} \mathrm{Pr}(\text{test rejects } H_0 \vert h) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Size (statistics)"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-03-19; URL: \url{https://en.wikipedia.org/wiki/Size_(statistics)}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D132 | shortcut: size | author: JoramSoch | date: 2021-03-19, 14:46.
\vspace{1em}



\subsubsection[\textit{Power of a test}]{Power of a test} \label{sec:power}
\setcounter{equation}{0}

\textbf{Definition:} Let there be a statistical hypothesis test ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:test}) with null hypothesis ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:h0}) $H_0$ and alternative hypothesis ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:h1}) $H_1$. Then, the power of the test is the probability of a true-positive result or not making a type II error, i.e. the probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob}) of rejecting $H_0$, given that $H_1$ is actually true.

For given null ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:h0}) and alternative ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:h1}) hypothesis ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:hyp}), the size is determined by the following conditional probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-cond}):

\begin{equation} \label{eq:power-power}
\mathrm{Pr}(\text{test rejects } H_0 \vert H_1) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Power of a test"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-03-31; URL: \url{https://en.wikipedia.org/wiki/Power_of_a_test#Description}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D137 | shortcut: power | author: JoramSoch | date: 2021-03-31, 09:01.
\vspace{1em}



\subsubsection[\textit{Significance level}]{Significance level} \label{sec:alpha}
\setcounter{equation}{0}

\textbf{Definition:} Let the size ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:size}) of a statistical hypothesis test ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:test}) be the probability of a false-positive result or making a type I error, i.e. the probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob}) of rejecting the null hypothesis ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:h0}) $H_0$, given that $H_0$ is actually true:

\begin{equation} \label{eq:alpha-size}
\mathrm{Pr}(\text{test rejects } H_0 \vert H_0) \; .
\end{equation}

Then, the test is said to have significance level $\alpha$, if the size is less than or equal to $\alpha$:

\begin{equation} \label{eq:alpha-alpha}
\mathrm{Pr}(\text{test rejects } H_0 \vert H_0) \leq \alpha \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Statistical hypothesis testing"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-03-19; URL: \url{https://en.wikipedia.org/wiki/Statistical_hypothesis_testing#Definition_of_terms}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D133 | shortcut: alpha | author: JoramSoch | date: 2021-03-19, 14:50.
\vspace{1em}



\subsubsection[\textit{Critical value}]{Critical value} \label{sec:cval}
\setcounter{equation}{0}

\textbf{Definition:} In a statistical hypothesis test ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:test}), the critical value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cval}) $t_\mathrm{crit}$ is that value of the test statistic ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:tstat}) $T(Y)$ which partitions the set of possible test statistics into "acceptance region" and "rejection region" based on a significance level ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:alpha}) $\alpha$. Put differently, if the observed test statistic $t_\mathrm{obs} = T(y)$ computed from actually measured data ($\rightarrow$ Definition "data") $y$ is as extreme or more extreme than the critical value, the test rejects the null hypothesis ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:h0}) $H_0$ in favor of the alternative hypothesis ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:h1}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Statistical hypothesis testing"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-03-19; URL: \url{https://en.wikipedia.org/wiki/Statistical_hypothesis_testing#Definition_of_terms}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D134 | shortcut: cval | author: JoramSoch | date: 2021-03-19, 14:54.
\vspace{1em}



\subsubsection[\textit{p-value}]{p-value} \label{sec:pval}
\setcounter{equation}{0}

\textbf{Definition:} Let there be a statistical test ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:test}) of the null hypothesis ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:h0}) $H_0$ and the alternative hypothesis ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:h1}) $H_1$ using the test statistic ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:tstat}) $T(Y)$. Let $y$ be the measured data ($\rightarrow$ Definition "data") and let $t_\mathrm{obs} = T(y)$ be the observed test statistic computed from $y$. Moreover, assume that $F_T(t)$ is the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) (CDF) of the distribution of $T(Y)$ under $H_0$.

Then, the p-value is the probability of obtaining a test statistic more extreme than or as extreme as $t_\mathrm{obs}$, given that the null hypothesis $H_0$ is true:

\begin{itemize}

\item $p = F_T^{-1}(t_\mathrm{obs})$, if $H_1$ is a left-sided one-tailed hypothesis ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:hyp-tail});

\item $p = 1 - F_T^{-1}(t_\mathrm{obs})$, if $H_1$ is a right-sided one-tailed hypothesis ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:hyp-tail});

\item $p = 2 \cdot \min \left( \left[ F_T^{-1}(t_\mathrm{obs}), \, 1 - F_T^{-1}(t_\mathrm{obs}) \right] \right)$, if $H_1$ is a two-tailed hypothesis ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:hyp-tail}).

\end{itemize}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Statistical hypothesis testing"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-03-19; URL: \url{https://en.wikipedia.org/wiki/Statistical_hypothesis_testing#Definition_of_terms}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D135 | shortcut: pval | author: JoramSoch | date: 2021-03-19, 14:58.
\vspace{1em}



\pagebreak
\section{Bayesian statistics}

\subsection{Probabilistic modeling}

\subsubsection[\textit{Generative model}]{Generative model} \label{sec:gm}
\setcounter{equation}{0}

\textbf{Definition:} Consider measured data $y$ and some unknown latent parameters $\theta$. A statement about the distribution of $y$ given $\theta$ is called a generative model $m$:

\begin{equation} \label{eq:gm-gm}
m: \, y \sim \mathcal{D}(\theta) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D27 | shortcut: gm | author: JoramSoch | date: 2020-03-03, 15:50.
\vspace{1em}



\subsubsection[\textit{Likelihood function}]{Likelihood function} \label{sec:lf}
\setcounter{equation}{0}

\textbf{Definition:} Let there be a generative model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) $m$ describing measured data $y$ using model parameters $\theta$. Then, the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of the distribution of $y$ given $\theta$ is called the likelihood function of $m$:

\begin{equation} \label{eq:lf-lf}
\mathcal{L}_m(\theta) = p(y|\theta,m) = \mathcal{D}(y; \theta) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D28 | shortcut: lf | author: JoramSoch | date: 2020-03-03, 15:50.
\vspace{1em}



\subsubsection[\textit{Prior distribution}]{Prior distribution} \label{sec:prior}
\setcounter{equation}{0}

\textbf{Definition:} Consider measured data $y$ and some unknown latent parameters $\theta$. A distribution of $\theta$ unconditional on $y$ is called a prior distribution:

\begin{equation} \label{eq:prior-prior}
\theta \sim \mathcal{D}(\lambda) \; .
\end{equation}

The parameters $\lambda$ of this distribution are called the prior hyperparameters and the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) is called the prior density:

\begin{equation} \label{eq:prior-prior-pdf}
p(\theta|m) = \mathcal{D}(\theta; \lambda) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D29 | shortcut: prior | author: JoramSoch | date: 2020-03-03, 16:09.
\vspace{1em}



\subsubsection[\textit{Full probability model}]{Full probability model} \label{sec:fpm}
\setcounter{equation}{0}

\textbf{Definition:} Consider measured data $y$ and some unknown latent parameters $\theta$. The combination of a generative model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) for $y$ and a prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) on $\theta$ is called a full probability model $m$:

\begin{equation} \label{eq:fpm-fpm}
m: \, y \sim \mathcal{D}(\theta), \, \theta \sim \mathcal{D}(\lambda) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D30 | shortcut: fpm | author: JoramSoch | date: 2020-03-03, 16:16.
\vspace{1em}



\subsubsection[\textit{Joint likelihood}]{Joint likelihood} \label{sec:jl}
\setcounter{equation}{0}

\textbf{Definition:} Let there be a generative model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) $m$ describing measured data $y$ using model parameters $\theta$ and a prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) on $\theta$. Then, the joint probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $y$ and $\theta$ is called the joint likelihood:

\begin{equation} \label{eq:jl-jl}
p(y,\theta|m) = p(y|\theta,m) \, p(\theta|m) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D31 | shortcut: jl | author: JoramSoch | date: 2020-03-03, 16:36.
\vspace{1em}



\subsubsection[\textbf{Joint likelihood is product of likelihood and prior}]{Joint likelihood is product of likelihood and prior} \label{sec:jl-lfnprior}
\setcounter{equation}{0}

\textbf{Theorem:} Let there be a generative model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) $m$ describing measured data $y$ using model parameters $\theta$ and a prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) on $\theta$. Then, the joint likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:jl}) is equal to the product of likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) and prior density ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}):

\begin{equation} \label{eq:jl-lfnprior-jl}
p(y,\theta|m) = p(y|\theta,m) \, p(\theta|m) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The joint likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:jl}) is defined as the joint probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of data $y$ and parameters $\theta$:

\begin{equation} \label{eq:jl-lfnprior-jl-def}
p(y,\theta|m) \; .
\end{equation}

Applying the law of conditional probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-cond}), we have:

\begin{equation} \label{eq:jl-lfnprior-jl-qed}
\begin{split}
p(y|\theta,m) &= \frac{p(y,\theta|m)}{p(\theta|m)} \\
&\Leftrightarrow \\
p(y,\theta|m) &= p(y|\theta,m) \, p(\theta|m) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P89 | shortcut: jl-lfnprior | author: JoramSoch | date: 2020-05-05, 04:21.
\vspace{1em}



\subsubsection[\textit{Posterior distribution}]{Posterior distribution} \label{sec:post}
\setcounter{equation}{0}

\textbf{Definition:} Consider measured data $y$ and some unknown latent parameters $\theta$. The distribution of $\theta$ conditional on $y$ is called the posterior distribution:

\begin{equation} \label{eq:post-post}
\theta|y \sim \mathcal{D}(\phi) \; .
\end{equation}

The parameters $\phi$ of this distribution are called the posterior hyperparameters and the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) is called the posterior density:

\begin{equation} \label{eq:post-prior-pdf}
p(\theta|y,m) = \mathcal{D}(\theta; \phi) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D32 | shortcut: post | author: JoramSoch | date: 2020-03-03, 16:43.
\vspace{1em}



\subsubsection[\textbf{Posterior density is proportional to joint likelihood}]{Posterior density is proportional to joint likelihood} \label{sec:post-jl}
\setcounter{equation}{0}

\textbf{Theorem:} In a full probability model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:fpm}) $m$ describing measured data $y$ using model parameters $\theta$, the posterior density ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) over the model parameters is proportional to the joint likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:jl}):

\begin{equation} \label{eq:post-jl-post}
p(\theta|y,m) \propto p(y,\theta|m) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} In a full probability model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:fpm}), the posterior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) can be expressed using Bayes' theorem ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:bayes-th}):

\begin{equation} \label{eq:post-jl-post-s1}
p(\theta|y,m) = \frac{p(y|\theta,m) \, p(\theta|m)}{p(y|m)} \; .
\end{equation}

Applying the law of conditional probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-cond}) to the numerator, we have:

\begin{equation} \label{eq:post-jl-post-s2}
p(\theta|y,m) = \frac{p(y,\theta|m)}{p(y|m)} \; .
\end{equation}

Because the denominator does not depend on $\theta$, it is constant in $\theta$ and thus acts a proportionality factor between the posterior distribution and the joint likelihood:

\begin{equation} \label{eq:post-jl-post-qed}
p(\theta|y,m) \propto p(y,\theta|m) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P90 | shortcut: post-jl | author: JoramSoch | date: 2020-05-05, 04:46.
\vspace{1em}



\subsubsection[\textit{Marginal likelihood}]{Marginal likelihood} \label{sec:ml}
\setcounter{equation}{0}

\textbf{Definition:} Let there be a generative model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) $m$ describing measured data $y$ using model parameters $\theta$ and a prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) on $\theta$. Then, the marginal probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}) density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $y$ across the parameter space $\Theta$ is called the marginal likelihood:

\begin{equation} \label{eq:ml-ml}
p(y|m) = \int_{\Theta} p(y|\theta,m) \, p(\theta|m) \, \mathrm{d}\theta \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D33 | shortcut: ml | author: JoramSoch | date: 2020-03-03, 16:49.
\vspace{1em}



\subsubsection[\textbf{Marginal likelihood is integral of joint likelihood}]{Marginal likelihood is integral of joint likelihood} \label{sec:ml-jl}
\setcounter{equation}{0}

\textbf{Theorem:} In a full probability model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:fpm}) $m$ describing measured data $y$ using model parameters $\theta$, the marginal likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ml}) is the integral of the joint likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:jl}) across the parameter space $\Theta$:

\begin{equation} \label{eq:ml-jl-ml}
p(y|m) = \int_{\Theta} p(y,\theta|m) \, \mathrm{d}\theta \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} In a full probability model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:fpm}), the marginal likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ml}) is defined as the marginal probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}) of the data $y$, given only the model $m$:

\begin{equation} \label{eq:ml-jl-ml-def}
p(y|m) \; .
\end{equation}

Using the law of marginal probabililty ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}), this can be obtained by integrating the joint likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:jl}) function over the entire parameter space:

\begin{equation} \label{eq:ml-jl-ml-qed}
p(y|m) = \int_{\Theta} p(y,\theta|m) \, \mathrm{d}\theta \; .
\end{equation}

Applying the law of conditional probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-cond}), the integrand can also be written as the product of likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) and prior density ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}):

\begin{equation} \label{eq:ml-jl-ml-int}
p(y|m) = \int_{\Theta} p(y|\theta,m) \, p(\theta|m) \, \mathrm{d}\theta \; .
\end{equation}



\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P91 | shortcut: ml-jl | author: JoramSoch | date: 2020-05-05, 04:59.
\vspace{1em}



\subsection{Prior distributions}

\subsubsection[\textit{Flat vs. hard vs. soft}]{Flat vs. hard vs. soft} \label{sec:prior-flat}
\setcounter{equation}{0}

\textbf{Definition:} Let $p(\theta \vert m)$ be a prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) for the parameter $\theta$ of a generative model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) $m$. Then,

\begin{itemize}

\item the distribution is called a "flat prior", if its precision ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prec}) is zero or variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) is infinite;

\item the distribution is called a "hard prior", if its precision ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prec}) is infinite or variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) is zero;

\item the distribution is called a "soft prior", if its precision ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prec}) and variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) are non-zero and finite.

\end{itemize}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Friston et al. (2002): "Classical and Bayesian Inference in Neuroimaging: Theory"; in: \textit{NeuroImage}, vol. 16, iss. 2, pp. 465-483, fn. 1; URL: \url{https://www.sciencedirect.com/science/article/pii/S1053811902910906}; DOI: 10.1006/nimg.2002.1090.
\item Friston et al. (2002): "Classical and Bayesian Inference in Neuroimaging: Applications"; in: \textit{NeuroImage}, vol. 16, iss. 2, pp. 484-512, fn. 10; URL: \url{https://www.sciencedirect.com/science/article/pii/S1053811902910918}; DOI: 10.1006/nimg.2002.1091.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D116 | shortcut: prior-flat | author: JoramSoch | date: 2020-12-02, 17:04.
\vspace{1em}



\subsubsection[\textit{Uniform vs. non-uniform}]{Uniform vs. non-uniform} \label{sec:prior-uni}
\setcounter{equation}{0}

\textbf{Definition:} Let $p(\theta \vert m)$ be a prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) for the parameter $\theta$ of a generative model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) $m$ where $\theta$ belongs to the parameter space $\Theta$. Then,

\begin{itemize}

\item the distribution is called a "uniform prior", if its density ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) or mass ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) is constant over $\Theta$;

\item the distribution is called a "non-uniform prior", if its density ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) or mass ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) is not constant over $\Theta$.

\end{itemize}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Lindley's paradox"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-11-25; URL: \url{https://en.wikipedia.org/wiki/Lindley%27s_paradox#Bayesian_approach}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D117 | shortcut: prior-uni | author: JoramSoch | date: 2020-12-02, 17:21.
\vspace{1em}



\subsubsection[\textit{Informative vs. non-informative}]{Informative vs. non-informative} \label{sec:prior-inf}
\setcounter{equation}{0}

\textbf{Definition:} Let $p(\theta \vert m)$ be a prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) for the parameter $\theta$ of a generative model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) $m$. Then,

\begin{itemize}

\item the distribution is called an "informative prior", if it biases the parameter towards particular values;

\item the distribution is called a "weakly informative prior", if it mildly influences the posterior distribution ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:post-jl});

\item the distribution is called a "non-informative prior", if it does not influence ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:post-jl}) the posterior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}).

\end{itemize}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Soch J, Allefeld C, Haynes JD (2016): "How to avoid mismodelling in GLM-based fMRI data analysis: cross-validated Bayesian model selection"; in: \textit{NeuroImage}, vol. 141, pp. 469-489, eq. 15, p. 473; URL: \url{https://www.sciencedirect.com/science/article/pii/S1053811916303615}; DOI: 10.1016/j.neuroimage.2016.07.047.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D118 | shortcut: prior-inf | author: JoramSoch | date: 2020-12-02, 17:28.
\vspace{1em}



\subsubsection[\textit{Empirical vs. non-empirical}]{Empirical vs. non-empirical} \label{sec:prior-emp}
\setcounter{equation}{0}

\textbf{Definition:} Let $p(\theta \vert m)$ be a prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) for the parameter $\theta$ of a generative model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) $m$. Then,

\begin{itemize}

\item the distribution is called an "empirical prior", if it has been derived from empirical data ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:post-jl});

\item the distribution is called a "theoretical prior", if it was specified without regard to empirical data.

\end{itemize}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Soch J, Allefeld C, Haynes JD (2016): "How to avoid mismodelling in GLM-based fMRI data analysis: cross-validated Bayesian model selection"; in: \textit{NeuroImage}, vol. 141, pp. 469-489, eq. 13, p. 473; URL: \url{https://www.sciencedirect.com/science/article/pii/S1053811916303615}; DOI: 10.1016/j.neuroimage.2016.07.047.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D119 | shortcut: prior-emp | author: JoramSoch | date: 2020-12-02, 17:37.
\vspace{1em}



\subsubsection[\textit{Conjugate vs. non-conjugate}]{Conjugate vs. non-conjugate} \label{sec:prior-conj}
\setcounter{equation}{0}

\textbf{Definition:} Let $m$ be a generative model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) with likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) $p(y \vert \theta, m)$ and prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) $p(\theta \vert m)$. Then,

\begin{itemize}

\item the prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) is called "conjugate", if it, when combined with the likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}), leads to a posterior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) that belongs to the same family of probability distributions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist});

\item the prior distribution is called "non-conjugate", if this is not the case.

\end{itemize}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Conjugate prior"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-12-02; URL: \url{https://en.wikipedia.org/wiki/Conjugate_prior}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D120 | shortcut: prior-conj | author: JoramSoch | date: 2020-12-02, 17:55.
\vspace{1em}



\subsubsection[\textit{Maximum entropy priors}]{Maximum entropy priors} \label{sec:prior-maxent}
\setcounter{equation}{0}

\textbf{Definition:} Let $m$ be a generative model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) with likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) $p(y \vert \theta, m)$ and prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) $p(\theta \vert \lambda, m)$ using prior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) $\lambda$. Then, the prior distribution is called a "maximum entropy prior", if

1) when $\theta$ is a discrete random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar-disc}), it maximizes the entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ent}) of the prior probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}):

\begin{equation} \label{eq:prior-maxent-prior-maxent-disc}
\lambda_{\mathrm{maxent}} = \operatorname*{arg\,max}_{\lambda} \mathrm{H}\left[ p(\theta \vert \lambda, m) \right] \; ;
\end{equation}

2) when $\theta$ is a continuous random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar-disc}), it maximizes the differential entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent}) of the prior probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}):

\begin{equation} \label{eq:prior-maxent-prior-maxent-cont}
\lambda_{\mathrm{maxent}} = \operatorname*{arg\,max}_{\lambda} \mathrm{h}\left[ p(\theta \vert \lambda, m) \right] \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Prior probability"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-12-02; URL: \url{https://en.wikipedia.org/wiki/Prior_probability#Uninformative_priors}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D121 | shortcut: prior-maxent | author: JoramSoch | date: 2020-12-02, 18:13.
\vspace{1em}



\subsubsection[\textit{Empirical Bayes priors}]{Empirical Bayes priors} \label{sec:prior-eb}
\setcounter{equation}{0}

\textbf{Definition:} Let $m$ be a generative model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) with likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) $p(y \vert \theta, m)$ and prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) $p(\theta \vert \lambda, m)$ using prior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) $\lambda$. Let $p(y \vert \lambda, m)$ be the marginal likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ml}) when integrating the parameters out of the joint likelihood ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:ml-jl}). Then, the prior distribution is called an "Empirical Bayes ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:eb}) prior", if it maximizes the logarithmized marginal likelihood:

\begin{equation} \label{eq:prior-eb-prior-eb}
\lambda_{\mathrm{EB}} = \operatorname*{arg\,max}_{\lambda} \log p(y \vert \lambda, m) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Empirical Bayes method"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-12-02; URL: \url{https://en.wikipedia.org/wiki/Empirical_Bayes_method#Introduction}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D122 | shortcut: prior-eb | author: JoramSoch | date: 2020-12-02, 18:19.
\vspace{1em}



\subsubsection[\textit{Reference priors}]{Reference priors} \label{sec:prior-ref}
\setcounter{equation}{0}

\textbf{Definition:} Let $m$ be a generative model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) with likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) $p(y \vert \theta, m)$ and prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) $p(\theta \vert \lambda, m)$ using prior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) $\lambda$. Let $p(\theta \vert y, \lambda, m)$ be the posterior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) that is proportional to the the joint likelihood ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:post-jl}). Then, the prior distribution is called a "reference prior", if it maximizes the expected ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) of the posterior distribution relative to the prior distribution:

\begin{equation} \label{eq:prior-ref-prior-ref}
\lambda_{\mathrm{ref}} = \operatorname*{arg\,max}_{\lambda} \left\langle \mathrm{KL} \left[ p(\theta \vert y, \lambda, m) \, || \, p(\theta \vert \lambda, m) \right] \right\rangle \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Prior probability"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-12-02; URL: \url{https://en.wikipedia.org/wiki/Prior_probability#Uninformative_priors}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D123 | shortcut: prior-ref | author: JoramSoch | date: 2020-12-02, 18:26.
\vspace{1em}



\subsection{Bayesian inference}

\subsubsection[\textbf{Bayes' theorem}]{Bayes' theorem} \label{sec:bayes-th}
\setcounter{equation}{0}

\textbf{Theorem:} Let $A$ and $B$ be two arbitrary statements about random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}), such as statements about the presence or absence of an event or about the value of a scalar, vector or matrix. Then, the conditional probability that $A$ is true, given that $B$ is true, is equal to

\begin{equation} \label{eq:bayes-th-BT}
p(A|B) = \frac{p(B|A) \, p(A)}{p(B)} \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The conditional probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-cond}) is defined as the ratio of joint probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}), i.e. the probability of both statements being true, and marginal probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}), i.e. the probability of only the second one being true:

\begin{equation} \label{eq:bayes-th-LCP}
p(A|B) = \frac{p(A,B)}{p(B)} \; .
\end{equation}

It can also be written down for the reverse situation, i.e. to calculate the probability that $B$ is true, given that $A$ is true:

\begin{equation} \label{eq:bayes-th-LCP-rev}
p(B|A) = \frac{p(A,B)}{p(A)} \; .
\end{equation}

Both equations can be rearranged for the joint probability

\begin{equation} \label{eq:bayes-th-JP}
p(A|B) \, p(B) \overset{\eqref{eq:bayes-th-LCP}}{=} p(A,B) \overset{\eqref{eq:bayes-th-LCP-rev}}{=} p(B|A) \, p(A)
\end{equation}

from which Bayes' theorem can be directly derived:

\begin{equation} \label{eq:bayes-th-BT-proof}
p(A|B) \overset{\eqref{eq:bayes-th-JP}}{=} \frac{p(B|A) \, p(A)}{p(B)} \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Koch, Karl-Rudolf (2007): "Rules of Probability"; in: \textit{Introduction to Bayesian Statistics}, Springer, Berlin/Heidelberg, 2007, pp. 6/13, eqs. 2.12/2.38; URL: \url{https://www.springer.com/de/book/9783540727231}; DOI: 10.1007/978-3-540-72726-2.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P4 | shortcut: bayes-th | author: JoramSoch | date: 2019-09-27, 16:24.
\vspace{1em}



\subsubsection[\textbf{Bayes' rule}]{Bayes' rule} \label{sec:bayes-rule}
\setcounter{equation}{0}

\textbf{Theorem:} Let $A_1$, $A_2$ and $B$ be arbitrary statements about random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) where $A_1$ and $A_2$ are mutually exclusive. Then, Bayes' rule states that the posterior odds ($\rightarrow$ Definition "post-odd") are equal to the Bayes factor ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:bf}) times the prior odds ($\rightarrow$ Definition "prior-odd"), i.e.

\begin{equation} \label{eq:bayes-rule-bayes-rule}
\frac{p(A_1|B)}{p(A_2|B)} = \frac{p(B|A_1)}{p(B|A_2)} \cdot \frac{p(A_1)}{p(A_2)} \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} Using Bayes' theorem ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:bayes-th}), the conditional probabilities ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-cond}) on the left are given by

\begin{equation} \label{eq:bayes-rule-bayes-th-A1}
p(A_1|B) = \frac{p(B|A_1) \cdot p(A_1)}{p(B)}
\end{equation}

\begin{equation} \label{eq:bayes-rule-bayes-th-A2}
p(A_2|B) = \frac{p(B|A_2) \cdot p(A_2)}{p(B)} \; .
\end{equation}

Dividing the two conditional probabilities by each other

\begin{equation} \label{eq:bayes-rule-bayes-rule-qed}
\begin{split}
\frac{p(A_1|B)}{p(A_2|B)} &= \frac{p(B|A_1) \cdot p(A_1) / p(B)}{p(B|A_2) \cdot p(A_2) / p(B)} \\
&= \frac{p(B|A_1)}{p(B|A_2)} \cdot \frac{p(A_1)}{p(A_2)} \; ,
\end{split}
\end{equation}

one obtains the posterior odds ratio as given by the theorem.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2019): "Bayes' theorem"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-01-06; URL: \url{https://en.wikipedia.org/wiki/Bayes%27_theorem#Bayes%E2%80%99_rule}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P12 | shortcut: bayes-rule | author: JoramSoch | date: 2020-01-06, 20:55.
\vspace{1em}



\subsubsection[\textit{Empirical Bayes}]{Empirical Bayes} \label{sec:eb}
\setcounter{equation}{0}

\textbf{Definition:} Let $m$ be a generative model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) with model parameters $\theta$ and hyper-parameters $\lambda$ implying the likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) $p(y \vert \theta, \lambda, m)$ and prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) $p(\theta \vert \lambda, m)$. Then, an Empirical Bayes treatment of $m$, also referred to as "type II maximum likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mle})" or "evidence ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme}) approximation", consists in

\vspace{1em}
1) evaluating the marginal likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ml}) of the model $m$

\begin{equation} \label{eq:eb-ML}
p(y \vert \lambda, m) = \int p(y \vert \theta, \lambda, m) \, (\theta \vert \lambda, m) \, \mathrm{d}\theta \; ,
\end{equation}

\vspace{1em}
2) maximizing the log model evidence ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme}) with respect to $\lambda$

\begin{equation} \label{eq:eb-EB}
\hat{\lambda} = \operatorname*{arg\,max}_{\lambda} \log p(y \vert \lambda, m)
\end{equation}

\vspace{1em}
3) and using the prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) at this maximum

\begin{equation} \label{eq:eb-prior-eb}
p(\theta \vert m) = p(\theta \vert \hat{\lambda}, m)
\end{equation}

for Bayesian inference ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:bayes-th}), i.e. obtaining the posterior distribution ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:post-jl}) and computing the marginal likelihood ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:ml-jl}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Empirical Bayes method"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-04-29; URL: \url{https://en.wikipedia.org/wiki/Empirical_Bayes_method#Introduction}.
\item Bishop CM (2006): "The Evidence Approximation"; in: \textit{Pattern Recognition for Machine Learning}, ch. 3.5, pp. 165-172; URL: \url{https://www.springer.com/gp/book/9780387310732}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D149 | shortcut: eb | author: JoramSoch | date: 2021-04-29, 06:46.
\vspace{1em}



\subsubsection[\textit{Variational Bayes}]{Variational Bayes} \label{sec:vb}
\setcounter{equation}{0}

\textbf{Definition:} Let $m$ be a generative model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) with model parameters $\theta$ implying the likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) $p(y \vert \theta, m)$ and prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) $p(\theta \vert m)$. Then, a Variational Bayes treatment of $m$, also referred to as "approximate inference" or "variational inference", consists in

\vspace{1em}
1) constructing an approximate posterior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post})

\begin{equation} \label{eq:vb-post-vb}
q(\theta) \approx p(\theta \vert y, m) \; ,
\end{equation}

\vspace{1em}
2) evaluating the variational free energy ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:vblme})

\begin{equation} \label{eq:vb-FE}
F_q(m) = \int q(\theta) \log p(y|\theta,m) \, \mathrm{d}\theta - \int q(\theta) \frac{q(\theta)}{p(\theta|m)} \, \mathrm{d}\theta
\end{equation}

\vspace{1em}
3) and maximizing this function with respect to $q(\theta)$

\begin{equation} \label{eq:vb-VB}
\hat{q}(\theta) = \operatorname*{arg\,max}_{q} F_q(m) \; .
\end{equation}

for Bayesian inference, i.e. obtaining the posterior distribution (from eq. \eqref{eq:vb-VB}) and approximating the marginal likelihood (by plugging eq. \eqref{eq:vb-VB} into eq. \eqref{eq:vb-FE}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Variational Bayesian methods"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-04-29; URL: \url{https://en.wikipedia.org/wiki/Variational_Bayesian_methods#Evidence_lower_bound}.
\item Penny W, Flandin G, Trujillo-Barreto N (2007): "Bayesian Comparison of Spatially Regularised General Linear Models"; in: \textit{Human Brain Mapping}, vol. 28, pp. 275â€“293, eqs. 2-9; URL: \url{https://onlinelibrary.wiley.com/doi/full/10.1002/hbm.20327}; DOI: 10.1002/hbm.20327.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D150 | shortcut: vb | author: JoramSoch | date: 2021-04-29, 07:15.
\vspace{1em}





% Chapter 2 %
\chapter{Probability Distributions} \label{sec:Probability Distributions} \newpage

\pagebreak
\section{Univariate discrete distributions}

\subsection{Discrete uniform distribution}

\subsubsection[\textit{Definition}]{Definition} \label{sec:duni}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a discrete random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}). Then, $X$ is said to be uniformly distributed with minimum $a$ and maximum $b$

\begin{equation} \label{eq:duni-duni}
X \sim \mathcal{U}(a, b) \; ,
\end{equation}

if and only if each integer between and including $a$ and $b$ occurs with the same probability.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Discrete uniform distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-07-28; URL: \url{https://en.wikipedia.org/wiki/Discrete_uniform_distribution}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D88 | shortcut: duni | author: JoramSoch | date: 2020-07-28, 04:05.
\vspace{1em}



\subsubsection[\textbf{Probability mass function}]{Probability mass function} \label{sec:duni-pmf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a discrete uniform distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:duni}):

\begin{equation} \label{eq:duni-pmf-duni}
X \sim \mathcal{U}(a, b) \; .
\end{equation}

Then, the probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) of $X$ is

\begin{equation} \label{eq:duni-pmf-duni-pmf}
f_X(x) = \frac{1}{b-a+1} \quad \text{where} \quad x \in \left\lbrace a, a+1, \ldots, b-1, b \right\rbrace \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} A discrete uniform variable is defined as ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:duni}) having the same probability for each integer between and including $a$ and $b$. The number of integers between and including $a$ and $b$ is

\begin{equation} \label{eq:duni-pmf-n}
n = b - a + 1
\end{equation}

and because the sum across all probabilities ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) is

\begin{equation} \label{eq:duni-pmf-1}
\sum_{x=a}^{b} f_X(x) = 1 \; ,
\end{equation}

we have

\begin{equation} \label{eq:duni-pmf-duni-pmf-qed}
f_X(x) = \frac{1}{n} = \frac{1}{b-a+1} \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P140 | shortcut: duni-pmf | author: JoramSoch | date: 2020-07-28, 04:57.
\vspace{1em}



\subsubsection[\textbf{Cumulative distribution function}]{Cumulative distribution function} \label{sec:duni-cdf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a discrete uniform distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:duni}):

\begin{equation} \label{eq:duni-cdf-duni}
X \sim \mathcal{U}(a, b) \; .
\end{equation}

Then, the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) of $X$ is

\begin{equation} \label{eq:duni-cdf-duni-cdf}
F_X(x) = \left\{
\begin{array}{rl}
0 \; , & \text{if} \; x < a \\
\frac{\left\lfloor{x}\right\rfloor - a + 1}{b - a + 1} \; , & \text{if} \; a \leq x \leq b \\
1 \; , & \text{if} \; x > b \; .
\end{array}
\right.
\end{equation}


\vspace{1em}
\textbf{Proof:} The probability mass function of the discrete uniform distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:duni-pmf}) is

\begin{equation} \label{eq:duni-cdf-duni-pmf}
\mathcal{U}(x; a, b) = \frac{1}{b-a+1} \quad \text{where} \quad x \in \left\lbrace a, a+1, \ldots, b-1, b \right\rbrace \; .
\end{equation}

Thus, the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) is:

\begin{equation} \label{eq:duni-cdf-duni-cdf-s1}
F_X(x) = \int_{-\infty}^{x} \mathcal{U}(z; a, b) \, \mathrm{d}z
\end{equation}

From \eqref{eq:duni-cdf-duni-pmf}, it follows that the cumulative probability increases step-wise by $1/n$ at each integer between and including $a$ and $b$ where

\begin{equation} \label{eq:duni-cdf-n}
n = b - a + 1
\end{equation}

is the number of integers between and including $a$ and $b$. This can be expressed by noting that

\begin{equation} \label{eq:duni-cdf-duni-cdf-s2b}
F_X(x) \overset{\eqref{eq:duni-cdf-duni-pmf}}{=} \frac{\left\lfloor{x}\right\rfloor - a + 1}{n}, \; \text{if} \; a \leq x \leq b \; .
\end{equation}

Also, because $\mathrm{Pr}(X < a) = 0$, we have

\begin{equation} \label{eq:duni-cdf-duni-cdf-s2a}
F_X(x) \overset{\eqref{eq:duni-cdf-duni-cdf-s1}}{=} \int_{-\infty}^{x} 0 \, \mathrm{d}z = 0, \; \text{if} \; x < a
\end{equation}

and because $\mathrm{Pr}(X > b) = 0$, we have

\begin{equation} \label{eq:duni-cdf-duni-cdf-s2c}
\begin{split}
F_X(x) &\overset{\eqref{eq:duni-cdf-duni-cdf-s1}}{=} \int_{-\infty}^{x} \mathcal{U}(z; a, b) \, \mathrm{d}z \\
&= \int_{-\infty}^{b} \mathcal{U}(z; a, b) \, \mathrm{d}z + \int_{b}^{x} \mathcal{U}(z; a, b) \, \mathrm{d}z \\
&= F_X(b) + \int_{b}^{x} 0 \, \mathrm{d}z \overset{\eqref{eq:duni-cdf-duni-cdf-s2b}}{=} 1 + 0 \\
&= 1, \; \text{if} \; x > b \; .
\end{split}
\end{equation}

This completes the proof.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P141 | shortcut: duni-cdf | author: JoramSoch | date: 2020-07-28, 05:34.
\vspace{1em}



\subsubsection[\textbf{Quantile function}]{Quantile function} \label{sec:duni-qf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a discrete uniform distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:duni}):

\begin{equation} \label{eq:duni-qf-duni}
X \sim \mathcal{U}(a, b) \; .
\end{equation}

Then, the quantile function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:qf}) of $X$ is

\begin{equation} \label{eq:duni-qf-duni-qf}
Q_X(p) = \left\{
\begin{array}{rl}
-\infty \; , & \text{if} \; p = 0 \\
a (1-p) + (b+1) p - 1 \; , & \text{when} \; p \in \left\lbrace \frac{1}{n}, \frac{2}{n}, \ldots, \frac{b-a}{n}, 1 \right\rbrace \; .
\end{array}
\right.
\end{equation}

with $n = b - a + 1$.


\vspace{1em}
\textbf{Proof:} The cumulative distribution function of the discrete uniform distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:duni-cdf}) is:

\begin{equation} \label{eq:duni-qf-duni-cdf}
F_X(x) = \left\{
\begin{array}{rl}
0 \; , & \text{if} \; x < a \\
\frac{\left\lfloor{x}\right\rfloor - a + 1}{b - a + 1} \; , & \text{if} \; a \leq x \leq b \\
1 \; , & \text{if} \; x > b \; .
\end{array}
\right.
\end{equation}

The quantile function $Q_X(p)$ is defined as ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:qf}) the smallest $x$, such that $F_X(x) = p$:

\begin{equation} \label{eq:duni-qf-qf}
Q_X(p) = \min \left\lbrace x \in \mathbb{R} \, \vert \, F_X(x) = p \right\rbrace \; .
\end{equation}

Because the CDF only returns ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:duni-cdf}) multiples of $1/n$ with $n = b - a + 1$, the quantile function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:qf}) is only defined for such values. First, we have $Q_X(p) = -\infty$, if $p = 0$. Second, since the cumulative probability increases step-wise ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:duni-cdf}) by $1/n$ at each integer between and including $a$ and $b$, the minimum $x$ at which

\begin{equation} \label{eq:duni-qf-duni-cdf-p}
F_X(x) = \frac{c}{n} \quad \text{where} \quad c \in \left\lbrace 1, \ldots, n \right\rbrace
\end{equation}

is given by

\begin{equation} \label{eq:duni-qf-duni-qf-p}
Q_X\left( \frac{c}{n} \right) = a + \frac{c}{n} \cdot n - 1 \; .
\end{equation}

Substituting $p = c/n$ and $n = b - a + 1$, we can finally show:

\begin{equation} \label{eq:duni-qf-duni-qf-qed}
\begin{split}
Q_X(p) &= a + p \cdot (b-a+1) - 1 \\
&= a + pb - pa + p - 1 \\
&= a (1-p) + (b+1) p - 1 \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P142 | shortcut: duni-qf | author: JoramSoch | date: 2020-07-28, 06:17.
\vspace{1em}



\subsection{Bernoulli distribution}

\subsubsection[\textit{Definition}]{Definition} \label{sec:bern}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}). Then, $X$ is said to follow a Bernoulli distribution with success probability $p$

\begin{equation} \label{eq:bern-bern}
X \sim \mathrm{Bern}(p) \; ,
\end{equation}

if $X = 1$ with probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob}) $p$ and $X = 0$ with probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob}) $q = 1-p$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Bernoulli distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-03-22; URL: \url{https://en.wikipedia.org/wiki/Bernoulli_distribution}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D44 | shortcut: bern | author: JoramSoch | date: 2020-03-22, 17:40.
\vspace{1em}



\subsubsection[\textbf{Probability mass function}]{Probability mass function} \label{sec:bern-pmf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a Bernoulli distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:bern}):

\begin{equation} \label{eq:bern-pmf-Bern}
X \sim \mathrm{Bern}(p) \; .
\end{equation}

Then, the probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) of $X$ is

\begin{equation} \label{eq:bern-pmf-Bern-pmf}
f_X(x) = \left\{
\begin{array}{rl}
p \; , & \text{if} \; x = 1 \\
1-p \; , & \text{if} \; x = 0 \; . \\
\end{array}
\right. \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} This follows directly from the definition of the Bernoulli distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:bern}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P96 | shortcut: bern-pmf | author: JoramSoch | date: 2020-05-11, 22:10.
\vspace{1em}



\subsubsection[\textbf{Mean}]{Mean} \label{sec:bern-mean}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a Bernoulli distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:bern}):

\begin{equation} \label{eq:bern-mean-bern}
X \sim \mathrm{Bern}(p) \; .
\end{equation}

Then, the mean or expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of $X$ is

\begin{equation} \label{eq:bern-mean-bern-mean}
\mathrm{E}(X) = p \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) is the probability-weighted average of all possible values:

\begin{equation} \label{eq:bern-mean-mean}
\mathrm{E}(X) = \sum_{x \in \mathcal{X}} x \cdot \mathrm{Pr}(X = x) \; .
\end{equation}

Since there are only two possible outcomes for a Bernoulli random variable ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:bern-pmf}), we have:

\begin{equation} \label{eq:bern-mean-bern-mean-qed}
\begin{split}
\mathrm{E}(X) &= 0 \cdot \mathrm{Pr}(X = 0) + 1 \cdot \mathrm{Pr}(X = 1) \\
&= 0 \cdot (1-p) + 1 \cdot p \\
&= p \; . \\
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Bernoulli distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-01-16; URL: \url{https://en.wikipedia.org/wiki/Bernoulli_distribution#Mean}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P22 | shortcut: bern-mean | author: JoramSoch | date: 2020-01-16, 10:58.
\vspace{1em}



\subsection{Binomial distribution}

\subsubsection[\textit{Definition}]{Definition} \label{sec:bin}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}). Then, $X$ is said to follow a binomial distribution with number of trials $n$ and success probability $p$

\begin{equation} \label{eq:bin-bin}
X \sim \mathrm{Bin}(n, p) \; ,
\end{equation}

if $X$ is the number of successes observed in $n$ independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}) trials, where each trial has two possible outcomes ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:bern}) (success/failure) and the probability of success and failure are identical across trials ($p$/$q = 1-p$).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Binomial distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-03-22; URL: \url{https://en.wikipedia.org/wiki/Binomial_distribution}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D45 | shortcut: bin | author: JoramSoch | date: 2020-03-22, 17:52.
\vspace{1em}



\subsubsection[\textbf{Probability mass function}]{Probability mass function} \label{sec:bin-pmf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a binomial distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:bin}):

\begin{equation} \label{eq:bin-pmf-bin}
X \sim \mathrm{Bin}(n,p) \; .
\end{equation}

Then, the probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) of $X$ is

\begin{equation} \label{eq:bin-pmf-bin-pmf}
f_X(x) = {n \choose x} \, p^x \, (1-p)^{n-x} \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} A binomial variable is defined as ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:bin}) the number of successes observed in $n$ independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}) trials, where each trial has two possible outcomes ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:bern}) (success/failure) and the probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob}) of success and failure are identical across trials ($p$/$q = 1-p$).

If one has obtained $x$ successes in $n$ trials, one has also obtained $(n-x)$ failures. The probability of a particular series of $x$ successes and $(n-x)$ failures, when order does matter, is

\begin{equation} \label{eq:bin-pmf-bin-prob}
p^x \, (1-p)^{n-x} \; .
\end{equation}

When order does not matter, there is a number of series consisting of $x$ successes and $(n-x)$ failures. This number is equal to the number of possibilities in which $x$ objects can be choosen from $n$ objects which is given by the binomial coefficient:

\begin{equation} \label{eq:bin-pmf-bin-coeff}
{n \choose x} \; .
\end{equation}

In order to obtain the probability of $x$ successes and $(n-x)$ failures, when order does not matter, the probability in \eqref{eq:bin-pmf-bin-prob} has to be multiplied with the number of possibilities in \eqref{eq:bin-pmf-bin-coeff} which gives

\begin{equation} \label{eq:bin-pmf-bin-pmf-qed}
p(X=x|n,p) = {n \choose x} \, p^x \, (1-p)^{n-x}
\end{equation}

which is equivalent to the expression above.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P97 | shortcut: bin-pmf | author: JoramSoch | date: 2020-05-11, 22:35.
\vspace{1em}



\subsubsection[\textbf{Mean}]{Mean} \label{sec:bin-mean}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a binomial distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:bin}):

\begin{equation} \label{eq:bin-mean-bin}
X \sim \mathrm{Bin}(n,p) \; .
\end{equation}

Then, the mean or expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of $X$ is

\begin{equation} \label{eq:bin-mean-bin-mean}
\mathrm{E}(X) = n p \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} By definition, a binomial random variable ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:bin}) is the sum of $n$ independent and identical Bernoulli trials ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:bern}) with success probability $p$. Therefore, the expected value is

\begin{equation} \label{eq:bin-mean-bin-mean-s1}
\mathrm{E}(X) = \mathrm{E}(X_1 + \ldots + X_n)
\end{equation}

and because the expected value is a linear operator ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-lin}), this is equal to

\begin{equation} \label{eq:bin-mean-bin-mean-s2}
\begin{split}
\mathrm{E}(X) &= \mathrm{E}(X_1) + \ldots + \mathrm{E}(X_n) \\
&= \sum_{i=1}^{n} \mathrm{E}(X_i) \; .
\end{split}
\end{equation}

With the expected value of the Bernoulli distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:bern-mean}), we have:

\begin{equation} \label{eq:bin-mean-bin-mean-s3}
\mathrm{E}(X) = \sum_{i=1}^{n} p = n p \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Binomial distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-01-16; URL: \url{https://en.wikipedia.org/wiki/Binomial_distribution#Expected_value_and_variance}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P23 | shortcut: bin-mean | author: JoramSoch | date: 2020-01-16, 11:06.
\vspace{1em}



\subsection{Poisson distribution}

\subsubsection[\textit{Definition}]{Definition} \label{sec:poiss}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}). Then, $X$ is said to follow a Poisson distribution with rate $\lambda$

\begin{equation} \label{eq:poiss-poiss}
X \sim \mathrm{Poiss}(\lambda) \; ,
\end{equation}

if and only if its probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) is given by

\begin{equation} \label{eq:poiss-poiss-pmf}
\mathrm{Poiss}(x; \lambda) = \frac{\lambda^x \, e^{-\lambda}}{x!}
\end{equation}

where $x \in \mathbb{N}_0$ and $\lambda > 0$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Poisson distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-05-25; URL: \url{https://en.wikipedia.org/wiki/Poisson_distribution#Definitions}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D62 | shortcut: poiss | author: JoramSoch | date: 2020-05-25, 23:34.
\vspace{1em}



\subsubsection[\textbf{Probability mass function}]{Probability mass function} \label{sec:poiss-pmf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a Poisson distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:poiss}):

\begin{equation} \label{eq:poiss-pmf-Poiss}
X \sim \mathrm{Poiss}(\lambda) \; .
\end{equation}

Then, the probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) of $X$ is

\begin{equation} \label{eq:poiss-pmf-Poiss-pmf}
f_X(x) = \frac{\lambda^x \, e^{-\lambda}}{x!}, \; x \in \mathbb{N}_0 \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} This follows directly from the definition of the Poisson distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:poiss}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P102 | shortcut: poiss-pmf | author: JoramSoch | date: 2020-05-14, 20:39.
\vspace{1em}



\subsubsection[\textbf{Mean}]{Mean} \label{sec:poiss-mean}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a Poisson distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:poiss}):

\begin{equation} \label{eq:poiss-mean-poiss}
X \sim \mathrm{Poiss}(\lambda) \; .
\end{equation}

Then, the mean or expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of $X$ is

\begin{equation} \label{eq:poiss-mean-poiss-mean}
\mathrm{E}(X) = \lambda \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The expected value of a discrete random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) is defined as

\begin{equation} \label{eq:poiss-mean-mean}
\mathrm{E}(X) = \sum_{x \in \mathcal{X}} x \cdot f_X(x) \; ,
\end{equation}

such that, with the probability mass function of the Poisson distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:poiss-pmf}), we have:

\begin{equation} \label{eq:poiss-mean-poiss-mean-s1}
\begin{split}
\mathrm{E}(X) &= \sum_{x=0}^\infty x \cdot \frac{\lambda^x \, e^{-\lambda}}{x!} \\
&= \sum_{x=1}^\infty x \cdot \frac{\lambda^x \, e^{-\lambda}}{x!} \\
&= e^{-\lambda} \cdot \sum_{x=1}^\infty \frac{x}{x!} \lambda^x \\
&= \lambda e^{-\lambda} \cdot \sum_{x=1}^\infty \frac{\lambda^{x-1}}{(x-1)!} \; .
\end{split}
\end{equation}

Substituting $z = x-1$, such that $x = z+1$, we get:

\begin{equation} \label{eq:poiss-mean-poiss-mean-s2}
\mathrm{E}(X) = \lambda e^{-\lambda} \cdot \sum_{z=0}^\infty \frac{\lambda^z}{z!} \; .
\end{equation}

Using the power series expansion of the exponential function

\begin{equation} \label{eq:poiss-mean-exp-ps}
e^x = \sum_{n=0}^\infty \frac{x^n}{n!} \; ,
\end{equation}

the expected value of $X$ finally becomes

\begin{equation} \label{eq:poiss-mean-poiss-mean-s3}
\begin{split}
\mathrm{E}(X) &= \lambda e^{-\lambda} \cdot e^{\lambda} \\
&= \lambda \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item ProofWiki (2020): "Expectation of Poisson Distribution"; in: \textit{ProofWiki}, retrieved on 2020-08-19; URL: \url{https://proofwiki.org/wiki/Expectation_of_Poisson_Distribution}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P151 | shortcut: poiss-mean | author: JoramSoch | date: 2020-08-19, 06:09.
\vspace{1em}



\subsubsection[\textbf{Variance}]{Variance} \label{sec:poiss-var}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a Poisson distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:poiss}):

\begin{equation} \label{eq:poiss-var-poiss}
X \sim \mathrm{Poiss}(\lambda) \; .
\end{equation}

Then, the variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) of $X$ is

\begin{equation} \label{eq:poiss-var-poiss-var}
\mathrm{Var}(X) = \lambda \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) can be expressed in terms of expected values ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:var-mean}) as

\begin{equation} \label{eq:poiss-var-var-mean}
\mathrm{Var}(X) = \mathrm{E}(X^2) - \mathrm{E}(X)^2 \; .
\end{equation}

The expected value of a Poisson random variable ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:poiss-mean}) is

\begin{equation} \label{eq:poiss-var-poiss-mean}
\mathrm{E}(X) = \lambda \; .
\end{equation}

Let us now consider the expectation ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of $X \, (X-1)$ which is defined as

\begin{equation} \label{eq:poiss-var-mean}
\mathrm{E}[X \, (X-1)] = \sum_{x \in \mathcal{X}} x \, (x-1) \cdot f_X(x) \; ,
\end{equation}

such that, with the probability mass function of the Poisson distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:poiss-pmf}), we have:

\begin{equation} \label{eq:poiss-var-poiss-x2x-mean-s1}
\begin{split}
\mathrm{E}[X \, (X-1)] &= \sum_{x=0}^\infty x \, (x-1) \cdot \frac{\lambda^x \, e^{-\lambda}}{x!} \\
&= \sum_{x=2}^\infty x \, (x-1) \cdot \frac{\lambda^x \, e^{-\lambda}}{x!} \\
&= e^{-\lambda} \cdot \sum_{x=2}^\infty x \, (x-1) \cdot \frac{\lambda^x}{x \cdot (x-1) \cdot (x-2)!} \\
&= \lambda^2 \cdot e^{-\lambda} \cdot \sum_{x=2}^\infty \frac{\lambda^{x-2}}{(x-2)!} \; .
\end{split}
\end{equation}

Substituting $z = x-2$, such that $x = z+2$, we get:

\begin{equation} \label{eq:poiss-var-poiss-x2x-mean-s2}
\mathrm{E}[X \, (X-1)] = \lambda^2 \cdot e^{-\lambda} \cdot \sum_{z=0}^\infty \frac{\lambda^z}{z!} \; .
\end{equation}

Using the power series expansion of the exponential function

\begin{equation} \label{eq:poiss-var-exp-ps}
e^x = \sum_{n=0}^\infty \frac{x^n}{n!} \; ,
\end{equation}

the expected value of $X \, (X-1)$ finally becomes

\begin{equation} \label{eq:poiss-var-poiss-x2x-mean-s3}
\mathrm{E}[X \, (X-1)] = \lambda^2 \cdot e^{-\lambda} \cdot e^{\lambda} = \lambda^2 \; .
\end{equation}

Note that this expectation can be written as

\begin{equation} \label{eq:poiss-var-poiss-x2-mean-s1}
\mathrm{E}[X \, (X-1)] = \mathrm{E}(X^2 - X) = \mathrm{E}(X^2) - \mathrm{E}(X) \; ,
\end{equation}

such that, with \eqref{eq:poiss-var-poiss-x2x-mean-s3} and \eqref{eq:poiss-var-poiss-mean}, we have:

\begin{equation} \label{eq:poiss-var-poiss-x2-mean-s2}
\mathrm{E}(X^2) - \mathrm{E}(X) = \lambda^2 \quad \Rightarrow \quad \mathrm{E}(X^2) = \lambda^2 + \lambda \; .
\end{equation}

Plugging \eqref{eq:poiss-var-poiss-x2-mean-s2} and \eqref{eq:poiss-var-poiss-mean} into \eqref{eq:poiss-var-var-mean}, the variance of a Poisson random variable finally becomes

\begin{equation} \label{eq:poiss-var-poiss-var-qed}
\mathrm{Var}(X) = \lambda^2 + \lambda - \lambda^2 = \lambda \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item jbstatistics (2013): "The Poisson Distribution: Mathematically Deriving the Mean and Variance"; in: \textit{YouTube}, retrieved on 2021-04-29; URL: \url{https://www.youtube.com/watch?v=65n_v92JZeE}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P230 | shortcut: poiss-var | author: JoramSoch | date: 2021-04-29, 09:59.
\vspace{1em}



\pagebreak
\section{Multivariate discrete distributions}

\subsection{Categorical distribution}

\subsubsection[\textit{Definition}]{Definition} \label{sec:cat}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}). Then, $X$ is said to follow a categorical distribution with success probability $p_1, \ldots, p_k$

\begin{equation} \label{eq:cat-cat}
X \sim \mathrm{Cat}(\left[p_1, \ldots, p_k \right]) \; ,
\end{equation}

if $X = e_i$ with probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob}) $p_i$ for all $i = 1, \ldots, k$, where $e_i$ is the $i$-th elementary row vector, i.e. a $1 \times k$ vector of zeros with a one in $i$-th position.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Categorical distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-03-22; URL: \url{https://en.wikipedia.org/wiki/Categorical_distribution}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D46 | shortcut: cat | author: JoramSoch | date: 2020-03-22, 18:09.
\vspace{1em}



\subsubsection[\textbf{Probability mass function}]{Probability mass function} \label{sec:cat-pmf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}) following a categorical distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:cat}):

\begin{equation} \label{eq:cat-pmf-cat}
X \sim \mathrm{Cat}(\left[p_1, \ldots, p_k \right]) \; .
\end{equation}

Then, the probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) of $X$ is

\begin{equation} \label{eq:cat-pmf-cat-pmf}
f_X(x) = \left\{
\begin{array}{rl}
p_1 \; , & \text{if} \; x = e_1 \\
\vdots \; \hphantom{,} & \quad \vdots \\
p_k \; , & \text{if} \; x = e_k \; . \\
\end{array}
\right.
\end{equation}

where $e_1, \ldots, e_k$ are the $1 \times k$ elementary row vectors.


\vspace{1em}
\textbf{Proof:} This follows directly from the definition of the categorical distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:cat}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P98 | shortcut: cat-pmf | author: JoramSoch | date: 2020-05-11, 22:58.
\vspace{1em}



\subsubsection[\textbf{Mean}]{Mean} \label{sec:cat-mean}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}) following a categorical distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:cat}):

\begin{equation} \label{eq:cat-mean-cat}
X \sim \mathrm{Cat}(\left[p_1, \ldots, p_k \right]) \; .
\end{equation}

Then, the mean or expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of $X$ is

\begin{equation} \label{eq:cat-mean-cat-mean}
\mathrm{E}(X) = \left[p_1, \ldots, p_k \right] \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} If we conceive the outcome of a categorical distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:cat}) to be a $1 \times k$ vector, then the elementary row vectors $e_1 = \left[1, 0, \ldots, 0 \right]$, ..., $e_k = \left[0, \ldots, 0, 1 \right]$ are all the possible outcomes and they occur with probabilities $\mathrm{Pr}(X = e_1) = p_1$, ..., $\mathrm{Pr}(X = e_k) = p_k$. Consequently, the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) is

\begin{equation} \label{eq:cat-mean-cat-mean-qed}
\begin{split}
\mathrm{E}(X) &= \sum_{x \in \mathcal{X}} x \cdot \mathrm{Pr}(X = x) \\
&= \sum_{i=1}^k e_i \cdot \mathrm{Pr}(X = e_i) \\
&= \sum_{i=1}^k e_i \cdot p_i \\
&= \left[p_1, \ldots, p_k \right] \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P24 | shortcut: cat-mean | author: JoramSoch | date: 2020-01-16, 11:17.
\vspace{1em}



\subsection{Multinomial distribution}

\subsubsection[\textit{Definition}]{Definition} \label{sec:mult}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}). Then, $X$ is said to follow a multinomial distribution with number of trials $n$ and category probabilities $p_1, \ldots, p_k$

\begin{equation} \label{eq:mult-mult}
X \sim \mathrm{Mult}(n, \left[p_1, \ldots, p_k \right]) \; ,
\end{equation}

if $X$ are the numbers of observations belonging to $k$ distinct categories in $n$ independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}) trials, where each trial has $k$ possible outcomes ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:cat}) and the category probabilities are identical across trials.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Binomial distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-03-22; URL: \url{https://en.wikipedia.org/wiki/Multinomial_distribution}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D47 | shortcut: mult | author: JoramSoch | date: 2020-03-22, 17:52.
\vspace{1em}



\subsubsection[\textbf{Probability mass function}]{Probability mass function} \label{sec:mult-pmf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}) following a multinomial distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mult}):

\begin{equation} \label{eq:mult-pmf-mult}
X \sim \mathrm{Mult}(n, \left[p_1, \ldots, p_k \right]) \; .
\end{equation}

Then, the probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) of $X$ is

\begin{equation} \label{eq:mult-pmf-mult-pmf}
f_X(x) = {n \choose {x_1, \ldots, x_k}} \, \prod_{i=1}^k {p_i}^{x_i} \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} A multinomial variable is defined as ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mult}) a vector of the numbers of observations belonging to $k$ distinct categories in $n$ independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}) trials, where each trial has $k$ possible outcomes ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:cat}) and the category probabilities ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob}) are identical across trials.

The probability of a particular series of $x_1$ observations for category $1$, $x_2$ observations for category $2$ etc., when order does matter, is

\begin{equation} \label{eq:mult-pmf-mult-prob}
\prod_{i=1}^k {p_i}^{x_i} \; .
\end{equation}

When order does not matter, there is a number of series consisting of $x_1$ observations for category $1$, ..., $x_k$ observations for category $k$. This number is equal to the number of possibilities in which $x_1$ category $1$ objects, ..., $x_k$ category $k$ objects can be distributed in a sequence of $n$ objects which is given by the multinomial coefficient that can be expressed in terms of factorials:

\begin{equation} \label{eq:mult-pmf-mult-coeff}
{n \choose {x_1, \ldots, x_k}} = \frac{n!}{x_1! \cdot \ldots \cdot x_k!} \; .
\end{equation}

In order to obtain the probability of $x_1$ observations for category $1$, ..., $x_k$ observations for category $k$, when order does not matter, the probability in \eqref{eq:mult-pmf-mult-prob} has to be multiplied with the number of possibilities in \eqref{eq:mult-pmf-mult-coeff} which gives

\begin{equation} \label{eq:mult-pmf-mult-pmf-qed}
p(X=x|n,\left[p_1, \ldots, p_k \right]) = {n \choose {x_1, \ldots, x_k}} \, \prod_{i=1}^k {p_i}^{x_i}
\end{equation}

which is equivalent to the expression above.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P99 | shortcut: mult-pmf | author: JoramSoch | date: 2020-05-11, 23:30.
\vspace{1em}



\subsubsection[\textbf{Mean}]{Mean} \label{sec:mult-mean}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}) following a multinomial distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mult}):

\begin{equation} \label{eq:mult-mean-mult}
X \sim \mathrm{Mult}(n,\left[p_1, \ldots, p_k \right]) \; .
\end{equation}

Then, the mean or expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of $X$ is

\begin{equation} \label{eq:mult-mean-bin-mean}
\mathrm{E}(X) = \left[n p_1, \ldots, n p_k \right] \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} By definition, a multinomial random variable ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mult}) is the sum of $n$ independent and identical categorical trials ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:cat}) with category probabilities $p_1, \ldots, p_k$. Therefore, the expected value is

\begin{equation} \label{eq:mult-mean-mult-mean-s1}
\mathrm{E}(X) = \mathrm{E}(X_1 + \ldots + X_n)
\end{equation}

and because the expected value is a linear operator ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-lin}), this is equal to

\begin{equation} \label{eq:mult-mean-mult-mean-s2}
\begin{split}
\mathrm{E}(X) &= \mathrm{E}(X_1) + \ldots + \mathrm{E}(X_n) \\
&= \sum_{i=1}^{n} \mathrm{E}(X_i) \; .
\end{split}
\end{equation}

With the expected value of the categorical distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:cat-mean}), we have:

\begin{equation} \label{eq:mult-mean-mult-mean-s3}
\mathrm{E}(X) = \sum_{i=1}^{n} \left[p_1, \ldots, p_k \right] = n \cdot \left[p_1, \ldots, p_k \right] = \left[n p_1, \ldots, n p_k \right] \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P25 | shortcut: mult-mean | author: JoramSoch | date: 2020-01-16, 11:26.
\vspace{1em}



\pagebreak
\section{Univariate continuous distributions}

\subsection{Continuous uniform distribution}

\subsubsection[\textit{Definition}]{Definition} \label{sec:cuni}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a continuous random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}). Then, $X$ is said to be uniformly distributed with minimum $a$ and maximum $b$

\begin{equation} \label{eq:cuni-cuni}
X \sim \mathcal{U}(a, b) \; ,
\end{equation}

if and only if each value between and including $a$ and $b$ occurs with the same probability.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Uniform distribution (continuous)"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-01-27; URL: \url{https://en.wikipedia.org/wiki/Uniform_distribution_(continuous)}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D3 | shortcut: cuni | author: JoramSoch | date: 2020-01-27, 14:05.
\vspace{1em}



\subsubsection[\textit{Standard uniform distribution}]{Standard uniform distribution} \label{sec:suni}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}). Then, $X$ is said to be standard uniformly distributed, if $X$ follows a continuous uniform distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:cuni}) with minimum $a = 0$ and maximum $b = 1$:

\begin{equation} \label{eq:suni-suni}
X \sim \mathcal{U}(0, 1) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Continuous uniform distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-07-23; URL: \url{https://en.wikipedia.org/wiki/Continuous_uniform_distribution#Standard_uniform}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D157 | shortcut: suni | author: JoramSoch | date: 2021-07-23, 17:32.
\vspace{1em}



\subsubsection[\textbf{Probability density function}]{Probability density function} \label{sec:cuni-pdf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a continuous uniform distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:cuni}):

\begin{equation} \label{eq:cuni-pdf-cuni}
X \sim \mathcal{U}(a, b) \; .
\end{equation}

Then, the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $X$ is

\begin{equation} \label{eq:cuni-pdf-cuni-pdf}
f_X(x) = \left\{
\begin{array}{rl}
\frac{1}{b-a} \; , & \text{if} \; a \leq x \leq b \\
0 \; , & \text{otherwise} \; .
\end{array}
\right.
\end{equation}


\vspace{1em}
\textbf{Proof:} A continuous uniform variable is defined as ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:cuni}) having a constant probability density between minimum $a$ and maximum $b$. Therefore,

\begin{equation} \label{eq:cuni-pdf-cuni-pdf-s1}
\begin{split}
f_X(x) &\propto 1 \quad \text{for all} \quad x \in [a,b] \quad \text{and} \\
f_X(x) &= 0, \quad\!\! \text{if} \quad x < a \quad \text{or} \quad x > b \; .
\end{split}
\end{equation}

To ensure that $f_X(x)$ is a proper probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}), the integral over all non-zero probabilities has to sum to $1$. Therefore,

\begin{equation} \label{eq:cuni-pdf-cuni-pdf-s2}
f_X(x) = \frac{1}{c(a,b)} \quad \text{for all} \quad x \in [a,b]
\end{equation}

where the normalization factor $c(a,b)$ is specified, such that

\begin{equation} \label{eq:cuni-pdf-cuni-pdf-s3}
\frac{1}{c(a,b)} \int_{a}^{b} 1 \, \mathrm{d}x = 1 \; .
\end{equation}

Solving this for $c(a,b)$, we obtain:

\begin{equation} \label{eq:cuni-pdf-cuni-pdf-s4}
\begin{split}
\int_{a}^{b} 1 \, \mathrm{d}x &= c(a,b) \\
[x]_a^b &= c(a,b) \\
c(a,b) &= b-a \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P37 | shortcut: cuni-pdf | author: JoramSoch | date: 2020-01-31, 15:41.
\vspace{1em}



\subsubsection[\textbf{Cumulative distribution function}]{Cumulative distribution function} \label{sec:cuni-cdf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a continuous uniform distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:cuni}):

\begin{equation} \label{eq:cuni-cdf-cuni}
X \sim \mathcal{U}(a, b) \; .
\end{equation}

Then, the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) of $X$ is

\begin{equation} \label{eq:cuni-cdf-cuni-cdf}
F_X(x) = \left\{
\begin{array}{rl}
0 \; , & \text{if} \; x < a \\
\frac{x-a}{b-a} \; , & \text{if} \; a \leq x \leq b \\
1 \; , & \text{if} \; x > b \; .
\end{array}
\right.
\end{equation}


\vspace{1em}
\textbf{Proof:} The probability density function of the continuous uniform distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:cuni-pdf}) is:

\begin{equation} \label{eq:cuni-cdf-cuni-pdf}
\mathcal{U}(x; a, b) = \left\{
\begin{array}{rl}
\frac{1}{b-a} \; , & \text{if} \; a \leq x \leq b \\
0 \; , & \text{otherwise} \; .
\end{array}
\right.
\end{equation}

Thus, the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) is:

\begin{equation} \label{eq:cuni-cdf-cuni-cdf-s1}
F_X(x) = \int_{-\infty}^{x} \mathcal{U}(z; a, b) \, \mathrm{d}z
\end{equation}

First of all, if $x < a$, we have

\begin{equation} \label{eq:cuni-cdf-cuni-cdf-s2a}
F_X(x) = \int_{-\infty}^{x} 0 \, \mathrm{d}z = 0 \; .
\end{equation}

Moreover, if $a \leq x \leq b$, we have using \eqref{eq:cuni-cdf-cuni-pdf}

\begin{equation} \label{eq:cuni-cdf-cuni-cdf-s2b}
\begin{split}
F_X(x) &= \int_{-\infty}^{a} \mathcal{U}(z; a, b) \, \mathrm{d}z + \int_{a}^{x} \mathcal{U}(z; a, b) \, \mathrm{d}z \\
&= \int_{-\infty}^{a} 0 \, \mathrm{d}z + \int_{a}^{x} \frac{1}{b-a} \, \mathrm{d}z \\
&= 0 + \frac{1}{b-a} [z]_a^x \\
&= \frac{x-a}{b-a} \; .
\end{split}
\end{equation}

Finally, if $x > b$, we have

\begin{equation} \label{eq:cuni-cdf-cuni-cdf-s2c}
\begin{split}
F_X(x) &= \int_{-\infty}^{b} \mathcal{U}(z; a, b) \, \mathrm{d}z + \int_{b}^{x} \mathcal{U}(z; a, b) \, \mathrm{d}z \\
&= F_X(b) + \int_{b}^{x} 0 \, \mathrm{d}z \\
&= \frac{b-a}{b-a} + 0 \\
&= 1 \; .
\end{split}
\end{equation}

This completes the proof.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P38 | shortcut: cuni-cdf | author: JoramSoch | date: 2020-01-02, 18:05.
\vspace{1em}



\subsubsection[\textbf{Quantile function}]{Quantile function} \label{sec:cuni-qf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a continuous uniform distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:cuni}):

\begin{equation} \label{eq:cuni-qf-cuni}
X \sim \mathcal{U}(a, b) \; .
\end{equation}

Then, the quantile function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:qf}) of $X$ is

\begin{equation} \label{eq:cuni-qf-cuni-qf}
Q_X(p) = \left\{
\begin{array}{rl}
-\infty \; , & \text{if} \; p = 0 \\
bp + a(1-p) \; , & \text{if} \; p > 0 \; .
\end{array}
\right.
\end{equation}


\vspace{1em}
\textbf{Proof:} The cumulative distribution function of the continuous uniform distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:cuni-cdf}) is:

\begin{equation} \label{eq:cuni-qf-cuni-cdf}
F_X(x) = \left\{
\begin{array}{rl}
0 \; , & \text{if} \; x < a \\
\frac{x-a}{b-a} \; , & \text{if} \; a \leq x \leq b \\
1 \; , & \text{if} \; x > b \; .
\end{array}
\right.
\end{equation}

The quantile function $Q_X(p)$ is defined as ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:qf}) the smallest $x$, such that $F_X(x) = p$:

\begin{equation} \label{eq:cuni-qf-qf}
Q_X(p) = \min \left\lbrace x \in \mathbb{R} \, \vert \, F_X(x) = p \right\rbrace \; .
\end{equation}

Thus, we have $Q_X(p) = -\infty$, if $p = 0$. When $p > 0$, it holds that ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:qf-cdf})

\begin{equation} \label{eq:cuni-qf-exp-qf-s1}
Q_X(p) = F_X^{-1}(x) \; .
\end{equation}

This can be derived by rearranging equation \eqref{eq:cuni-qf-cuni-cdf}:

\begin{equation} \label{eq:cuni-qf-cuni-cdf-s2}
\begin{split}
p &= \frac{x-a}{b-a} \\
x &= p(b-a) + a \\
x &= bp + a(1-p) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P39 | shortcut: cuni-qf | author: JoramSoch | date: 2020-01-02, 18:27.
\vspace{1em}



\subsubsection[\textbf{Mean}]{Mean} \label{sec:cuni-mean}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a continuous uniform distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:cuni}):

\begin{equation} \label{eq:cuni-mean-cuni}
X \sim \mathcal{U}(a, b) \; .
\end{equation}

Then, the mean or expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of $X$ is

\begin{equation} \label{eq:cuni-mean-cuni-mean}
\mathrm{E}(X) = \frac{1}{2} (a+b) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) is the probability-weighted average over all possible values:

\begin{equation} \label{eq:cuni-mean-mean}
\mathrm{E}(X) = \int_{\mathcal{X}} x \cdot f_X(x) \, \mathrm{d}x \; .
\end{equation}

With the probability density function of the continuous uniform distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:cuni-pdf}), this becomes:

\begin{equation} \label{eq:cuni-mean-cuni-mean-qed}
\begin{split}
\mathrm{E}(X) &= \int_a^b x \cdot \frac{1}{b-a} \, \mathrm{d}x \\
&= \left[ \frac{1}{2} \, \frac{x^2}{b-a} \right]_a^b \\
&= \frac{1}{2} \, \frac{b^2 - a^2}{b-a} \\
&= \frac{1}{2} \, \frac{(b+a)(b-a)}{b-a} \\
&= \frac{1}{2} (a+b) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P82 | shortcut: cuni-mean | author: JoramSoch | date: 2020-03-16, 16:12.
\vspace{1em}



\subsubsection[\textbf{Median}]{Median} \label{sec:cuni-med}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a continuous uniform distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:cuni}):

\begin{equation} \label{eq:cuni-med-cuni}
X \sim \mathcal{U}(a, b) \; .
\end{equation}

Then, the median ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:med}) of $X$ is

\begin{equation} \label{eq:cuni-med-cuni-med}
\mathrm{median}(X) = \frac{1}{2} (a+b) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The median ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:med}) is the value at which the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) is $1/2$:

\begin{equation} \label{eq:cuni-med-median}
F_X(\mathrm{median}(X)) = \frac{1}{2} \; .
\end{equation}

The cumulative distribution function of the continuous uniform distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:cuni-cdf}) is

\begin{equation} \label{eq:cuni-med-cuni-cdf}
F_X(x) = \left\{
\begin{array}{rl}
0 \; , & \text{if} \; x < a \\
\frac{x-a}{b-a} \; , & \text{if} \; a \leq x \leq b \\
1 \; , & \text{if} \; x > b \; .
\end{array}
\right.
\end{equation}

Thus, the inverse CDF ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:cuni-qf}) is

\begin{equation} \label{eq:cuni-med-cuni-cdf-inv}
x = bp + a(1-p) \; .
\end{equation}

Setting $p = 1/2$, we obtain:

\begin{equation} \label{eq:cuni-med-cuni-med-qed}
\mathrm{median}(X) = b \cdot \frac{1}{2} + a \cdot \left( 1-\frac{1}{2} \right) = \frac{1}{2} (a+b) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P83 | shortcut: cuni-med | author: JoramSoch | date: 2020-03-16, 16:19.
\vspace{1em}



\subsubsection[\textbf{Mode}]{Mode} \label{sec:cuni-med}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a continuous uniform distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:cuni}):

\begin{equation} \label{eq:cuni-med-cuni}
X \sim \mathcal{U}(a, b) \; .
\end{equation}

Then, the mode ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mode}) of $X$ is

\begin{equation} \label{eq:cuni-med-cuni-mode}
\mathrm{mode}(X) \in [a,b] \; .
\end{equation}


\vspace{1em}
\textbf{Proof:}  The mode ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mode}) is the value which maximizes the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}):

\begin{equation} \label{eq:cuni-med-mode}
\mathrm{mode}(X) = \operatorname*{arg\,max}_x f_X(x) \; .
\end{equation}

The probability density function of the continuous uniform distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:cuni-pdf}) is:

\begin{equation} \label{eq:cuni-med-cuni-pdf}
f_X(x) = \left\{
\begin{array}{rl}
\frac{1}{b-a} \; , & \text{if} \; a \leq x \leq b \\
0 \; , & \text{otherwise} \; .
\end{array}
\right.
\end{equation}

Since the PDF attains its only non-zero value whenever $a \leq x \leq b$,

\begin{equation} \label{eq:cuni-med-cuni-pdf-max}
\operatorname*{max}_x f_X(x) = \frac{1}{b-a} \; ,
\end{equation}

any value in the interval $[a,b]$ may be considered the mode of $X$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P84 | shortcut: cuni-med | author: JoramSoch | date: 2020-03-16, 16:29.
\vspace{1em}



\subsection{Normal distribution}

\subsubsection[\textit{Definition}]{Definition} \label{sec:norm}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}). Then, $X$ is said to be normally distributed with mean $\mu$ and variance $\sigma^2$ (or, standard deviation $\sigma$)

\begin{equation} \label{eq:norm-norm}
X \sim \mathcal{N}(\mu, \sigma^2) \; ,
\end{equation}

if and only if its probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) is given by

\begin{equation} \label{eq:norm-norm-pdf}
\mathcal{N}(x; \mu, \sigma^2) = \frac{1}{\sqrt{2 \pi} \sigma} \cdot \exp \left[ -\frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right]
\end{equation}

where $\mu \in \mathbb{R}$ and $\sigma^2 > 0$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Normal distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-01-27; URL: \url{https://en.wikipedia.org/wiki/Normal_distribution}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D4 | shortcut: norm | author: JoramSoch | date: 2020-01-27, 14:15.
\vspace{1em}



\subsubsection[\textit{Standard normal distribution}]{Standard normal distribution} \label{sec:snorm}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}). Then, $X$ is said to be standard normally distributed, if $X$ follows a normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}) with mean $\mu = 0$ and variance $\sigma^2 = 1$:

\begin{equation} \label{eq:snorm-snorm}
X \sim \mathcal{N}(0, 1) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Normal distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-05-26; URL: \url{https://en.wikipedia.org/wiki/Normal_distribution#Standard_normal_distribution}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D63 | shortcut: snorm | author: JoramSoch | date: 2020-05-26, 23:32.
\vspace{1em}



\subsubsection[\textbf{Relationship to standard normal distribution}]{Relationship to standard normal distribution} \label{sec:norm-snorm}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}) with mean $\mu$ and variance $\sigma^2$:

\begin{equation} \label{eq:norm-snorm-X-norm}
X \sim \mathcal{N}(\mu, \sigma^2) \; .
\end{equation}

Then, the quantity $Z = (X-\mu)/\sigma$ will have a standard normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:snorm}) with mean $0$ and variance $1$:

\begin{equation} \label{eq:norm-snorm-Z-snorm}
Z = \frac{X-\mu}{\sigma} \sim \mathcal{N}(0, 1) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} Note that $Z$ is a function of $X$

\begin{equation} \label{eq:norm-snorm-Z-X}
Z = g(X) = \frac{X-\mu}{\sigma}
\end{equation}

with the inverse function

\begin{equation} \label{eq:norm-snorm-X-Z}
X = g^{-1}(Z) = \sigma Z + \mu \; .
\end{equation}

Because $\sigma$ is positive, $g(X)$ is strictly increasing and we can calculate the cumulative distribution function of a strictly increasing function ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:cdf-sifct}) as

\begin{equation} \label{eq:norm-snorm-cdf-sifct}
F_Y(y) = \left\{
\begin{array}{rl}
0 \; , & \text{if} \; y < \mathrm{min}(\mathcal{Y}) \\
F_X(g^{-1}(y)) \; , & \text{if} \; y \in \mathcal{Y} \\
1 \; , & \text{if} \; y > \mathrm{max}(\mathcal{Y}) \; .
\end{array}
\right.
\end{equation}

The cumulative distribution function of the normally distributed ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-cdf}) $X$ is

\begin{equation} \label{eq:norm-snorm-norm-cdf}
F_X(x) = \int_{-\infty}^{x} \frac{1}{\sqrt{2 \pi} \sigma} \cdot \exp \left[ -\frac{1}{2} \left( \frac{t-\mu}{\sigma} \right)^2 \right] \, \mathrm{d}t \; .
\end{equation}

Applying \eqref{eq:norm-snorm-cdf-sifct} to \eqref{eq:norm-snorm-norm-cdf}, we have:

\begin{equation} \label{eq:norm-snorm-Z-cdf-s1}
\begin{split}
F_Z(z) &\overset{\eqref{eq:norm-snorm-cdf-sifct}}{=} F_X(g^{-1}(z)) \\
&\overset{\eqref{eq:norm-snorm-norm-cdf}}{=} \int_{-\infty}^{\sigma z + \mu} \frac{1}{\sqrt{2 \pi} \sigma} \cdot \exp \left[ -\frac{1}{2} \left( \frac{t-\mu}{\sigma} \right)^2 \right] \, \mathrm{d}t \; .
\end{split}
\end{equation}

Substituting $s = (t - \mu)/\sigma$, such that $t = \sigma s + \mu$, we obtain

\begin{equation} \label{eq:norm-snorm-Z-cdf-s2}
\begin{split}
F_Z(z) &= \int_{(-\infty - \mu)/\sigma}^{([\sigma z + \mu] - \mu)/\sigma} \frac{1}{\sqrt{2 \pi} \sigma} \cdot \exp \left[ -\frac{1}{2} \left( \frac{(\sigma s + \mu)-\mu}{\sigma} \right)^2 \right] \, \mathrm{d}(\sigma s + \mu) \\
&= \int_{-\infty}^{z} \frac{\sigma}{\sqrt{2 \pi} \sigma} \cdot \exp \left[ -\frac{1}{2} s^2 \right] \, \mathrm{d}s \\
&= \int_{-\infty}^{z} \frac{1}{\sqrt{2 \pi}} \cdot \exp \left[ -\frac{1}{2} s^2 \right] \, \mathrm{d}s
\end{split}
\end{equation}

which is the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) of the standard normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:snorm}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P111 | shortcut: norm-snorm | author: JoramSoch | date: 2020-05-26, 23:01.
\vspace{1em}



\subsubsection[\textbf{Relationship to standard normal distribution}]{Relationship to standard normal distribution} \label{sec:norm-snorm2}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}) with mean $\mu$ and variance $\sigma^2$:

\begin{equation} \label{eq:norm-snorm2-X-norm}
X \sim \mathcal{N}(\mu, \sigma^2) \; .
\end{equation}

Then, the quantity $Z = (X-\mu)/\sigma$ will have a standard normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:snorm}) with mean $0$ and variance $1$:

\begin{equation} \label{eq:norm-snorm2-Z-snorm}
Z = \frac{X-\mu}{\sigma} \sim \mathcal{N}(0, 1) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} Note that $Z$ is a function of $X$

\begin{equation} \label{eq:norm-snorm2-Z-X}
Z = g(X) = \frac{X-\mu}{\sigma}
\end{equation}

with the inverse function

\begin{equation} \label{eq:norm-snorm2-X-Z}
X = g^{-1}(Z) = \sigma Z + \mu \; .
\end{equation}

Because $\sigma$ is positive, $g(X)$ is strictly increasing and we can calculate the probability density function of a strictly increasing function ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:pdf-sifct}) as

\begin{equation} \label{eq:norm-snorm2-pdf-sifct}
f_Y(y) = \left\{
\begin{array}{rl}
f_X(g^{-1}(y)) \, \frac{\mathrm{d}g^{-1}(y)}{\mathrm{d}y} \; , & \text{if} \; y \in \mathcal{Y} \\
0 \; , & \text{if} \; y \notin \mathcal{Y}
\end{array}
\right.
\end{equation}

where $\mathcal{Y} = \left\lbrace y = g(x): x \in \mathcal{X} \right\rbrace$. With the probability density function of the normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-pdf}), we have

\begin{equation} \label{eq:norm-snorm2-pdf-Z}
\begin{split}
f_Z(z) &= \frac{1}{\sqrt{2 \pi} \sigma} \cdot \exp \left[ -\frac{1}{2} \left( \frac{g^{-1}(z)-\mu}{\sigma} \right)^2 \right] \cdot \frac{\mathrm{d}g^{-1}(z)}{\mathrm{d}z} \\
&= \frac{1}{\sqrt{2 \pi} \sigma} \cdot \exp \left[ -\frac{1}{2} \left( \frac{(\sigma z + \mu)-\mu}{\sigma} \right)^2 \right] \cdot \frac{\mathrm{d}(\sigma z + \mu)}{\mathrm{d}z} \\
&= \frac{1}{\sqrt{2 \pi} \sigma} \cdot \exp \left[ -\frac{1}{2} z^2 \right] \cdot \sigma \\
&= \frac{1}{\sqrt{2 \pi}} \cdot \exp \left[ -\frac{1}{2} z^2 \right]
\end{split}
\end{equation}

which is the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of the standard normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:snorm}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P176 | shortcut: norm-snorm2 | author: JoramSoch | date: 2020-10-15, 11:42.
\vspace{1em}



\subsubsection[\textbf{Relationship to standard normal distribution}]{Relationship to standard normal distribution} \label{sec:norm-snorm3}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}) with mean $\mu$ and variance $\sigma^2$:

\begin{equation} \label{eq:norm-snorm3-X-norm}
X \sim \mathcal{N}(\mu, \sigma^2) \; .
\end{equation}

Then, the quantity $Z = (X-\mu)/\sigma$ will have a standard normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:snorm}) with mean $0$ and variance $1$:

\begin{equation} \label{eq:norm-snorm3-Z-snorm}
Z = \frac{X-\mu}{\sigma} \sim \mathcal{N}(0, 1) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The linear transformation theorem for multivariate normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mvn-ltt}) states

\begin{equation} \label{eq:norm-snorm3-mvn-ltt}
x \sim \mathcal{N}(\mu, \Sigma) \quad \Rightarrow \quad y = Ax + b \sim \mathcal{N}(A\mu + b, A \Sigma A^\mathrm{T})
\end{equation}

where $x$ is an $n \times 1$ random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}) following a multivariate normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mvn}) with mean $\mu$ and covariance $\Sigma$, $A$ is an $m \times n$ matrix and $b$ is an $m \times 1$ vector. Note that

\begin{equation} \label{eq:norm-snorm3-Z-X}
Z = \frac{X-\mu}{\sigma} = \frac{X}{\sigma} - \frac{\mu}{\sigma}
\end{equation}

is a special case of \eqref{eq:norm-snorm3-mvn-ltt} with $x = X$, $\mu = \mu$, $\Sigma = \sigma^2$, $A = 1/\sigma$ and $b = \mu/\sigma$. Applying theorem \eqref{eq:norm-snorm3-mvn-ltt} to $Z$ as a function of $X$, we have

\begin{equation} \label{eq:norm-snorm3-mvn-ltt-norm}
X \sim \mathcal{N}(\mu, \sigma^2) \quad \Rightarrow \quad Z = \frac{X}{\sigma} - \frac{\mu}{\sigma} \sim \mathcal{N}\left( \frac{\mu}{\sigma} - \frac{\mu}{\sigma}, \frac{1}{\sigma} \cdot \sigma^2 \cdot \frac{1}{\sigma} \right)
\end{equation}

which results in the distribution:

\begin{equation} \label{eq:norm-snorm3-Z-snorm-qed}
Z \sim \mathcal{N}(0, 1) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P180 | shortcut: norm-snorm3 | author: JoramSoch | date: 2020-10-22, 06:34.
\vspace{1em}



\subsubsection[\textbf{Relationship to chi-squared distribution}]{Relationship to chi-squared distribution} \label{sec:norm-chi2}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X_1, \ldots, X_n$ be independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}) random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) where each of them is following a normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}) with mean $\mu$ and variance $\sigma^2$:

\begin{equation} \label{eq:norm-chi2-norm}
X_i \sim \mathcal{N}(\mu, \sigma^2) \quad \text{for} \quad i = 1, \ldots, n \; .
\end{equation}

Define the sample mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean-samp})

\begin{equation} \label{eq:norm-chi2-mean-samp}
\bar{X} = \frac{1}{n} \sum_{i=1}^{n} X_i
\end{equation}

and the unbiased sample variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var-samp})

\begin{equation} \label{eq:norm-chi2-var-samp}
s^2 = \frac{1}{n-1} \sum_{i=1}^{n} \left( X_i - \bar{X} \right)^2 \; .
\end{equation}

Then, the sampling distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-samp}) of the sample variance is given by a chi-squared distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:chi2}) with $n-1$ degrees of freedom:

\begin{equation} \label{eq:norm-chi2-norm-chi2}
V = (n-1) \, \frac{s^2}{\sigma^2} \sim \chi^2(n-1) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} Consider the random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $U_i$ defined as

\begin{equation} \label{eq:norm-chi2-Ui}
U_i = \frac{X_i - \mu}{\sigma}
\end{equation}

which follows a standard normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-snorm})

\begin{equation} \label{eq:norm-chi2-norm-snorm}
U_i \sim \mathcal{N}(0,1) \; .
\end{equation}

Then, the sum of squared random variables $U_i$ can be rewritten as

\begin{equation} \label{eq:norm-chi2-sum-Ui2-s1}
\begin{split}
\sum_{i=1}^{n} U_i^2 &= \sum_{i=1}^{n} \left( \frac{X_i - \mu}{\sigma} \right)^2 \\
&= \sum_{i=1}^{n} \left( \frac{(X_i - \bar{X}) + (\bar{X} - \mu)}{\sigma} \right)^2 \\
&= \sum_{i=1}^{n} \frac{(X_i - \bar{X})^2}{\sigma^2} + \sum_{i=1}^{n} \frac{(\bar{X} - \mu)^2}{\sigma^2} + \sum_{i=1}^{n} \frac{(X_i - \bar{X})(\bar{X} - \mu)}{\sigma^2} \\
&= \sum_{i=1}^{n} \left( \frac{X_i - \bar{X}}{\sigma^2} \right)^2 + \sum_{i=1}^{n} \left( \frac{\bar{X} - \mu}{\sigma^2} \right)^2 + \frac{(\bar{X} - \mu)}{\sigma^2} \sum_{i=1}^{n} (X_i - \bar{X}) \; .
\end{split}
\end{equation}

Because the following sum is zero

\begin{equation} \label{eq:norm-chi2-Xi-Xb}
\begin{split}
\sum_{i=1}^{n} (X_i - \bar{X}) &= \sum_{i=1}^{n} X_i - n \bar{X} \\
&= \sum_{i=1}^{n} X_i - n \cdot \frac{1}{n} \sum_{i=1}^{n} X_i \\
&= \sum_{i=1}^{n} X_i - \sum_{i=1}^{n} X_i \\
&= 0 \; ,
\end{split}
\end{equation}

the third term disappears, i.e.

\begin{equation} \label{eq:norm-chi2-sum-Ui2-s2}
\sum_{i=1}^{n} U_i^2 = \sum_{i=1}^{n} \left( \frac{X_i - \bar{X}}{\sigma^2} \right)^2 + \sum_{i=1}^{n} \left( \frac{\bar{X} - \mu}{\sigma^2} \right)^2 \; .
\end{equation}

Cochran's theorem ($\rightarrow$ Proof "snorm-cochran") states that, if a sum of squared standard normal ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:snorm}) random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) can be written as a sum of squared forms

\begin{equation} \label{eq:norm-chi2-cochran-p1}
\begin{split}
\sum_{i=1}^{n} U_i^2 = \sum_{j=1}^{m} Q_j \quad &\text{where} \quad Q_j = \sum_{k=1}^{n} \sum_{l=1}^{n} U_k B^{(j)}_{kl} U_l \\
&\text{with} \quad \sum_{j=1}^{m} B^{(j)} = I_n \\
&\text{and} \quad r_j = \mathrm{rank}(B^{(j)}) \; ,
\end{split}
\end{equation}

then the terms $Q_j$ are independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}) and each term $Q_j$ follows a chi-squared distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:chi2}) with $r_j$ degrees of freedom:

\begin{equation} \label{eq:norm-chi2-cochran-p2}
Q_j \sim \chi^2(r_j) \; .
\end{equation}

We observe that \eqref{eq:norm-chi2-sum-Ui2-s2} can be represented as

\begin{equation} \label{eq:norm-chi2-sum-Ui2-s3}
\begin{split}
\sum_{i=1}^{n} U_i^2 &= \sum_{i=1}^{n} \left( \frac{X_i - \bar{X}}{\sigma^2} \right)^2 + \sum_{i=1}^{n} \left( \frac{\bar{X} - \mu}{\sigma^2} \right)^2 \\
= Q_1 + Q_2 &= \sum_{i=1}^{n} \left( U_i - \frac{1}{n} \sum_{j=1}^n U_j \right)^2 + \frac{1}{n} \left( \sum_{i=1}^{n} U_i \right)^2
\end{split}
\end{equation}

where, with the $n \times n$ matrix of ones $J_n$, the matrices $B^{(j)}$ are

\begin{equation} \label{eq:norm-chi2-sum-Ui2-s3-Bj}
B^{(1)} = I_n - \frac{J_n}{n} \quad \text{and} \quad B^{(2)} = \frac{J_n}{n} \; .
\end{equation}

Because all columns of $B^{(2)}$ are identical, it has rank $r_2 = 1$. Because the $n$ columns of $B^{(1)}$ add up to zero, it has rank $r_1 = n-1$. Thus, the conditions of Cochran's theorem ($\rightarrow$ Proof "snorm-cochran") are met and the squared form

\begin{equation} \label{eq:norm-chi2-Q1}
Q_1 = \sum_{i=1}^{n} \left( \frac{X_i - \bar{X}}{\sigma^2} \right)^2 = (n-1) \, \frac{1}{\sigma^2} \, \frac{1}{n-1} \sum_{i=1}^{n} \left( X_i - \bar{X} \right)^2 = (n-1) \, \frac{s^2}{\sigma^2}
\end{equation}

follows a chi-squared distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:chi2}) with $n-1$ degrees of freedom:

\begin{equation} \label{eq:norm-chi2-norm-chi2-qed}
(n-1) \, \frac{s^2}{\sigma^2} \sim \chi^2(n-1) \; .
\end{equation}



\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Glen-b (2014): "Why is the sampling distribution of variance a chi-squared distribution?"; in: \textit{StackExchange CrossValidated}, retrieved on 2021-05-20; URL: \url{https://stats.stackexchange.com/questions/121662/why-is-the-sampling-distribution-of-variance-a-chi-squared-distribution}.
\item Wikipedia (2021): "Cochran's theorem"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-05-20; URL: \url{https://en.wikipedia.org/wiki/Cochran%27s_theorem#Sample_mean_and_sample_variance}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P233 | shortcut: norm-chi2 | author: JoramSoch | date: 2021-05-20, 10:18.
\vspace{1em}



\subsubsection[\textbf{Relationship to t-distribution}]{Relationship to t-distribution} \label{sec:norm-t}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X_1, \ldots, X_n$ be independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}) random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) where each of them is following a normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}) with mean $\mu$ and variance $\sigma^2$:

\begin{equation} \label{eq:norm-t-norm}
X_i \sim \mathcal{N}(\mu, \sigma^2) \quad \text{for} \quad i = 1, \ldots, n \; .
\end{equation}

Define the sample mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean-samp})

\begin{equation} \label{eq:norm-t-mean-samp}
\bar{X} = \frac{1}{n} \sum_{i=1}^{n} X_i
\end{equation}

and the unbiased sample variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var-samp})

\begin{equation} \label{eq:norm-t-var-samp}
s^2 = \frac{1}{n-1} \sum_{i=1}^{n} \left( X_i - \bar{X} \right)^2 \; .
\end{equation}

Then, subtracting $\mu$ from the sample mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}), dividing by the sample standard deviation ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:std}) and multiplying with $\sqrt{n}$ results in a qunatity that follows a t-distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:t}) with $n-1$ degrees of freedom:

\begin{equation} \label{eq:norm-t-norm-t}
t = \sqrt{n} \, \frac{\bar{X}-\mu}{s} \sim \mathrm{t}(n-1) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} Note that $\bar{X}$ is a linear combination of $X_1, \ldots, X_n$:

\begin{equation} \label{eq:norm-t-X-bar-lincomb}
\bar{X} = \frac{1}{n} X_1, + \ldots + \frac{1}{n} X_n \; .
\end{equation}

Because the linear combination of independent normal random variables is also normally distributed ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-lincomb}), we have:

\begin{equation} \label{eq:norm-t-X-bar-dist}
\bar{X} \sim \mathcal{N}\left( \frac{1}{n} \, n \mu, \left(\frac{1}{n}\right)^2 n \sigma^2 \right) = \mathcal{N}\left( \mu, \sigma^2/n \right) \; .
\end{equation}

Let $Z = \sqrt{n} \, (\bar{X}-\mu)/\sigma$. Because $Z$ is a linear transformation ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mvn-ltt}) of $\bar{X}$, it also follows a normal distribution:

\begin{equation} \label{eq:norm-t-Z-dist}
Z = \sqrt{n} \frac{\bar{X}-\mu}{\sigma} \sim \mathcal{N}\left( \frac{\sqrt{n}}{\sigma} (\mu - \mu), \left(\frac{\sqrt{n}}{\sigma}\right)^2 \sigma^2/n \right) = \mathcal{N}\left( 0, 1 \right) \; .
\end{equation}

Let $V = (n-1) \, s^2/\sigma^2$. We know that this function of the sample variance follows a chi-squared distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-chi2}) with $n-1$ degrees of freedom:

\begin{equation} \label{eq:norm-t-V-dist}
V = (n-1) \frac{s^2}{\sigma^2} \sim \chi^2(n-1) \; .
\end{equation}

Observe that $t$ is the ratio of a standard normal random variable ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:snorm}) and the square root of a chi-squared random variable ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:chi2}), divided by its degrees of freedom:

\begin{equation} \label{eq:norm-t-t-Z-V}
t = \sqrt{n} \, \frac{\bar{X}-\mu}{s} = \frac{\sqrt{n} \frac{\bar{X}-\mu}{\sigma}}{\sqrt{(n-1) \frac{s^2}{\sigma^2}/(n-1)}} =  \frac{Z}{\sqrt{V/(n-1)}} \; .
\end{equation}

Thus, by definition of the t-distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:t}), this ratio follows a t-distribution with $n-1$ degrees of freedom:

\begin{equation} \label{eq:norm-t-norm-t-qed}
t \sim \mathrm{t}(n-1) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Student's t-distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-05-27; URL: \url{https://en.wikipedia.org/wiki/Student%27s_t-distribution#Characterization}.
\item Wikipedia (2021): "Normal distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-05-27; URL: \url{https://en.wikipedia.org/wiki/Normal_distribution#Operations_on_multiple_independent_normal_variables}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P234 | shortcut: norm-t | author: JoramSoch | date: 2021-05-27, 08:10.
\vspace{1em}



\subsubsection[\textbf{Gaussian integral}]{Gaussian integral} \label{sec:norm-gi}
\setcounter{equation}{0}

\textbf{Theorem:} The definite integral of $\mathrm{exp}\left[ -x^2 \right]$ from $-\infty$ to $+\infty$ is equal to the square root of $\pi$:

\begin{equation} \label{eq:norm-gi-norm-gi}
\int_{-\infty}^{+\infty} \mathrm{exp}\left[ -x^2 \right] \, \mathrm{d}x = \sqrt{\pi} \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} Let

\begin{equation} \label{eq:norm-gi-I}
I = \int_{0}^{\infty} \mathrm{exp}\left[ -x^2 \right] \, \mathrm{d}x
\end{equation}

and 

\begin{equation} \label{eq:norm-gi-IP}
I_P = \int_{0}^{P} \mathrm{exp}\left[ -x^2 \right] \, \mathrm{d}x = \int_{0}^{P} \mathrm{exp}\left[ -y^2 \right] \, \mathrm{d}y \; .
\end{equation}

Then, we have

\begin{equation} \label{eq:norm-gi-IP-I}
\lim\limits_{P \rightarrow \infty} I_P = I
\end{equation}

and

\begin{equation} \label{eq:norm-gi-IP2-I2}
\lim\limits_{P \rightarrow \infty} I_P^2 = I^2 \; .
\end{equation}

Moreover, we can write

\begin{equation} \label{eq:norm-gi-IP2}
\begin{split}
I_P^2 &\overset{\eqref{eq:norm-gi-IP}}{=} \left( \int_{0}^{P} \mathrm{exp}\left[ -x^2 \right] \, \mathrm{d}x \right) \left( \int_{0}^{P} \mathrm{exp}\left[ -y^2 \right] \, \mathrm{d}y \right) \\
&= \int_{0}^{P} \int_{0}^{P} \mathrm{exp}\left[ - \left( x^2 + y^2 \right) \right] \, \mathrm{d}x \, \mathrm{d}y \\
&= \iint_{S_P} \mathrm{exp}\left[ - \left( x^2 + y^2 \right) \right] \, \mathrm{d}x \, \mathrm{d}y
\end{split}
\end{equation}

where $S_P$ is the square with corners $(0,0)$, $(0,P)$, $(P,P)$ and $(P,0)$. For this integral, we can write down the following inequality

\begin{equation} \label{eq:norm-gi-IP2-ineq}
\iint_{C_1} \mathrm{exp}\left[ - \left( x^2 + y^2 \right) \right] \, \mathrm{d}x \, \mathrm{d}y \leq I_P^2 \leq \iint_{C_2} \mathrm{exp}\left[ - \left( x^2 + y^2 \right) \right] \, \mathrm{d}x \, \mathrm{d}y
\end{equation}

where $C_1$ and $C_2$ are the regions in the first quadrant bounded by circles with center at $(0,0)$ and going through the points $(0,P)$ and $(P,P)$, respectively. The radii of these two circles are $r_1 = \sqrt{P^2} = P$ and $r_2 = \sqrt{2 P^2} = P \sqrt{2}$, such that we can rewrite equation \eqref{eq:norm-gi-IP2-ineq} using polar coordinates as

\begin{equation} \label{eq:norm-gi-IP2-ineq-PC}
\int_{0}^{\frac{\pi}{2}} \int_{0}^{r_1} \mathrm{exp}\left[ -r^2 \right] \, r \, \mathrm{d}r \, \mathrm{d}\theta \leq I_P^2 \leq \int_{0}^{\frac{\pi}{2}} \int_{0}^{r_2} \mathrm{exp}\left[ -r^2 \right] \, r \, \mathrm{d}r \, \mathrm{d}\theta \; .
\end{equation}

Solving the definite integrals yields:

\begin{equation} \label{eq:norm-gi-IP2-ineq-PC-int}
\begin{split}
\int_{0}^{\frac{\pi}{2}} \int_{0}^{r_1} \mathrm{exp}\left[ -r^2 \right] r \, \mathrm{d}r \, \mathrm{d}\theta &\leq I_P^2 \leq \int_{0}^{\frac{\pi}{2}} \int_{0}^{r_2} \mathrm{exp}\left[ -r^2 \right] r \, \mathrm{d}r \, \mathrm{d}\theta \\
\int_{0}^{\frac{\pi}{2}} \left[ -\frac{1}{2} \mathrm{exp}\left[ -r^2 \right] \right]_{0}^{r_1} \, \mathrm{d}\theta &\leq I_P^2 \leq \int_{0}^{\frac{\pi}{2}} \left[ -\frac{1}{2} \mathrm{exp}\left[ -r^2 \right] \right]_{0}^{r_2} \, \mathrm{d}\theta \\
-\frac{1}{2} \int_{0}^{\frac{\pi}{2}} \left( \mathrm{exp}\left[ -r_1^2 \right] - 1 \right) \, \mathrm{d}\theta &\leq I_P^2 \leq -\frac{1}{2} \int_{0}^{\frac{\pi}{2}} \left( \mathrm{exp}\left[ -r_2^2 \right] - 1 \right) \, \mathrm{d}\theta \\
-\frac{1}{2} \left[ \left( \mathrm{exp}\left[ -r_1^2 \right] - 1 \right) \theta \right]_{0}^{\frac{\pi}{2}} &\leq I_P^2 \leq -\frac{1}{2} \left[ \left( \mathrm{exp}\left[ -r_2^2 \right] - 1 \right) \theta \right]_{0}^{\frac{\pi}{2}} \\
\frac{1}{2} \left( 1 - \mathrm{exp}\left[ -r_1^2 \right] \right) \frac{\pi}{2} &\leq I_P^2 \leq \frac{1}{2} \left( 1 - \mathrm{exp}\left[ -r_2^2 \right] \right) \frac{\pi}{2} \\
\frac{\pi}{4} \left( 1 - \mathrm{exp}\left[ -P^2 \right] \right) &\leq I_P^2 \leq \frac{\pi}{4} \left( 1 - \mathrm{exp}\left[ -2 P^2 \right] \right)
\end{split}
\end{equation}

Calculating the limit for $P \rightarrow \infty$, we obtain

\begin{equation} \label{eq:norm-gi-IP2-ineq-PC-int-lim}
\begin{split}
\lim\limits_{P \rightarrow \infty} \frac{\pi}{4} \left( 1 - \mathrm{exp}\left[ -P^2 \right] \right) \leq \lim\limits_{P \rightarrow \infty} I_P^2 &\leq \lim\limits_{P \rightarrow \infty} \frac{\pi}{4} \left( 1 - \mathrm{exp}\left[ -2 P^2 \right] \right) \\
\frac{\pi}{4} \leq I^2 &\leq \frac{\pi}{4} \; ,
\end{split}
\end{equation}

such that we have a preliminary result for $I$:

\begin{equation} \label{eq:norm-gi-I-qed}
I^2 = \frac{\pi}{4} \quad \Rightarrow \quad I = \frac{\sqrt{\pi}}{2} \; .
\end{equation}

Because the integrand in \eqref{eq:norm-gi-norm-gi} is an even function, we can calculate the final result as follows:

\begin{equation} \label{eq:norm-gi-norm-gi-qed}
\begin{split}
\int_{-\infty}^{+\infty} \mathrm{exp}\left[ -x^2 \right] \, \mathrm{d}x &= 2 \int_{0}^{\infty} \mathrm{exp}\left[ -x^2 \right] \, \mathrm{d}x \\
&\overset{\eqref{eq:norm-gi-I-qed}}{=} 2 \, \frac{\sqrt{\pi}}{2} \\
&= \sqrt{\pi} \; . 
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item ProofWiki (2020): "Gaussian Integral"; in: \textit{ProofWiki}, retrieved on 2020-11-25; URL: \url{https://proofwiki.org/wiki/Gaussian_Integral}.
\item ProofWiki (2020): "Integral to Infinity of Exponential of minus t squared"; in: \textit{ProofWiki}, retrieved on 2020-11-25; URL: \url{https://proofwiki.org/wiki/Integral_to_Infinity_of_Exponential_of_-t%5E2}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P196 | shortcut: norm-gi | author: JoramSoch | date: 2020-11-25, 04:47.
\vspace{1em}



\subsubsection[\textbf{Probability density function}]{Probability density function} \label{sec:norm-pdf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}):

\begin{equation} \label{eq:norm-pdf-norm}
X \sim \mathcal{N}(\mu, \sigma^2) \; .
\end{equation}

Then, the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $X$ is

\begin{equation} \label{eq:norm-pdf-norm-pdf}
f_X(x) = \frac{1}{\sqrt{2 \pi} \sigma} \cdot \exp \left[ -\frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right] \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} This follows directly from the definition of the normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P33 | shortcut: norm-pdf | author: JoramSoch | date: 2020-01-27, 15:15.
\vspace{1em}



\subsubsection[\textbf{Moment-generating function}]{Moment-generating function} \label{sec:norm-mgf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}):

\begin{equation} \label{eq:norm-mgf-norm}
X \sim \mathcal{N}(\mu, \sigma^2) \; .
\end{equation}

Then, the moment-generating function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mgf}) of $X$ is

\begin{equation} \label{eq:norm-mgf-norm-mgf}
M_X(t) = \exp\left[ \mu t + \frac{1}{2} \sigma^2 t^2 \right] \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The probability density function of the normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-pdf}) is

\begin{equation} \label{eq:norm-mgf-norm-pdf}
f_X(x) = \frac{1}{\sqrt{2 \pi} \sigma} \cdot \exp \left[ -\frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right]
\end{equation}

and the moment-generating function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mgf}) is defined as

\begin{equation} \label{eq:norm-mgf-mgf-var}
M_X(t) = \mathrm{E} \left[ e^{tX} \right] \; .
\end{equation}

Using the expected value for continuous random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}), the moment-generating function of $X$ therefore is

\begin{equation} \label{eq:norm-mgf-norm-mgf-s1}
\begin{split}
M_X(t) &= \int_{-\infty}^{+\infty} \exp[tx] \cdot \frac{1}{\sqrt{2 \pi} \sigma} \cdot \exp \left[ -\frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right] \, \mathrm{d}x \\
&= \frac{1}{\sqrt{2 \pi} \sigma} \int_{-\infty}^{+\infty} \exp\left[ tx - \frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right] \, \mathrm{d}x \; .
\end{split}
\end{equation}

Substituting $u = (x-\mu)/(\sqrt{2}\sigma)$, i.e. $x = \sqrt{2}\sigma u + \mu$, we have

\begin{equation} \label{eq:norm-mgf-norm-mgf-s2}
\begin{split}
M_X(t) &= \frac{1}{\sqrt{2 \pi} \sigma} \int_{(-\infty-\mu)/(\sqrt{2}\sigma)}^{(+\infty-\mu)/(\sqrt{2}\sigma)} \exp\left[ t\left( \sqrt{2} \sigma u + \mu \right) - \frac{1}{2} \left( \frac{ \sqrt{2} \sigma u + \mu - \mu}{\sigma} \right)^2 \right] \, \mathrm{d}\left( \sqrt{2} \sigma u + \mu \right) \\
&= \frac{\sqrt{2} \sigma}{\sqrt{2 \pi} \sigma} \int_{-\infty}^{+\infty} \exp\left[ \left( \sqrt{2} \sigma u + \mu \right) t - u^2 \right] \, \mathrm{d}u \\
&= \frac{\exp(\mu t)}{\sqrt{\pi}} \int_{-\infty}^{+\infty} \exp\left[ \sqrt{2} \sigma u t - u^2 \right] \, \mathrm{d}u \\
&= \frac{\exp(\mu t)}{\sqrt{\pi}} \int_{-\infty}^{+\infty} \exp\left[ - \left( u^2 - \sqrt{2} \sigma u t \right) \right] \, \mathrm{d}u \\
&= \frac{\exp(\mu t)}{\sqrt{\pi}} \int_{-\infty}^{+\infty} \exp\left[ - \left( u - \frac{\sqrt{2}}{2} \sigma t \right)^2 + \frac{1}{2} \sigma^2 t^2 \right] \, \mathrm{d}u \\
&= \frac{\exp\left[ \mu t + \frac{1}{2} \sigma^2 t^2 \right]}{\sqrt{\pi}} \int_{-\infty}^{+\infty} \exp\left[ - \left( u - \frac{\sqrt{2}}{2} \sigma t \right)^2 \right] \, \mathrm{d}u
\end{split}
\end{equation}

Now substituting $v = u - \sqrt{2}/2 \, \sigma t$, i.e. $u = v + \sqrt{2}/2 \, \sigma t$, we have

\begin{equation} \label{eq:norm-mgf-norm-mgf-s3}
\begin{split}
M_X(t) &= \frac{\exp\left[ \mu t + \frac{1}{2} \sigma^2 t^2 \right]}{\sqrt{\pi}} \int_{-\infty - \sqrt{2}/2 \, \sigma t}^{+\infty - \sqrt{2}/2 \, \sigma t} \exp\left[ -v^2 \right] \, \mathrm{d}\left( v + \sqrt{2}/2 \, \sigma t \right) \\
&= \frac{\exp\left[ \mu t + \frac{1}{2} \sigma^2 t^2 \right]}{\sqrt{\pi}} \int_{-\infty}^{+\infty} \exp\left[ -v^2 \right] \, \mathrm{d}v \; .
\end{split}
\end{equation}

With the Gaussian integral ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-gi})

\begin{equation} \label{eq:norm-mgf-gauss}
\int_{-\infty}^{+\infty} \exp\left[ -x^2 \right] \, \mathrm{d}x = \sqrt{\pi} \; ,
\end{equation}

this finally becomes

\begin{equation} \label{eq:norm-mgf-norm-mgf-qed}
M_X(t) = \exp\left[ \mu t + \frac{1}{2} \sigma^2 t^2 \right] \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item ProofWiki (2020): "Moment Generating Function of Gaussian Distribution"; in: \textit{ProofWiki}, retrieved on 2020-03-03; URL: \url{https://proofwiki.org/wiki/Moment_Generating_Function_of_Gaussian_Distribution}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P71 | shortcut: norm-mgf | author: JoramSoch | date: 2020-03-03, 11:29.
\vspace{1em}



\subsubsection[\textbf{Cumulative distribution function}]{Cumulative distribution function} \label{sec:norm-cdf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a normal distributions ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}):

\begin{equation} \label{eq:norm-cdf-norm}
X \sim \mathcal{N}(\mu, \sigma^2) \; .
\end{equation}

Then, the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) of $X$ is

\begin{equation} \label{eq:norm-cdf-norm-cdf}
F_X(x) = \frac{1}{2} \left[ 1 + \mathrm{erf}\left( \frac{x-\mu}{\sqrt{2} \sigma} \right) \right]
\end{equation}

where $\mathrm{erf}(x)$ is the error function defined as

\begin{equation} \label{eq:norm-cdf-erf}
\mathrm{erf}(x) = \frac{2}{\sqrt{\pi}} \int_{0}^{x} \exp(-t^2) \, \mathrm{d}t \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The probability density function of the normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-pdf}) is:

\begin{equation} \label{eq:norm-cdf-norm-pdf}
f_X(x) = \frac{1}{\sqrt{2 \pi} \sigma} \cdot \exp \left[ -\frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right] \; .
\end{equation}

Thus, the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) is:

\begin{equation} \label{eq:norm-cdf-norm-cdf-s1}
\begin{split}
F_X(x) &= \int_{-\infty}^{x} \mathcal{N}(z; \mu, \sigma^2) \, \mathrm{d}z \\
&= \int_{-\infty}^{x} \frac{1}{\sqrt{2 \pi} \sigma} \cdot \exp \left[ -\frac{1}{2} \left( \frac{z-\mu}{\sigma} \right)^2 \right] \, \mathrm{d}z \\
&= \frac{1}{\sqrt{2 \pi} \sigma} \int_{-\infty}^{x} \exp \left[ -\left( \frac{z-\mu}{\sqrt{2} \sigma} \right)^2 \right] \, \mathrm{d}z \; .
\end{split}
\end{equation}

Substituting $t = (z-\mu)/(\sqrt{2} \sigma)$, i.e. $z = \sqrt{2} \sigma t + \mu$, this becomes:

\begin{equation} \label{eq:norm-cdf-norm-cdf-s2}
\begin{split}
F_X(x) &= \frac{1}{\sqrt{2 \pi} \sigma} \int_{(-\infty-\mu)/(\sqrt{2} \sigma)}^{(x-\mu)/(\sqrt{2} \sigma)} \exp(-t^2) \, \mathrm{d}\left( \sqrt{2} \sigma t + \mu \right) \\
&= \frac{\sqrt{2} \sigma}{\sqrt{2 \pi} \sigma} \int_{-\infty}^{\frac{x-\mu}{\sqrt{2} \sigma}} \exp(-t^2) \, \mathrm{d}t \\
&= \frac{1}{\sqrt{\pi}} \int_{-\infty}^{\frac{x-\mu}{\sqrt{2} \sigma}} \exp(-t^2) \, \mathrm{d}t \\
&= \frac{1}{\sqrt{\pi}} \int_{-\infty}^{0} \exp(-t^2) \, \mathrm{d}t + \frac{1}{\sqrt{\pi}} \int_{0}^{\frac{x-\mu}{\sqrt{2} \sigma}} \exp(-t^2) \, \mathrm{d}t \\
&= \frac{1}{\sqrt{\pi}} \int_{0}^{\infty} \exp(-t^2) \, \mathrm{d}t + \frac{1}{\sqrt{\pi}} \int_{0}^{\frac{x-\mu}{\sqrt{2} \sigma}} \exp(-t^2) \, \mathrm{d}t \; .
\end{split}
\end{equation}

Applying \eqref{eq:norm-cdf-erf} to \eqref{eq:norm-cdf-norm-cdf-s2}, we have:

\begin{equation} \label{eq:norm-cdf-norm-cdf-s3}
\begin{split}
F_X(x) &= \frac{1}{2} \lim_{x \to \infty} \mathrm{erf}(x) + \frac{1}{2} \, \mathrm{erf}\left( \frac{x-\mu}{\sqrt{2} \sigma} \right) \\
&= \frac{1}{2} + \frac{1}{2} \, \mathrm{erf}\left( \frac{x-\mu}{\sqrt{2} \sigma} \right) \\
&= \frac{1}{2} \left[ 1 + \mathrm{erf}\left( \frac{x-\mu}{\sqrt{2} \sigma} \right) \right] \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Normal distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-03-20; URL: \url{https://en.wikipedia.org/wiki/Normal_distribution#Cumulative_distribution_function}.
\item Wikipedia (2020): "Error function"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-03-20; URL: \url{https://en.wikipedia.org/wiki/Error_function}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P85 | shortcut: norm-cdf | author: JoramSoch | date: 2020-03-20, 01:33.
\vspace{1em}



\subsubsection[\textbf{Cumulative distribution function without error function}]{Cumulative distribution function without error function} \label{sec:norm-cdfwerf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}):

\begin{equation} \label{eq:norm-cdfwerf-norm}
X \sim \mathcal{N}(\mu, \sigma^2) \; .
\end{equation}

Then, the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) of $X$ can be expressed as

\begin{equation} \label{eq:norm-cdfwerf-norm-cdf}
f_X(x) = \Phi_{\mu,\sigma}(x) = \varphi\left( \frac{x-\mu}{\sigma} \right) \cdot \sum_{i=1}^{\infty} \frac{\left( \frac{x-\mu}{\sigma} \right)^{2i-1}}{(2i-1)!!} + \frac{1}{2}
\end{equation}

where $\varphi(x)$ is the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of the standard normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:snorm}) and $n!!$ is a double factorial.


\vspace{1em}
\textbf{Proof:}

1) First, consider the standard normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:snorm}) $\mathcal{N}(0, 1)$ which has the probability density function ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-pdf})

\begin{equation} \label{eq:norm-cdfwerf-snorm-pdf}
\varphi(x) = \frac{1}{\sqrt{2 \pi}} \cdot e^{-\frac{1}{2} x^2} \; .
\end{equation}

Let $T(x)$ be the indefinite integral of this function. It can be obtained using infinitely repeated integration by parts as follows:

\begin{equation} \label{eq:norm-cdfwerf-snorm-pdf-ii-s1}
\begin{split}
T(x) &= \int \varphi(x) \, \mathrm{d}x \\
&= \int \frac{1}{\sqrt{2 \pi}} \cdot e^{-\frac{1}{2} x^2} \, \mathrm{d}x \\
&= \frac{1}{\sqrt{2 \pi}} \int 1 \cdot e^{-\frac{1}{2} x^2} \, \mathrm{d}x \\
&= \frac{1}{\sqrt{2 \pi}} \cdot \left[ x \cdot e^{-\frac{1}{2} x^2} + \int x^2 \cdot e^{-\frac{1}{2} x^2} \, \mathrm{d}x \right] \\
&= \frac{1}{\sqrt{2 \pi}} \cdot \left[ x \cdot e^{-\frac{1}{2} x^2} + \left[ \frac{1}{3} x^3 \cdot e^{-\frac{1}{2} x^2} + \int \frac{1}{3} x^4 \cdot e^{-\frac{1}{2} x^2} \, \mathrm{d}x \right] \right] \\
&= \frac{1}{\sqrt{2 \pi}} \cdot \left[ x \cdot e^{-\frac{1}{2} x^2} + \left[ \frac{1}{3} x^3 \cdot e^{-\frac{1}{2} x^2} + \left[ \frac{1}{15} x^5 \cdot e^{-\frac{1}{2} x^2} + \int \frac{1}{15} x^6 \cdot e^{-\frac{1}{2} x^2} \, \mathrm{d}x \right] \right] \right] \\
&= \ldots \\
&= \frac{1}{\sqrt{2 \pi}} \cdot \left[ \sum_{i=1}^{n} \left( \frac{x^{2i-1}}{(2i-1)!!} \cdot e^{-\frac{1}{2} x^2} \right) + \int \left( \frac{x^{2n}}{(2n-1)!!} \cdot e^{-\frac{1}{2} x^2} \right) \, \mathrm{d}x \right] \\
&= \frac{1}{\sqrt{2 \pi}} \cdot \left[ \sum_{i=1}^{\infty} \left( \frac{x^{2i-1}}{(2i-1)!!} \cdot e^{-\frac{1}{2} x^2} \right) + \lim_{n \to \infty} \int \left( \frac{x^{2n}}{(2n-1)!!} \cdot e^{-\frac{1}{2} x^2} \right) \, \mathrm{d}x \right] \; .
\end{split}
\end{equation}

Since $(2n-1)!!$ grows faster than $x^{2n}$, it holds that

\begin{equation} \label{eq:norm-cdfwerf-int-const}
\frac{1}{\sqrt{2 \pi}} \cdot \lim_{n \to \infty} \int \left( \frac{x^{2n}}{(2n-1)!!} \cdot e^{-\frac{1}{2} x^2} \right) \, \mathrm{d}x = \int 0 \, \mathrm{d}x = c
\end{equation}

for constant $c$, such that the indefinite integral becomes

\begin{equation} \label{eq:norm-cdfwerf-snorm-pdf-ii-s2}
\begin{split}
T(x) &= \frac{1}{\sqrt{2 \pi}} \cdot \sum_{i=1}^{\infty} \left( \frac{x^{2i-1}}{(2i-1)!!} \cdot e^{-\frac{1}{2} x^2} \right) + c \\
&= \frac{1}{\sqrt{2 \pi}} \cdot e^{-\frac{1}{2} x^2} \cdot \sum_{i=1}^{\infty} \frac{x^{2i-1}}{(2i-1)!!} + c \\
&\overset{\eqref{eq:norm-cdfwerf-snorm-pdf}}{=} \varphi(x) \cdot \sum_{i=1}^{\infty} \frac{x^{2i-1}}{(2i-1)!!} + c \; .
\end{split}
\end{equation}

2) Next, let $\Phi(x)$ be the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) of the standard normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:snorm}):

\begin{equation} \label{eq:norm-cdfwerf-snorm-cdf}
\Phi(x) = \int_{-\infty}^x \varphi(x) \, \mathrm{d}x \; .
\end{equation}

It can be obtained by matching $T(0)$ to $\Phi(0)$ which is $1/2$, because the standard normal distribution is symmetric around zero:

\begin{equation} \label{eq:norm-cdfwerf-snorm-cdf-c}
\begin{split}
T(0) = \varphi(0) \cdot \sum_{i=1}^{\infty} \frac{0^{2i-1}}{(2i-1)!!} + c &= \frac{1}{2} = \Phi(0) \\
\Leftrightarrow c &= \frac{1}{2} \\
\Rightarrow \Phi(x) = \varphi(x) \cdot \sum_{i=1}^{\infty} \frac{x^{2i-1}}{(2i-1)!!} + \frac{1}{2} \! &\; .
\end{split}
\end{equation}

3) Finally, the cumulative distribution functions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) of the standard normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:snorm}) and the general normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}) are related to each other ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-snorm}) as

\begin{equation} \label{eq:norm-cdfwerf-norm-snorm-cdf}
\Phi_{\mu,\sigma}(x) = \Phi\left( \frac{x-\mu}{\sigma} \right) \; .
\end{equation}

Combining \eqref{eq:norm-cdfwerf-norm-snorm-cdf} with \eqref{eq:norm-cdfwerf-snorm-cdf-c}, we have:

\begin{equation} \label{eq:norm-cdfwerf-norm-cdf-qed}
\Phi_{\mu,\sigma}(x) = \varphi\left( \frac{x-\mu}{\sigma} \right) \cdot \sum_{i=1}^{\infty} \frac{\left( \frac{x-\mu}{\sigma} \right)^{2i-1}}{(2i-1)!!} + \frac{1}{2} \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Soch J (2015): "Solution for the Indefinite Integral of the Standard Normal Probability Density Function"; in: \textit{arXiv stat.OT}, arXiv:1512.04858; URL: \url{https://arxiv.org/abs/1512.04858}.
\item Wikipedia (2020): "Normal distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-03-20; URL: \url{https://en.wikipedia.org/wiki/Normal_distribution#Cumulative_distribution_function}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P86 | shortcut: norm-cdfwerf | author: JoramSoch | date: 2020-03-20, 04:26.
\vspace{1em}



\subsubsection[\textbf{Quantile function}]{Quantile function} \label{sec:norm-qf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a normal distributions ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}):

\begin{equation} \label{eq:norm-qf-norm}
X \sim \mathcal{N}(\mu, \sigma^2) \; .
\end{equation}

Then, the quantile function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:qf}) of $X$ is

\begin{equation} \label{eq:norm-qf-norm-qf}
Q_X(p) = \sqrt{2}\sigma \cdot \mathrm{erf}^{-1}(2p-1) + \mu
\end{equation}

where $\mathrm{erf}^{-1}(x)$ is the inverse error function.


\vspace{1em}
\textbf{Proof:} The cumulative distribution function of the normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-cdf}) is:

\begin{equation} \label{eq:norm-qf-norm-cdf}
F_X(x) = \frac{1}{2} \left[ 1 + \mathrm{erf}\left( \frac{x-\mu}{\sqrt{2} \sigma} \right) \right] \; .
\end{equation}

Because the cumulative distribution function (CDF) is strictly monotonically increasing, the quantile function is equal to the inverse of the CDF ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:qf-cdf}):

\begin{equation} \label{eq:norm-qf-norm-qf-s1}
Q_X(p) = F_X^{-1}(x) \; .
\end{equation}

This can be derived by rearranging equation \eqref{eq:norm-qf-norm-cdf}:

\begin{equation} \label{eq:norm-qf-norm-qf-s2}
\begin{split}
p &= \frac{1}{2} \left[ 1 + \mathrm{erf}\left( \frac{x-\mu}{\sqrt{2} \sigma} \right) \right] \\
2 p - 1 &= \mathrm{erf}\left( \frac{x-\mu}{\sqrt{2} \sigma} \right) \\
\mathrm{erf}^{-1}(2p-1) &= \frac{x-\mu}{\sqrt{2} \sigma} \\
x &= \sqrt{2}\sigma \cdot \mathrm{erf}^{-1}(2p-1) + \mu \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Normal distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-03-20; URL: \url{https://en.wikipedia.org/wiki/Normal_distribution#Quantile_function}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P87 | shortcut: norm-qf | author: JoramSoch | date: 2020-03-20, 04:47.
\vspace{1em}



\subsubsection[\textbf{Mean}]{Mean} \label{sec:norm-mean}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}):

\begin{equation} \label{eq:norm-mean-norm}
X \sim \mathcal{N}(\mu, \sigma^2) \; .
\end{equation}

Then, the mean or expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of $X$ is

\begin{equation} \label{eq:norm-mean-norm-mean}
\mathrm{E}(X) = \mu \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) is the probability-weighted average over all possible values:

\begin{equation} \label{eq:norm-mean-mean}
\mathrm{E}(X) = \int_{\mathcal{X}} x \cdot f_X(x) \, \mathrm{d}x \; .
\end{equation}

With the probability density function of the normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-pdf}), this reads:

\begin{equation} \label{eq:norm-mean-norm-mean-s1}
\begin{split}
\mathrm{E}(X) &= \int_{-\infty}^{+\infty} x \cdot \frac{1}{\sqrt{2 \pi} \sigma} \cdot \exp \left[ -\frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right] \, \mathrm{d}x \\
&= \frac{1}{\sqrt{2 \pi} \sigma} \int_{-\infty}^{+\infty} x \cdot \exp \left[ -\frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right] \, \mathrm{d}x \; .
\end{split}
\end{equation}

Substituting $z = x -\mu$, we have:

\begin{equation} \label{eq:norm-mean-norm-mean-s2}
\begin{split}
\mathrm{E}(X) &= \frac{1}{\sqrt{2 \pi} \sigma} \int_{-\infty-\mu}^{+\infty-\mu} (z + \mu) \cdot \exp \left[ -\frac{1}{2} \left( \frac{z}{\sigma} \right)^2 \right] \, \mathrm{d}(z + \mu) \\
&= \frac{1}{\sqrt{2 \pi} \sigma} \int_{-\infty}^{+\infty} (z + \mu) \cdot \exp \left[ -\frac{1}{2} \left( \frac{z}{\sigma} \right)^2 \right] \, \mathrm{d}z \\
&= \frac{1}{\sqrt{2 \pi} \sigma} \left( \int_{-\infty}^{+\infty} z \cdot \exp \left[ -\frac{1}{2} \left( \frac{z}{\sigma} \right)^2 \right] \, \mathrm{d}z + \mu \int_{-\infty}^{+\infty} \exp \left[ -\frac{1}{2} \left( \frac{z}{\sigma} \right)^2 \right] \, \mathrm{d}z \right) \\
&= \frac{1}{\sqrt{2 \pi} \sigma} \left( \int_{-\infty}^{+\infty} z \cdot \exp \left[ -\frac{1}{2 \sigma^2} \cdot z^2 \right] \, \mathrm{d}z + \mu \int_{-\infty}^{+\infty} \exp \left[ -\frac{1}{2 \sigma^2} \cdot z^2 \right] \, \mathrm{d}z \right) \; .
\end{split}
\end{equation}

The general antiderivatives are

\begin{equation} \label{eq:norm-mean-exp-erf-anti-der}
\begin{split}
\int x \cdot \exp \left[ -a x^2 \right] \mathrm{d}x &= -\frac{1}{2a} \cdot \exp \left[ -a x^2 \right] \\
\int \exp \left[ -a x^2 \right] \mathrm{d}x &= \frac{1}{2} \sqrt{\frac{\pi}{a}} \cdot \mathrm{erf} \left[ \sqrt{a} x \right]
\end{split}
\end{equation}

where $\mathrm{erf}(x)$ is the error function. Using this, the integrals can be calculated as:

\begin{equation} \label{eq:norm-mean-norm-mean-s3}
\begin{split}
\mathrm{E}(X) &= \frac{1}{\sqrt{2 \pi} \sigma} \left( \left[ -\sigma^2 \cdot \exp \left[ -\frac{1}{2 \sigma^2} \cdot z^2 \right] \right]_{-\infty}^{+\infty} + \mu \left[ \sqrt{\frac{\pi}{2}} \sigma \cdot \mathrm{erf} \left[ \frac{1}{\sqrt{2} \sigma} z \right] \right]_{-\infty}^{+\infty} \right) \\
&= \frac{1}{\sqrt{2 \pi} \sigma} \left( \left[ \lim_{z \to \infty} \left( -\sigma^2 \cdot \exp \left[ -\frac{1}{2 \sigma^2} \cdot z^2 \right] \right) - \lim_{z \to -\infty} \left( -\sigma^2 \cdot \exp \left[ -\frac{1}{2 \sigma^2} \cdot z^2 \right] \right) \right] \right. \\
&\hphantom{\sqrt{2 \pi}\sigma \;} + \mu \left. \left[ \lim_{z \to \infty} \left( \sqrt{\frac{\pi}{2}} \sigma \cdot \mathrm{erf} \left[ \frac{1}{\sqrt{2} \sigma} z \right] \right) - \lim_{z \to -\infty} \left( \sqrt{\frac{\pi}{2}} \sigma \cdot \mathrm{erf} \left[ \frac{1}{\sqrt{2} \sigma} z \right] \right) \right] \right) \\
&= \frac{1}{\sqrt{2 \pi} \sigma} \left( [0 - 0] + \mu \left[ \sqrt{\frac{\pi}{2}} \sigma - \left(- \sqrt{\frac{\pi}{2}} \sigma \right) \right] \right) \\
&= \frac{1}{\sqrt{2 \pi} \sigma} \cdot \mu \cdot 2 \sqrt{\frac{\pi}{2}} \sigma \\
&= \mu \; .
\end{split}
\end{equation}



\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Papadopoulos, Alecos (2013): "How to derive the mean and variance of Gaussian random variable?"; in: \textit{StackExchange Mathematics}, retrieved on 2020-01-09; URL: \url{https://math.stackexchange.com/questions/518281/how-to-derive-the-mean-and-variance-of-a-gaussian-random-variable}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P15 | shortcut: norm-mean | author: JoramSoch | date: 2020-01-09, 15:04.
\vspace{1em}



\subsubsection[\textbf{Median}]{Median} \label{sec:norm-med}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}):

\begin{equation} \label{eq:norm-med-norm}
X \sim \mathcal{N}(\mu, \sigma^2) \; .
\end{equation}

Then, the median ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:med}) of $X$ is

\begin{equation} \label{eq:norm-med-norm-median}
\mathrm{median}(X) = \mu \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The median ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:med}) is the value at which the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) is $1/2$:

\begin{equation} \label{eq:norm-med-median}
F_X(\mathrm{median}(X)) = \frac{1}{2} \; .
\end{equation}

The cumulative distribution function of the normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-cdf}) is

\begin{equation} \label{eq:norm-med-norm-cdf}
F_X(x) = \frac{1}{2} \left[ 1 + \mathrm{erf} \left( \frac{x-\mu}{\sqrt{2}\sigma} \right) \right]
\end{equation}

where $\mathrm{erf}(x)$ is the error function. Thus, the inverse CDF is

\begin{equation} \label{eq:norm-med-norm-cdf-inv}
x = \sqrt{2}\sigma \cdot \mathrm{erf}^{-1}(2p-1) + \mu
\end{equation}

where $\mathrm{erf}^{-1}(x)$ is the inverse error function. Setting $p = 1/2$, we obtain:

\begin{equation} \label{eq:norm-med-norm-med-qed}
\mathrm{median}(X) = \sqrt{2}\sigma \cdot \mathrm{erf}^{-1}(0) + \mu = \mu \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P16 | shortcut: norm-med | author: JoramSoch | date: 2020-01-09, 15:33.
\vspace{1em}



\subsubsection[\textbf{Mode}]{Mode} \label{sec:norm-mode}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}):

\begin{equation} \label{eq:norm-mode-norm}
X \sim \mathcal{N}(\mu, \sigma^2) \; .
\end{equation}

Then, the mode ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mode}) of $X$ is

\begin{equation} \label{eq:norm-mode-norm-mode}
\mathrm{mode}(X) = \mu \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The mode ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mode}) is the value which maximizes the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}):

\begin{equation} \label{eq:norm-mode-mode}
\mathrm{mode}(X) = \operatorname*{arg\,max}_x f_X(x) \; .
\end{equation}

The probability density function of the normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-pdf}) is:

\begin{equation} \label{eq:norm-mode-norm-pdf}
f_X(x) = \frac{1}{\sqrt{2 \pi} \sigma} \cdot \exp \left[ -\frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right] \; .
\end{equation}

The first two deriatives of this function are:

\begin{equation} \label{eq:norm-mode-norm-pdf-der1}
f'_X(x) = \frac{\mathrm{d}f_X(x)}{\mathrm{d}x} = \frac{1}{\sqrt{2 \pi} \sigma^3} \cdot (-x + \mu) \cdot \exp \left[ -\frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right]
\end{equation}

\begin{equation} \label{eq:norm-mode-norm-pdf-der2}
f''_X(x) = \frac{\mathrm{d}^2f_X(x)}{\mathrm{d}x^2} = -\frac{1}{\sqrt{2 \pi} \sigma^3} \cdot \exp \left[ -\frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right] + \frac{1}{\sqrt{2 \pi} \sigma^5} \cdot (-x + \mu)^2 \cdot \exp \left[ -\frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right] \; .
\end{equation}

We now calculate the root of the first derivative \eqref{eq:norm-mode-norm-pdf-der1}:

\begin{equation} \label{eq:norm-mode-norm-mode-s1}
\begin{split}
f'_X(x) = 0 &= \frac{1}{\sqrt{2 \pi} \sigma^3} \cdot (-x + \mu) \cdot \exp \left[ -\frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right] \\
0 &= -x + \mu \\
x &= \mu \; .
\end{split}
\end{equation}

By plugging this value into the second deriative \eqref{eq:norm-mode-norm-pdf-der2},

\begin{equation} \label{eq:norm-mode-norm-mode-s2}
\begin{split}
f''_X(\mu) &= -\frac{1}{\sqrt{2 \pi} \sigma^3} \cdot \exp(0) + \frac{1}{\sqrt{2 \pi} \sigma^5} \cdot (0)^2 \cdot \exp(0) \\
&= -\frac{1}{\sqrt{2 \pi} \sigma^3} < 0 \; ,
\end{split}
\end{equation}

we confirm that it is in fact a maximum which shows that

\begin{equation} \label{eq:norm-mode-norm-mode-qed}
\mathrm{mode}(X) = \mu \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P17 | shortcut: norm-mode | author: JoramSoch | date: 2020-01-09, 15:58.
\vspace{1em}



\subsubsection[\textbf{Variance}]{Variance} \label{sec:norm-var}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}):

\begin{equation} \label{eq:norm-var-norm}
X \sim \mathcal{N}(\mu, \sigma^2) \; .
\end{equation}

Then, the variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) of $X$ is

\begin{equation} \label{eq:norm-var-norm-var}
\mathrm{Var}(X) = \sigma^2 \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) is the probability-weighted average of the squared deviation from the mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}):

\begin{equation} \label{eq:norm-var-var}
\mathrm{Var}(X) = \int_{\mathbb{R}} (x - \mathrm{E}(X))^2 \cdot f_\mathrm{X}(x) \, \mathrm{d}x \; .
\end{equation}

With the expected value ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-mean}) and probability density function ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-pdf}) of the normal distribution, this reads:

\begin{equation} \label{eq:norm-var-norm-var-s1}
\begin{split}
\mathrm{Var}(X) &= \int_{-\infty}^{+\infty} (x - \mu)^2 \cdot \frac{1}{\sqrt{2 \pi} \sigma} \cdot \exp \left[ -\frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right] \, \mathrm{d}x \\
&= \frac{1}{\sqrt{2 \pi} \sigma} \int_{-\infty}^{+\infty} (x - \mu)^2 \cdot \exp \left[ -\frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right] \, \mathrm{d}x \; .
\end{split}
\end{equation}

Substituting $z = x -\mu$, we have:

\begin{equation} \label{eq:norm-var-norm-var-s2}
\begin{split}
\mathrm{Var}(X) &= \frac{1}{\sqrt{2 \pi} \sigma} \int_{-\infty-\mu}^{+\infty-\mu} z^2 \cdot \exp \left[ -\frac{1}{2} \left( \frac{z}{\sigma} \right)^2 \right] \, \mathrm{d}(z + \mu) \\
&= \frac{1}{\sqrt{2 \pi} \sigma} \int_{-\infty}^{+\infty} z^2 \cdot \exp \left[ -\frac{1}{2} \left( \frac{z}{\sigma} \right)^2 \right] \, \mathrm{d}z \; .
\end{split}
\end{equation}

Now substituting $z = \sqrt{2} \sigma x$, we have:

\begin{equation} \label{eq:norm-var-norm-var-s3}
\begin{split}
\mathrm{Var}(X) &= \frac{1}{\sqrt{2 \pi} \sigma} \int_{-\infty}^{+\infty} (\sqrt{2} \sigma x)^2 \cdot \exp \left[ -\frac{1}{2} \left( \frac{\sqrt{2} \sigma x}{\sigma} \right)^2 \right] \, \mathrm{d}(\sqrt{2} \sigma x) \\
&= \frac{1}{\sqrt{2 \pi} \sigma} \cdot 2 \sigma^2 \cdot \sqrt{2} \sigma \int_{-\infty}^{+\infty} x^2 \cdot \exp \left[ -x^2 \right] \, \mathrm{d}x \\
&= \frac{2 \sigma^2}{\sqrt{\pi}} \int_{-\infty}^{+\infty} x^2 \cdot e^{-x^2} \, \mathrm{d}x \; .
\end{split}
\end{equation}

Since the integrand is symmetric with respect to $x = 0$, we can write:

\begin{equation} \label{eq:norm-var-norm-var-s4}
\mathrm{Var}(X) = \frac{4 \sigma^2}{\sqrt{\pi}} \int_{0}^{\infty} x^2 \cdot e^{-x^2} \, \mathrm{d}x \; .
\end{equation}

If we define $z = x^2$, then $x = \sqrt{z}$ and $\mathrm{d}x = 1/2 \, z^{-1/2} \, \mathrm{d}z$. Substituting this into the integral

\begin{equation} \label{eq:norm-var-norm-var-s5}
\mathrm{Var}(X) = \frac{4 \sigma^2}{\sqrt{\pi}} \int_{0}^{\infty} z \cdot e^{-z} \cdot \frac{1}{2} z^{-\frac{1}{2}} \, \mathrm{d}z = \frac{2 \sigma^2}{\sqrt{\pi}} \int_{0}^{\infty} z^{\frac{3}{2}-1} \cdot e^{-z} \, \mathrm{d}z
\end{equation}

and using the definition of the gamma function

\begin{equation} \label{eq:norm-var-gam-fct}
\Gamma(x) = \int_{0}^{\infty} z^{x-1} \cdot e^{-z} \, \mathrm{d}z \; ,
\end{equation}

we can finally show that

\begin{equation} \label{eq:norm-var-norm-var-s6}
\mathrm{Var}(X) = \frac{2 \sigma^2}{\sqrt{\pi}} \cdot \Gamma\!\left(\frac{3}{2}\right) = \frac{2 \sigma^2}{\sqrt{\pi}} \cdot \frac{\sqrt{\pi}}{2} = \sigma^2 \; .
\end{equation}



\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Papadopoulos, Alecos (2013): "How to derive the mean and variance of Gaussian random variable?"; in: \textit{StackExchange Mathematics}, retrieved on 2020-01-09; URL: \url{https://math.stackexchange.com/questions/518281/how-to-derive-the-mean-and-variance-of-a-gaussian-random-variable}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P18 | shortcut: norm-var | author: JoramSoch | date: 2020-01-09, 22:47.
\vspace{1em}



\subsubsection[\textbf{Full width at half maximum}]{Full width at half maximum} \label{sec:norm-fwhm}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}):

\begin{equation} \label{eq:norm-fwhm-norm}
X \sim \mathcal{N}(\mu, \sigma^2) \; .
\end{equation}

Then, the full width at half maximum ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:fwhm}) (FWHM) of $X$ is

\begin{equation} \label{eq:norm-fwhm-norm-fwhm}
\mathrm{FWHM}(X) = 2 \sqrt{2 \ln 2} \sigma \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The probability density function of the normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-pdf}) is

\begin{equation} \label{eq:norm-fwhm-norm-pdf}
f_X(x) = \frac{1}{\sqrt{2 \pi} \sigma} \cdot \exp \left[ -\frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right]
\end{equation}

and the mode of the normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-mode}) is

\begin{equation} \label{eq:norm-fwhm-norm-mode}
\mathrm{mode}(X) = \mu \; ,
\end{equation}

such that

\begin{equation} \label{eq:norm-fwhm-norm-pdf-max}
f_\mathrm{max} = f_X(\mathrm{mode}(X)) \overset{\eqref{eq:norm-fwhm-norm-mode}}{=} f_X(\mu) \overset{\eqref{eq:norm-fwhm-norm-pdf}}{=} \frac{1}{\sqrt{2 \pi} \sigma} \; .
\end{equation}

The FWHM bounds satisfy the equation ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:fwhm})

\begin{equation} \label{eq:norm-fwhm-x-FHWM}
f_X(x_\mathrm{FWHM}) = \frac{1}{2} f_\mathrm{max} \overset{\eqref{eq:norm-fwhm-norm-pdf-max}}{=} \frac{1}{2 \sqrt{2 \pi} \sigma} \; .
\end{equation}

Using \eqref{eq:norm-fwhm-norm-pdf}, we can develop this equation as follows:

\begin{equation} \label{eq:norm-fwhm-x-FHWM-s1}
\begin{split}
\frac{1}{\sqrt{2 \pi} \sigma} \cdot \exp \left[ -\frac{1}{2} \left( \frac{x_\mathrm{FWHM}-\mu}{\sigma} \right)^2 \right] &= \frac{1}{2 \sqrt{2 \pi} \sigma} \\
\exp \left[ -\frac{1}{2} \left( \frac{x_\mathrm{FWHM}-\mu}{\sigma} \right)^2 \right] &= \frac{1}{2} \\
-\frac{1}{2} \left( \frac{x_\mathrm{FWHM}-\mu}{\sigma} \right)^2 &= \ln \frac{1}{2} \\
\left( \frac{x_\mathrm{FWHM}-\mu}{\sigma} \right)^2 &= -2 \ln \frac{1}{2} \\
\frac{x_\mathrm{FWHM}-\mu}{\sigma} &= \pm \sqrt{2 \ln 2} \\
x_\mathrm{FWHM}-\mu &= \pm \sqrt{2 \ln 2} \sigma \\
x_\mathrm{FWHM} &= \pm \sqrt{2 \ln 2} \sigma + \mu \; .
\end{split}
\end{equation}

This implies the following two solutions for $x_\mathrm{FWHM}$

\begin{equation} \label{eq:norm-fwhm-x-FHWM-s2}
\begin{split}
x_1 &= \mu - \sqrt{2 \ln 2} \sigma \\
x_2 &= \mu + \sqrt{2 \ln 2} \sigma \; ,
\end{split}
\end{equation}

such that the full width at half maximum ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:fwhm}) of $X$ is

\begin{equation} \label{eq:norm-fwhm-norm-fwhm-qed}
\begin{split}
\mathrm{FWHM}(X) &= \Delta x = x_2 - x_1 \\
&\overset{\eqref{eq:norm-fwhm-x-FHWM-s2}}{=} \left( \mu + \sqrt{2 \ln 2} \sigma \right) - \left( \mu - \sqrt{2 \ln 2} \sigma \right) \\
&= 2 \sqrt{2 \ln 2} \sigma \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Full width at half maximum"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-08-19; URL: \url{https://en.wikipedia.org/wiki/Full_width_at_half_maximum}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P152 | shortcut: norm-fwhm | author: JoramSoch | date: 2020-08-19, 06:39.
\vspace{1em}



\subsubsection[\textbf{Extreme points}]{Extreme points} \label{sec:norm-extr}
\setcounter{equation}{0}

\textbf{Theorem:} The probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of the normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}) with mean $\mu$ and variance $\sigma^2$ has a maximum at $x = \mu$ and no other extrema. Consequently, the normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}) is a unimodal probability distribution ($\rightarrow$ Definition "dist-uni").


\vspace{1em}
\textbf{Proof:} The probability density function of the normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-pdf}) is:

\begin{equation} \label{eq:norm-extr-norm-pdf}
f_X(x) = \frac{1}{\sqrt{2 \pi} \sigma} \cdot \exp \left[ -\frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right] \; .
\end{equation}

The first two deriatives of this function ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-mode}) are:

\begin{equation} \label{eq:norm-extr-norm-pdf-der1}
f'_X(x) = \frac{\mathrm{d}f_X(x)}{\mathrm{d}x} = \frac{1}{\sqrt{2 \pi} \sigma^3} \cdot (-x + \mu) \cdot \exp \left[ -\frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right]
\end{equation}

\begin{equation} \label{eq:norm-extr-norm-pdf-der2}
f''_X(x) = \frac{\mathrm{d}^2f_X(x)}{\mathrm{d}x^2} = -\frac{1}{\sqrt{2 \pi} \sigma^3} \cdot \exp \left[ -\frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right] + \frac{1}{\sqrt{2 \pi} \sigma^5} \cdot (-x + \mu)^2 \cdot \exp \left[ -\frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right] \; .
\end{equation}

The first derivative is zero, if and only if

\begin{equation} \label{eq:norm-extr-norm-pdf-der1-zero}
-x + \mu = 0 \quad \Leftrightarrow \quad x = \mu \; .
\end{equation}

Since the second derivative is negative at this value

\begin{equation} \label{eq:norm-extr-norm-pdf-der2-extr}
f''_X(\mu) = -\frac{1}{\sqrt{2 \pi} \sigma^3} < 0 \; ,
\end{equation}

there is a maximum at $x = \mu$. From \eqref{eq:norm-extr-norm-pdf-der1}, it can be seen that $f'_X(x)$ is positive for $x < \mu$ and negative for $x > \mu$. Thus, there are no further extrema and $\mathcal{N}(\mu, \sigma^2)$ is unimodal ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-mode}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Normal distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-08-25; URL: \url{https://en.wikipedia.org/wiki/Normal_distribution#Symmetries_and_derivatives}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P251 | shortcut: norm-extr | author: JoramSoch | date: 2020-08-25, 21:11.
\vspace{1em}



\subsubsection[\textbf{Inflection points}]{Inflection points} \label{sec:norm-infl}
\setcounter{equation}{0}

\textbf{Theorem:} The probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of the normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}) with mean $\mu$ and variance $\sigma^2$ has two inflection points at $x = \mu - \sigma$ and $x = \mu + \sigma$, i.e. exactly one standard deviation ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:std}) away from the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}).


\vspace{1em}
\textbf{Proof:} The probability density function of the normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-pdf}) is:

\begin{equation} \label{eq:norm-infl-norm-pdf}
f_X(x) = \frac{1}{\sqrt{2 \pi} \sigma} \cdot \exp \left[ -\frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right] \; .
\end{equation}

The first three deriatives of this function are:

\begin{equation} \label{eq:norm-infl-norm-pdf-der1}
f'_X(x) = \frac{\mathrm{d}f_X(x)}{\mathrm{d}x} = \frac{1}{\sqrt{2 \pi} \sigma} \cdot \left( - \frac{x - \mu}{\sigma^2} \right) \cdot \exp \left[ -\frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right]
\end{equation}

\begin{equation} \label{eq:norm-infl-norm-pdf-der2}
\begin{split}
f''_X(x) = \frac{\mathrm{d}^2f_X(x)}{\mathrm{d}x^2} &= \frac{1}{\sqrt{2 \pi} \sigma} \cdot \left( - \frac{1}{\sigma^2} \right) \cdot \exp \left[ -\frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right] + \frac{1}{\sqrt{2 \pi} \sigma} \cdot \left( \frac{x-\mu}{\sigma^2} \right)^2 \cdot \exp \left[ -\frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right] \\
&= \frac{1}{\sqrt{2 \pi} \sigma} \cdot \left[ \left( \frac{x-\mu}{\sigma^2} \right)^2 - \frac{1}{\sigma^2} \right] \cdot \exp \left[ -\frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right]
\end{split}
\end{equation}

\begin{equation} \label{eq:norm-infl-norm-pdf-der3}
\begin{split}
f'''_X(x) = \frac{\mathrm{d}^3f_X(x)}{\mathrm{d}x^3} &= \frac{1}{\sqrt{2 \pi} \sigma} \cdot \left[ \frac{2}{\sigma^2} \left( \frac{x-\mu}{\sigma^2} \right) \right] \cdot \exp \left[ -\frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right] - \frac{1}{\sqrt{2 \pi} \sigma} \cdot \left[ \left( \frac{x-\mu}{\sigma^2} \right)^2 - \frac{1}{\sigma^2} \right] \cdot \left( \frac{x - \mu}{\sigma^2}  \right) \cdot \exp \left[ -\frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right] \\
&= \frac{1}{\sqrt{2 \pi} \sigma} \cdot \left[ -\left( \frac{x - \mu}{\sigma^2} \right)^3 + 3 \left( \frac{x - \mu}{\sigma^4} \right) \right] \cdot \exp \left[ -\frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right] \; .
\end{split}
\end{equation}

The second derivative is zero, if and only if

\begin{equation} \label{eq:norm-infl-norm-pdf-der2-zero}
\begin{split}
0 &= \left[ \left( \frac{x-\mu}{\sigma^2} \right)^2 - \frac{1}{\sigma^2} \right] \\
0 &= \frac{x^2}{\sigma^4} - \frac{2 \mu x}{\sigma^4} + \frac{\mu^2}{\sigma^4} - \frac{1}{\sigma^2} \\
0 &= x^2 - 2 \mu x + (\mu^2 - \sigma^2) \\
x_{1/2} &= -\frac{-2 \mu}{2} \pm \sqrt{ \left(\frac{-2 \mu}{2}\right)^2 - (\mu^2 - \sigma^2)} \\
x_{1/2} &= \mu \pm \sqrt{ \mu^2 - \mu^2 + \sigma^2} \\
x_{1/2} &= \mu \pm \sigma \; .
\end{split}
\end{equation}

Since the third derivative is non-zero at this value

\begin{equation} \label{eq:norm-infl-norm-pdf-der3-infl}
\begin{split}
f'''_X(\mu \pm \sigma) &= \frac{1}{\sqrt{2 \pi} \sigma} \cdot \left[ -\left( \frac{\pm \sigma}{\sigma^2} \right)^3 + 3 \left( \frac{\pm \sigma}{\sigma^4} \right) \right] \cdot \exp \left[ -\frac{1}{2} \left( \frac{\pm \sigma}{\sigma} \right)^2 \right] \\
&= \frac{1}{\sqrt{2 \pi} \sigma} \cdot \left( \pm \frac{2}{\sigma^3} \right) \cdot \exp \left( - \frac{1}{2} \right) \neq 0 \; ,
\end{split}
\end{equation}

there are inflection points at $x_{1/2} = \mu \pm \sigma$. Because $\mu$ is the mean and $\sigma^2$ is the variance of a normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}), these points are exactly one standard deviation ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:std}) away from the mean.



\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Normal distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-08-25; URL: \url{https://en.wikipedia.org/wiki/Normal_distribution#Symmetries_and_derivatives}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P252 | shortcut: norm-infl | author: JoramSoch | date: 2020-08-26, 12:26.
\vspace{1em}



\subsubsection[\textbf{Differential entropy}]{Differential entropy} \label{sec:norm-dent}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}):

\begin{equation} \label{eq:norm-dent-norm}
X \sim \mathcal{N}(\mu, \sigma^2) \; .
\end{equation}

Then, the differential entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent}) of $X$ is

\begin{equation} \label{eq:norm-dent-norm-dent}
\mathrm{h}(X) = \frac{1}{2} \ln\left( 2 \pi \sigma^2 e \right) \; .
\end{equation}

\vspace{1em}
\textbf{Proof:} The differential entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent}) of a random variable is defined as

\begin{equation} \label{eq:norm-dent-dent}
\mathrm{h}(X) = - \int_{\mathcal{X}} p(x) \, \log_b p(x) \, \mathrm{d}x \; .
\end{equation}

To measure $h(X)$ in nats, we set $b = e$, such that ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean})

\begin{equation} \label{eq:norm-dent-dent-nats}
\mathrm{h}(X) = - \mathrm{E}\left[ \ln p(x) \right] \; .
\end{equation}

With the probability density function of the normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-pdf}), the differential entropy of $X$ is:

\begin{equation} \label{eq:norm-dent-norm-dent-qed}
\begin{split}
\mathrm{h}(X) &= - \mathrm{E}\left[ \ln \left( \frac{1}{\sqrt{2 \pi} \sigma} \cdot \exp \left[ -\frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right] \right) \right] \\
&= - \mathrm{E}\left[ - \frac{1}{2} \ln(2\pi\sigma^2) - \frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right] \\
&= \frac{1}{2} \ln(2 \pi \sigma^2) + \frac{1}{2} \, \mathrm{E}\left[ \left( \frac{x-\mu}{\sigma} \right)^2 \right] \\
&= \frac{1}{2} \ln(2 \pi \sigma^2) + \frac{1}{2} \cdot \frac{1}{\sigma^2} \cdot \mathrm{E}\left[ (x-\mu)^2 \right] \\
&= \frac{1}{2} \ln(2 \pi \sigma^2) + \frac{1}{2} \cdot \frac{1}{\sigma^2} \cdot \sigma^2 \\
&= \frac{1}{2} \ln(2 \pi \sigma^2) + \frac{1}{2} \\
&= \frac{1}{2} \ln(2 \pi \sigma^2 e) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wang, Peng-Hua (2012): "Differential Entropy"; in: \textit{National Taipei University}; URL: \url{https://web.ntpu.edu.tw/~phwang/teaching/2012s/IT/slides/chap08.pdf}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P101 | shortcut: norm-dent | author: JoramSoch | date: 2020-05-14, 20:09.
\vspace{1em}



\subsubsection[\textbf{Kullback-Leibler divergence}]{Kullback-Leibler divergence} \label{sec:norm-kl}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}). Assume two normal distributions ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}) $P$ and $Q$ specifying the probability distribution of $X$ as

\begin{equation} \label{eq:norm-kl-norms}
\begin{split}
P: \; X &\sim \mathcal{N}(\mu_1, \sigma_1^2) \\
Q: \; X &\sim \mathcal{N}(\mu_2, \sigma_2^2) \; .
\end{split}
\end{equation}

Then, the Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) of $P$ from $Q$ is given by

\begin{equation} \label{eq:norm-kl-norm-KL}
\mathrm{KL}[P\,||\,Q] = \frac{1}{2} \left[ \frac{(\mu_2 - \mu_1)^2}{\sigma_2^2} + \frac{\sigma_1^2}{\sigma_2^2} - \ln \frac{\sigma_1^2}{\sigma_2^2} - 1 \right] \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The KL divergence for a continuous random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) is given by 

\begin{equation} \label{eq:norm-kl-KL-cont}
\mathrm{KL}[P\,||\,Q] = \int_{\mathcal{X}} p(x) \, \ln \frac{p(x)}{q(x)} \, \mathrm{d}x
\end{equation}

which, applied to the normal distributions ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}) in \eqref{eq:norm-kl-norms}, yields

\begin{equation} \label{eq:norm-kl-norm-KL-s1}
\begin{split}
\mathrm{KL}[P\,||\,Q] &= \int_{-\infty}^{+\infty} \mathcal{N}(x; \mu_1, \sigma_1^2) \, \ln \frac{\mathcal{N}(x; \mu_1, \sigma_1^2)}{\mathcal{N}(x; \mu_2, \sigma_2^2)} \, \mathrm{d}x \\
&= \left\langle \ln \frac{\mathcal{N}(x; \mu_1, \sigma_1^2)}{\mathcal{N}(x; \mu_2, \sigma_2^2)} \right\rangle_{p(x)} \; .
\end{split}
\end{equation}

Using the probability density function of the normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-pdf}), this becomes:

\begin{equation} \label{eq:norm-kl-norm-KL-s2}
\begin{split}
\mathrm{KL}[P\,||\,Q] &= \left\langle \ln \frac{ \frac{1}{\sqrt{2 \pi} \sigma_1} \cdot \exp \left[ -\frac{1}{2} \left( \frac{x-\mu_1}{\sigma_1} \right)^2 \right] }{ \frac{1}{\sqrt{2 \pi} \sigma_2} \cdot \exp \left[ -\frac{1}{2} \left( \frac{x-\mu_2}{\sigma_2} \right)^2 \right] } \right\rangle_{p(x)} \\
&= \left\langle \ln \left( \sqrt \frac{\sigma_2^2}{\sigma_1^2} \cdot \exp\left[ -\frac{1}{2} \left( \frac{x-\mu_1}{\sigma_1} \right)^2 + \frac{1}{2} \left( \frac{x-\mu_2}{\sigma_2} \right)^2 \right] \right) \right\rangle_{p(x)} \\
&= \left\langle \frac{1}{2} \ln \frac{\sigma_2^2}{\sigma_1^2} -\frac{1}{2} \left( \frac{x-\mu_1}{\sigma_1} \right)^2 + \frac{1}{2} \left( \frac{x-\mu_2}{\sigma_2} \right)^2 \right\rangle_{p(x)} \\
&= \frac{1}{2} \left\langle - \left( \frac{x-\mu_1}{\sigma_1} \right)^2 + \left( \frac{x-\mu_2}{\sigma_2} \right)^2 - \ln \frac{\sigma_1^2}{\sigma_2^2} \right\rangle_{p(x)} \\
&= \frac{1}{2} \left\langle - \frac{(x-\mu_1)^2}{\sigma_1^2} + \frac{x^2 - 2 \mu_2 x + \mu_2^2}{\sigma_2^2} - \ln \frac{\sigma_1^2}{\sigma_2^2} \right\rangle_{p(x)} \; .
\end{split}
\end{equation}

Because the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) is a linear operator ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-lin}), the expectation can be moved into the sum:

\begin{equation} \label{eq:norm-kl-norm-KL-s3}
\begin{split}
\mathrm{KL}[P\,||\,Q] &= \frac{1}{2} \left[ - \frac{\left\langle (x-\mu_1)^2 \right\rangle}{\sigma_1^2} + \frac{\left\langle x^2 - 2 \mu_2 x + \mu_2^2 \right\rangle}{\sigma_2^2} - \left\langle \ln \frac{\sigma_1^2}{\sigma_2^2} \right\rangle \right] \\
&= \frac{1}{2} \left[ - \frac{\left\langle (x-\mu_1)^2 \right\rangle}{\sigma_1^2} + \frac{\left\langle x^2 \right\rangle - \left\langle 2 \mu_2 x \right\rangle + \left\langle \mu_2^2 \right\rangle}{\sigma_2^2} - \ln \frac{\sigma_1^2}{\sigma_2^2} \right] \; .
\end{split}
\end{equation}

The first expectation corresponds to the variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var})

\begin{equation} \label{eq:norm-kl-var}
\left\langle (X-\mu)^2 \right\rangle = \mathrm{E}[(X-\mathrm{E}(X))^2] = \mathrm{Var}(X)
\end{equation}

and the variance of a normally distributed random variable ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-var}) is

\begin{equation} \label{eq:norm-kl-norm-var}
X \sim \mathcal{N}(\mu, \sigma^2) \quad \Rightarrow \quad \mathrm{Var}(X) = \sigma^2 \; .
\end{equation}

Additionally applying the raw moments of the normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-mgf})

\begin{equation} \label{eq:norm-kl-norm-mom-raw}
X \sim \mathcal{N}(\mu, \sigma^2) \quad \Rightarrow \quad \left\langle x \right\rangle = \mu \quad \text{and} \quad \left\langle x^2 \right\rangle = \mu^2 + \sigma^2 \; ,
\end{equation}

the Kullback-Leibler divergence in \eqref{eq:norm-kl-norm-KL-s3} becomes

\begin{equation} \label{eq:norm-kl-norm-KL-s4}
\begin{split}
\mathrm{KL}[P\,||\,Q] &= \frac{1}{2} \left[ - \frac{\sigma_1^2}{\sigma_1^2} + \frac{\mu_1^2 + \sigma_1^2 - 2 \mu_2 \mu_1 + \mu_2^2}{\sigma_2^2} - \ln \frac{\sigma_1^2}{\sigma_2^2} \right] \\
&= \frac{1}{2} \left[ \frac{\mu_1^2 - 2 \mu_1 \mu_2 + \mu_2^2}{\sigma_2^2} + \frac{\sigma_1^2}{\sigma_2^2} - \ln \frac{\sigma_1^2}{\sigma_2^2} - 1 \right] \\
&= \frac{1}{2} \left[ \frac{(\mu_1 - \mu_2)^2}{\sigma_2^2} + \frac{\sigma_1^2}{\sigma_2^2} - \ln \frac{\sigma_1^2}{\sigma_2^2} - 1 \right]
\end{split}
\end{equation}

which is equivalent to \eqref{eq:norm-kl-norm-KL}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P193 | shortcut: norm-kl | author: JoramSoch | date: 2020-11-19, 07:08.
\vspace{1em}



\subsubsection[\textbf{Maximum entropy distribution}]{Maximum entropy distribution} \label{sec:norm-maxent}
\setcounter{equation}{0}

\textbf{Theorem:} The normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}) maximizes differential entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent}) for a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with fixed variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}).


\vspace{1em}
\textbf{Proof:} For a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X$ with set of possible values with probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) $f(x)$, the differential entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent}) is defined as:

\begin{equation} \label{eq:norm-maxent-dent}
\mathrm{h}(X) = - \int_{\mathcal{X}} p(x) \log p(x) \, \mathrm{d}x
\end{equation}

Let $g(x)$ be the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of a normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}) with mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) $\mu$ and variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) $\sigma^2$ and let $f(x)$ be an arbitrary probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) with the same variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}). Since differential entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent}) is translation-invariant ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:dent-inv}), we can assume that $f(x)$ has the same mean as $g(x)$.

Consider the Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) of distribution $f(x)$ from distribution $g(x)$ which is non-negative ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:kl-nonneg}):

\begin{equation} \label{eq:norm-maxent-kl-fg}
\begin{split}
0 \leq \mathrm{KL}[f||g] &= \int_{\mathcal{X}} f(x) \log \frac{f(x)}{g(x)} \, \mathrm{d}x \\
&= \int_{\mathcal{X}} f(x) \log f(x) \, \mathrm{d}x - \int_{\mathcal{X}} f(x) \log g(x) \, \mathrm{d}x \\
&\overset{\eqref{eq:norm-maxent-dent}}{=} - \mathrm{h}[f(x)] - \int_{\mathcal{X}} f(x) \log g(x) \, \mathrm{d}x \; .
\end{split}
\end{equation}

By plugging the probability density function of the normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-pdf}) into the second term, we obtain:

\begin{equation} \label{eq:norm-maxent-int-fg-s1}
\begin{split}
\int_{\mathcal{X}} f(x) \log g(x) \, \mathrm{d}x &= \int_{\mathcal{X}} f(x) \log \left( \frac{1}{\sqrt{2 \pi} \sigma} \cdot \exp \left[ -\frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right] \right) \, \mathrm{d}x \\
&= \int_{\mathcal{X}} f(x) \log \left( \frac{1}{\sqrt{2 \pi \sigma^2}} \right) \, \mathrm{d}x + \int_{\mathcal{X}} f(x) \log \left( \exp \left[ -\frac{(x-\mu)^2}{2 \sigma^2} \right] \right) \, \mathrm{d}x \\
&= -\frac{1}{2} \log \left( 2 \pi \sigma^2 \right) \int_{\mathcal{X}} f(x) \, \mathrm{d}x - \frac{\log(e)}{2 \sigma^2} \int_{\mathcal{X}} f(x) (x-\mu)^2 \, \mathrm{d}x \; .
\end{split}
\end{equation}

Because the entire integral over a probability density function is one ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) and the second central moment is equal to the variance ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:momcent-2nd}), we have:

\begin{equation} \label{eq:norm-maxent-int-fg-s2}
\begin{split}
\int_{\mathcal{X}} f(x) \log g(x) \, \mathrm{d}x &= -\frac{1}{2} \log \left( 2 \pi \sigma^2 \right) - \frac{\log(e) \sigma^2}{2 \sigma^2} \\
&= -\frac{1}{2} \left[ \log \left( 2 \pi \sigma^2 \right) + \log(e) \right] \\
&= -\frac{1}{2} \log \left( 2 \pi \sigma^2 e \right) \; .
\end{split}
\end{equation}

This is actually the negative of the differential entropy of the normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-dent}), such that:

\begin{equation} \label{eq:norm-maxent-int-fg-s3}
\int_{\mathcal{X}} f(x) \log g(x) \, \mathrm{d}x = -\mathrm{h}[g(x)] \; .
\end{equation}

Combining \eqref{eq:norm-maxent-kl-fg} with \eqref{eq:norm-maxent-int-fg-s3}, we can show that

\begin{equation} \label{eq:norm-maxent-norm-maxent}
\begin{split}
0 &\leq - \mathrm{h}[f(x)] - \left( -\mathrm{h}[g(x)] \right) \\
\mathrm{h}[g(x)] - \mathrm{h}[f(x)] &\geq 0
\end{split}
\end{equation}

which means that the differential entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent}) of the normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}) $\mathcal{N}(\mu, \sigma^2)$ will be larger than or equal to any other distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist}) with the same variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) $\sigma^2$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Differential entropy"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-08-25; URL: \url{https://en.wikipedia.org/wiki/Differential_entropy#Maximization_in_the_normal_distribution}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P250 | shortcut: norm-maxent | author: JoramSoch | date: 2020-08-25, 08:31.
\vspace{1em}



\subsubsection[\textbf{Linear combination}]{Linear combination} \label{sec:norm-lincomb}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X_1, \ldots, X_n$ be independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}) normally distributed ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}) random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with means ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) $\mu_1, \ldots, \mu_n$ and variances ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) $\sigma^2_1, \ldots, \sigma^2_n$:

\begin{equation} \label{eq:norm-lincomb-norm}
X_i \sim \mathcal{N}(\mu_i, \sigma^2_i) \quad \text{for} \quad i = 1, \ldots, n \; .
\end{equation}

Then, any linear combination of those random variables

\begin{equation} \label{eq:norm-lincomb-lincomb}
Y = \sum_{i=1}^{n} a_i X_i \quad \text{where} \quad a_1, \ldots, a_n \in \mathbb{R}
\end{equation}

also follows a normal distribution

\begin{equation} \label{eq:norm-lincomb-norm-lincomb}
Y \sim \mathcal{N}\left( \sum_{i=1}^{n} a_i \mu_i, \; \sum_{i=1}^{n} a_i^2 \sigma^2_i \right)
\end{equation}

with mean and variance which are functions of the individual means and variances.


\vspace{1em}
\textbf{Proof:} A set of $n$ independent normal random variables $X_1, \ldots, X_n$ is equivalent ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mvn-ind}) to an $n \times 1$ random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}) $x$ following a multivariate normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mvn}) with a diagonal covariance matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:covmat}). Therefore, we can write

\begin{equation} \label{eq:norm-lincomb-norm-mvn}
X_i \sim \mathcal{N}(\mu_i, \sigma^2_i), \; i = 1, \ldots, n \quad \Rightarrow \quad x = \left[ \begin{array}{c} X_1 \\ \vdots \\ X_n \end{array} \right] \sim \mathcal{N}(\mu, \Sigma)
\end{equation}

with mean vector and covariance matrix

\begin{equation} \label{eq:norm-lincomb-mu-Sigma}
\mu = \left[ \begin{array}{c} \mu_1 \\ \vdots \\ \mu_n \end{array} \right] \quad \text{and} \quad \Sigma = \left[ \begin{array}{ccc} \sigma^2_1 & \cdots & 0 \\ \vdots & \ddots & \vdots \\ 0 & \cdots & \sigma^2_n \end{array} \right] = \mathrm{diag}\left( \left[ \sigma^2_1, \ldots, \sigma^2_n \right] \right) \; .
\end{equation}

Thus, we can apply the linear transformation theorem for the multivariate normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mvn-ltt})

\begin{equation} \label{eq:norm-lincomb-mvn-ltt}
x \sim \mathcal{N}(\mu, \Sigma) \quad \Rightarrow \quad y = Ax + b \sim \mathcal{N}(A\mu + b, A \Sigma A^\mathrm{T})
\end{equation}

with the constant matrix and vector

\begin{equation} \label{eq:norm-lincomb-A-b}
A = \left[ a_1, \ldots, a_n \right] \quad \text{and} \quad b = 0 \; .
\end{equation}

This implies the following distribution the linear combination given by equation \eqref{eq:norm-lincomb-lincomb}:

\begin{equation} \label{eq:norm-lincomb-norm-lincomb-p1}
Y = Ax + b \sim \mathcal{N}(A\mu, A \Sigma A^\mathrm{T}) \; .
\end{equation}

Finally, we note that

\begin{equation} \label{eq:norm-lincomb-A-b-mu-Sigma}
\begin{split}
A \mu &= \left[ a_1, \ldots, a_n \right] \left[ \begin{array}{c} \mu_1 \\ \vdots \\ \mu_n \end{array} \right] = \sum_{i=1}^{n} a_i \mu_i \quad \text{and} \quad \\
A \Sigma A^\mathrm{T} &= \left[ a_1, \ldots, a_n \right] \left[ \begin{array}{ccc} \sigma^2_1 & \cdots & 0 \\ \vdots & \ddots & \vdots \\ 0 & \cdots & \sigma^2_n \end{array} \right] \left[ \begin{array}{c} a_1 \\ \vdots \\ a_n \end{array} \right] = \sum_{i=1}^{n} a_i^2 \sigma^2_i \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P235 | shortcut: norm-lincomb | author: JoramSoch | date: 2021-06-02, 08:24.
\vspace{1em}



\subsection{t-distribution}

\subsubsection[\textit{Definition}]{Definition} \label{sec:t}
\setcounter{equation}{0}

\textbf{Definition:} Let $Z$ and $V$ be independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}) random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a standard normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:snorm}) and a chi-squared distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:chi2}) with $\nu$ degrees of freedom ($\rightarrow$ Definition "dof"), respectively:

\begin{equation} \label{eq:t-snorm-chi2}
\begin{split}
Z &\sim \mathcal{N}(0,1) \\
V &\sim \chi^{2}(\nu) \; .
\end{split}
\end{equation}

Then, the ratio of $Z$ to the square root of $V$, divided by the respective degrees of freedom, is said to be $t$-distributed with degrees of freedom $\nu$:

\begin{equation} \label{eq:t-t}
Y = \frac{Z}{\sqrt{V/\nu}} \sim t(\nu) \; .
\end{equation}

The $t$-distribution is also called "Student's $t$-distribution", after William S. Gosset a.k.a. "Student".


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Student's t-distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-04-21; URL: \url{https://en.wikipedia.org/wiki/Student%27s_t-distribution#Characterization}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D147 | shortcut: t | author: JoramSoch | date: 2021-04-21, 07:53.
\vspace{1em}



\subsubsection[\textit{Non-standardized t-distribution}]{Non-standardized t-distribution} \label{sec:nst}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a Student's t-distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:t}) with $\nu$ degrees of freedom. Then, the random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar})

\begin{equation} \label{eq:nst-Y}
Y = \sigma X + \mu
\end{equation}

is said to follow a non-standardized t-distribution with non-centrality $\mu$, scale $\sigma^2$ and degrees of freedom $\nu$:

\begin{equation} \label{eq:nst-nct}
Y \sim \mathrm{nst}(\mu, \sigma^2, \nu) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Student's t-distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-05-20; URL: \url{https://en.wikipedia.org/wiki/Student%27s_t-distribution#Generalized_Student's_t-distribution}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D152 | shortcut: nst | author: JoramSoch | date: 2021-05-20, 07:35.
\vspace{1em}



\subsubsection[\textbf{Relationship to non-standardized t-distribution}]{Relationship to non-standardized t-distribution} \label{sec:nst-t}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a non-standardized t-distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:nst}) with mean $\mu$, scale $\sigma^2$ and degrees of freedom $\nu$:

\begin{equation} \label{eq:nst-t-X}
X \sim \mathrm{nst}(\mu, \sigma^2, \nu) \; .
\end{equation}

Then, subtracting the mean and dividing by the square root of the scale results in a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a t-distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:t}) with degrees of freedom $\nu$:

\begin{equation} \label{eq:nst-t-nst-t}
Y = \frac{X-\mu}{\sigma} \sim t(\nu) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The non-standardized t-distribution is a special case ($\rightarrow$ Proof "nst-mvt") of the multivariate t-distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mvt}) in which the mean vector and scale matrix are scalars:

\begin{equation} \label{eq:nst-t-nst-mvt}
X \sim \mathrm{nst}(\mu, \sigma^2, \nu) \quad \Rightarrow \quad X \sim t(\mu, \sigma^2, \nu) \; .
\end{equation}

Therefore, we can apply the linear transformation theorem for the multivariate t-distribution ($\rightarrow$ Proof "mvt-ltt") for an $n \times 1$ random vector $x$:

\begin{equation} \label{eq:nst-t-mvt-ltt}
x \sim t(\mu, \Sigma, \nu) \quad \Rightarrow \quad y = Ax + b \sim t(A\mu + b, A \Sigma A^\mathrm{T}, \nu) \; .
\end{equation}

Comparing with equation \eqref{eq:nst-t-nst-t}, we have $A = 1/\sigma$, $b = -\mu/\sigma$ and the variable $Y$ is distributed as:

\begin{equation} \label{eq:nst-t-Y-dist}
\begin{split}
Y &= \frac{X-\mu}{\sigma} = \frac{X}{\sigma} - \frac{\mu}{\sigma} \\
&\sim t\left( \frac{\mu}{\sigma} - \frac{\mu}{\sigma}, \left( \frac{1}{\sigma} \right)^2 \sigma^2, \nu \right) \\
&= t\left( 0, 1, \nu \right) \; .
\end{split}
\end{equation}

Plugging $\mu = 0$, $\Sigma = 1$ and $n = 1$ into the probability density function of the multivariate t-distribution ($\rightarrow$ Proof "mvt-pdf"),

\begin{equation} \label{eq:nst-t-mvt-pdf}
p(x) = \sqrt{\frac{1}{(\nu \pi)^{n} |\Sigma|}} \, \frac{\Gamma([\nu+n]/2)}{\Gamma(\nu/2)} \, \left[ 1 + \frac{1}{\nu} (x-\mu)^\mathrm{T} \Sigma^{-1} (x-\mu) \right] \; ,
\end{equation}

we get

\begin{equation} \label{eq:nst-t-t-pdf}
p(x) = \sqrt{\frac{1}{\nu \pi}} \, \frac{\Gamma([\nu+1]/2)}{\Gamma(\nu/2)} \, \left[ 1 + \frac{x^2}{\nu} \right]
\end{equation}

which is the probability density function of Student's t-distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:t-pdf}) with $\nu$ degrees of freedom.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P232 | shortcut: nst-t | author: JoramSoch | date: 2021-05-11, 15:46.
\vspace{1em}



\subsubsection[\textbf{Probability density function}]{Probability density function} \label{sec:t-pdf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $T$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a t-distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:t}):

\begin{equation} \label{eq:t-pdf-t}
T \sim t(\nu) \; .
\end{equation}

Then, the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $T$ is

\begin{equation} \label{eq:t-pdf-t-pdf}
f_T(t) = \frac{\Gamma\left( \frac{\nu+1}{2} \right)}{\Gamma\left( \frac{\nu}{2} \right) \cdot \sqrt{\nu \pi}} \cdot \left( \frac{t^2}{\nu}+1 \right)^{-\frac{\nu+1}{2}} \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} A t-distributed random variable ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:t}) is defined as the ratio of a standard normal random variable ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:snorm}) and the square root of a chi-squared random variable ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:chi2}), divided by its degrees of freedom ($\rightarrow$ Definition "dof")

\begin{equation} \label{eq:t-pdf-t-def}
X \sim \mathcal{N}(0,1), \; Y \sim \chi^2(\nu) \quad \Rightarrow \quad T = \frac{X}{\sqrt{Y/\nu}} \sim t(\nu)
\end{equation}

where $X$ and $Y$ are independent of each other ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}).

The probability density function ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-pdf}) of the standard normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:snorm}) is

\begin{equation} \label{eq:t-pdf-snorm-pdf}
f_X(x) = \frac{1}{\sqrt{2 \pi}} \cdot e^{-\frac{x^2}{2}}
\end{equation}

and the probability density function of the chi-squared distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:chi2-pdf}) is

\begin{equation} \label{eq:t-pdf-chi2-pdf}
f_Y(y) = \frac{1}{\Gamma\left( \frac{\nu}{2} \right) \cdot 2^{\nu/2}} \cdot y^{\frac{\nu}{2}-1} \cdot e^{-\frac{y}{2}} \; .
\end{equation}

Define the random variables $T$ and $W$ as functions of $X$ and $Y$

\begin{equation} \label{eq:t-pdf-TW-XY}
\begin{split}
T &= X \cdot \sqrt{\frac{\nu}{Y}} \\
W &= Y \; ,
\end{split}
\end{equation}

such that the inverse functions $X$ and $Y$ in terms of $T$ and $W$ are

\begin{equation} \label{eq:t-pdf-XY-TW}
\begin{split}
X &= T \cdot \sqrt{\frac{W}{\nu}} \\
Y &= W \; .
\end{split}
\end{equation}

This implies the following Jacobian matrix and determinant:

\begin{equation} \label{eq:t-pdf-XY-TW-jac}
\begin{split}
J &= \left[ \begin{matrix}
\frac{\mathrm{d}X}{\mathrm{d}T} & \frac{\mathrm{d}X}{\mathrm{d}W} \\
\frac{\mathrm{d}Y}{\mathrm{d}T} & \frac{\mathrm{d}Y}{\mathrm{d}W}
\end{matrix} \right]
= \left[ \begin{matrix}
\sqrt{\frac{W}{\nu}} & \frac{T}{2 \sqrt{W/\nu}} \\
0 & 1
\end{matrix} \right] \\
\lvert J \rvert  &= \sqrt{\frac{W}{\nu}} \; .
\end{split}
\end{equation}

Because $X$ and $Y$ are independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}), the joint density ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-joint}) of $X$ and $Y$ is equal to the product ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:prob-ind}) of the marginal densities ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-marg}):

\begin{equation} \label{eq:t-pdf-f-XY}
f_{X,Y}(x,y) = f_X(x) \cdot f_Y(y) \; .
\end{equation}

With the probability density function of an invertible function ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:pdf-invfct}), the joint density ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-joint}) of $T$ and $W$ can be derived as:

\begin{equation} \label{eq:t-pdf-f-TW-s1}
f_{T,W}(t,w) = f_{X,Y}(x,y) \cdot \lvert J \rvert \; .
\end{equation}

Substituting \eqref{eq:t-pdf-XY-TW} into \eqref{eq:t-pdf-snorm-pdf} and \eqref{eq:t-pdf-chi2-pdf}, and then with \eqref{eq:t-pdf-XY-TW-jac} into \eqref{eq:t-pdf-f-TW-s1}, we get:

\begin{equation} \label{eq:t-pdf-f-TW-s2}
\begin{split}
f_{T,W}(t,w) &= f_X\left( t \cdot \sqrt{\frac{w}{\nu}} \right) \cdot f_Y(w) \cdot \lvert J \rvert \\
&= \frac{1}{\sqrt{2 \pi}} \cdot e^{-\frac{\left( t \cdot \sqrt{\frac{w}{\nu}} \right)^2}{2}} \cdot \frac{1}{\Gamma\left( \frac{\nu}{2} \right) \cdot 2^{\nu/2}} \cdot w^{\frac{\nu}{2}-1} \cdot e^{-\frac{w}{2}} \cdot \sqrt{\frac{w}{\nu}} \\
&= \frac{1}{\sqrt{2 \pi \nu} \cdot \Gamma\left( \frac{\nu}{2} \right) \cdot 2^{\nu/2}} \cdot w^{\frac{\nu+1}{2}-1} \cdot e^{-\frac{w}{2} \left( \frac{t^2}{\nu} + 1 \right)} \; .
\end{split}
\end{equation}

The marginal density ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-marg}) of $T$ can now be obtained by integrating out ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}) $W$:

\begin{equation} \label{eq:t-pdf-f-T-s1}
\begin{split}
f_T(t) &= \int_{0}^{\infty} f_{T,W}(t,w) \, \mathrm{d}w \\
&= \frac{1}{\sqrt{2 \pi \nu} \cdot \Gamma\left( \frac{\nu}{2} \right) \cdot 2^{\nu/2}} \cdot \int_{0}^{\infty} w^{\frac{\nu+1}{2}-1} \cdot \mathrm{exp}\left[ -\frac{1}{2}\left( \frac{t^2}{\nu}+1 \right) w \right] \, \mathrm{d}w \\
&= \frac{1}{\sqrt{2 \pi \nu} \cdot \Gamma\left( \frac{\nu}{2} \right) \cdot 2^{\nu/2}} \cdot \frac{\Gamma\left( \frac{\nu+1}{2} \right)}{\left[ \frac{1}{2}\left( \frac{t^2}{\nu}+1 \right) \right]^{(\nu+1)/2}} \cdot \int_{0}^{\infty} \frac{\left[ \frac{1}{2}\left( \frac{t^2}{\nu}+1 \right) \right]^{(\nu+1)/2}}{\Gamma\left( \frac{\nu+1}{2} \right)} \cdot w^{\frac{\nu+1}{2}-1} \cdot \mathrm{exp}\left[ -\frac{1}{2}\left( \frac{t^2}{\nu}+1 \right) w \right] \, \mathrm{d}w \; .
\end{split}
\end{equation}

At this point, we can recognize that the integrand is equal to the probability density function of a gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-pdf}) with

\begin{equation} \label{eq:t-pdf-f-W-gam-ab}
a = \frac{\nu+1}{2} \quad \text{and} \quad b = \frac{1}{2}\left( \frac{t^2}{\nu}+1 \right) \; ,
\end{equation}

and because a probability density function integrates to one ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}), we finally have:

\begin{equation} \label{eq:t-pdf-f-T-s2}
\begin{split}
f_T(t) &= \frac{1}{\sqrt{2 \pi \nu} \cdot \Gamma\left( \frac{\nu}{2} \right) \cdot 2^{\nu/2}} \cdot \frac{\Gamma\left( \frac{\nu+1}{2} \right)}{\left[ \frac{1}{2}\left( \frac{t^2}{\nu}+1 \right) \right]^{(\nu+1)/2}} \\
&= \frac{\Gamma\left( \frac{\nu+1}{2} \right)}{\Gamma\left( \frac{\nu}{2} \right) \cdot \sqrt{\nu \pi}} \cdot \left( \frac{t^2}{\nu}+1 \right)^{-\frac{\nu+1}{2}} \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Computation Empire (2021): "Student's t Distribution: Derivation of PDF"; in: \textit{YouTube}, retrieved on 2021-10-11; URL: \url{https://www.youtube.com/watch?v=6BraaGEVRY8}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P263 | shortcut: t-pdf | author: JoramSoch | date: 2021-10-12, 08:15.
\vspace{1em}



\subsection{Gamma distribution}

\subsubsection[\textit{Definition}]{Definition} \label{sec:gam}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}). Then, $X$ is said to follow a gamma distribution with shape $a$ and rate $b$

\begin{equation} \label{eq:gam-gam}
X \sim \mathrm{Gam}(a, b) \; ,
\end{equation}

if and only if its probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) is given by

\begin{equation} \label{eq:gam-gam-pdf}
\mathrm{Gam}(x; a, b) = \frac{b^a}{\Gamma(a)} x^{a-1} \exp[-b x], \quad x > 0
\end{equation}

where $a > 0$ and $b > 0$, and the density is zero, if $x \leq 0$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Koch, Karl-Rudolf (2007): "Gamma Distribution"; in: \textit{Introduction to Bayesian Statistics}, Springer, Berlin/Heidelberg, 2007, p. 47, eq. 2.172; URL: \url{https://www.springer.com/de/book/9783540727231}; DOI: 10.1007/978-3-540-72726-2.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D7 | shortcut: gam | author: JoramSoch | date: 2020-02-08, 23:29.
\vspace{1em}



\subsubsection[\textit{Standard gamma distribution}]{Standard gamma distribution} \label{sec:sgam}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}). Then, $X$ is said to have a standard gamma distribution, if $X$ follows a gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:gam}) with shape $a > 0$ and rate $b = 1$:

\begin{equation} \label{eq:sgam-sgam}
X \sim \mathrm{Gam}(a, 1) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item JoramSoch (2017): "Gamma-distributed random numbers"; in: \textit{MACS â€“ a new SPM toolbox for model assessment, comparison and selection}, retrieved on 2020-05-26; URL: \url{https://github.com/JoramSoch/MACS/blob/master/MD_gamrnd.m}; DOI: 10.5281/zenodo.845404.
\item NIST/SEMATECH (2012): "Gamma distribution"; in: \textit{e-Handbook of Statistical Methods}, ch. 1.3.6.6.11; URL: \url{https://www.itl.nist.gov/div898/handbook/eda/section3/eda366b.htm}; DOI: 10.18434/M32189.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D64 | shortcut: sgam | author: JoramSoch | date: 2020-05-26, 23:36.
\vspace{1em}



\subsubsection[\textbf{Relationship to standard gamma distribution}]{Relationship to standard gamma distribution} \label{sec:gam-sgam}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:gam}) with shape $a$ and rate $b$:

\begin{equation} \label{eq:gam-sgam-X-gam}
X \sim \mathrm{Gam}(a,b) \; .
\end{equation}

Then, the quantity $Y = b X$ will have a standard gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:sgam}) with shape $a$ and rate $1$:

\begin{equation} \label{eq:gam-sgam-Y-snorm}
Y = b X \sim \mathrm{Gam}(a,1) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} Note that $Y$ is a function of $X$

\begin{equation} \label{eq:gam-sgam-Y-X}
Y = g(X) = b X
\end{equation}

with the inverse function

\begin{equation} \label{eq:gam-sgam-X-Y}
X = g^{-1}(Y) = \frac{1}{b} Y \; .
\end{equation}

Because $b$ is positive, $g(X)$ is strictly increasing and we can calculate the cumulative distribution function of a strictly increasing function ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:cdf-sifct}) as

\begin{equation} \label{eq:gam-sgam-cdf-sifct}
F_Y(y) = \left\{
\begin{array}{rl}
0 \; , & \text{if} \; y < \mathrm{min}(\mathcal{Y}) \\
F_X(g^{-1}(y)) \; , & \text{if} \; y \in \mathcal{Y} \\
1 \; , & \text{if} \; y > \mathrm{max}(\mathcal{Y}) \; .
\end{array}
\right.
\end{equation}

The cumulative distribution function of the gamma-distributed ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-cdf}) $X$ is

\begin{equation} \label{eq:gam-sgam-gam-cdf}
F_X(x) = \int_{-\infty}^{x} \frac{b^a}{\Gamma(a)} t^{a-1} \exp[-b t] \, \mathrm{d}t \; .
\end{equation}

Applying \eqref{eq:gam-sgam-cdf-sifct} to \eqref{eq:gam-sgam-gam-cdf}, we have:

\begin{equation} \label{eq:gam-sgam-Y-cdf-s1}
\begin{split}
F_Y(y) &\overset{\eqref{eq:gam-sgam-cdf-sifct}}{=} F_X(g^{-1}(y)) \\
&\overset{\eqref{eq:gam-sgam-gam-cdf}}{=} \int_{-\infty}^{y/b} \frac{b^a}{\Gamma(a)} t^{a-1} \exp[-b t] \, \mathrm{d}t \; .
\end{split}
\end{equation}

Substituting $s = b t$, such that $t = s/b$, we obtain

\begin{equation} \label{eq:gam-sgam-Z-cdf-s2}
\begin{split}
F_Y(y) &= \int_{-b \infty}^{b (y/b)} \frac{b^a}{\Gamma(a)} \left(\frac{s}{b}\right)^{a-1} \exp\left[-b \left(\frac{s}{b}\right)\right] \, \mathrm{d}\left(\frac{s}{b}\right) \\
&= \int_{-\infty}^{y} \frac{b^a}{\Gamma(a)} \, \frac{1}{b^{a-1} \, b} \, s^{a-1} \exp[-s] \, \mathrm{d}s \\
&= \int_{-\infty}^{y} \frac{1}{\Gamma(a)} s^{a-1} \exp[-s] \, \mathrm{d}s
\end{split}
\end{equation}

which is the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) of the standard gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:sgam}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P112 | shortcut: gam-sgam | author: JoramSoch | date: 2020-05-26, 23:14.
\vspace{1em}



\subsubsection[\textbf{Relationship to standard gamma distribution}]{Relationship to standard gamma distribution} \label{sec:gam-sgam2}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:gam}) with shape $a$ and rate $b$:

\begin{equation} \label{eq:gam-sgam2-X-gam}
X \sim \mathrm{Gam}(a,b) \; .
\end{equation}

Then, the quantity $Y = b X$ will have a standard gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:sgam}) with shape $a$ and rate $1$:

\begin{equation} \label{eq:gam-sgam2-Y-snorm}
Y = b X \sim \mathrm{Gam}(a,1) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} Note that $Y$ is a function of $X$

\begin{equation} \label{eq:gam-sgam2-Y-X}
Y = g(X) = b X
\end{equation}

with the inverse function

\begin{equation} \label{eq:gam-sgam2-X-Y}
X = g^{-1}(Y) = \frac{1}{b} Y \; .
\end{equation}

Because $b$ is positive, $g(X)$ is strictly increasing and we can calculate the probability density function of a strictly increasing function ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:pdf-sifct}) as

\begin{equation} \label{eq:gam-sgam2-pdf-sifct}
f_Y(y) = \left\{
\begin{array}{rl}
f_X(g^{-1}(y)) \, \frac{\mathrm{d}g^{-1}(y)}{\mathrm{d}y} \; , & \text{if} \; y \in \mathcal{Y} \\
0 \; , & \text{if} \; y \notin \mathcal{Y}
\end{array}
\right.
\end{equation}

where $\mathcal{Y} = \left\lbrace y = g(x): x \in \mathcal{X} \right\rbrace$. With the probability density function of the gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-pdf}), we have

\begin{equation} \label{eq:gam-sgam2-pdf-Y}
\begin{split}
f_Y(y) &= \frac{b^a}{\Gamma(a)} [g^{-1}(y)]^{a-1} \exp[-b \, g^{-1}(y)] \cdot \frac{\mathrm{d}g^{-1}(y)}{\mathrm{d}y} \\
&= \frac{b^a}{\Gamma(a)} \left(\frac{1}{b} y\right)^{a-1} \exp\left[-b \left(\frac{1}{b} y\right)\right] \cdot \frac{\mathrm{d}\left(\frac{1}{b} y\right)}{\mathrm{d}y} \\
&= \frac{b^a}{\Gamma(a)} \, \frac{1}{b^{a-1}} \, y^{a-1} \exp[-y] \cdot \frac{1}{b} \\
&= \frac{1}{\Gamma(a)} \, y^{a-1} \exp[-y]
\end{split}
\end{equation}

which is the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of the standard gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:sgam}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P177 | shortcut: gam-sgam2 | author: JoramSoch | date: 2020-10-15, 12:04.
\vspace{1em}



\subsubsection[\textbf{Probability density function}]{Probability density function} \label{sec:gam-pdf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a positive random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:gam}):

\begin{equation} \label{eq:gam-pdf-gam}
X \sim \mathrm{Gam}(a, b) \; .
\end{equation}

Then, the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $X$ is

\begin{equation} \label{eq:gam-pdf-gam-pdf}
f_X(x) = \frac{b^a}{\Gamma(a)} x^{a-1} \exp[-b x] \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} This follows directly from the definition of the gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:gam}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P45 | shortcut: gam-pdf | author: JoramSoch | date: 2020-02-08, 23:41.
\vspace{1em}



\subsubsection[\textbf{Cumulative distribution function}]{Cumulative distribution function} \label{sec:gam-cdf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a positive random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:gam}):

\begin{equation} \label{eq:gam-cdf-gam}
X \sim \mathrm{Gam}(a, b) \; .
\end{equation}

Then, the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) of $X$ is

\begin{equation} \label{eq:gam-cdf-gam-cdf}
F_X(x) = \frac{\gamma(a,bx)}{\Gamma(a)}
\end{equation}

where $\Gamma(x)$ is the gamma function and $\gamma(s,x)$ is the lower incomplete gamma function.


\vspace{1em}
\textbf{Proof:} The probability density function of the gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-pdf}) is:

\begin{equation} \label{eq:gam-cdf-gam-pdf}
f_X(x) = \frac{b^a}{\Gamma(a)} x^{a-1} \exp[-b x] \; .
\end{equation}

Thus, the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) is:

\begin{equation} \label{eq:gam-cdf-gam-cdf-s1}
\begin{split}
F_X(x) &= \int_{0}^{x} \mathrm{Gam}(z; a, b) \, \mathrm{d}z \\
&= \int_{0}^{x} \frac{b^a}{\Gamma(a)} z^{a-1} \exp[-b z] \, \mathrm{d}z \\
&= \frac{b^a}{\Gamma(a)} \int_{0}^{x} z^{a-1} \exp[-b z] \, \mathrm{d}z \; .
\end{split}
\end{equation}

Substituting $t = b z$, i.e. $z = t/b$, this becomes:

\begin{equation} \label{eq:gam-cdf-gam-cdf-s2}
\begin{split}
F_X(x) &= \frac{b^a}{\Gamma(a)} \int_{b \cdot 0}^{b x} \left(\frac{t}{b}\right)^{a-1} \exp\left[-b \left(\frac{t}{b}\right)\right] \, \mathrm{d}\left(\frac{t}{b}\right) \\
&= \frac{b^a}{\Gamma(a)} \cdot \frac{1}{b^{a-1}} \cdot \frac{1}{b} \int_{0}^{b x} t^{a-1} \exp[-t] \, \mathrm{d}t \\
&= \frac{1}{\Gamma(a)} \int_{0}^{b x} t^{a-1} \exp[-t] \, \mathrm{d}t \; .
\end{split}
\end{equation}

With the definition of the lower incomplete gamma function

\begin{equation} \label{eq:gam-cdf-low-inc-gam-fct}
\gamma(s,x) = \int_{0}^{x} t^{s-1} \exp[-t] \, \mathrm{d}t \; ,
\end{equation}

we arrive at the final result given by equation \eqref{eq:gam-cdf-gam-cdf}:

\begin{equation} \label{eq:gam-cdf-gam-cdf-qed}
F_X(x) = \frac{\gamma(a,bx)}{\Gamma(a)} \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Incomplete gamma function"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-10-29; URL: \url{https://en.wikipedia.org/wiki/Incomplete_gamma_function#Definition}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P178 | shortcut: gam-cdf | author: JoramSoch | date: 2020-10-15, 12:34.
\vspace{1em}



\subsubsection[\textbf{Quantile function}]{Quantile function} \label{sec:gam-qf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:gam}):

\begin{equation} \label{eq:gam-qf-gam}
X \sim \mathrm{Gam}(a,b) \; .
\end{equation}

Then, the quantile function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:qf}) of $X$ is

\begin{equation} \label{eq:gam-qf-gam-qf}
Q_X(p) = \left\{
\begin{array}{rl}
-\infty \; , & \text{if} \; p = 0 \\
\gamma^{-1}(a, \Gamma(a) \cdot p)/b \; , & \text{if} \; p > 0
\end{array}
\right.
\end{equation}

where $\gamma^{-1}(s, y)$ is the inverse of the lower incomplete gamma function $\gamma(s, x)$


\vspace{1em}
\textbf{Proof:} The cumulative distribution function of the gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-cdf}) is:

\begin{equation} \label{eq:gam-qf-gam-cdf}
F_X(x) = \left\{
\begin{array}{rl}
0 \; , & \text{if} \; x < 0 \\
\frac{\gamma(a,bx)}{\Gamma(a)} \; , & \text{if} \; x \geq 0 \; .
\end{array}
\right.
\end{equation}

The quantile function $Q_X(p)$ is defined as ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:qf}) the smallest $x$, such that $F_X(x) = p$:

\begin{equation} \label{eq:gam-qf-qf}
Q_X(p) = \min \left\lbrace x \in \mathbb{R} \, \vert \, F_X(x) = p \right\rbrace \; .
\end{equation}

Thus, we have $Q_X(p) = -\infty$, if $p = 0$. When $p > 0$, it holds that ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:qf-cdf})

\begin{equation} \label{eq:gam-qf-gam-qf-s1}
Q_X(p) = F_X^{-1}(x) \; .
\end{equation}

This can be derived by rearranging equation \eqref{eq:gam-qf-gam-cdf}:

\begin{equation} \label{eq:gam-qf-gam-qf-s2}
\begin{split}
p &= \frac{\gamma(a,bx)}{\Gamma(a)} \\
\Gamma(a) \cdot p &= \gamma(a,bx) \\
\gamma^{-1}(a, \Gamma(a) \cdot p) &= bx \\
x &= \frac{\gamma^{-1}(a, \Gamma(a) \cdot p)}{b} \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Incomplete gamma function"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-11-19; URL: \url{https://en.wikipedia.org/wiki/Incomplete_gamma_function#Definition}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P194 | shortcut: gam-qf | author: JoramSoch | date: 2020-11-19, 07:31.
\vspace{1em}



\subsubsection[\textbf{Mean}]{Mean} \label{sec:gam-mean}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:gam}):

\begin{equation} \label{eq:gam-mean-gam}
X \sim \mathrm{Gam}(a, b) \; .
\end{equation}

Then, the mean or expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of $X$ is

\begin{equation} \label{eq:gam-mean-gam-mean}
\mathrm{E}(X) = \frac{a}{b} \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) is the probability-weighted average over all possible values:

\begin{equation} \label{eq:gam-mean-mean}
\mathrm{E}(X) = \int_{\mathcal{X}} x \cdot f_X(x) \, \mathrm{d}x \; .
\end{equation}

With the probability density function of the gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-pdf}), this reads:

\begin{equation} \label{eq:gam-mean-gam-mean-s1}
\begin{split}
\mathrm{E}(X) &= \int_{0}^{\infty} x \cdot \frac{b^a}{\Gamma(a)} x^{a-1} \exp[-b x] \, \mathrm{d}x \\
&= \int_{0}^{\infty} \frac{b^a}{\Gamma(a)} x^{(a+1)-1} \exp[-b x] \, \mathrm{d}x \\
&= \int_{0}^{\infty} \frac{1}{b} \cdot \frac{b^{a+1}}{\Gamma(a)} x^{(a+1)-1} \exp[-b x] \, \mathrm{d}x \; .
\end{split}
\end{equation}

Employing the relation $\Gamma(x+1) = \Gamma(x) \cdot x$, we have

\begin{equation} \label{eq:gam-mean-gam-mean-s2}
\mathrm{E}(X) = \int_{0}^{\infty} \frac{a}{b} \cdot \frac{b^{a+1}}{\Gamma(a+1)} x^{(a+1)-1} \exp[-b x] \, \mathrm{d}x
\end{equation}

and again using the density of the gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-pdf}), we get

\begin{equation} \label{eq:gam-mean-gam-mean-s3}
\begin{split}
\mathrm{E}(X) &= \frac{a}{b} \int_{0}^{\infty} \mathrm{Gam}(x; a+1, b) \, \mathrm{d}x \\
&= \frac{a}{b} \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Turlapaty, Anish (2013): "Gamma random variable: mean \& variance"; in: \textit{YouTube}, retrieved on 2020-05-19; URL: \url{https://www.youtube.com/watch?v=Sy4wP-Y2dmA}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P108 | shortcut: gam-mean | author: JoramSoch | date: 2020-05-19, 06:54.
\vspace{1em}



\subsubsection[\textbf{Variance}]{Variance} \label{sec:gam-var}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:gam}):

\begin{equation} \label{eq:gam-var-gam}
X \sim \mathrm{Gam}(a, b) \; .
\end{equation}

Then, the variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) of $X$ is

\begin{equation} \label{eq:gam-var-gam-var}
\mathrm{Var}(X) = \frac{a}{b^2} \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) can be expressed in terms of expected values ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:var-mean}) as

\begin{equation} \label{eq:gam-var-var-mean}
\mathrm{Var}(X) = \mathrm{E}(X^2) - \mathrm{E}(X)^2 \; .
\end{equation}

The expected value of a gamma random variable ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-mean}) is

\begin{equation} \label{eq:gam-var-gam-mean}
\mathrm{E}(X) = \frac{a}{b} \; .
\end{equation}

With the probability density function of the gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-pdf}), the expected value of a squared gamma random variable is

\begin{equation} \label{eq:gam-var-gam-sqr-mean-s1}
\begin{split}
\mathrm{E}(X^2) &= \int_{0}^{\infty} x^2 \cdot \frac{b^a}{\Gamma(a)} x^{a-1} \exp[-b x] \, \mathrm{d}x \\
&= \int_{0}^{\infty} \frac{b^a}{\Gamma(a)} x^{(a+2)-1} \exp[-b x] \, \mathrm{d}x \\
&= \int_{0}^{\infty} \frac{1}{b^2} \cdot \frac{b^{a+2}}{\Gamma(a)} x^{(a+2)-1} \exp[-b x] \, \mathrm{d}x \; .
\end{split}
\end{equation}

Twice-applying the relation $\Gamma(x+1) = \Gamma(x) \cdot x$, we have

\begin{equation} \label{eq:gam-var-gam-sqr-mean-s2}
\mathrm{E}(X^2) = \int_{0}^{\infty} \frac{a \, (a+1)}{b^2} \cdot \frac{b^{a+2}}{\Gamma(a+2)} x^{(a+2)-1} \exp[-b x] \, \mathrm{d}x
\end{equation}

and again using the density of the gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-pdf}), we get

\begin{equation} \label{eq:gam-var-gam-sqr-mean-s3}
\begin{split}
\mathrm{E}(X^2) &= \frac{a \, (a+1)}{b^2} \int_{0}^{\infty} \mathrm{Gam}(x; a+2, b) \, \mathrm{d}x \\
&= \frac{a^2+a}{b^2} \; .
\end{split}
\end{equation}

Plugging \eqref{eq:gam-var-gam-sqr-mean-s3} and \eqref{eq:gam-var-gam-mean} into \eqref{eq:gam-var-var-mean}, the variance of a gamma random variable finally becomes

\begin{equation} \label{eq:gam-var-gam-var-qed}
\begin{split}
\mathrm{Var}(X) &= \frac{a^2+a}{b^2} - \left( \frac{a}{b} \right)^2 \\
&= \frac{a}{b^2} \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Turlapaty, Anish (2013): "Gamma random variable: mean \& variance"; in: \textit{YouTube}, retrieved on 2020-05-19; URL: \url{https://www.youtube.com/watch?v=Sy4wP-Y2dmA}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P109 | shortcut: gam-var | author: JoramSoch | date: 2020-05-19, 07:20.
\vspace{1em}



\subsubsection[\textbf{Logarithmic expectation}]{Logarithmic expectation} \label{sec:gam-logmean}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:gam}):

\begin{equation} \label{eq:gam-logmean-gam}
X \sim \mathrm{Gam}(a, b) \; .
\end{equation}

Then, the expectation ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of the natural logarithm of $X$ is

\begin{equation} \label{eq:gam-logmean-gam-logmean}
\mathrm{E}(\ln X) = \psi(a) - \ln(b)
\end{equation}

where $\psi(x)$ is the digamma function.


\vspace{1em}
\textbf{Proof:} Let $Y = \ln(X)$, such that $\mathrm{E}(Y) = \mathrm{E}(\ln X)$ and consider the special case that $b = 1$. In this case, the probability density function of the gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-pdf}) is

\begin{equation} \label{eq:gam-logmean-X-pdf-s1}
f_X(x) = \frac{1}{\Gamma(a)} \, x^{a-1} \, \mathrm{exp} [-x] \; .
\end{equation}

Multiplying this function with $\mathrm{d}x$, we obtain

\begin{equation} \label{eq:gam-logmean-X-pdf-s2}
f_X(x) \, \mathrm{d}x = \frac{1}{\Gamma(a)} \, x^a \, \mathrm{exp} [-x] \, \frac{\mathrm{d}x}{x} \; .
\end{equation}

Substituting $y = \ln x$, i.e. $x = e^y$, such that $\mathrm{d}x/\mathrm{d}y = x$, i.e. $\mathrm{d}x/x = \mathrm{d}y$, we get

\begin{equation} \label{eq:gam-logmean-Y-pdf-s1}
\begin{split}
f_Y(y) \, \mathrm{d}y &= \frac{1}{\Gamma(a)} \, \left( e^y \right)^a \, \mathrm{exp} [-e^y] \, \mathrm{d}y \\
&= \frac{1}{\Gamma(a)} \, \mathrm{exp}\left[ ay - e^y \right] \, \mathrm{d}y \; .
\end{split}
\end{equation}

Because $f_Y(y)$ integrates to one, we have

\begin{equation} \label{eq:gam-logmean-Y-pdf-s2}
\begin{split}
1 &= \int_{\mathbb{R}} f_Y(y) \, \mathrm{d}y \\
1 &= \int_{\mathbb{R}} \frac{1}{\Gamma(a)} \, \mathrm{exp}\left[ ay - e^y \right] \, \mathrm{d}y \\
\Gamma(a) &= \int_{\mathbb{R}} \mathrm{exp}\left[ ay - e^y \right] \, \mathrm{d}y \; .
\end{split}
\end{equation}

Note that the integrand in \eqref{eq:gam-logmean-Y-pdf-s2} is differentiable with respect to $a$:

\begin{equation} \label{eq:gam-logmean-dfy-da}
\begin{split}
\frac{\mathrm{d}}{\mathrm{d}a} \mathrm{exp}\left[ ay - e^y \right] \, \mathrm{d}y &= y \, \mathrm{exp}\left[ ay - e^y \right] \, \mathrm{d}y \\
&\overset{\eqref{eq:gam-logmean-Y-pdf-s1}}{=} \Gamma(a) \, y \, f_Y(y) \, \mathrm{d}y \; .
\end{split}
\end{equation}

Now we can calculate the expected value of $Y = \ln(X)$:

\begin{equation} \label{eq:gam-logmean-E-Y-s1}
\begin{split}
\mathrm{E}(Y) &= \int_{\mathbb{R}} y \, f_Y(y) \, \mathrm{d}y \\
&\overset{\eqref{eq:gam-logmean-dfy-da}}{=} \frac{1}{\Gamma(a)} \int_{\mathbb{R}} \frac{\mathrm{d}}{\mathrm{d}a} \mathrm{exp}\left[ ay - e^y \right] \, \mathrm{d}y \\
&= \frac{1}{\Gamma(a)} \frac{\mathrm{d}}{\mathrm{d}a} \int_{\mathbb{R}} \mathrm{exp}\left[ ay - e^y \right] \, \mathrm{d}y \\
&\overset{\eqref{eq:gam-logmean-Y-pdf-s2}}{=} \frac{1}{\Gamma(a)} \frac{\mathrm{d}}{\mathrm{d}a} \Gamma(a) \\
&= \frac{\Gamma'(a)}{\Gamma(a)} \; .
\end{split}
\end{equation}

Using the derivative of a logarithmized function

\begin{equation} \label{eq:gam-logmean-log-der}
\frac{\mathrm{d}}{\mathrm{d}x} \ln f(x) = \frac{f'(x)}{f(x)}
\end{equation}

and the definition of the digamma function

\begin{equation} \label{eq:gam-logmean-psi}
\psi(x) = \frac{\mathrm{d}}{\mathrm{d}x} \ln \Gamma(x) \; ,
\end{equation}

we have

\begin{equation} \label{eq:gam-logmean-E-Y-s2}
\mathrm{E}(Y) = \psi(a) \; .
\end{equation}

Finally, noting that $1/b$ acts as a scaling parameter ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-sgam}) on a gamma-distributed ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:gam}) random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}),

\begin{equation} \label{eq:gam-logmean-gam-sgam}
X \sim \mathrm{Gam}(a,1) \quad \Rightarrow \quad \frac{1}{b} X \sim \mathrm{Gam}(a,b) \; ,
\end{equation}

and that a scaling parameter acts additively on the logarithmic expectation of a random variable,

\begin{equation} \label{eq:gam-logmean-logmean}
\mathrm{E}\left[\ln(cX)\right] = \mathrm{E}\left[\ln(X) + \ln(c)\right] = \mathrm{E}\left[\ln(X)\right] + \ln(c) \; ,
\end{equation}

it follows that

\begin{equation} \label{eq:gam-logmean-E-Y-s3}
X \sim \mathrm{Gam}(a,b) \quad \Rightarrow \quad \mathrm{E}(\ln X) = \psi(a) - \ln(b) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item whuber (2018): "What is the expected value of the logarithm of Gamma distribution?"; in: \textit{StackExchange CrossValidated}, retrieved on 2020-05-25; URL: \url{https://stats.stackexchange.com/questions/370880/what-is-the-expected-value-of-the-logarithm-of-gamma-distribution}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P110 | shortcut: gam-logmean | author: JoramSoch | date: 2020-05-25, 21:28.
\vspace{1em}



\subsubsection[\textbf{Expectation of x ln x}]{Expectation of x ln x} \label{sec:gam-xlogx}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:gam}):

\begin{equation} \label{eq:gam-xlogx-gam}
X \sim \mathrm{Gam}(a, b) \; .
\end{equation}

Then, the mean or expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of $(X \cdot \ln X)$ is

\begin{equation} \label{eq:gam-xlogx-gam-xlogx}
\mathrm{E}(X \ln X) = \frac{a}{b} \left[ \psi(a) - \ln(b) \right] \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} With the definition of the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}), the law of the unconscious statistician ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-lotus}) and the probability density function of the gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-pdf}), we have:

\begin{equation} \label{eq:gam-xlogx-gam-xlogx-s1}
\begin{split}
\mathrm{E}(X \ln X) &= \int_{0}^{\infty} x \ln x \cdot \frac{b^a}{\Gamma(a)} x^{a-1} \exp[-b x] \, \mathrm{d}x \\
&= \frac{1}{\Gamma(a)} \int_{0}^{\infty} \ln x \cdot \frac{b^{a+1}}{b} x^{a} \exp[-b x] \, \mathrm{d}x \\
&= \frac{\Gamma(a+1)}{\Gamma(a) \, b} \int_{0}^{\infty} \ln x \cdot \frac{b^{a+1}}{\Gamma(a+1)} x^{(a+1)-1} \exp[-b x] \, \mathrm{d}x \\
\end{split}
\end{equation}

The integral now corresponds to the logarithmic expectation of a gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-logmean}) with shape $a+1$ and rate $b$

\begin{equation} \label{eq:gam-xlogx-logmean-a+1}
\mathrm{E}(\ln Y) \quad \text{where} \quad Y \sim \mathrm{Gam}(a+1,b)
\end{equation}

which is given by ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-logmean})

\begin{equation} \label{eq:gam-xlogx-gam-logmean}
\mathrm{E}(\ln Y) = \psi(a+1) - \ln(b)
\end{equation}

where $\psi(x)$ is the digamma function. Additionally employing the relation

\begin{equation} \label{eq:gam-xlogx-gam-fct}
\Gamma(x+1) = \Gamma(x) \cdot x \quad \Leftrightarrow \quad \frac{\Gamma(x+1)}{\Gamma(x)} = x \; ,
\end{equation}

the expression in equation \eqref{eq:gam-xlogx-gam-xlogx-s1} develops into:

\begin{equation} \label{eq:gam-xlogx-gam-xlogx-qed}
\mathrm{E}(X \ln X) = \frac{a}{b} \left[ \psi(a) - \ln(b) \right] \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item gunes (2020): "What is the expected value of x log(x) of the gamma distribution?"; in: \textit{StackExchange CrossValidated}, retrieved on 2020-10-15; URL: \url{https://stats.stackexchange.com/questions/457357/what-is-the-expected-value-of-x-logx-of-the-gamma-distribution}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P179 | shortcut: gam-xlogx | author: JoramSoch | date: 2020-10-15, 13:02.
\vspace{1em}



\subsubsection[\textbf{Differential entropy}]{Differential entropy} \label{sec:gam-dent}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:gam}):

\begin{equation} \label{eq:gam-dent-gam}
X \sim \mathrm{Gam}(a, b)
\end{equation}

Then, the differential entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent}) of $X$ in nats is

\begin{equation} \label{eq:gam-dent-gam-dent}
\mathrm{h}(X) = a + \ln \Gamma(a) + (1-a) \cdot \psi(a) + \ln b \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The differential entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent}) of a random variable is defined as

\begin{equation} \label{eq:gam-dent-dent}
\mathrm{h}(X) = - \int_{\mathcal{X}} p(x) \, \log_b p(x) \, \mathrm{d}x \; .
\end{equation}

To measure $h(X)$ in nats, we set $b = e$, such that ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean})

\begin{equation} \label{eq:gam-dent-dent-nats}
\mathrm{h}(X) = - \mathrm{E}\left[ \ln p(x) \right] \; .
\end{equation}

With the probability density function of the gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-pdf}), the differential entropy of $X$ is:

\begin{equation} \label{eq:gam-dent-gam-dent-s1}
\begin{split}
\mathrm{h}(X) &= - \mathrm{E}\left[ \ln \left( \frac{b^a}{\Gamma(a)} x^{a-1} \exp[-b x] \right) \right] \\
&= - \mathrm{E}\left[ a \cdot \ln b - \ln \Gamma(a) + (a-1) \ln x - b x \right] \\
&= - a \cdot \ln b + \ln \Gamma(a) - (a-1) \cdot \mathrm{E}(\ln x) + b \cdot \mathrm{E}(x) \; .
\end{split}
\end{equation}

Using the mean ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-mean}) and logarithmic expectation ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-logmean}) of the gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:gam})

\begin{equation} \label{eq:gam-dent-gam-mean-logmean}
X \sim \mathrm{Gam}(a, b) \quad \Rightarrow \quad \mathrm{E}(X) = \frac{a}{b} \quad \text{and} \quad \mathrm{E}(\ln X) = \psi(a) - \ln(b) \; ,
\end{equation}

the differential entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent}) of $X$ becomes:

\begin{equation} \label{eq:gam-dent-gam-dent-s2}
\begin{split}
\mathrm{h}(X) &= - a \cdot \ln b + \ln \Gamma(a) - (a-1) \cdot (\psi(a) - \ln b) + b \cdot \frac{a}{b} \\
&= - a \cdot \ln b + \ln \Gamma(a) + (1-a) \cdot \psi(a) + a \cdot \ln b - \ln b + a \\
&= a + \ln \Gamma(a) + (1-a) \cdot \psi(a) - \ln b \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Gamma distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-07-14; URL: \url{https://en.wikipedia.org/wiki/Gamma_distribution#Information_entropy}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P239 | shortcut: gam-dent | author: JoramSoch | date: 2021-07-14, 07:37.
\vspace{1em}



\subsubsection[\textbf{Kullback-Leibler divergence}]{Kullback-Leibler divergence} \label{sec:gam-kl}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}). Assume two gamma distributions ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:gam}) $P$ and $Q$ specifying the probability distribution of $X$ as

\begin{equation} \label{eq:gam-kl-gams}
\begin{split}
P: \; X &\sim \mathrm{Gam}(a_1, b_1) \\
Q: \; X &\sim \mathrm{Gam}(a_2, b_2) \; .
\end{split}
\end{equation}

Then, the Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) of $P$ from $Q$ is given by

\begin{equation} \label{eq:gam-kl-gam-KL}
\mathrm{KL}[P\,||\,Q] = a_2 \, \ln \frac{b_1}{b_2} - \ln \frac{\Gamma(a_1)}{\Gamma(a_2)} + (a_1 - a_2) \, \psi(a_1) - (b_1 - b_2) \, \frac{a_1}{b_1} \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The KL divergence for a continuous random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) is given by 

\begin{equation} \label{eq:gam-kl-KL-cont}
\mathrm{KL}[P\,||\,Q] = \int_{\mathcal{X}} p(x) \, \ln \frac{p(x)}{q(x)} \, \mathrm{d}x
\end{equation}

which, applied to the gamma distributions ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:gam}) in \eqref{eq:gam-kl-gams}, yields

\begin{equation} \label{eq:gam-kl-gam-KL-s1}
\begin{split}
\mathrm{KL}[P\,||\,Q] &= \int_{-\infty}^{+\infty} \mathrm{Gam}(x; a_1, b_1) \, \ln \frac{\mathrm{Gam}(x; a_1, b_1)}{\mathrm{Gam}(x; a_2, b_2)} \, \mathrm{d}x \\
&= \left\langle \ln \frac{\mathrm{Gam}(x; a_1, b_1)}{\mathrm{Gam}(x; a_2, b_2)} \right\rangle_{p(x)} \; .
\end{split}
\end{equation}

Using the probability density function of the gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-pdf}), this becomes:

\begin{equation} \label{eq:gam-kl-gam-KL-s2}
\begin{split}
\mathrm{KL}[P\,||\,Q] &= \left\langle \ln \frac{ \frac{ {b_1}^{a_1}}{\Gamma(a_1)} x^{a_1-1} \exp[-b_1 x] }{ \frac{ {b_2}^{a_2}}{\Gamma(a_2)} x^{a_2-1} \exp[-b_2 x] } \right\rangle_{p(x)} \\
&= \left\langle \ln \left( \frac{ {b_1}^{a_1}}{ {b_2}^{a_2}} \cdot \frac{\Gamma(a_2)}{\Gamma(a_1)} \cdot x^{a_1-a_2} \cdot \exp[-(b_1-b_2) x] \right) \right\rangle_{p(x)} \\
&= \left\langle a_1 \cdot \ln b_1 - a_2 \cdot \ln b_2 - \ln \Gamma(a_1) + \ln \Gamma(a_2) + (a_1-a_2) \cdot \ln x - (b_1-b_2) \cdot x \right\rangle_{p(x)} \; .
\end{split}
\end{equation}

Using the mean of the gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-mean}) and the expected value of a logarithmized gamma variate ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-logmean})

\begin{equation} \label{eq:gam-kl-gam-means}
\begin{split}
x \sim \mathrm{Gam}(a,b) \quad \Rightarrow \quad &\left\langle x \right\rangle = \frac{a}{b} \quad \text{and} \\
&\left\langle \ln x \right\rangle = \psi(a) - \ln(b) \; ,
\end{split}
\end{equation}

the Kullback-Leibler divergence from \eqref{eq:gam-kl-gam-KL-s2} becomes:

\begin{equation} \label{eq:gam-kl-gam-KL-s3}
\begin{split}
\mathrm{KL}[P\,||\,Q] &= a_1 \cdot \ln b_1 - a_2 \cdot \ln b_2 - \ln \Gamma(a_1) + \ln \Gamma(a_2) + (a_1-a_2) \cdot \left( \psi(a_1) - \ln(b_1) \right) - (b_1-b_2) \cdot \frac{a_1}{b_1} \\
&= a_2 \cdot \ln b_1 - a_2 \cdot \ln b_2 - \ln \Gamma(a_1) + \ln \Gamma(a_2) + (a_1-a_2) \cdot \psi(a_1) - (b_1-b_2) \cdot \frac{a_1}{b_1} \; .
\end{split}
\end{equation}

Finally, combining the logarithms, we get:

\begin{equation} \label{eq:gam-kl-gam-KL-qed}
\mathrm{KL}[P\,||\,Q] = a_2 \, \ln \frac{b_1}{b_2} - \ln \frac{\Gamma(a_1)}{\Gamma(a_2)} + (a_1 - a_2) \, \psi(a_1) - (b_1 - b_2) \, \frac{a_1}{b_1} \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Penny, William D. (2001): "KL-Divergences of Normal, Gamma, Dirichlet and Wishart densities"; in: \textit{University College, London}; URL: \url{https://www.fil.ion.ucl.ac.uk/~wpenny/publications/densities.ps}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P93 | shortcut: gam-kl | author: JoramSoch | date: 2020-05-05, 08:41.
\vspace{1em}



\subsection{Exponential distribution}

\subsubsection[\textit{Definition}]{Definition} \label{sec:exp}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}). Then, $X$ is said to be exponentially distributed with rate (or, inverse scale) $\lambda$

\begin{equation} \label{eq:exp-exp}
X \sim \mathrm{Exp}(\lambda) \; ,
\end{equation}

if and only if its probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) is given by

\begin{equation} \label{eq:exp-exp-pdf}
\mathrm{Exp}(x; \lambda) = \lambda \exp[-\lambda x], \quad x \geq 0
\end{equation}

where $\lambda > 0$, and the density is zero, if $x < 0$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Exponential distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-02-08; URL: \url{https://en.wikipedia.org/wiki/Exponential_distribution#Definitions}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D8 | shortcut: exp | author: JoramSoch | date: 2020-02-08, 23:48.
\vspace{1em}



\subsubsection[\textbf{Special case of gamma distribution}]{Special case of gamma distribution} \label{sec:exp-gam}
\setcounter{equation}{0}

\textbf{Theorem:} The exponential distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:exp}) is a special case of the gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:gam}) with shape $a = 1$ and rate $b = \lambda$.


\vspace{1em}
\textbf{Proof:} The probability density function of the gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-pdf}) is

\begin{equation} \label{eq:exp-gam-gam-pdf}
\mathrm{Gam}(x; a, b) = \frac{b^a}{\Gamma(a)} x^{a-1} \exp[-b x] \; .
\end{equation}

Setting $a = 1$ and $b = \lambda$, we obtain

\begin{equation} \label{eq:exp-gam-exp-pdf}
\begin{split}
\mathrm{Gam}(x; 1, \lambda) &= \frac{\lambda^1}{\Gamma(1)} x^{1-1} \exp[-\lambda x] \\
&= \frac{x^0}{\Gamma(1)} \lambda \exp[-\lambda x] \\
&= \lambda \exp[-\lambda x]
\end{split}
\end{equation}

which is equivalent to the probability density function of the exponential distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:exp-pdf}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P69 | shortcut: exp-gam | author: JoramSoch | date: 2020-03-02, 20:49.
\vspace{1em}



\subsubsection[\textbf{Probability density function}]{Probability density function} \label{sec:exp-pdf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a non-negative random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following an exponential distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:exp}):

\begin{equation} \label{eq:exp-pdf-exp}
X \sim \mathrm{Exp}(\lambda) \; .
\end{equation}

Then, the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $X$ is

\begin{equation} \label{eq:exp-pdf-gam-pdf}
f_X(x) = \lambda \exp[-\lambda x] \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} This follows directly from the definition of the exponential distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:exp}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P46 | shortcut: exp-pdf | author: JoramSoch | date: 2020-02-08, 23:53.
\vspace{1em}



\subsubsection[\textbf{Cumulative distribution function}]{Cumulative distribution function} \label{sec:exp-cdf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following an exponential distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:exp}):

\begin{equation} \label{eq:exp-cdf-exp}
X \sim \mathrm{Exp}(\lambda) \; .
\end{equation}

Then, the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) of $X$ is

\begin{equation} \label{eq:exp-cdf-exp-cdf}
F_X(x) = \left\{
\begin{array}{rl}
0 \; , & \text{if} \; x < 0 \\
1 - \exp[-\lambda x] \; , & \text{if} \; x \geq 0 \; .
\end{array}
\right.
\end{equation}


\vspace{1em}
\textbf{Proof:}  The probability density function of the exponential distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:exp-pdf}) is:

\begin{equation} \label{eq:exp-cdf-exp-pdf}
\mathrm{Exp}(x; \lambda) = \left\{
\begin{array}{rl}
0 \; , & \text{if} \; x < 0 \\
\lambda \exp[-\lambda x] \; , & \text{if} \; x \geq 0 \; .
\end{array}
\right.
\end{equation}

Thus, the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) is:

\begin{equation} \label{eq:exp-cdf-exp-cdf-s1}
F_X(x) = \int_{-\infty}^{x} \mathrm{Exp}(z; \lambda) \, \mathrm{d}z \; .
\end{equation}

If $x < 0$, we have:

\begin{equation} \label{eq:exp-cdf-exp-cdf-s2a}
F_X(x) = \int_{-\infty}^{x} 0 \, \mathrm{d}z = 0 \; .
\end{equation}

If $x \geq 0$, we have using \eqref{eq:exp-cdf-exp-pdf}:

\begin{equation} \label{eq:exp-cdf-exp-cdf-s2b}
\begin{split}
F_X(x) &= \int_{-\infty}^{0} \mathrm{Exp}(z; \lambda) \, \mathrm{d}z + \int_{0}^{x} \mathrm{Exp}(z; \lambda) \, \mathrm{d}z \\
&= \int_{-\infty}^{0} 0 \, \mathrm{d}z + \int_{0}^{x} \lambda \exp[-\lambda z] \, \mathrm{d}z \\
&= 0 + \lambda \left[ -\frac{1}{\lambda} \exp[-\lambda z] \right]_{0}^{x} \\
&= \lambda \left[ \left( -\frac{1}{\lambda} \exp[-\lambda x] \right) - \left( -\frac{1}{\lambda} \exp[-\lambda \cdot 0] \right) \right] \\
&= 1 - \exp[-\lambda x] \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P48 | shortcut: exp-cdf | author: JoramSoch | date: 2020-02-11, 14:48.
\vspace{1em}



\subsubsection[\textbf{Quantile function}]{Quantile function} \label{sec:exp-qf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following an exponential distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:exp}):

\begin{equation} \label{eq:exp-qf-exp}
X \sim \mathrm{Exp}(\lambda) \; .
\end{equation}

Then, the quantile function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:qf}) of $X$ is

\begin{equation} \label{eq:exp-qf-exp-qf}
Q_X(p) = \left\{
\begin{array}{rl}
-\infty \; , & \text{if} \; p = 0 \\
-\frac{\ln(1-p)}{\lambda} \; , & \text{if} \; p > 0 \; .
\end{array}
\right.
\end{equation}


\vspace{1em}
\textbf{Proof:} The cumulative distribution function of the exponential distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:exp-cdf}) is:

\begin{equation} \label{eq:exp-qf-exp-cdf}
F_X(x) = \left\{
\begin{array}{rl}
0 \; , & \text{if} \; x < 0 \\
1 - \exp[-\lambda x] \; , & \text{if} \; x \geq 0 \; .
\end{array}
\right.
\end{equation}

The quantile function $Q_X(p)$ is defined as ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:qf}) the smallest $x$, such that $F_X(x) = p$:

\begin{equation} \label{eq:exp-qf-qf}
Q_X(p) = \min \left\lbrace x \in \mathbb{R} \, \vert \, F_X(x) = p \right\rbrace \; .
\end{equation}

Thus, we have $Q_X(p) = -\infty$, if $p = 0$. When $p > 0$, it holds that ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:qf-cdf})

\begin{equation} \label{eq:exp-qf-exp-qf-s1}
Q_X(p) = F_X^{-1}(x) \; .
\end{equation}

This can be derived by rearranging equation \eqref{eq:exp-qf-exp-cdf}:

\begin{equation} \label{eq:exp-qf-exp-qf-s2}
\begin{split}
p &= 1 - \exp[-\lambda x] \\
\exp[-\lambda x] &= 1-p \\
-\lambda x &= \ln(1-p) \\
x &= -\frac{\ln(1-p)}{\lambda} \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P50 | shortcut: exp-qf | author: JoramSoch | date: 2020-02-12, 15:48.
\vspace{1em}



\subsubsection[\textbf{Mean}]{Mean} \label{sec:exp-mean}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following an exponential distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:exp}):

\begin{equation} \label{eq:exp-mean-exp}
X \sim \mathrm{Exp}(\lambda) \; .
\end{equation}

Then, the mean or expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of $X$ is

\begin{equation} \label{eq:exp-mean-exp-mean}
\mathrm{E}(X) = \frac{1}{\lambda} \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) is the probability-weighted average over all possible values:

\begin{equation} \label{eq:exp-mean-mean}
\mathrm{E}(X) = \int_{\mathcal{X}} x \cdot f_\mathrm{X}(x) \, \mathrm{d}x \; .
\end{equation}

With the probability density function of the exponential distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:exp-pdf}), this reads:

\begin{equation} \label{eq:exp-mean-exp-mean-s1}
\begin{split}
\mathrm{E}(X) &= \int_{0}^{+\infty} x \cdot \lambda \exp(-\lambda x) \, \mathrm{d}x \\
&= \lambda \int_{0}^{+\infty} x \cdot \exp(-\lambda x) \, \mathrm{d}x \; .
\end{split}
\end{equation}

Using the following anti-deriative

\begin{equation} \label{eq:exp-mean-exp-mean-s2}
\int x \cdot \exp(-\lambda x) \, \mathrm{d}x = \left( - \frac{1}{\lambda} x - \frac{1}{\lambda^2} \right) \exp(-\lambda x) \; ,
\end{equation}

the expected value becomes

\begin{equation} \label{eq:exp-mean-exp-mean-s3}
\begin{split}
\mathrm{E}(X) &= \lambda \left[ \left( - \frac{1}{\lambda} x - \frac{1}{\lambda^2} \right) \exp(-\lambda x) \right]_{0}^{+\infty} \\
&= \lambda \left[ \lim_{x \to \infty} \left( - \frac{1}{\lambda} x - \frac{1}{\lambda^2} \right) \exp(-\lambda x) - \left( - \frac{1}{\lambda} \cdot 0 - \frac{1}{\lambda^2} \right) \exp(-\lambda \cdot 0) \right] \\
&= \lambda \left[ 0 + \frac{1}{\lambda^2} \right] \\
&= \frac{1}{\lambda} \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Koch, Karl-Rudolf (2007): "Expected Value"; in: \textit{Introduction to Bayesian Statistics}, Springer, Berlin/Heidelberg, 2007, p. 39, eq. 2.142a; URL: \url{https://www.springer.com/de/book/9783540727231}; DOI: 10.1007/978-3-540-72726-2.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P47 | shortcut: exp-mean | author: JoramSoch | date: 2020-02-10, 21:57.
\vspace{1em}



\subsubsection[\textbf{Median}]{Median} \label{sec:exp-med}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following an exponential distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:exp}):

\begin{equation} \label{eq:exp-med-exp}
X \sim \mathrm{Exp}(\lambda) \; .
\end{equation}

Then, the median ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:med}) of $X$ is

\begin{equation} \label{eq:exp-med-exp-med}
\mathrm{median}(X) = \frac{\ln 2}{\lambda} \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The median ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:med}) is the value at which the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) is $1/2$:

\begin{equation} \label{eq:exp-med-median}
F_X(\mathrm{median}(X)) = \frac{1}{2} \; .
\end{equation}

The cumulative distribution function of the exponential distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:exp-cdf}) is

\begin{equation} \label{eq:exp-med-exp-cdf}
F_X(x) = 1 - \exp[-\lambda x], \quad x \geq 0 \; .
\end{equation}

Thus, the inverse CDF is

\begin{equation} \label{eq:exp-med-exp-cdf-inv}
x = -\frac{\ln(1-p)}{\lambda}
\end{equation}

and setting $p = 1/2$, we obtain:

\begin{equation} \label{eq:exp-med-exp-med-qed}
\mathrm{median}(X) = -\frac{\ln(1-\frac{1}{2})}{\lambda} = \frac{\ln 2}{\lambda} \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P49 | shortcut: exp-med | author: JoramSoch | date: 2020-02-11, 15:03.
\vspace{1em}



\subsubsection[\textbf{Mode}]{Mode} \label{sec:exp-mode}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following an exponential distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:exp}):

\begin{equation} \label{eq:exp-mode-exp}
X \sim \mathrm{Exp}(\lambda) \; .
\end{equation}

Then, the mode ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mode}) of $X$ is

\begin{equation} \label{eq:exp-mode-exp-mode}
\mathrm{mode}(X) = 0 \; .
\end{equation}


\vspace{1em}
\textbf{Proof:}  The mode ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mode}) is the value which maximizes the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}):

\begin{equation} \label{eq:exp-mode-mode}
\mathrm{mode}(X) = \operatorname*{arg\,max}_x f_X(x) \; .
\end{equation}

The probability density function of the exponential distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:exp-pdf}) is:

\begin{equation} \label{eq:exp-mode-exp-pdf}
f_X(x) = \left\{
\begin{array}{rl}
0 \; , & \text{if} \; x < 0 \\
\lambda \exp[-\lambda x] \; , & \text{if} \; x \geq 0 \; .
\end{array}
\right.
\end{equation}

Since

\begin{equation} \label{eq:exp-mode-exp-pdf-eq0}
\lim_{x \to 0} f_X(x) = \infty
\end{equation}

and

\begin{equation} \label{eq:exp-mode-exp-pdf-neq0}
f_X(x) < \infty \quad \text{for any} \quad x \neq 0 \; ,
\end{equation}

it follows that

\begin{equation} \label{eq:exp-mode-exp-mode-qed}
\mathrm{mode}(X) = 0 \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P51 | shortcut: exp-mode | author: JoramSoch | date: 2020-02-12, 15:53.
\vspace{1em}



\subsection{Chi-squared distribution}

\subsubsection[\textit{Definition}]{Definition} \label{sec:chi2}
\setcounter{equation}{0}

\textbf{Definition:} Let $X_{1}, ..., X_{k}$ be independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}) random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) where each of them is following a standard normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:snorm}):

\begin{equation} \label{eq:chi2-snorm}
X_{i} \sim \mathcal{N}(0,1) \quad \text{for} \quad i = 1, \ldots, n \; .
\end{equation}

Then, the sum of their squares follows a chi-squared distribution with $k$ degrees of freedom:

\begin{equation}\label{eq:chi2-chi2}
Y = \sum_{i=1}^{k} X_{i}^{2} \sim \chi^{2}(k) \quad \text{where} \quad k > 0 \; .
\end{equation}

The probability density function of the chi-squared distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:chi2-pdf}) with $k$ degress of freedom is

\begin{equation} \label{eq:chi2-chi2-pdf}
\chi^{2}(x; k) = \frac{1}{2^{k/2}\Gamma (k/2)} \, x^{k/2-1} \, e^{-x/2}
\end{equation}

where $k > 0$ and the density is zero if $x \leq 0$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Chi-square distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-10-12; URL: \url{https://en.wikipedia.org/wiki/Chi-square_distribution#Definitions}.
\item Robert V. Hogg, Joseph W. McKean, Allen T. Craig (2018): "The Chi-Squared-Distribution"; in: \textit{Introduction to Mathematical Statistics}, Pearson, Boston, 2019, p. 178, eq. 3.3.7; URL: \url{https://www.pearson.com/store/p/introduction-to-mathematical-statistics/P100000843744}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D100 | shortcut: chi2 | author: kjpetrykowski | date: 2020-10-13, 01:20.
\vspace{1em}



\subsubsection[\textbf{Special case of gamma distribution}]{Special case of gamma distribution} \label{sec:chi2-gam}
\setcounter{equation}{0}

\textbf{Theorem:} The chi-squared distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:chi2}) with $k$ degrees of freedom is a special case of the gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:gam}) with shape $\frac{k}{2}$ and rate $\frac{1}{2}$:

\begin{equation} \label{eq:chi2-gam-chi2-gam}
X \sim \mathrm{Gam}\left( \frac{k}{2}, \frac{1}{2} \right) \Rightarrow X \sim \chi^{2}(k) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The probability density function of the gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-pdf}) for $x > 0$, where $\alpha$ is the shape parameter and $\beta$ is the rate paramete, is as follows:

\begin{equation} \label{eq:chi2-gam-gam-pdf}
\mathrm{Gam}(x; \alpha, \beta) = \frac{\beta^{\alpha}}{\Gamma(\alpha)} \, x^{\alpha-1} \, e^{-\beta x}
\end{equation}

If we let $\alpha = k/2$ and $\beta = 1/2$, we obtain

\begin{equation} \label{eq:chi2-gam-gam-pdf-chi2}
\mathrm{Gam}\left(x; \frac{k}{2}, \frac{1}{2}\right) = \frac{x^{k/2-1} \, e^{-x/2}}{\Gamma(k/2) 2^{k/2}} = \frac{1}{2^{k/2} \Gamma(k/2)} \, x^{k/2-1} \, e^{-x/2}
\end{equation}

which is equivalent to the probability density function of the chi-squared distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:chi2-pdf}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P174 | shortcut: chi2-gam | author: kjpetrykowski | date: 2020-10-12, 22:15.
\vspace{1em}



\subsubsection[\textbf{Probability density function}]{Probability density function} \label{sec:chi2-pdf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $Y$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a chi-squared distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:chi2}):

\begin{equation} \label{eq:chi2-pdf-chi2}
Y \sim \chi^{2}(k) \; .
\end{equation}

Then, the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $Y$ is

\begin{equation} \label{eq:chi2-pdf-chi2-pdf}
f_Y(y) = \frac{1}{2^{k/2} \, \Gamma (k/2)} \, y^{k/2-1} \, e^{-y/2} \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} A chi-square-distributed random variable ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:chi2}) with $k$ degrees of freedom is defined as the sum of $k$ squared standard normal random variables ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:snorm}):

\begin{equation} \label{eq:chi2-pdf-chi2-def}
X_1, \ldots, X_k \sim \mathcal{N}(0,1) \quad \Rightarrow \quad Y = \sum_{i=1}^{k} X_i^2 \sim \chi^{2}(k) \; .
\end{equation}

Let $x_1, \ldots, x_k$ be values of $X_1, \ldots, X_k$ and consider $x = \left( x_1, \ldots, x_k \right)$ to be a point in $k$-dimensional space. Define

\begin{equation} \label{eq:chi2-pdf-y-x}
y = \sum_{i=1}^{k} x_i^2
\end{equation}

and let $f_Y(y)$ and $F_Y(y)$ be the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) and cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) of $Y$. Because the PDF is the first derivative of the CDF ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:pdf-cdf}), we can write:

\begin{equation} \label{eq:chi2-pdf-y-pdf-s0}
F_Y(y) = \frac{F_Y(y)}{\mathrm{d}y} \, \mathrm{d}y = f_Y(y) \, \mathrm{d}y \; .
\end{equation}

Then, the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) of $Y$ can be expressed as

\begin{equation} \label{eq:chi2-pdf-y-cdf-s1}
f_Y(y) \, \mathrm{d}y = \int_{V} \prod_{i=1}^{k} \left( \mathcal{N}(x_i; 0, 1) \, \mathrm{d}x_i \right)
\end{equation}

where $\mathcal{N}(x_i; 0, 1)$ is the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of the standard normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:snorm}) and $V$ is the elemental shell volume at $y(x)$, which is proportional to the $(k-1)$-dimensional surface in $k$-space for which equation \eqref{eq:chi2-pdf-y-x} is fulfilled. Using the probability density function of the normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-pdf}), equation \eqref{eq:chi2-pdf-y-cdf-s1} can be developed as follows:

\begin{equation} \label{eq:chi2-pdf-y-cdf-s2}
\begin{split}
f_Y(y) \, \mathrm{d}y &= \int_{V} \prod_{i=1}^{k} \left( \frac{1}{\sqrt{2 \pi}} \cdot \exp \left[ -\frac{1}{2} x_i^2 \right] \, \mathrm{d}x_i \right) \\
&= \int_{V} \frac{\exp \left[ -\frac{1}{2} \left( x_1^2 + \ldots + x_k^2 \right) \right]}{(2 \pi)^{k/2}} \; \mathrm{d}x_1 \, \ldots \, \mathrm{d}x_k \\
&= \frac{1}{(2 \pi)^{k/2}} \int_{V} \exp \left[ -\frac{y}{2} \right] \; \mathrm{d}x_1 \, \ldots \, \mathrm{d}x_k \; .
\end{split}
\end{equation}

Because $y$ is constant within the set $V$, it can be moved out of the integral:

\begin{equation} \label{eq:chi2-pdf-y-cdf-s3}
f_Y(y) \, \mathrm{d}y = \frac{\exp \left[ -y/2 \right]}{(2 \pi)^{k/2}} \int_{V} \; \mathrm{d}x_1 \, \ldots \, \mathrm{d}x_k \; .
\end{equation}

Now, the integral is simply the surface area of the $(k-1)$-dimensional sphere with radius $r = \sqrt{y}$, which is

\begin{equation} \label{eq:chi2-pdf-A}
A = 2 r^{k-1} \, \frac{\pi^{k/2}}{\Gamma(k/2)} \; ,
\end{equation}

times the infinitesimal thickness of the sphere, which is

\begin{equation} \label{eq:chi2-pdf-dR}
\frac{\mathrm{d}r}{\mathrm{d}y} = \frac{1}{2} y^{-1/2} \quad \Leftrightarrow \quad \mathrm{d}r = \frac{\mathrm{d}y}{2 y^{1/2}} \; .
\end{equation}

Substituting \eqref{eq:chi2-pdf-A} and \eqref{eq:chi2-pdf-dR} into \eqref{eq:chi2-pdf-y-cdf-s3}, we have:

\begin{equation} \label{eq:chi2-pdf-y-cdf-s4}
\begin{split}
f_Y(y) \, \mathrm{d}y &= \frac{\exp \left[ -y/2 \right]}{(2 \pi)^{k/2}} \cdot A \, \mathrm{d}r \\
&= \frac{\exp \left[ -y/2 \right]}{(2 \pi)^{k/2}} \cdot 2 r^{k-1} \, \frac{\pi^{k/2}}{\Gamma(k/2)} \cdot \frac{\mathrm{d}y}{2 y^{1/2}} \\
&= \frac{1}{2^{k/2} \, \Gamma(k/2)} \cdot \frac{2 \sqrt{y}^{k-1}}{2 \sqrt{y}} \cdot \exp \left[ -y/2 \right] \, \mathrm{d}y \\
&= \frac{1}{2^{k/2} \, \Gamma(k/2)} \cdot y^{\frac{k}{2}-1} \cdot \exp \left[ -\frac{y}{2} \right] \, \mathrm{d}y \; .
\end{split}
\end{equation}

From this, we get the final result in \eqref{eq:chi2-pdf-chi2-pdf}:

\begin{equation} \label{eq:chi2-pdf-y-cdf-s5}
f_Y(y) = \frac{1}{2^{k/2} \, \Gamma (k/2)} \, y^{k/2-1} \, e^{-y/2} \; .
\end{equation}



\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Proofs related to chi-squared distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-11-25; URL: \url{https://en.wikipedia.org/wiki/Proofs_related_to_chi-squared_distribution#Derivation_of_the_pdf_for_k_degrees_of_freedom}.
\item Wikipedia (2020): "n-sphere"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-11-25; URL: \url{https://en.wikipedia.org/wiki/N-sphere#Volume_and_surface_area}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P197 | shortcut: chi2-pdf | author: JoramSoch | date: 2020-11-25, 05:56.
\vspace{1em}



\subsubsection[\textbf{Moments}]{Moments} \label{sec:chi2-mom}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a chi-squared distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:chi2}):

\begin{equation} \label{eq:chi2-mom-chi2}
X \sim \chi^{2}(k) \; .
\end{equation}

If $m > -k/2$, then $E(X^{m})$ exists and is equal to:

\begin{equation} \label{eq:chi2-mom-chi2-mom}
\mathrm{E}(X^{m}) = \frac{2^{m} \Gamma\left( \frac{k}{2}+m \right)}{\Gamma\left( \frac{k}{2} \right)} \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} Combining the definition of the $m$-th raw moment ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mom-raw}) with the probability density function of the chi-squared distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:chi2-pdf}), we have:

\begin{equation} \label{eq:chi2-mom-chi2-mom-int}
\mathrm{E}(X^{m}) = \int_{0}^{\infty} \frac{1}{\Gamma\left( \frac{k}{2} \right) 2^{k/2}} \, x^{(k/2)+m-1} \, e^{-x/2} \mathrm{d}x \; . 
\end{equation}

Now define a new variable $u = x/2$. As a result, we obtain:

\begin{equation} \label{eq:chi2-mom-chi-2-mom-int-u}
\mathrm{E}(X^{m}) = \int_{0}^{\infty} \frac{1}{\Gamma\left( \frac{k}{2} \right) 2^{(k/2)-1}} \, 2^{(k/2)+m-1} \, u^{(k/2)+m-1} \, e^{-u} \mathrm{d}u \; .
\end{equation}

This leads to the desired result when $m > -k/2$. Observe that, if $m$ is a nonnegative integer, then $m > -k/2$ is always true. Therefore, all moments ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mom}) of a chi-squared distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:chi2}) exist and the $m$-th raw moment is given by the foregoing equation.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Robert V. Hogg, Joseph W. McKean, Allen T. Craig (2018): "The Ï‡2-Distribution"; in: \textit{Introduction to Mathematical Statistics}, Pearson, Boston, 2019, p. 179, eq. 3.3.8; URL: \url{https://www.pearson.com/store/p/introduction-to-mathematical-statistics/P100000843744}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P175 | shortcut: chi2-mom | author: kjpetrykowski | date: 2020-10-13, 01:30.
\vspace{1em}



\subsection{F-distribution}

\subsubsection[\textit{Definition}]{Definition} \label{sec:f}
\setcounter{equation}{0}

\textbf{Definition:} Let $X_1$ and $X_2$ be independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}) random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a chi-squared distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:chi2}) with $d_1$ and $d_2$ degrees of freedom ($\rightarrow$ Definition "dof"), respectively:

\begin{equation} \label{eq:f-chi2}
\begin{split}
X_1 &\sim \chi^{2}(d_1) \\
X_2 &\sim \chi^{2}(d_2) \; .
\end{split}
\end{equation}

Then, the ratio of $X_1$ to $X_2$, divided by their respective degrees of freedom, is said to be $F$-distributed with numerator degrees of freedom $d_1$ and denominator degrees of freedom $d_2$:

\begin{equation}\label{eq:f-F}
Y = \frac{X_1 / d_1}{X_2 / d_2} \sim F(d_1,d_2) \quad \text{where} \quad d_1, d_2 > 0 \; .
\end{equation}

The $F$-distribution is also called "Snedecor's $F$-distribution" or "Fisherâ€“Snedecor distribution", after Ronald A. Fisher and George W. Snedecor.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "F-distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-04-21; URL: \url{https://en.wikipedia.org/wiki/F-distribution#Characterization}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D146 | shortcut: f | author: JoramSoch | date: 2020-04-21, 07:26.
\vspace{1em}



\subsubsection[\textbf{Probability density function}]{Probability density function} \label{sec:f-pdf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $F$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following an F-distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:f}):

\begin{equation} \label{eq:f-pdf-f}
F \sim F(u,v) \; .
\end{equation}

Then, the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $F$ is

\begin{equation} \label{eq:f-pdf-f-pdf}
f_F(f) = \frac{\Gamma\left( \frac{u+v}{2} \right)}{\Gamma\left( \frac{u}{2} \right) \cdot \Gamma\left( \frac{v}{2} \right)} \cdot \left( \frac{u}{v} \right)^{\frac{u}{2}} \cdot f^{\frac{u}{2}-1} \cdot \left( \frac{u}{v}f+1 \right)^{-\frac{u+v}{2}} \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} An F-distributed random variable ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:f}) is defined as the ratio of two chi-squared random variables ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:chi2}), divided by their degrees of freedom ($\rightarrow$ Definition "dof")

\begin{equation} \label{eq:f-pdf-f-def}
X \sim \chi^2(u), \; Y \sim \chi^2(v) \quad \Rightarrow \quad F = \frac{X/u}{Y/v} \sim F(u,v)
\end{equation}

where $X$ and $Y$ are independent of each other ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}).

The probability density function of the chi-squared distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:chi2-pdf}) is

\begin{equation} \label{eq:f-pdf-chi2-pdf}
f_X(x) = \frac{1}{\Gamma\left( \frac{u}{2} \right) \cdot 2^{u/2}} \cdot x^{\frac{u}{2}-1} \cdot e^{-\frac{x}{2}} \; .
\end{equation}

Define the random variables $F$ and $W$ as functions of $X$ and $Y$

\begin{equation} \label{eq:f-pdf-FW-XY}
\begin{split}
F &= \frac{X/u}{Y/v} \\
W &= Y \; ,
\end{split}
\end{equation}

such that the inverse functions $X$ and $Y$ in terms of $F$ and $W$ are

\begin{equation} \label{eq:f-pdf-XY-FW}
\begin{split}
X &= \frac{u}{v} F W \\
Y &= W \; .
\end{split}
\end{equation}

This implies the following Jacobian matrix and determinant:

\begin{equation} \label{eq:f-pdf-XY-FW-jac}
\begin{split}
J &= \left[ \begin{matrix}
\frac{\mathrm{d}X}{\mathrm{d}F} & \frac{\mathrm{d}X}{\mathrm{d}W} \\
\frac{\mathrm{d}Y}{\mathrm{d}F} & \frac{\mathrm{d}Y}{\mathrm{d}W}
\end{matrix} \right]
= \left[ \begin{matrix}
\frac{u}{v} W & \frac{u}{v} F \\
0 & 1
\end{matrix} \right] \\
\lvert J \rvert  &= \frac{u}{v} W \; .
\end{split}
\end{equation}

Because $X$ and $Y$ are independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}), the joint density ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-joint}) of $X$ and $Y$ is equal to the product ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:prob-ind}) of the marginal densities ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-marg}):

\begin{equation} \label{eq:f-pdf-f-XY}
f_{X,Y}(x,y) = f_X(x) \cdot f_Y(y) \; .
\end{equation}

With the probability density function of an invertible function ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:pdf-invfct}), the joint density ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-joint}) of $T$ and $W$ can be derived as:

\begin{equation} \label{eq:f-pdf-f-FW-s1}
f_{F,W}(f,w) = f_{X,Y}(x,y) \cdot \lvert J \rvert \; .
\end{equation}

Substituting \eqref{eq:f-pdf-XY-FW} into \eqref{eq:f-pdf-chi2-pdf}, and then with \eqref{eq:f-pdf-XY-FW-jac} into \eqref{eq:f-pdf-f-FW-s1}, we get:

\begin{equation} \label{eq:f-pdf-f-FW-s2}
\begin{split}
f_{F,W}(f,w) &= f_X\left( \frac{u}{v} f w \right) \cdot f_Y(w) \cdot \lvert J \rvert \\
&= \frac{1}{\Gamma\left( \frac{u}{2} \right) \cdot 2^{u/2}} \cdot \left( \frac{u}{v} f w \right)^{\frac{u}{2}-1} \cdot e^{-\frac{1}{2} \left( \frac{u}{v} f w \right)} \cdot \frac{1}{\Gamma\left( \frac{v}{2} \right) \cdot 2^{v/2}} \cdot w^{\frac{v}{2}-1} \cdot e^{-\frac{w}{2}} \cdot \frac{u}{v} w \\
&= \frac{\left( \frac{u}{v} \right)^{\frac{u}{2}} \cdot f^{\frac{u}{2}-1}}{\Gamma\left( \frac{u}{2} \right) \cdot \Gamma\left( \frac{v}{2} \right) \cdot 2^{(u+v)/2}} \cdot w^{\frac{u+v}{2}-1} \cdot e^{-\frac{w}{2} \left( \frac{u}{v} f + 1 \right)} \; .
\end{split}
\end{equation}

The marginal density ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-marg}) of $F$ can now be obtained by integrating out ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}) $W$:

\begin{equation} \label{eq:f-pdf-f-F-s1}
\begin{split}
f_F(f) &= \int_{0}^{\infty} f_{F,W}(f,w) \, \mathrm{d}w \\
&= \frac{\left( \frac{u}{v} \right)^{\frac{u}{2}} \cdot f^{\frac{u}{2}-1}}{\Gamma\left( \frac{u}{2} \right) \cdot \Gamma\left( \frac{v}{2} \right) \cdot 2^{(u+v)/2}} \cdot \int_{0}^{\infty} w^{\frac{u+v}{2}-1} \cdot \mathrm{exp}\left[ -\frac{1}{2} \left( \frac{u}{v} f + 1 \right) w \right] \, \mathrm{d}w \\
&= \frac{\left( \frac{u}{v} \right)^{\frac{u}{2}} \cdot f^{\frac{u}{2}-1}}{\Gamma\left( \frac{u}{2} \right) \cdot \Gamma\left( \frac{v}{2} \right) \cdot 2^{(u+v)/2}} \cdot \frac{\Gamma\left( \frac{u+v}{2} \right)}{\left[ \frac{1}{2}\left( \frac{u}{v} f + 1 \right) \right]^{(u+v)/2}} \cdot \int_{0}^{\infty} \frac{\left[ \frac{1}{2}\left( \frac{u}{v} f + 1 \right) \right]^{(u+v)/2}}{\Gamma\left( \frac{u+v}{2} \right)} \cdot w^{\frac{u+v}{2}-1} \cdot \mathrm{exp}\left[ -\frac{1}{2} \left( \frac{u}{v} f + 1 \right) w \right] \, \mathrm{d}w \; .
\end{split}
\end{equation}

At this point, we can recognize that the integrand is equal to the probability density function of a gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-pdf}) with

\begin{equation} \label{eq:f-pdf-f-W-gam-ab}
a = \frac{u+v}{2} \quad \text{and} \quad b = \frac{1}{2}\left( \frac{u}{v} f + 1 \right) \; ,
\end{equation}

and because a probability density function integrates to one ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}), we finally have:

\begin{equation} \label{eq:f-pdf-f-F-s2}
\begin{split}
f_F(f) &= \frac{\left( \frac{u}{v} \right)^{\frac{u}{2}} \cdot f^{\frac{u}{2}-1}}{\Gamma\left( \frac{u}{2} \right) \cdot \Gamma\left( \frac{v}{2} \right) \cdot 2^{(u+v)/2}} \cdot \frac{\Gamma\left( \frac{u+v}{2} \right)}{\left[ \frac{1}{2}\left( \frac{u}{v} f + 1 \right) \right]^{(u+v)/2}} \\
&= \frac{\Gamma\left( \frac{u+v}{2} \right)}{\Gamma\left( \frac{u}{2} \right) \cdot \Gamma\left( \frac{v}{2} \right)} \cdot \left( \frac{u}{v} \right)^{\frac{u}{2}} \cdot f^{\frac{u}{2}-1} \cdot \left( \frac{u}{v}f+1 \right)^{-\frac{u+v}{2}} \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item statisticsmatt (2018): "Statistical Distributions: Derive the F Distribution"; in: \textit{YouTube}, retrieved on 2021-10-11; URL: \url{https://www.youtube.com/watch?v=AmHiOKYmHkI}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P264 | shortcut: f-pdf | author: JoramSoch | date: 2021-10-12, 09:00.
\vspace{1em}



\subsection{Beta distribution}

\subsubsection[\textit{Definition}]{Definition} \label{sec:beta}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}). Then, $X$ is said to follow a beta distribution with shape parameters $\alpha$ and $\beta$

\begin{equation} \label{eq:beta-beta}
X \sim \mathrm{Bet}(\alpha, \beta) \; ,
\end{equation}

if and only if its probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) is given by

\begin{equation} \label{eq:beta-beta-pdf}
\mathrm{Bet}(x; \alpha, \beta) = \frac{1}{\mathrm{B}(\alpha, \beta)} \, x^{\alpha-1} \, (1-x)^{\beta-1}
\end{equation}

where $\alpha > 0$ and $\beta > 0$, and the density is zero, if $x \notin [0,1]$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Beta distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-05-10; URL: \url{https://en.wikipedia.org/wiki/Beta_distribution#Definitions}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D53 | shortcut: beta | author: JoramSoch | date: 2020-05-10, 20:29.
\vspace{1em}



\subsubsection[\textbf{Probability density function}]{Probability density function} \label{sec:beta-pdf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a beta distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:beta}):

\begin{equation} \label{eq:beta-pdf-beta}
X \sim \mathrm{Bet}(\alpha, \beta) \; .
\end{equation}

Then, the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $X$ is

\begin{equation} \label{eq:beta-pdf-beta-pdf}
f_X(x) = \frac{1}{\mathrm{B}(\alpha, \beta)} \, x^{\alpha-1} \, (1-x)^{\beta-1} \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} This follows directly from the definition of the beta distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:beta}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P94 | shortcut: beta-pdf | author: JoramSoch | date: 2020-05-05, 21:03.
\vspace{1em}



\subsubsection[\textbf{Moment-generating function}]{Moment-generating function} \label{sec:beta-mgf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a positive random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a beta distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:gam}):

\begin{equation} \label{eq:beta-mgf-beta}
X \sim \mathrm{Bet}(\alpha, \beta) \; .
\end{equation}

Then, the moment-generating function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mgf}) of $X$ is

\begin{equation} \label{eq:beta-mgf-beta-mgf}
M_X(t) = 1 + \sum_{n=1}^{\infty} \left( \prod_{m=0}^{n-1} \frac{\alpha + m}{\alpha + \beta + m} \right) \frac{t^n}{n!} \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The probability density function of the beta distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:beta-pdf}) is

\begin{equation} \label{eq:beta-mgf-beta-pdf}
f_X(x) = \frac{1}{\mathrm{B}(\alpha, \beta)} \, x^{\alpha-1} \, (1-x)^{\beta-1}
\end{equation}

and the moment-generating function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mgf}) is defined as

\begin{equation} \label{eq:beta-mgf-mgf-var}
M_X(t) = \mathrm{E} \left[ e^{tX} \right] \; .
\end{equation}

Using the expected value for continuous random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}), the moment-generating function of $X$ therefore is

\begin{equation} \label{eq:beta-mgf-beta-mgf-s1}
\begin{split}
M_X(t) &= \int_{0}^{1} \exp[tx] \cdot \frac{1}{\mathrm{B}(\alpha, \beta)} \, x^{\alpha-1} \, (1-x)^{\beta-1} \, \mathrm{d}x \\
&= \frac{1}{\mathrm{B}(\alpha, \beta)} \int_{0}^{1} e^{tx} \, x^{\alpha-1} \, (1-x)^{\beta-1} \, \mathrm{d}x \; .
\end{split}
\end{equation}

With the relationship between beta function and gamma function

\begin{equation} \label{eq:beta-mgf-beta-gam-fct}
\mathrm{B}(\alpha, \beta) = \frac{\Gamma(\alpha) \, \Gamma(\beta)}{\Gamma(\alpha+\beta)}
\end{equation}

and the integral representation of the confluent hypergeometric function (Kummer's function of the first kind)

\begin{equation} \label{eq:beta-mgf-con-hyp-geo-fct-int}
{}_1 F_1(a,b,z) = \frac{\Gamma(b)}{\Gamma(a) \, \Gamma(b-a)} \int_{0}^{1} e^{zu} \, u^{a-1} \, (1-u)^{(b-a)-1} \, \mathrm{d}u \; ,
\end{equation}

the moment-generating function can be written as

\begin{equation} \label{eq:beta-mgf-beta-mgf-s2}
M_X(t) = {}_1 F_1(\alpha,\alpha+\beta,t) \; .
\end{equation}

Note that the series equation for the confluent hypergeometric function (Kummer's function of the first kind) is

\begin{equation} \label{eq:beta-mgf-con-hyp-geo-fct-ser}
{}_1 F_1(a,b,z) = \sum_{n=0}^{\infty} \frac{a^{\overline{n}}}{b^{\overline{n}}} \, \frac{z^n}{n!}
\end{equation}

where $m^{\overline{n}}$ is the rising factorial

\begin{equation} \label{eq:beta-mgf-fact-rise}
m^{\overline{n}} = \prod_{i=0}^{n-1} (m+i) \; ,
\end{equation}

so that the moment-generating function can be written as

\begin{equation} \label{eq:beta-mgf-beta-mgf-s3}
M_X(t) = \sum_{n=0}^{\infty} \frac{\alpha^{\overline{n}}}{(\alpha+\beta)^{\overline{n}}} \, \frac{t^n}{n!} \; .
\end{equation}

Applying the rising factorial equation \eqref{eq:beta-mgf-fact-rise} and using $m^{\overline{0}} = x^0 = 0! = 1$, we finally have:

\begin{equation} \label{eq:beta-mgf-beta-mgf-s4}
M_X(t) = 1 + \sum_{n=1}^{\infty} \left( \prod_{m=0}^{n-1} \frac{\alpha + m}{\alpha + \beta + m} \right) \frac{t^n}{n!} \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Beta distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-11-25; URL: \url{https://en.wikipedia.org/wiki/Beta_distribution#Moment_generating_function}.
\item Wikipedia (2020): "Confluent hypergeometric function"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-11-25; URL: \url{https://en.wikipedia.org/wiki/Confluent_hypergeometric_function#Kummer's_equation}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P198 | shortcut: beta-mgf | author: JoramSoch | date: 2020-11-25, 06:55.
\vspace{1em}



\subsubsection[\textbf{Cumulative distribution function}]{Cumulative distribution function} \label{sec:beta-cdf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a positive random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a beta distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:gam}):

\begin{equation} \label{eq:beta-cdf-beta}
X \sim \mathrm{Bet}(\alpha, \beta) \; .
\end{equation}

Then, the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) of $X$ is

\begin{equation} \label{eq:beta-cdf-beta-cdf}
F_X(x) = \frac{B(x; \alpha, \beta)}{B(\alpha, \beta)}
\end{equation}

where $B(a,b)$ is the beta function and $B(x;a,b)$ is the incomplete gamma function.


\vspace{1em}
\textbf{Proof:} The probability density function of the beta distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:beta-pdf}) is:

\begin{equation} \label{eq:beta-cdf-beta-pdf}
f_X(x) = \frac{1}{\mathrm{B}(\alpha, \beta)} \, x^{\alpha-1} \, (1-x)^{\beta-1} \; .
\end{equation}

Thus, the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) is:

\begin{equation} \label{eq:beta-cdf-beta-cdf-app}
\begin{split}
F_X(x) &= \int_{0}^{x} \mathrm{Bet}(z; \alpha, \beta) \, \mathrm{d}z \\
&= \int_{0}^{x} \frac{1}{\mathrm{B}(\alpha, \beta)} \, z^{\alpha-1} \, (1-z)^{\beta-1} \, \mathrm{d}z \\
&= \frac{1}{\mathrm{B}(\alpha, \beta)} \int_{0}^{x} z^{\alpha-1} \, (1-z)^{\beta-1} \, \mathrm{d}z \; .
\end{split}
\end{equation}

With the definition of the incomplete beta function

\begin{equation} \label{eq:beta-cdf-inc-beta-fct}
B(x;a,b) = \int_{0}^{x} t^{a-1} \, (1-t)^{b-1} \, \mathrm{d}t \; ,
\end{equation}

we arrive at the final result given by equation \eqref{eq:beta-cdf-beta-cdf}:

\begin{equation} \label{eq:beta-cdf-beta-cdf-qed}
F_X(x) = \frac{B(x; \alpha, \beta)}{B(\alpha, \beta)} \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Beta distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-11-19; URL: \url{https://en.wikipedia.org/wiki/Beta_distribution#Cumulative_distribution_function}.
\item Wikipedia (2020): "Beta function"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-11-19; URL: \url{https://en.wikipedia.org/wiki/Beta_function#Incomplete_beta_function}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P195 | shortcut: beta-cdf | author: JoramSoch | date: 2020-11-19, 08:01.
\vspace{1em}



\subsubsection[\textbf{Mean}]{Mean} \label{sec:beta-mean}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a beta distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:beta}):

\begin{equation} \label{eq:beta-mean-beta}
X \sim \mathrm{Bet}(\alpha, \beta) \; .
\end{equation}

Then, the mean or expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of $X$ is

\begin{equation} \label{eq:beta-mean-beta-mean}
\mathrm{E}(X) = \frac{\alpha}{\alpha + \beta} \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) is the probability-weighted average over all possible values:

\begin{equation} \label{eq:beta-mean-mean}
\mathrm{E}(X) = \int_{\mathcal{X}} x \cdot f_X(x) \, \mathrm{d}x \; .
\end{equation}

The probability density function of the beta distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:beta-pdf}) is

\begin{equation} \label{eq:beta-mean-beta-pdf}
f_X(x) = \frac{1}{\mathrm{B}(\alpha, \beta)} \, x^{\alpha-1} \, (1-x)^{\beta-1}, \quad 0 \leq x \leq 1
\end{equation}

where the beta function is given by a ratio gamma functions:

\begin{equation} \label{eq:beta-mean-beta-fct}
\mathrm{B}(\alpha, \beta) = \frac{\Gamma(\alpha) \cdot \Gamma(\beta)}{\Gamma(\alpha+\beta)} \; .
\end{equation}

Combining \eqref{eq:beta-mean-mean}, \eqref{eq:beta-mean-beta-pdf} and \eqref{eq:beta-mean-beta-fct}, we have:

\begin{equation} \label{eq:beta-mean-beta-mean-s1}
\begin{split}
\mathrm{E}(X) &= \int_{0}^{1} x \cdot \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha) \cdot \Gamma(\beta)} \, x^{\alpha-1} \, (1-x)^{\beta-1} \, \mathrm{d}x \\
&= \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)} \cdot \frac{\Gamma(\alpha+1)}{\Gamma(\alpha+1+\beta)} \int_{0}^{1} \frac{\Gamma(\alpha+1+\beta)}{\Gamma(\alpha+1) \cdot \Gamma(\beta)} \, x^{(\alpha+1)-1} \, (1-x)^{\beta-1} \, \mathrm{d}x \; .
\end{split}
\end{equation}

Employing the relation $\Gamma(x+1) = \Gamma(x) \cdot x$, we have

\begin{equation} \label{eq:beta-mean-beta-mean-s2}
\begin{split}
\mathrm{E}(X) &= \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)} \cdot \frac{\alpha \cdot \Gamma(\alpha)}{(\alpha+\beta) \cdot \Gamma(\alpha+\beta)} \int_{0}^{1} \frac{\Gamma(\alpha+1+\beta)}{\Gamma(\alpha+1) \cdot \Gamma(\beta)} \, x^{(\alpha+1)-1} \, (1-x)^{\beta-1} \, \mathrm{d}x \\
&= \frac{\alpha}{\alpha+\beta} \int_{0}^{1} \frac{\Gamma(\alpha+1+\beta)}{\Gamma(\alpha+1) \cdot \Gamma(\beta)} \, x^{(\alpha+1)-1} \, (1-x)^{\beta-1} \, \mathrm{d}x
\end{split}
\end{equation}

and again using the density of the beta distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:beta-pdf}), we get

\begin{equation} \label{eq:beta-mean-beta-mean-s3}
\begin{split}
\mathrm{E}(X) &= \frac{\alpha}{\alpha+\beta} \int_{0}^{1} \mathrm{Bet}(x; \alpha+1, \beta) \, \mathrm{d}x \\
&= \frac{\alpha}{\alpha+\beta} \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Boer Commander (2020): "Beta Distribution Mean and Variance Proof"; in: \textit{YouTube}, retrieved on 2021-04-29; URL: \url{https://www.youtube.com/watch?v=3OgCcnpZtZ8}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P228 | shortcut: beta-mean | author: JoramSoch | date: 2021-04-29, 09:12.
\vspace{1em}



\subsubsection[\textbf{Variance}]{Variance} \label{sec:beta-var}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a beta distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:beta}):

\begin{equation} \label{eq:beta-var-beta}
X \sim \mathrm{Bet}(\alpha, \beta) \; .
\end{equation}

Then, the variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) of $X$ is

\begin{equation} \label{eq:beta-var-beta-var}
\mathrm{Var}(X) = \frac{\alpha \beta}{(\alpha + \beta + 1) \cdot (\alpha + \beta)^2} \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) can be expressed in terms of expected values ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:var-mean}) as

\begin{equation} \label{eq:beta-var-var-mean}
\mathrm{Var}(X) = \mathrm{E}(X^2) - \mathrm{E}(X)^2 \; .
\end{equation}

The expected value of a beta random variable ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:beta-mean}) is

\begin{equation} \label{eq:beta-var-beta-mean}
\mathrm{E}(X) = \frac{\alpha}{\alpha+\beta} \; .
\end{equation}

The probability density function of the beta distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:beta-pdf}) is

\begin{equation} \label{eq:beta-var-beta-pdf}
f_X(x) = \frac{1}{\mathrm{B}(\alpha, \beta)} \, x^{\alpha-1} \, (1-x)^{\beta-1}, \quad 0 \leq x \leq 1
\end{equation}

where the beta function is given by a ratio gamma functions:

\begin{equation} \label{eq:beta-var-beta-fct}
\mathrm{B}(\alpha, \beta) = \frac{\Gamma(\alpha) \cdot \Gamma(\beta)}{\Gamma(\alpha+\beta)} \; .
\end{equation}

Therefore, the expected value of a squared beta random variable becomes

\begin{equation} \label{eq:beta-var-beta-sqr-mean-s1}
\begin{split}
\mathrm{E}(X^2) &= \int_{0}^{1} x^2 \cdot \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha) \cdot \Gamma(\beta)} \, x^{\alpha-1} \, (1-x)^{\beta-1} \, \mathrm{d}x \\
&= \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)} \cdot \frac{\Gamma(\alpha+2)}{\Gamma(\alpha+2+\beta)} \int_{0}^{1} \frac{\Gamma(\alpha+2+\beta)}{\Gamma(\alpha+2) \cdot \Gamma(\beta)} \, x^{(\alpha+2)-1} \, (1-x)^{\beta-1} \, \mathrm{d}x \; .
\end{split}
\end{equation}

Twice-applying the relation $\Gamma(x+1) = \Gamma(x) \cdot x$, we have

\begin{equation} \label{eq:beta-var-beta-sqr-mean-s2}
\begin{split}
\mathrm{E}(X^2) &= \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)} \cdot \frac{(\alpha+1) \cdot \alpha \cdot \Gamma(\alpha)}{(\alpha+\beta+1) \cdot (\alpha+\beta) \cdot \Gamma(\alpha+\beta)} \int_{0}^{1} \frac{\Gamma(\alpha+2+\beta)}{\Gamma(\alpha+2) \cdot \Gamma(\beta)} \, x^{(\alpha+2)-1} \, (1-x)^{\beta-1} \, \mathrm{d}x \\
&= \frac{(\alpha+1) \cdot \alpha}{(\alpha+\beta+1) \cdot (\alpha+\beta)} \int_{0}^{1} \frac{\Gamma(\alpha+2+\beta)}{\Gamma(\alpha+2) \cdot \Gamma(\beta)} \, x^{(\alpha+2)-1} \, (1-x)^{\beta-1} \, \mathrm{d}x
\end{split}
\end{equation}

and again using the density of the beta distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:beta-pdf}), we get

\begin{equation} \label{eq:beta-var-beta-sqr-mean-s3}
\begin{split}
\mathrm{E}(X^2) &= \frac{(\alpha+1) \cdot \alpha}{(\alpha+\beta+1) \cdot (\alpha+\beta)} \int_{0}^{1} \mathrm{Bet}(x; \alpha+2, \beta) \, \mathrm{d}x \\
&= \frac{(\alpha+1) \cdot \alpha}{(\alpha+\beta+1) \cdot (\alpha+\beta)} \; .
\end{split}
\end{equation}

Plugging \eqref{eq:beta-var-beta-sqr-mean-s3} and \eqref{eq:beta-var-beta-mean} into \eqref{eq:beta-var-var-mean}, the variance of a beta random variable finally becomes

\begin{equation} \label{eq:beta-var-beta-var-qed}
\begin{split}
\mathrm{Var}(X) &= \frac{(\alpha+1) \cdot \alpha}{(\alpha+\beta+1) \cdot (\alpha+\beta)} - \left( \frac{\alpha}{\alpha+\beta} \right)^2 \\
&= \frac{(\alpha^2+\alpha) \cdot (\alpha + \beta)}{(\alpha + \beta + 1) \cdot (\alpha + \beta)^2} - \frac{\alpha^2 \cdot (\alpha + \beta + 1)}{(\alpha + \beta + 1) \cdot (\alpha + \beta)^2} \\
&= \frac{(\alpha^3 + \alpha^2 \beta + \alpha^2 + \alpha \beta) - (\alpha^3 + \alpha^2 \beta + \alpha^2)}{(\alpha + \beta + 1) \cdot (\alpha + \beta)^2} \\
&= \frac{\alpha \beta}{(\alpha + \beta + 1) \cdot (\alpha + \beta)^2} \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Boer Commander (2020): "Beta Distribution Mean and Variance Proof"; in: \textit{YouTube}, retrieved on 2021-04-29; URL: \url{https://www.youtube.com/watch?v=3OgCcnpZtZ8}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P229 | shortcut: beta-var | author: JoramSoch | date: 2021-04-29, 09:31.
\vspace{1em}



\subsection{Wald distribution}

\subsubsection[\textit{Definition}]{Definition} \label{sec:wald}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}). Then, $X$ is said to follow a Wald distribution with drift rate $\gamma$ and threshold $\alpha$

\begin{equation} \label{eq:wald-wald}
X \sim \mathrm{Wald}(\gamma, \alpha) \; ,
\end{equation}

if and only if its probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) is given by

\begin{equation} \label{eq:wald-wald-pdf}
\mathrm{Wald}(x; \gamma, \alpha) = \frac{\alpha}{\sqrt{2\pi x^3}}\exp\left(-\frac{(\alpha-\gamma x)^2}{2x}\right)
\end{equation}

where $\gamma > 0$, $\alpha > 0$, and the density is zero if $x \leq 0$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Anders, R., Alario, F.-X., and van Maanen, L. (2016): "The Shifted Wald Distribution for Response Time Data Analysis"; in: \textit{Psychological Methods}, vol. 21, no. 3, pp. 309-327; URL: \url{https://dx.doi.org/10.1037/met0000066}; DOI: 10.1037/met0000066.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D95 | shortcut: wald | author: tomfaulkenberry | date: 2020-09-04, 12:00.
\vspace{1em}



\subsubsection[\textbf{Probability density function}]{Probability density function} \label{sec:wald-pdf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a positive random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a Wald distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:wald}):

\begin{equation} \label{eq:wald-pdf-wald}
X \sim \mathrm{Wald}(\gamma, \alpha) \; .
\end{equation}

Then, the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $X$ is

\begin{equation} \label{eq:wald-pdf-wald-pdf}
f_X(x) = \frac{\alpha}{\sqrt{2\pi x^3}}\exp\left(-\frac{(\alpha-\gamma x)^2}{2x}\right) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} This follows directly from the definition of the Wald distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:wald}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P162 | shortcut: wald-pdf | author: tomfaulkenberry | date: 2020-09-04, 12:00.
\vspace{1em}



\subsubsection[\textbf{Moment-generating function}]{Moment-generating function} \label{sec:wald-mgf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a positive random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a Wald distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:wald}):

\begin{equation} \label{eq:wald-mgf-wald}
X \sim \mathrm{Wald}(\gamma, \alpha) \; .
\end{equation}

Then, the moment-generating function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mgf}) of $X$ is

\begin{equation} \label{eq:wald-mgf-wald-mgf}
M_X(t) = \exp \left[ \alpha\gamma-\sqrt{\alpha^2(\gamma^2-2t)}\right] \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The probability density function of the Wald distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:wald-pdf}) is

\begin{equation} \label{eq:wald-mgf-wald-pdf}
f_X(x) = \frac{\alpha}{\sqrt{2\pi x^3}}\exp\left(-\frac{(\alpha-\gamma x)^2}{2x}\right)
\end{equation}

and the moment-generating function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mgf}) is defined as

\begin{equation} \label{eq:wald-mgf-mgf-var}
M_X(t) = \mathrm{E} \left[ e^{tX} \right] \; .
\end{equation}

Using the definition of expected value for continuous random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}), the moment-generating function of $X$ therefore is

\begin{equation} \label{eq:wald-mgf-wald-mgf-s1}
\begin{split}
M_X(t) &= \int_0^{\infty} e^{tx} \cdot \frac{\alpha}{\sqrt{2\pi x^3}}\cdot \exp\left[-\frac{(\alpha-\gamma x)^2}{2x}\right]dx \\
&= \frac{\alpha}{\sqrt{2\pi}}\int_0^{\infty} x^{-3/2}\cdot \exp\left[tx - \frac{(\alpha-\gamma x)^2}{2x}\right]dx \; .
\end{split}
\end{equation}

To evaluate this integral, we will need two identities about modified Bessel functions of the second kind\footnote{\url{https://dlmf.nist.gov/10.25}}, denoted $K_{p}$. The function $K_{p}$ (for $p\in \mathbb{R}$) is one of the two linearly independent solutions of the differential equation

\begin{equation} \label{eq:wald-mgf-bessel-de}
x^2\frac{d^2y}{dx^2} + x\frac{dy}{dx}-(x^2+p^2)y=0 \; .
\end{equation}

The first of these identities\footnote{\url{https://dlmf.nist.gov/10.39.2}} gives an explicit solution for $K_{-1/2}$:

\begin{equation} \label{eq:wald-mgf-bessel-fact1}
K_{-1/2}(x) = \sqrt{\frac{\pi}{2x}} e^{-x} \; .
\end{equation}

The second of these identities\footnote{\url{https://dlmf.nist.gov/10.32.10}} gives an integral representation of $K_p$:

\begin{equation} \label{eq:wald-mgf-bessel-fact2}
K_p(\sqrt{ab}) = \frac{1}{2}\left(\frac{a}{b}\right)^{p/2} \int_0^{\infty}x^{p-1}\cdot \exp\left[-\frac{1}{2}\left(ax + \frac{b}{x}\right)\right]dx \; .
\end{equation}

Starting from \eqref{eq:wald-mgf-wald-mgf-s1}, we can expand the binomial term and rearrange the moment generating function into the following form:

\begin{equation} \label{eq:wald-mgf-wald-mgf-s2}
\begin{split}
M_X(t) &= \frac{\alpha}{\sqrt{2\pi}} \int_0^{\infty} x^{-3/2}\cdot \exp\left[ tx - \frac{\alpha^2}{2x} + \alpha\gamma - \frac{\gamma^2x}{2}\right]dx \\
       &= \frac{\alpha}{\sqrt{2\pi}}\cdot e^{\alpha \gamma} \int_0^{\infty} x^{-3/2}\cdot \exp\left[\left(t-\frac{\gamma^2}{2}\right)x - \frac{\alpha^2}{2x}\right]dx \\
       &= \frac{\alpha}{\sqrt{2\pi}}\cdot e^{\alpha \gamma} \int_0^{\infty} x^{-3/2}\cdot \exp \left[-\frac{1}{2}\left(\gamma^2-2t\right)x - \frac{1}{2}\cdot \frac{\alpha^2}{x}\right]dx \; .
\end{split}
\end{equation}

The integral now has the form of the integral in \eqref{eq:wald-mgf-bessel-fact2} with $p=-1/2$, $a=\gamma^2-2t$, and $b=\alpha^2$. This allows us to write the moment-generating function in terms of the modified Bessel function $K_{-1/2}$:

\begin{equation} \label{eq:wald-mgf-wald-mgf-s3}
M_X(t) = \frac{\alpha}{\sqrt{2\pi}}\cdot e^{\alpha \gamma}\cdot 2\left(\frac{\gamma^2-2t}{\alpha^2}\right)^{1/4}\cdot K_{-1/2}\left(\sqrt{\alpha^2(\gamma^2-2t)}\right).
\end{equation}

Combining with \eqref{eq:wald-mgf-bessel-fact1} and simplifying gives

\begin{equation} \label{eq:wald-mgf-wald-mgf-s4}
\begin{split}
M_X(t) &= \frac{\alpha}{\sqrt{2\pi}}\cdot e^{\alpha \gamma}\cdot 2\left(\frac{\gamma^2-2t}{\alpha^2}\right)^{1/4} \cdot \sqrt{\frac{\pi}{2\sqrt{\alpha^2(\gamma^2-2t)}}}\cdot \exp\left[-\sqrt{\alpha^2(\gamma^2-2t)}\right] \\
       &= \frac{\alpha}{\sqrt{2}\cdot \sqrt{\pi}}\cdot e^{\alpha \gamma}\cdot 2 \cdot \frac{(\gamma^2-2t)^{1/4}}{\sqrt{\alpha}}\cdot \frac{\sqrt{\pi}}{\sqrt{2}\cdot \sqrt{\alpha}\cdot (\gamma^2-2t)^{1/4}}\cdot \exp\left[-\sqrt{\alpha^2(\gamma^2-2t)}\right] \\
       &= e^{\alpha \gamma} \cdot \exp\left[-\sqrt{\alpha^2(\gamma^2-2t)}\right] \\
       &= \exp\left[\alpha \gamma-\sqrt{\alpha^2(\gamma^2-2t)}\right] \; .
\end{split}
\end{equation}

This finishes the proof of \eqref{eq:wald-mgf-wald-mgf}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Siegrist, K. (2020): "The Wald Distribution"; in: \textit{Random: Probability, Mathematical Statistics, Stochastic Processes}, retrieved on 2020-09-13; URL: \url{https://www.randomservices.org/random/special/Wald.html}.
\item National Institute of Standards and Technology (2020): "NIST Digital Library of Mathematical Functions", retrieved on 2020-09-13; URL: \url{https://dlmf.nist.gov}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P168 | shortcut: wald-mgf | author: tomfaulkenberry | date: 2020-09-13, 12:00.
\vspace{1em}



\subsubsection[\textbf{Mean}]{Mean} \label{sec:wald-mean}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a positive random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a Wald distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:wald}):

\begin{equation} \label{eq:wald-mean-wald}
X \sim \mathrm{Wald}(\gamma, \alpha) \; .
\end{equation}

Then, the mean or expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of $X$ is

\begin{equation} \label{eq:wald-mean-wald-mean}
\mathrm{E}(X) = \frac{\alpha}{\gamma} \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The mean or expected value $\mathrm{E}(X)$ is the first moment ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mom}) of $X$, so we can use ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mom-mgf}) the moment-generating function of the Wald distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:wald-mgf}) to calculate

\begin{equation} \label{eq:wald-mean-wald-moment}
\mathrm{E}(X) = M_X'(0) \; .
\end{equation}

First we differentiate

\begin{equation} \label{eq:wald-mean-wald-mgf}
M_X(t) = \exp\left[\alpha \gamma - \sqrt{\alpha^2(\gamma^2-2t)}\right]
\end{equation}

with respect to $t$. Using the chain rule gives

\begin{equation} \label{eq:wald-mean-wald-mean-s1}
\begin{split}
  M_X'(t) &= \exp\left[\alpha \gamma - \sqrt{\alpha^2(\gamma^2-2t)}\right] \cdot -\frac{1}{2}\left(\alpha^2(\gamma^2-2t)\right)^{-1/2}\cdot -2\alpha^2 \\
  &= \exp\left[\alpha \gamma-\sqrt{\alpha^2(\gamma^2-2t)}\right] \cdot \frac{\alpha^2}{\sqrt{\alpha^2(\gamma^2-2t)}} \; .
\end{split}
\end{equation}

Evaluating \eqref{eq:wald-mean-wald-mean-s1} at $t=0$ gives the desired result:

\begin{equation} \label{eq:wald-mean-wald-mean-s2}
\begin{split}
  M_X'(0) &= \exp\left[\alpha \gamma-\sqrt{\alpha^2(\gamma^2-2(0))}\right] \cdot \frac{\alpha^2}{\sqrt{\alpha^2(\gamma^2-2(0))}} \\
          &= \exp\left[\alpha \gamma - \sqrt{\alpha^2 \cdot \gamma^2}\right]\cdot \frac{\alpha^2}{\sqrt{\alpha^2\cdot \gamma^2}} \\
          &= \exp[0] \cdot \frac{\alpha^2}{\alpha \gamma} \\
          &= \frac{\alpha}{\gamma} \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P169 | shortcut: wald-mean | author: tomfaulkenberry | date: 2020-09-13, 12:00.
\vspace{1em}



\subsubsection[\textbf{Variance}]{Variance} \label{sec:wald-var}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a positive random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a Wald distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:wald}):

\begin{equation} \label{eq:wald-var-wald}
X \sim \mathrm{Wald}(\gamma, \alpha) \; .
\end{equation}

Then, the variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) of $X$ is

\begin{equation} \label{eq:wald-var-wald-var}
\mathrm{Var}(X) = \frac{\alpha}{\gamma^3} \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} To compute the variance of $X$, we partition the variance into expected values ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:var-mean}):

\begin{equation} \label{eq:wald-var-var-mean}
\mathrm{Var}(X) = \mathrm{E}(X^2)-\mathrm{E}(X)^2.
\end{equation}

We then use the moment-generating function of the Wald distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:wald-mgf}) to calculate

\begin{equation} \label{eq:wald-var-wald-moment}
\mathrm{E}(X^2) = M_X''(0) \; .
\end{equation}

First we differentiate

\begin{equation} \label{eq:wald-var-wald-mgf}
M_X(t) = \exp\left[\alpha \gamma - \sqrt{\alpha^2(\gamma^2-2t)}\right]
\end{equation}

with respect to $t$. Using the chain rule gives

\begin{equation} \label{eq:wald-var-wald-var-s1}
\begin{split}
  M_X'(t) &= \exp\left[\alpha \gamma - \sqrt{\alpha^2(\gamma^2-2t)}\right] \cdot -\frac{1}{2}\left(\alpha^2(\gamma^2-2t)\right)^{-1/2}\cdot -2\alpha^2 \\
          &= \exp\left[\alpha \gamma-\sqrt{\alpha^2(\gamma^2-2t)}\right] \cdot \frac{\alpha^2}{\sqrt{\alpha^2(\gamma^2-2t)}} \\
          &= \alpha \cdot \exp\left[\alpha \gamma -\sqrt{\alpha^2(\gamma^2-2t)}\right] \cdot (\gamma^2-2t)^{-1/2} \; .
\end{split}
\end{equation}

Now we use the product rule to obtain the second derivative:

\begin{equation} \label{eq:wald-var-wald-var-s2}
\begin{split}
  M_X''(t) &= \alpha \cdot \exp\left[\alpha \gamma-\sqrt{\alpha^2(\gamma^2-2t)}\right]\cdot (\gamma^2-2t)^{-1/2}\cdot -\frac{1}{2}\left(\alpha^2(\gamma^2-2t)\right)^{-1/2}\cdot -2\alpha^2 \\
           &+ \alpha \cdot \exp\left[\alpha \gamma-\sqrt{\alpha^2(\gamma^2-2t)}\right]\cdot -\frac{1}{2}(\gamma^2-2t)^{-3/2}\cdot -2 \\
           &= \alpha^2\cdot \exp\left[\alpha \gamma-\sqrt{\alpha^2(\gamma^2-2t)}\right]\cdot (\gamma^2-2t)^{-1} \\
           &+ \alpha\cdot \exp\left[\alpha \gamma-\sqrt{\alpha^2(\gamma^2-2t)}\right]\cdot (\gamma^2-2t)^{-3/2} \\
           &= \alpha \cdot \exp\left[\alpha \gamma-\sqrt{\alpha^2(\gamma^2-2t)}\right]\left[\frac{\alpha}{\gamma^2-2t}+\frac{1}{\sqrt{(\gamma^2-2t)^3}}\right] \; .
\end{split}
\end{equation}

Applying \eqref{eq:wald-var-wald-moment} yields

\begin{equation} \label{eq:wald-var-wald-var-s3}
\begin{split}
  \mathrm{E}(X^2) &= M_X''(0) \\
                  &= \alpha \cdot \exp\left[\alpha \gamma-\sqrt{\alpha^2(\gamma^2-2(0))}\right]\left[\frac{\alpha}{\gamma^2-2(0)}+\frac{1}{\sqrt{(\gamma^2-2(0))^3}}\right] \\
                  &= \alpha \cdot \exp\left[\alpha \gamma - \alpha \gamma\right] \cdot \left[\frac{\alpha}{\gamma^2} + \frac{1}{\gamma^3}\right] \\
                  &= \frac{\alpha^2}{\gamma^2} + \frac{\alpha}{\gamma^3} \; .
\end{split}
\end{equation}

Since the mean of a Wald distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:wald-mean}) is given by $\mathrm{E}(X)=\alpha/\gamma$, we can apply \eqref{eq:wald-var-var-mean} to show

\begin{equation} \label{eq:wald-var-wald-var-s4}
\begin{split}
  \mathrm{Var}(X) &= \mathrm{E}(X^2) - \mathrm{E}(X)^2 \\
                  &= \frac{\alpha^2}{\gamma^2} + \frac{\alpha}{\gamma^3} - \left(\frac{\alpha}{\gamma}\right)^2 \\
                  &= \frac{\alpha}{\gamma^3}
\end{split}
\end{equation}

which completes the proof of \eqref{eq:wald-var-wald-var}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P170 | shortcut: wald-var | author: tomfaulkenberry | date: 2020-09-13, 12:00.
\vspace{1em}



\pagebreak
\section{Multivariate continuous distributions}

\subsection{Multivariate normal distribution}

\subsubsection[\textit{Definition}]{Definition} \label{sec:mvn}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be an $n \times 1$ random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}). Then, $X$ is said to be multivariate normally distributed with mean $\mu$ and covariance $\Sigma$

\begin{equation} \label{eq:mvn-mvn}
X \sim \mathcal{N}(\mu, \Sigma) \; ,
\end{equation}

if and only if its probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) is given by

\begin{equation} \label{eq:mvn-mvn-pdf}
\mathcal{N}(x; \mu, \Sigma) = \frac{1}{\sqrt{(2 \pi)^n |\Sigma|}} \cdot \exp \left[ -\frac{1}{2} (x-\mu)^\mathrm{T} \Sigma^{-1} (x-\mu) \right]
\end{equation}

where $\mu$ is an $n \times 1$ real vector and $\Sigma$ is an $n \times n$ positive definite matrix.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Koch KR (2007): "Multivariate Normal Distribution"; in: \textit{Introduction to Bayesian Statistics}, ch. 2.5.1, pp. 51-53, eq. 2.195; URL: \url{https://www.springer.com/gp/book/9783540727231}; DOI: 10.1007/978-3-540-72726-2.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D1 | shortcut: mvn | author: JoramSoch | date: 2020-01-22, 05:20.
\vspace{1em}



\subsubsection[\textbf{Probability density function}]{Probability density function} \label{sec:mvn-pdf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}) following a multivariate normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mvn}):

\begin{equation} \label{eq:mvn-pdf-mvn}
X \sim \mathcal{N}(\mu, \Sigma) \; .
\end{equation}

Then, the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $X$ is

\begin{equation} \label{eq:mvn-pdf-mvn-pdf}
f_X(x) = \frac{1}{\sqrt{(2 \pi)^n |\Sigma|}} \cdot \exp \left[ -\frac{1}{2} (x-\mu)^\mathrm{T} \Sigma^{-1} (x-\mu) \right] \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} This follows directly from the definition of the multivariate normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mvn}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P34 | shortcut: mvn-pdf | author: JoramSoch | date: 2020-01-27, 15:23.
\vspace{1em}



\subsubsection[\textbf{Differential entropy}]{Differential entropy} \label{sec:mvn-dent}
\setcounter{equation}{0}

\textbf{Theorem:} Let $x$ follow a multivariate normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mvn})

\begin{equation} \label{eq:mvn-dent-mvn}
x \sim \mathcal{N}(\mu, \Sigma) \; .
\end{equation}

Then, the differential entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent}) of $x$ in nats is

\begin{equation} \label{eq:mvn-dent-mvn-dent}
\mathrm{h}(x) = \frac{n}{2} \ln(2\pi) + \frac{1}{2} \ln|\Sigma| + \frac{1}{2} n \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The differential entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent}) of a random variable is defined as

\begin{equation} \label{eq:mvn-dent-dent}
\mathrm{h}(X) = - \int_{\mathcal{X}} p(x) \, \log_b p(x) \, \mathrm{d}x \; .
\end{equation}

To measure $h(X)$ in nats, we set $b = e$, such that ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean})

\begin{equation} \label{eq:mvn-dent-dent-nats}
\mathrm{h}(X) = - \mathrm{E}\left[ \ln p(x) \right] \; .
\end{equation}

With the probability density function of the multivariate normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mvn-pdf}), the differential entropy of $x$ is:

\begin{equation} \label{eq:mvn-dent-mvn-dent-s1}
\begin{split}
\mathrm{h}(x) &= - \mathrm{E}\left[ \ln \left( \frac{1}{\sqrt{(2 \pi)^n |\Sigma|}} \cdot \exp \left[ -\frac{1}{2} (x-\mu)^\mathrm{T} \Sigma^{-1} (x-\mu) \right] \right) \right] \\
&= - \mathrm{E}\left[ - \frac{n}{2} \ln(2\pi) - \frac{1}{2} \ln|\Sigma| - \frac{1}{2} (x-\mu)^\mathrm{T} \Sigma^{-1} (x-\mu) \right] \\
&= \frac{n}{2} \ln(2\pi) + \frac{1}{2} \ln|\Sigma| + \frac{1}{2} \, \mathrm{E}\left[ (x-\mu)^\mathrm{T} \Sigma^{-1} (x-\mu) \right] \; .
\end{split}
\end{equation}

The last term can be evaluted as

\begin{equation} \label{eq:mvn-dent-mvn-dent-t3}
\begin{split}
\mathrm{E}\left[ (x-\mu)^\mathrm{T} \Sigma^{-1} (x-\mu) \right] &= \mathrm{E}\left[ \mathrm{tr}\left( (x-\mu)^\mathrm{T} \Sigma^{-1} (x-\mu) \right) \right] \\
&= \mathrm{E}\left[ \mathrm{tr}\left( \Sigma^{-1} (x-\mu) (x-\mu)^\mathrm{T} \right) \right] \\
&= \mathrm{tr}\left( \Sigma^{-1} \mathrm{E}\left[ (x-\mu) (x-\mu)^\mathrm{T} \right] \right) \\
&= \mathrm{tr}\left( \Sigma^{-1} \Sigma \right) \\
&= \mathrm{tr}\left( I_n \right) \\
&= n \; , \\
\end{split}
\end{equation}

such that the differential entropy is

\begin{equation} \label{eq:mvn-dent-mvn-dent-qed}
\mathrm{h}(x) = \frac{n}{2} \ln(2\pi) + \frac{1}{2} \ln|\Sigma| + \frac{1}{2} \, n \; .
\end{equation}



\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Kiuhnm (2018): "Entropy of the multivariate Gaussian"; in: \textit{StackExchange Mathematics}, retrieved on 2020-05-14; URL: \url{https://math.stackexchange.com/questions/2029707/entropy-of-the-multivariate-gaussian}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P100 | shortcut: mvn-dent | author: JoramSoch | date: 2020-05-14, 19:49.
\vspace{1em}



\subsubsection[\textbf{Kullback-Leibler divergence}]{Kullback-Leibler divergence} \label{sec:mvn-kl}
\setcounter{equation}{0}

\textbf{Theorem:} Let $x$ be an $n \times 1$ random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}). Assume two multivariate normal distributions ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mvn}) $P$ and $Q$ specifying the probability distribution of $x$ as

\begin{equation} \label{eq:mvn-kl-mvns}
\begin{split}
P: \; x &\sim \mathcal{N}(\mu_1, \Sigma_1) \\
Q: \; x &\sim \mathcal{N}(\mu_2, \Sigma_2) \; .
\end{split}
\end{equation}

Then, the Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) of $P$ from $Q$ is given by

\begin{equation} \label{eq:mvn-kl-mvn-KL}
\mathrm{KL}[P\,||\,Q] = \frac{1}{2} \left[ (\mu_2 - \mu_1)^T \Sigma_2^{-1} (\mu_2 - \mu_1) + \mathrm{tr}(\Sigma_2^{-1} \Sigma_1) - \ln \frac{|\Sigma_1|}{|\Sigma_2|} - n \right] \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The KL divergence for a continuous random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) is given by 

\begin{equation} \label{eq:mvn-kl-KL-cont}
\mathrm{KL}[P\,||\,Q] = \int_{\mathcal{X}} p(x) \, \ln \frac{p(x)}{q(x)} \, \mathrm{d}x
\end{equation}

which, applied to the multivariate normal distributions ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mvn}) in \eqref{eq:mvn-kl-mvns}, yields

\begin{equation} \label{eq:mvn-kl-mvn-KL-s1}
\begin{split}
\mathrm{KL}[P\,||\,Q] &= \int_{\mathbb{R}^n} \mathcal{N}(x; \mu_1, \Sigma_1) \, \ln \frac{\mathcal{N}(x; \mu_1, \Sigma_1)}{\mathcal{N}(x; \mu_2, \Sigma_2)} \, \mathrm{d}x \\
&= \left\langle \ln \frac{\mathcal{N}(x; \mu_1, \Sigma_1)}{\mathcal{N}(x; \mu_2, \Sigma_2)} \right\rangle_{p(x)} \; .
\end{split}
\end{equation}

Using the probability density function of the multivariate normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mvn-pdf}), this becomes:

\begin{equation} \label{eq:mvn-kl-mvn-KL-s2}
\begin{split}
\mathrm{KL}[P\,||\,Q] &= \left\langle \ln \frac{ \frac{1}{\sqrt{(2 \pi)^n |\Sigma_1|}} \cdot \exp \left[ -\frac{1}{2} (x-\mu_1)^\mathrm{T} \Sigma_1^{-1} (x-\mu_1) \right] }{ \frac{1}{\sqrt{(2 \pi)^n |\Sigma_2|}} \cdot \exp \left[ -\frac{1}{2} (x-\mu_2)^\mathrm{T} \Sigma_2^{-1} (x-\mu_2) \right] } \right\rangle_{p(x)} \\
&= \left\langle \frac{1}{2} \ln \frac{|\Sigma_2|}{|\Sigma_1|} - \frac{1}{2} (x-\mu_1)^\mathrm{T} \Sigma_1^{-1} (x-\mu_1) + \frac{1}{2} (x-\mu_2)^\mathrm{T} \Sigma_2^{-1} (x-\mu_2) \right\rangle_{p(x)} \\
&= \frac{1}{2} \left\langle \ln \frac{|\Sigma_2|}{|\Sigma_1|} - (x-\mu_1)^\mathrm{T} \Sigma_1^{-1} (x-\mu_1) + (x-\mu_2)^\mathrm{T} \Sigma_2^{-1} (x-\mu_2) \right\rangle_{p(x)} \; .
\end{split}
\end{equation}

Now, using the fact that $x = \mathrm{tr}(x)$, if $a$ is scalar, and the trace property $\mathrm{tr}(ABC) = \mathrm{tr}(BCA)$, we have:

\begin{equation} \label{eq:mvn-kl-mvn-KL-s3}
\begin{split}
\mathrm{KL}[P\,||\,Q] &= \frac{1}{2} \left\langle \ln \frac{|\Sigma_2|}{|\Sigma_1|} - \mathrm{tr}\left[ \Sigma_1^{-1} (x-\mu_1) (x-\mu_1)^\mathrm{T} \right] + \mathrm{tr}\left[ \Sigma_2^{-1} (x-\mu_2) (x-\mu_2)^\mathrm{T} \right] \right\rangle_{p(x)} \\
&= \frac{1}{2} \left\langle \ln \frac{|\Sigma_2|}{|\Sigma_1|} - \mathrm{tr}\left[ \Sigma_1^{-1} (x-\mu_1) (x-\mu_1)^\mathrm{T} \right] + \mathrm{tr}\left[ \Sigma_2^{-1} \left( x x^\mathrm{T} - 2 \mu_2 x^\mathrm{T} + \mu_2 \mu_2^\mathrm{T} \right) \right] \right\rangle_{p(x)} \; .
\end{split}
\end{equation}

Because trace function and expected value are both linear operators ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-tr}), the expectation can be moved inside the trace:

\begin{equation} \label{eq:mvn-kl-mvn-KL-s4}
\begin{split}
\mathrm{KL}[P\,||\,Q] &= \frac{1}{2} \left( \ln \frac{|\Sigma_2|}{|\Sigma_1|} - \mathrm{tr}\left[ \Sigma_1^{-1} \left\langle (x-\mu_1) (x-\mu_1)^\mathrm{T} \right\rangle_{p(x)} \right] + \mathrm{tr}\left[ \Sigma_2^{-1} \left\langle x x^\mathrm{T} - 2 \mu_2 x^\mathrm{T} + \mu_2 \mu_2^\mathrm{T} \right\rangle_{p(x)} \right] \right) \\
&= \frac{1}{2} \left( \ln \frac{|\Sigma_2|}{|\Sigma_1|} - \mathrm{tr}\left[ \Sigma_1^{-1} \left\langle (x-\mu_1) (x-\mu_1)^\mathrm{T} \right\rangle_{p(x)} \right] + \mathrm{tr}\left[ \Sigma_2^{-1} \left( \left\langle x x^\mathrm{T} \right\rangle_{p(x)} - \left\langle 2 \mu_2 x^\mathrm{T} \right\rangle_{p(x)} + \left\langle \mu_2 \mu_2^\mathrm{T} \right\rangle_{p(x)} \right) \right] \right) \; .
\end{split}
\end{equation}

Using the expectation of a linear form for the multivariate normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mvn-ltt})

\begin{equation} \label{eq:mvn-kl-mvn-lfmean}
x \sim \mathcal{N}(\mu, \Sigma) \quad \Rightarrow \quad \left\langle A x \right\rangle = A \mu
\end{equation}

and the expectation of a quadratic form for the multivariate normal distribution ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-qf})

\begin{equation} \label{eq:mvn-kl-mvn-qfmean}
x \sim \mathcal{N}(\mu, \Sigma) \quad \Rightarrow \quad \left\langle x^\mathrm{T} A x \right\rangle = \mu^\mathrm{T} A \mu + \mathrm{tr}(A \Sigma) \; ,
\end{equation}

the Kullback-Leibler divergence from \eqref{eq:mvn-kl-mvn-KL-s4} becomes:

\begin{equation} \label{eq:mvn-kl-mvn-KL-s5}
\begin{split}
\mathrm{KL}[P\,||\,Q] &= \frac{1}{2} \left( \ln \frac{|\Sigma_2|}{|\Sigma_1|} - \mathrm{tr}\left[ \Sigma_1^{-1} \Sigma_1 \right] + \mathrm{tr}\left[ \Sigma_2^{-1} \left( \Sigma_1 + \mu_1 \mu_1^\mathrm{T} - 2 \mu_2 \mu_1^\mathrm{T} + \mu_2 \mu_2^\mathrm{T} \right) \right] \right) \\
&= \frac{1}{2} \left( \ln \frac{|\Sigma_2|}{|\Sigma_1|} - \mathrm{tr}\left[ I_n \right] + \mathrm{tr}\left[ \Sigma_2^{-1} \Sigma_1 \right] + \mathrm{tr}\left[ \Sigma_2^{-1} \left( \mu_1 \mu_1^\mathrm{T} - 2 \mu_2 \mu_1^\mathrm{T} + \mu_2 \mu_2^\mathrm{T} \right) \right] \right) \\
&= \frac{1}{2} \left( \ln \frac{|\Sigma_2|}{|\Sigma_1|} - n + \mathrm{tr}\left[ \Sigma_2^{-1} \Sigma_1 \right] + \mathrm{tr}\left[ \mu_1^\mathrm{T} \Sigma_2^{-1} \mu_1  - 2 \mu_1^\mathrm{T} \Sigma_2^{-1} \mu_2  + \mu_2^\mathrm{T} \Sigma_2^{-1} \mu_2 \right] \right) \\
&= \frac{1}{2} \left[ \ln \frac{|\Sigma_2|}{|\Sigma_1|} - n + \mathrm{tr}\left[ \Sigma_2^{-1} \Sigma_1 \right] + (\mu_2 - \mu_1)^T \Sigma_2^{-1} (\mu_2 - \mu_1) \right] \; .
\end{split}
\end{equation}

Finally, rearranging the terms, we get:

\begin{equation} \label{eq:mvn-kl-mvn-KL-qed}
\mathrm{KL}[P\,||\,Q] = \frac{1}{2} \left[ (\mu_2 - \mu_1)^T \Sigma_2^{-1} (\mu_2 - \mu_1) + \mathrm{tr}(\Sigma_2^{-1} \Sigma_1) - \ln \frac{|\Sigma_1|}{|\Sigma_2|} - n \right] \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Duchi, John (2014): "Derivations for Linear Algebra and Optimization"; in: \textit{University of California, Berkeley}; URL: \url{http://www.eecs.berkeley.edu/~jduchi/projects/general_notes.pdf}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P92 | shortcut: mvn-kl | author: JoramSoch | date: 2020-05-05, 06:57.
\vspace{1em}



\subsubsection[\textbf{Linear transformation}]{Linear transformation} \label{sec:mvn-ltt}
\setcounter{equation}{0}

\textbf{Theorem:} Let $x$ follow a multivariate normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mvn}):

\begin{equation} \label{eq:mvn-ltt-mvn}
x \sim \mathcal{N}(\mu, \Sigma) \; .
\end{equation}

Then, any linear transformation of $x$ is also multivariate normally distributed:

\begin{equation} \label{eq:mvn-ltt-mvn-lt}
y = Ax + b \sim \mathcal{N}(A\mu + b, A \Sigma A^\mathrm{T}) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The moment-generating function of a random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mgf}) $x$ is

\begin{equation} \label{eq:mvn-ltt-vect-mgf}
M_x(t) = \mathbb{E} \left( \exp \left[ t^\mathrm{T} x \right] \right)
\end{equation}

and therefore the moment-generating function of the random vector $y$ is given by

\begin{equation} \label{eq:mvn-ltt-y-mgf-s1}
\begin{split}
M_y(t) &\overset{\eqref{eq:mvn-ltt-mvn-lt}}{=} \mathbb{E} \left( \exp \left[ t^\mathrm{T} (Ax + b) \right] \right) \\
&= \mathbb{E} \left( \exp \left[ t^\mathrm{T} A x \right] \cdot \exp \left[ t^\mathrm{T} b \right] \right) \\
&= \exp \left[ t^\mathrm{T} b \right] \cdot \mathbb{E} \left( \exp \left[ t^\mathrm{T} A x \right] \right) \\
&\overset{\eqref{eq:mvn-ltt-vect-mgf}}{=} \exp \left[ t^\mathrm{T} b \right] \cdot M_x(At) \; .
\end{split}
\end{equation}

The moment-generating function of the multivariate normal distribution ($\rightarrow$ Proof "mvn-mgf") is

\begin{equation} \label{eq:mvn-ltt-mvn-mgf}
M_x(t) = \exp \left[ t^\mathrm{T} \mu + \frac{1}{2} t^\mathrm{T} \Sigma t \right]
\end{equation}

and therefore the moment-generating function of the random vector $y$ becomes

\begin{equation} \label{eq:mvn-ltt-y-mgf-s2}
\begin{split}
M_y(t) &\overset{\eqref{eq:mvn-ltt-y-mgf-s1}}{=} \exp \left[ t^\mathrm{T} b \right] \cdot M_x(At) \\
&\overset{\eqref{eq:mvn-ltt-mvn-mgf}}{=} \exp \left[ t^\mathrm{T} b \right] \cdot \exp \left[ t^\mathrm{T} A \mu + \frac{1}{2} t^\mathrm{T} A \Sigma A^\mathrm{T} t \right] \\
&= \exp \left[ t^\mathrm{T} \left( A \mu + b \right) + \frac{1}{2} t^\mathrm{T} A \Sigma A^\mathrm{T} t \right] \; .
\end{split}
\end{equation}

Because moment-generating function and probability density function of a random variable are equivalent, this demonstrates that $y$ is following a multivariate normal distribution with mean $A \mu + b$ and covariance $A \Sigma A^\mathrm{T}$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Taboga, Marco (2010): "Linear combinations of normal random variables"; in: \textit{Lectures on probability and statistics}, retrieved on 2019-08-27; URL: \url{https://www.statlect.com/probability-distributions/normal-distribution-linear-combinations}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P1 | shortcut: mvn-ltt | author: JoramSoch | date: 2019-08-27, 12:14.
\vspace{1em}



\subsubsection[\textbf{Marginal distributions}]{Marginal distributions} \label{sec:mvn-marg}
\setcounter{equation}{0}

\textbf{Theorem:} Let $x$ follow a multivariate normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mvn}):

\begin{equation} \label{eq:mvn-marg-mvn}
x \sim \mathcal{N}(\mu, \Sigma) \; .
\end{equation}

Then, the marginal distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-marg}) of any subset vector $x_s$ is also a multivariate normal distribution

\begin{equation} \label{eq:mvn-marg-mvn-marg}
x_s \sim \mathcal{N}(\mu_s, \Sigma_s)
\end{equation}

where $\mu_s$ drops the irrelevant variables (the ones not in the subset, i.e. marginalized out) from the mean vector $\mu$ and $\Sigma_s$ drops the corresponding rows and columns from the covariance matrix $\Sigma$.


\vspace{1em}
\textbf{Proof:} Define an $m \times n$ subset matrix $S$ such that $s_{ij} = 1$, if the $j$-th element in $x_s$ corresponds to the $i$-th element in $x$, and $s_{ij} = 0$ otherwise. Then,

\begin{equation} \label{eq:mvn-marg-xs}
x_s = S x
\end{equation}

and we can apply the linear transformation theorem ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mvn-ltt}) to give

\begin{equation} \label{eq:mvn-marg-mvn-marg-qed}
x_s \sim \mathcal{N}(S \mu, S \Sigma S^\mathrm{T}) \; .
\end{equation}

Finally, we see that $S \mu = \mu_s$ and $S \Sigma S^\mathrm{T} = \Sigma_s$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P35 | shortcut: mvn-marg | author: JoramSoch | date: 2020-01-29, 15:12.
\vspace{1em}



\subsubsection[\textbf{Conditional distributions}]{Conditional distributions} \label{sec:mvn-cond}
\setcounter{equation}{0}

\textbf{Theorem:} Let $x$ follow a multivariate normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mvn})

\begin{equation} \label{eq:mvn-cond-mvn}
x \sim \mathcal{N}(\mu, \Sigma) \; .
\end{equation}

Then, the conditional distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-cond}) of any subset vector $x_1$, given the complement vector $x_2$, is also a multivariate normal distribution

\begin{equation} \label{eq:mvn-cond-mvn-cond}
x_1|x_2 \sim \mathcal{N}(\mu_{1|2}, \Sigma_{1|2})
\end{equation}

where the conditional mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) and covariance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cov}) are

\begin{equation} \label{eq:mvn-cond-mvn-cond-hyp}
\begin{split}
\mu_{1|2} &= \mu_1 + \Sigma_{12} \Sigma_{22}^{-1} (x_2 - \mu_2) \\
\Sigma_{1|2} &= \Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21}
\end{split}
\end{equation}

with block-wise mean and covariance defined as

\begin{equation} \label{eq:mvn-cond-mvn-joint-hyp}
\begin{split}
\mu &= \begin{bmatrix} \mu_1 \\ \mu_2 \end{bmatrix} \\
\Sigma &= \begin{bmatrix} \Sigma_{11} & \Sigma_{12} \\ \Sigma_{21} & \Sigma_{22} \end{bmatrix} \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Proof:} Without loss of generality, we assume that, in parallel to \eqref{eq:mvn-cond-mvn-joint-hyp},

\begin{equation} \label{eq:mvn-cond-x}
x = \begin{bmatrix} x_1 \\ x_2 \end{bmatrix}
\end{equation}

where $x_1$ is an $n_1 \times 1$ vector, $x_2$ is an $n_2 \times 1$ vector and $x$ is an $n_1 + n_2 = n \times 1$ vector.

\vspace{1em}
By construction, the joint distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-joint}) of $x_1$ and $x_2$ is:

\begin{equation} \label{eq:mvn-cond-mvn-joint}
x_1,x_2 \sim \mathcal{N}(\mu, \Sigma) \; .
\end{equation}

Moreover, the marginal distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-marg}) of $x_2$ follows from ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mvn-marg}) \eqref{eq:mvn-cond-mvn} and \eqref{eq:mvn-cond-mvn-joint-hyp} as

\begin{equation} \label{eq:mvn-cond-mvn-marg}
x_2 \sim \mathcal{N}(\mu_2, \Sigma_{22}) \; .
\end{equation}

According to the law of conditional probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-cond}), it holds that

\begin{equation} \label{eq:mvn-cond-mvn-cond-s1}
p(x_1|x_2) = \frac{p(x_1,x_2)}{p(x_2)}
\end{equation}

Applying \eqref{eq:mvn-cond-mvn-joint} and \eqref{eq:mvn-cond-mvn-marg} to \eqref{eq:mvn-cond-mvn-cond-s1}, we have:

\begin{equation} \label{eq:mvn-cond-mvn-cond-s2}
p(x_1|x_2) = \frac{\mathcal{N}(x; \mu, \Sigma)}{\mathcal{N}(x_2; \mu_2, \Sigma_{22})} \; .
\end{equation}

Using the probability density function of the multivariate normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mvn-pdf}), this becomes:

\begin{equation} \label{eq:mvn-cond-mvn-cond-s3}
\begin{split}
p(x_1|x_2) &= \frac{1/\sqrt{(2 \pi)^n |\Sigma|} \cdot \exp \left[ -\frac{1}{2} (x-\mu)^\mathrm{T} \Sigma^{-1} (x-\mu) \right]}{1/\sqrt{(2 \pi)^{n_2} |\Sigma_{22}|} \cdot \exp \left[ -\frac{1}{2} (x_2-\mu_2)^\mathrm{T} \Sigma_{22}^{-1} (x_2-\mu_2) \right]} \\
&= \frac{1}{\sqrt{(2 \pi)^{n-n_2}}} \cdot \sqrt{\frac{|\Sigma_{22}|}{|\Sigma|}} \cdot \exp \left[ -\frac{1}{2} (x-\mu)^\mathrm{T} \Sigma^{-1} (x-\mu) + \frac{1}{2} (x_2-\mu_2)^\mathrm{T} \Sigma_{22}^{-1} (x_2-\mu_2) \right] \; .
\end{split}
\end{equation}

Writing the inverse of $\Sigma$ as

\begin{equation} \label{eq:mvn-cond-Sigma-inv-def}
\Sigma^{-1} = \begin{bmatrix} \Sigma^{11} & \Sigma^{12} \\ \Sigma^{21} & \Sigma^{22} \end{bmatrix}
\end{equation}

and applying \eqref{eq:mvn-cond-mvn-joint-hyp} to \eqref{eq:mvn-cond-mvn-cond-s3}, we get:

\begin{equation} \label{eq:mvn-cond-mvn-cond-s4}
\begin{split}
p(x_1|x_2) = &\frac{1}{\sqrt{(2 \pi)^{n-n_2}}} \cdot \sqrt{\frac{|\Sigma_{22}|}{|\Sigma|}} \cdot \\
&\exp \left[ -\frac{1}{2} \left( \begin{bmatrix} x_1 \\ x_2 \end{bmatrix} - \begin{bmatrix} \mu_1 \\ \mu_2 \end{bmatrix} \right)^\mathrm{T} \begin{bmatrix} \Sigma^{11} & \Sigma^{12} \\ \Sigma^{21} & \Sigma^{22} \end{bmatrix} \left( \begin{bmatrix} x_1 \\ x_2 \end{bmatrix} - \begin{bmatrix} \mu_1 \\ \mu_2 \end{bmatrix} \right) \right. \\
&\hphantom{\exp \left[\right.} \left. + \frac{1}{2} \, (x_2-\mu_2)^\mathrm{T} \, \Sigma_{22}^{-1} \, (x_2-\mu_2) \right] \; .
\end{split}
\end{equation}

Multiplying out within the exponent of \eqref{eq:mvn-cond-mvn-cond-s4}, we have

\begin{equation} \label{eq:mvn-cond-mvn-cond-s5}
\begin{split}
p(x_1|x_2) = &\frac{1}{\sqrt{(2 \pi)^{n-n_2}}} \cdot \sqrt{\frac{|\Sigma_{22}|}{|\Sigma|}} \cdot \\
&\exp \left[ -\frac{1}{2} \left( (x_1-\mu_1)^\mathrm{T} \Sigma^{11} (x_1-\mu_1) + 2 (x_1-\mu_1)^\mathrm{T} \Sigma^{12} (x_2-\mu_2) + (x_2-\mu_2)^\mathrm{T} \Sigma^{22} (x_2-\mu_2) \right) \right. \\
&\hphantom{\exp \left[\right.} \left. + \frac{1}{2} (x_2-\mu_2)^\mathrm{T} \Sigma_{22}^{-1} (x_2-\mu_2) \right]
\end{split}
\end{equation}

where we have used the fact that ${\Sigma^{21}}^\mathrm{T} = \Sigma^{12}$, because $\Sigma^{-1}$ is a symmetric matrix.

\vspace{1em}
The inverse of a block matrix is

\begin{equation} \label{eq:mvn-cond-Block-inv}
\begin{bmatrix} A & B \\ C & D \end{bmatrix}^{-1} = \begin{bmatrix} (A-BD^{-1}C)^{-1} & -(A-BD^{-1}C)^{-1}BD^{-1} \\ -D^{-1}C(A-BD^{-1}C)^{-1} & D^{-1}+D^{-1}C(A-BD^{-1}C)^{-1}BD^{-1} \end{bmatrix} \; ,
\end{equation}

thus the inverse of $\Sigma$ in \eqref{eq:mvn-cond-Sigma-inv-def} is

\begin{equation} \label{eq:mvn-cond-Sigma-inv}
\begin{bmatrix} \Sigma_{11} & \Sigma_{12} \\ \Sigma_{21} & \Sigma_{22} \end{bmatrix}^{-1} = \begin{bmatrix} (\Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21})^{-1} & -(\Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21})^{-1} \Sigma_{12} \Sigma_{22}^{-1} \\ -\Sigma_{22}^{-1} \Sigma_{21} (\Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21})^{-1} & \Sigma_{22}^{-1} + \Sigma_{22}^{-1} \Sigma_{21} (\Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21})^{-1} \Sigma_{12} \Sigma_{22}^{-1} \end{bmatrix} \; .
\end{equation}

Plugging this into \eqref{eq:mvn-cond-mvn-cond-s5}, we have:

\begin{equation} \label{eq:mvn-cond-mvn-cond-s6}
\begin{split}
p(x_1|x_2) = &\frac{1}{\sqrt{(2 \pi)^{n-n_2}}} \cdot \sqrt{\frac{|\Sigma_{22}|}{|\Sigma|}} \cdot \\
&\exp \left[ -\frac{1}{2} \left( (x_1-\mu_1)^\mathrm{T} (\Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21})^{-1} (x_1-\mu_1) \right. \right. - \\
&\hphantom{\exp \left[ -\frac{1}{2} \left( \right. \right.} 2 (x_1-\mu_1)^\mathrm{T} (\Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21})^{-1} \Sigma_{12} \Sigma_{22}^{-1} (x_2-\mu_2) + \\
&\hphantom{\exp \left[ -\frac{1}{2} \left( \right. \right.} \left. (x_2-\mu_2)^\mathrm{T} \left[ \Sigma_{22}^{-1} + \Sigma_{22}^{-1} \Sigma_{21} (\Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21})^{-1} \Sigma_{12} \Sigma_{22}^{-1} \right] (x_2-\mu_2) \right) \\
&\hphantom{\exp \left[\right.} \left. + \frac{1}{2} \left( (x_2-\mu_2)^\mathrm{T} \Sigma_{22}^{-1} (x_2-\mu_2) \right) \right] \; .
\end{split}
\end{equation}

Eliminating some terms, we have:

\begin{equation} \label{eq:mvn-cond-mvn-cond-s7}
\begin{split}
p(x_1|x_2) = &\frac{1}{\sqrt{(2 \pi)^{n-n_2}}} \cdot \sqrt{\frac{|\Sigma_{22}|}{|\Sigma|}} \cdot \\
&\exp \left[ -\frac{1}{2} \left( (x_1-\mu_1)^\mathrm{T} (\Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21})^{-1} (x_1-\mu_1) \right. \right. - \\
&\hphantom{\exp \left[ -\frac{1}{2} \left( \right. \right.} 2 (x_1-\mu_1)^\mathrm{T} (\Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21})^{-1} \Sigma_{12} \Sigma_{22}^{-1} (x_2-\mu_2) + \\
&\hphantom{\exp \left[ -\frac{1}{2} \left( \right. \right.} \left. \left. (x_2-\mu_2)^\mathrm{T} \Sigma_{22}^{-1} \Sigma_{21} (\Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21})^{-1} \Sigma_{12} \Sigma_{22}^{-1} (x_2-\mu_2) \right) \right] \; .
\end{split}
\end{equation}

Rearranging the terms, we have

\begin{equation} \label{eq:mvn-cond-mvn-cond-s8}
\begin{split}
p(x_1|x_2) = &\frac{1}{\sqrt{(2 \pi)^{n-n_2}}} \cdot \sqrt{\frac{|\Sigma_{22}|}{|\Sigma|}} \cdot \exp \left[ -\frac{1}{2} \cdot \right. \\
&\! \left. \left[ (x_1-\mu_1) - \Sigma_{12}^\mathrm{T} \Sigma_{22}^{-1} (x_2-\mu_2) \right]^\mathrm{T} (\Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21})^{-1} \left[ (x_1-\mu_1) - \Sigma_{12}^\mathrm{T} \Sigma_{22}^{-1} (x_2-\mu_2) \right] \right] \\
= &\frac{1}{\sqrt{(2 \pi)^{n-n_2}}} \cdot \sqrt{\frac{|\Sigma_{22}|}{|\Sigma|}} \cdot \exp \left[ -\frac{1}{2} \cdot \right. \\
&\! \left. \left[ x_1 - \left( \mu_1 + \Sigma_{12}^\mathrm{T} \Sigma_{22}^{-1} (x_2-\mu_2) \right) \right]^\mathrm{T} (\Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21})^{-1} \left[ x_1 - \left( \mu_1 + \Sigma_{12}^\mathrm{T} \Sigma_{22}^{-1} (x_2-\mu_2) \right) \right] \right]
\end{split}
\end{equation}

where we have used the fact that $\Sigma_{21}^\mathrm{T} = \Sigma_{12}$, because $\Sigma$ is a covariance matrix.

\vspace{1em}
The determinant of a block matrix is

\begin{equation} \label{eq:mvn-cond-Block-det}
\begin{vmatrix} A & B \\ C & D \end{vmatrix} = |D| \cdot | A - B D^{-1} C | \; ,
\end{equation}

such that we have for $\Sigma$ that

\begin{equation} \label{eq:mvn-cond-Sigma-det}
\begin{vmatrix} \Sigma_{11} & \Sigma_{12} \\ \Sigma_{21} & \Sigma_{22} \end{vmatrix} = |\Sigma_{22}| \cdot | \Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21} | \; .
\end{equation}

With this and $n - n_2 = n_1$, we finally arrive at

\begin{equation} \label{eq:mvn-cond-mvn-cond-s9}
\begin{split}
p(x_1|x_2) = &\frac{1}{\sqrt{(2 \pi)^{n_1} | \Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21} |}} \cdot \exp \left[ -\frac{1}{2} \cdot \right. \\
&\! \left. \left[ x_1 - \left( \mu_1 + \Sigma_{12}^\mathrm{T} \Sigma_{22}^{-1} (x_2-\mu_2) \right) \right]^\mathrm{T} (\Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21})^{-1} \left[ x_1 - \left( \mu_1 + \Sigma_{12}^\mathrm{T} \Sigma_{22}^{-1} (x_2-\mu_2) \right) \right] \right]
\end{split}
\end{equation}

which is the probability density function of a multivariate normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mvn-pdf})

\begin{equation} \label{eq:mvn-cond-mvn-cond-s10}
p(x_1|x_2) = \mathcal{N}(x_1; \mu_{1|2}, \Sigma_{1|2})
\end{equation}

with the mean $\mu_{1 \vert 2}$ and variance $\Sigma_{1 \vert 2}$ given by \eqref{eq:mvn-cond-mvn-cond-hyp}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wang, Ruye (2006): "Marginal and conditional distributions of multivariate normal distribution"; in: \textit{Computer Image Processing and Analysis}; URL: \url{http://fourier.eng.hmc.edu/e161/lectures/gaussianprocess/node7.html}.
\item Wikipedia (2020): "Multivariate normal distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-03-20; URL: \url{https://en.wikipedia.org/wiki/Multivariate_normal_distribution#Conditional_distributions}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P88 | shortcut: mvn-cond | author: JoramSoch | date: 2020-03-20, 08:44.
\vspace{1em}



\subsubsection[\textbf{Conditions for independence}]{Conditions for independence} \label{sec:mvn-ind}
\setcounter{equation}{0}

\textbf{Theorem:} Let $x$ be an $n \times 1$ random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}) following a multivariate normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mvn}):

\begin{equation} \label{eq:mvn-ind-mvn}
x \sim \mathcal{N}(\mu, \Sigma) \; .
\end{equation}

Then, the components of $x$ are statistically independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}), if and only if the covariance matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:covmat}) is a diagonal matrix:

\begin{equation} \label{eq:mvn-ind-mvn-ind}
p(x) = p(x_1) \cdot \ldots \cdot p(x_n) \quad \Leftrightarrow \quad \Sigma = \mathrm{diag}\left( \left[ \sigma^2_1, \ldots, \sigma^2_n \right] \right) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The marginal distribution of one entry from a multivariate normal random vector is a univariate normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mvn-marg}) where mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) and variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) are equal to the corresponding entries of the mean vector and covariance matrix:

\begin{equation} \label{eq:mvn-ind-mvn-marg}
x \sim \mathcal{N}(\mu, \Sigma) \quad \Rightarrow \quad x_i \sim \mathcal{N}(\mu_i, \sigma^2_{ii}) \; .
\end{equation}

The probability density function of the multivariate normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mvn-pdf}) is

\begin{equation} \label{eq:mvn-ind-mvn-pdf}
p(x) = \frac{1}{\sqrt{(2 \pi)^n |\Sigma|}} \cdot \exp \left[ -\frac{1}{2} (x-\mu)^\mathrm{T} \Sigma^{-1} (x-\mu) \right]
\end{equation}

and the probability density function of the univariate normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-pdf}) is

\begin{equation} \label{eq:mvn-ind-norm-pdf}
p(x_i) = \frac{1}{\sqrt{2 \pi \sigma^2_i}} \cdot \exp \left[ -\frac{1}{2} \left( \frac{x_i-\mu_i}{\sigma_i} \right)^2 \right] \; .
\end{equation}

\vspace{1em}
1) Let

\begin{equation} \label{eq:mvn-ind-x-ind}
p(x) = p(x_1) \cdot \ldots \cdot p(x_n) \; .
\end{equation}

Then, we have

\begin{equation} \label{eq:mvn-ind-x-ind-dev}
\begin{split}
\frac{1}{\sqrt{(2 \pi)^n |\Sigma|}} \cdot \exp \left[ -\frac{1}{2} (x-\mu)^\mathrm{T} \Sigma^{-1} (x-\mu) \right] &\overset{\eqref{eq:mvn-ind-mvn-pdf},\eqref{eq:mvn-ind-norm-pdf}}{=} \prod_{i=1}^{n} \frac{1}{\sqrt{2 \pi \sigma^2_i}} \cdot \exp \left[ -\frac{1}{2} \left( \frac{x_i-\mu_i}{\sigma_i} \right)^2 \right] \\
\frac{1}{\sqrt{(2 \pi)^n |\Sigma|}} \cdot \exp \left[ -\frac{1}{2} (x-\mu)^\mathrm{T} \Sigma^{-1} (x-\mu) \right] &= \frac{1}{\sqrt{(2 \pi)^n \prod_{i=1}^{n} \sigma^2_i}} \cdot \exp \left[ -\frac{1}{2} \sum_{i=1}^{n} (x_i-\mu_i) \frac{1}{\sigma^2_i} (x_i-\mu_i) \right] \\
- \frac{1}{2} \log |\Sigma| - \frac{1}{2} (x-\mu)^\mathrm{T} \Sigma^{-1} (x-\mu) &= - \frac{1}{2} \sum_{i=1}^{n} \log \sigma^2_i - \frac{1}{2} \sum_{i=1}^{n} (x_i-\mu_i) \frac{1}{\sigma^2_i} (x_i-\mu_i)
\end{split}
\end{equation}

which, given the laws for matrix determinants and matrix inverses, is only fulfilled if

\begin{equation} \label{eq:mvn-ind-Sigma-diag-qed}
\Sigma = \mathrm{diag}\left( \left[ \sigma^2_1, \ldots, \sigma^2_n \right] \right) \; .
\end{equation}

\vspace{1em}
2) Let

\begin{equation} \label{eq:mvn-ind-Sigma-diag}
\Sigma = \mathrm{diag}\left( \left[ \sigma^2_1, \ldots, \sigma^2_n \right] \right) \; .
\end{equation}

Then, we have

\begin{equation} \label{eq:mvn-ind-Sigma-diag-dev}
\begin{split}
p(x) &\overset{\eqref{eq:mvn-ind-mvn-pdf}}{=} \frac{1}{\sqrt{(2 \pi)^n |\mathrm{diag}\left( \left[ \sigma^2_1, \ldots, \sigma^2_n \right] \right)|}} \cdot \exp \left[ -\frac{1}{2} (x-\mu)^\mathrm{T} \mathrm{diag}\left( \left[ \sigma^2_1, \ldots, \sigma^2_n \right] \right)^{-1} (x-\mu) \right] \\
&= \frac{1}{\sqrt{(2 \pi)^n \prod_{i=1}^{n} \sigma^2_i}} \cdot \exp \left[ -\frac{1}{2} (x-\mu)^\mathrm{T} \mathrm{diag}\left( \left[ 1/\sigma^2_1, \ldots, 1/\sigma^2_n \right] \right) (x-\mu) \right] \\
&= \frac{1}{\sqrt{(2 \pi)^n \prod_{i=1}^{n} \sigma^2_i}} \cdot \exp \left[ -\frac{1}{2} \sum_{i=1}^{n} \frac{(x_i-\mu_i)^2}{\sigma^2_i} \right] \\
&= \prod_{i=1}^n \frac{1}{\sqrt{2 \pi \sigma^2_i}} \cdot \exp \left[ -\frac{1}{2} \left( \frac{x_i-\mu_i}{\sigma_i} \right)^2 \right]
\end{split}
\end{equation}

which implies that

\begin{equation} \label{eq:mvn-ind-x-ind-qed}
p(x) = p(x_1) \cdot \ldots \cdot p(x_n) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P236 | shortcut: mvn-ind | author: JoramSoch | date: 2021-06-02, 09:22.
\vspace{1em}



\subsection{Multivariate t-distribution}

\subsubsection[\textit{Definition}]{Definition} \label{sec:mvt}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be an $n \times 1$ random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}). Then, $X$ is said to follow a multivariate $t$-distribution with mean $\mu$, scale matrix $\Sigma$ and degrees of freedom $\nu$

\begin{equation} \label{eq:mvt-mvt}
X \sim t(\mu, \Sigma, \nu) \; ,
\end{equation}

if and only if its probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) is given by

\begin{equation} \label{eq:mvt-mvt-pdf}
t(x; \mu, \Sigma, \nu) = \sqrt{\frac{1}{(\nu \pi)^{n} |\Sigma|}} \, \frac{\Gamma([\nu+n]/2)}{\Gamma(\nu/2)} \, \left[ 1 + \frac{1}{\nu} (x-\mu)^\mathrm{T} \Sigma^{-1} (x-\mu) \right]^{-(\nu+n)/2}
\end{equation}

where $\mu$ is an $n \times 1$ real vector, $\Sigma$ is an $n \times n$ positive definite matrix and $\nu > 0$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Koch KR (2007): "Multivariate t-Distribution"; in: \textit{Introduction to Bayesian Statistics}, ch. 2.5.2, pp. 53-55; URL: \url{https://www.springer.com/gp/book/9783540727231}; DOI: 10.1007/978-3-540-72726-2.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D148 | shortcut: mvt | author: JoramSoch | date: 2020-04-21, 08:16.
\vspace{1em}



\subsubsection[\textbf{Relationship to F-distribution}]{Relationship to F-distribution} \label{sec:mvt-f}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a $n \times 1$ random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}) following a multivariate t-distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mvt}) with mean $\mu$, scale matrix $\Sigma$ and degrees of freedom $\nu$:

\begin{equation} \label{eq:mvt-f-X}
X \sim t(\mu, \Sigma, \nu) \; .
\end{equation}

Then, the centered, weighted and standardized quadratic form of $X$ follows an F-distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:f}) with degrees of freedom $n$ and $\nu$:

\begin{equation} \label{eq:mvt-f-mvt-f}
(X-\mu)^\mathrm{T} \, \Sigma^{-1} (X-\mu)/n \sim F(n, \nu) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The linear transformation theorem for the multivariate t-distribution ($\rightarrow$ Proof "mvt-ltt") states

\begin{equation} \label{eq:mvt-f-mvt-ltt}
x \sim t(\mu, \Sigma, \nu) \quad \Rightarrow \quad y = Ax + b \sim t(A\mu + b, A \Sigma A^\mathrm{T}, \nu)
\end{equation}

where $x$ is an $n \times 1$ random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}) following a multivariate t-distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mvt}), $A$ is an $m \times n$ matrix and $b$ is an $m \times 1$ vector. Define the following quantities

\begin{equation} \label{eq:mvt-f-YZ}
\begin{split}
Y = \Sigma^{-1/2} (X-\mu) = \Sigma^{-1/2} X - \Sigma^{-1/2} \mu \\
Z = Y^\mathrm{T} Y / n = (X-\mu)^\mathrm{T} \, \Sigma^{-1} (X-\mu)/n
\end{split}
\end{equation}

where $\Sigma^{-1/2}$ is a matrix square root of the inverse of $\Sigma$. Then, applying \eqref{eq:mvt-f-mvt-ltt} to \eqref{eq:mvt-f-YZ} with \eqref{eq:mvt-f-X}, one obtains the distribution of $Y$ as

\begin{equation} \label{eq:mvt-f-Y-dist}
\begin{split}
Y &\sim t(\Sigma^{-1/2} \mu - \Sigma^{-1/2} \mu, \Sigma^{-1/2} \Sigma \, \Sigma^{-1/2}, \nu) \\
&= t(0_n, \Sigma^{-1/2} \Sigma^{1/2} \Sigma^{1/2} \Sigma^{-1/2}, \nu) \\
&= t(0_n, I_n, \nu) \; ,
\end{split}
\end{equation}

i.e. $Y$ is an $n \times 1$ vector of independent and identically distributed ($\rightarrow$ Definition "iid") random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a univariate t-distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:t}) with $\nu$ degrees of freedom:

\begin{equation} \label{eq:mvt-f-yi-dist}
Y_i \sim t(\nu), \; i = 1,\ldots,n \; .
\end{equation}

Note that, when $X$ follows a t-distribution with $n$ degrees of freedom, this is equivalent to ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:t}) an expression of $X$ in terms of a standard normal ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:snorm}) random variable $Z$ and a chi-squared ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:chi2}) random variable $V$:

\begin{equation} \label{eq:mvt-f-t}
X \sim t(n) \quad \Leftrightarrow \quad X = \frac{Z}{\sqrt{V/n}} \quad \text{with independent} \quad Z \sim \mathcal{N}(0,1) \quad \text{and} \quad V \sim \chi^2(n) \; .
\end{equation}

With that, $Z$ from \eqref{eq:mvt-f-YZ} can be rewritten as follows:

\begin{equation} \label{eq:mvt-f-Z-eq-s1}
\begin{split}
Z &\overset{\eqref{eq:mvt-f-YZ}}{=} Y^\mathrm{T} Y / n \\
&= \frac{1}{n} \sum_{i=1}^n Y_i^2 \\
&\overset{\eqref{eq:mvt-f-t}}{=} \frac{1}{n} \sum_{i=1}^n \left( \frac{Z_i}{\sqrt{V/\nu}} \right)^2 \\
&= \frac{\left( \sum_{i=1}^n Z_i^2 \right)/n}{V/\nu} \; .
\end{split}
\end{equation}

Because by definition, the sum of squared standard normal random variables follows a chi-squared distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:chi2})

\begin{equation} \label{eq:mvt-f-chi2}
X_i \sim \mathcal{N}(0,1), \; i = 1,\ldots,n \quad \Rightarrow \quad \sum_{i=1}^n X_i^2 \sim \chi^2(n) \; ,
\end{equation}

the quantity $Z$ becomes a ratio of the following form

\begin{equation} \label{eq:mvt-f-Z-eq-s2}
Z = \frac{W/n}{V/\nu} \quad \text{with} \quad W \sim \chi^2(n) \quad \text{and} \quad V \sim \chi^2(\nu) \; ,
\end{equation}

such that $Z$, by definition, follows an F-distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:f}):

\begin{equation} \label{eq:mvt-f-Z-dist}
Z = \frac{W/n}{V/\nu} \sim F(n, \nu) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Lin, Pi-Erh (1972): "Some Characterizations of the Multivariate t Distribution"; in: \textit{Journal of Multivariate Analysis}, vol. 2, pp. 339-344, Lemma 2; URL: \url{https://core.ac.uk/download/pdf/81139018.pdf}; DOI: 10.1016/0047-259X(72)90021-8.
\item Nadarajah, Saralees; Kotz, Samuel (2005): "Mathematical Properties of the Multivariate t Distribution"; in: \textit{Acta Applicandae Mathematicae}, vol. 89, pp. 53-84, page 56; URL: \url{https://link.springer.com/content/pdf/10.1007/s10440-005-9003-4.pdf}; DOI: 10.1007/s10440-005-9003-4.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P231 | shortcut: mvt-f | author: JoramSoch | date: 2021-05-04, 10:29.
\vspace{1em}



\subsection{Normal-gamma distribution}

\subsubsection[\textit{Definition}]{Definition} \label{sec:ng}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be an $n \times 1$ random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}) and let $Y$ be a positive random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}). Then, $X$ and $Y$ are said to follow a normal-gamma distribution

\begin{equation} \label{eq:ng-ng}
X,Y \sim \mathrm{NG}(\mu, \Lambda, a, b) \; ,
\end{equation}

if and only if their joint probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) is given by

\begin{equation} \label{eq:ng-ng-pdf}
f_{X,Y}(x,y) = \mathcal{N}(x; \mu, (y \Lambda)^{-1}) \cdot \mathrm{Gam}(y; a, b)
\end{equation}

where $\mathcal{N}(x; \mu, \Sigma)$ is the probability density function of the multivariate normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mvn-pdf}) with mean $\mu$ and covariance $\Sigma$ and $\mathrm{Gam}(x; a, b)$ is the probability density function of the gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-pdf}) with shape $a$ and rate $b$. The $n \times n$ matrix $\Lambda$ is referred to as the precision matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:precmat}) of the normal-gamma distribution.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Koch KR (2007): "Normal-Gamma Distribution"; in: \textit{Introduction to Bayesian Statistics}, ch. 2.5.3, pp. 55-56, eq. 2.212; URL: \url{https://www.springer.com/gp/book/9783540727231}; DOI: 10.1007/978-3-540-72726-2.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D5 | shortcut: ng | author: JoramSoch | date: 2020-01-27, 14:28.
\vspace{1em}



\subsubsection[\textbf{Probability density function}]{Probability density function} \label{sec:ng-pdf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $x$ and $y$ follow a normal-gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:ng}):

\begin{equation} \label{eq:ng-pdf-ng}
x,y \sim \mathrm{NG}(\mu, \Lambda, a, b) \; .
\end{equation}

Then, the joint probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $x$ and $y$ is

\begin{equation} \label{eq:ng-pdf-ng-pdf}
p(x,y) = \sqrt{\frac{|\Lambda|}{(2 \pi)^n}} \frac{b^a}{\Gamma(a)} \cdot y^{a+\frac{n}{2}-1} \exp \left[ -\frac{y}{2} \left( (x-\mu)^\mathrm{T} \Lambda (x-\mu) + 2b \right) \right] \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The probability density of the normal-gamma distribution is defined as ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:ng}) as the product of a multivariate normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mvn}) over $x$ conditional on $y$ and a univariate gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:gam}) over $y$:

\begin{equation} \label{eq:ng-pdf-ng-pdf-w1}
p(x,y) = \mathcal{N}(x; \mu, (y \Lambda)^{-1}) \cdot \mathrm{Gam}(y; a, b)
\end{equation}

With the probability density function of the multivariate normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mvn-pdf}) and the probability density function of the gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-pdf}), this becomes:

\begin{equation} \label{eq:ng-pdf-ng-pdf-s2}
p(x,y) = \sqrt{\frac{|y \Lambda|}{(2 \pi)^n}} \exp \left[ -\frac{1}{2} (x-\mu)^\mathrm{T} (y \Lambda) (x-\mu) \right] \cdot \frac{b^a}{\Gamma(a)} y^{a-1} \exp\left[-by\right] \; .
\end{equation}

Using the relation $\lvert y A \rvert = y^n \lvert A \rvert$ for an $n \times n$ matrix $A$ and rearranging the terms, we have:

\begin{equation} \label{eq:ng-pdf-ng-pdf-qed}
p(x,y) = \sqrt{\frac{|\Lambda|}{(2 \pi)^n}} \frac{b^a}{\Gamma(a)} \cdot y^{a+\frac{n}{2}-1} \exp \left[ -\frac{y}{2} \left( (x-\mu)^\mathrm{T} \Lambda (x-\mu) + 2b \right) \right] \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Koch KR (2007): "Normal-Gamma Distribution"; in: \textit{Introduction to Bayesian Statistics}, ch. 2.5.3, pp. 55-56, eq. 2.212; URL: \url{https://www.springer.com/gp/book/9783540727231}; DOI: 10.1007/978-3-540-72726-2.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P44 | shortcut: ng-pdf | author: JoramSoch | date: 2020-02-07, 20:44.
\vspace{1em}



\subsubsection[\textbf{Mean}]{Mean} \label{sec:ng-mean}
\setcounter{equation}{0}

\textbf{Theorem:} Let $x \in \mathbb{R}^n$ and $y > 0$ follow a normal-gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:ng}):

\begin{equation} \label{eq:ng-mean-ng}
x,y \sim \mathrm{NG}(\mu, \Lambda, a, b) \; .
\end{equation}

Then, the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of $x$ and $y$ is

\begin{equation} \label{eq:ng-mean-ng-mean}
\mathrm{E}[(x,y)] = \left[ \left( \mu, \frac{a}{b} \right) \right] \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} Consider the random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec})

\begin{equation} \label{eq:ng-mean-rvec}
\left[ \begin{array}{c} x \\ y \end{array} \right] = \left[ \begin{array}{c} x_1 \\ \vdots \\ x_n \\ y \end{array} \right] \; .
\end{equation}

According to the expected value of a random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean-rvec}), its expected value is

\begin{equation} \label{eq:ng-mean-mean-rvec}
\mathrm{E}\left( \left[ \begin{array}{c} x \\ y \end{array} \right] \right) = \left[ \begin{array}{c} \mathrm{E}(x_1) \\ \vdots \\ \mathrm{E}(x_n) \\ \mathrm{E}(y) \end{array} \right] = \left[ \begin{array}{c} \mathrm{E}(x) \\ \mathrm{E}(y) \end{array} \right] \; .
\end{equation}

When $x$ and $y$ are jointly normal-gamma distributed, then ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:ng}) by definition $x$ follows a multivariate normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mvn}) conditional on $y$ and $y$ follows a univariate gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:gam}):

\begin{equation} \label{eq:ng-mean-ng-def}
x,y \sim \mathrm{NG}(\mu, \Lambda, a, b) \quad \Leftrightarrow \quad x \vert y \sim \mathcal{N}(\mu, (y \Lambda)^{-1}) \quad \wedge \quad y \sim \mathrm{Gam}(a,b) \; .
\end{equation}

Thus, with the expected value of the multivariate normal distribution ($\rightarrow$ Proof "mvn-mean") and the law of conditional probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-cond}), $\mathrm{E}(x)$ becomes

\begin{equation} \label{eq:ng-mean-mean-x}
\begin{split}
\mathrm{E}(x) &= \iint x \cdot p(x,y) \, \mathrm{d}x \, \mathrm{d}y \\
&= \iint x \cdot p(x|y) \cdot p(y) \, \mathrm{d}x \, \mathrm{d}y \\
&= \int p(y) \int x \cdot p(x|y) \, \mathrm{d}x \, \mathrm{d}y \\
&= \int p(y) \left\langle x \right\rangle_{\mathcal{N}(\mu, (y \Lambda)^{-1})} \, \mathrm{d}y \\
&= \int p(y) \cdot \mu \, \mathrm{d}y \\
&= \mu \int p(y) \, \mathrm{d}y \\
&= \mu \; ,
\end{split}
\end{equation}

and with the expected value of the gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-mean}), $\mathrm{E}(y)$ becomes

\begin{equation} \label{eq:ng-mean-mean-y}
\begin{split}
\mathrm{E}(y) &= \int y \cdot p(y) \, \mathrm{d}y \\
&= \left\langle y \right\rangle_{\mathrm{Gam}(a,b)} \\
&= \frac{a}{b} \; .
\end{split}
\end{equation}

Thus, the expectation of the random vector in equations \eqref{eq:ng-mean-rvec} and \eqref{eq:ng-mean-mean-rvec} is

\begin{equation} \label{eq:ng-mean-ng-mean-qed}
\mathrm{E}\left( \left[ \begin{array}{c} x \\ y \end{array} \right] \right) = \left[ \begin{array}{c} \mu \\ a/b \end{array} \right] \; ,
\end{equation}

as indicated by equation \eqref{eq:ng-mean-ng-mean}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P237 | shortcut: ng-mean | author: JoramSoch | date: 2021-07-08, 09:40.
\vspace{1em}



\subsubsection[\textbf{Differential entropy}]{Differential entropy} \label{sec:ng-dent}
\setcounter{equation}{0}

\textbf{Theorem:} Let $x$ be an $n \times 1$ random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}) and let $y$ be a positive random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}). Assume that $x$ and $y$ are jointly normal-gamma distributed:

\begin{equation} \label{eq:ng-dent-NG}
(x,y) \sim \mathrm{NG}(\mu, \Lambda^{-1}, a, b)
\end{equation}

Then, the differential entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent}) of $x$ in nats is

\begin{equation} \label{eq:ng-dent-NG-dent}
\begin{split}
\mathrm{h}(x,y) &= \frac{n}{2} \ln(2\pi) - \frac{1}{2} \ln|\Lambda| + \frac{1}{2} n \\
&+ a + \ln \Gamma(a) - \frac{n-2+2a}{2} \psi(a) + \frac{n-2}{2} \ln b \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Proof:} The probabibility density function of the normal-gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:ng-pdf}) is

\begin{equation} \label{eq:ng-dent-NG-pdf}
p(x,y) = p(x|y) \cdot p(y) = \mathcal{N}(x; \mu, (y \Lambda)^{-1}) \cdot \mathrm{Gam}(y; a, b) \; .
\end{equation}

The differential entropy of the multivariate normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mvn-dent}) is

\begin{equation} \label{eq:ng-dent-mvn-dent}
\mathrm{h}(x) = \frac{n}{2} \ln(2\pi) + \frac{1}{2} \ln|\Sigma| + \frac{1}{2} n
\end{equation}

and the differential entropy of the univariate gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-dent}) is

\begin{equation} \label{eq:ng-dent-gam-dent}
\mathrm{h}(y) = a + \ln \Gamma(a) + (1-a) \cdot \psi(a) - \ln b
\end{equation}

where $\Gamma(x)$ is the gamma function and $\psi(x)$ is the digamma function.

\vspace{1em}
The differential entropy of a continuous random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent}) in nats is given by

\begin{equation} \label{eq:ng-dent-dent}
\mathrm{h}(Z) = - \int_{\mathcal{Z}} p(z) \ln p(z) \, \mathrm{d}z
\end{equation}

which, applied to the normal-gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:ng}) over $x$ and $y$, yields

\begin{equation} \label{eq:ng-dent-NG-dent0}
\mathrm{h}(x,y) = - \int_{0}^{\infty} \int_{\mathbb{R}^n} p(x,y) \, \ln p(x,y) \, \mathrm{d}x \, \mathrm{d}y \; .
\end{equation}

Using the law of conditional probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-cond}), this can be evaluated as follows:

\begin{equation} \label{eq:ng-dent-NG-dent1}
\begin{split}
\mathrm{h}(x,y) &= - \int_{0}^{\infty} \int_{\mathbb{R}^n} p(x|y) \, p(y) \, \ln p(x|y) \, p(y) \, \mathrm{d}x \, \mathrm{d}y \\
&= - \int_{0}^{\infty} \int_{\mathbb{R}^n} p(x|y)\, p(y) \, \ln p(x|y) \, \mathrm{d}x \, \mathrm{d}y - \int_{0}^{\infty} \int_{\mathbb{R}^n} p(x|y)\, p(y) \, \ln p(y) \, \mathrm{d}x \, \mathrm{d}y \\
&= \int_{0}^{\infty} p(y) \int_{\mathbb{R}^n} p(x|y) \, \ln p(x|y) \, \mathrm{d}x \, \mathrm{d}y + \int_{0}^{\infty} p(y) \, \ln p(y) \int_{\mathbb{R}^n} p(x|y) \, \mathrm{d}x \, \mathrm{d}y \\
&= \left\langle \mathrm{h}(x|y) \right\rangle_{p(y)} + \mathrm{h}(y) \; .
\end{split}
\end{equation}

In other words, the differential entropy of the normal-gamma distribution over $x$ and $y$ is equal to the sum of a multivariate normal entropy regarding $x$ conditional on $y$, expected over $y$, and a univariate gamma entropy regarding $y$.

\vspace{1em}
From equations \eqref{eq:ng-dent-NG-pdf} and \eqref{eq:ng-dent-mvn-dent}, the first term becomes

\begin{equation} \label{eq:ng-dent-exp-mvn-dent-s1}
\begin{split}
\left\langle \mathrm{h}(x|y) \right\rangle_{p(y)} &= \left\langle \frac{n}{2} \ln(2\pi) + \frac{1}{2} \ln|(y \Lambda)^{-1}| + \frac{1}{2} n \right\rangle_{p(y)} \\
&= \left\langle \frac{n}{2} \ln(2\pi) - \frac{1}{2} \ln|(y \Lambda)| + \frac{1}{2} n \right\rangle_{p(y)} \\
&= \left\langle \frac{n}{2} \ln(2\pi) - \frac{1}{2} \ln(y^n |\Lambda|) + \frac{1}{2} n \right\rangle_{p(y)} \\
&= \frac{n}{2} \ln(2\pi) - \frac{1}{2} \ln|\Lambda| + \frac{1}{2} n - \left\langle \frac{n}{2} \ln y \right\rangle_{p(y)} \\
\end{split}
\end{equation}

and using the relation ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-logmean}) $y \sim \mathrm{Gam}(a,b) \Rightarrow \left\langle \ln y \right\rangle = \psi(a) - \ln(b)$, we have

\begin{equation} \label{eq:ng-dent-exp-mvn-dent-s2}
\begin{split}
\left\langle \mathrm{h}(x|y) \right\rangle_{p(y)} = \frac{n}{2} \ln(2\pi) - \frac{1}{2} \ln|\Lambda| + \frac{1}{2} n - \frac{n}{2} \psi(a) + \frac{n}{2} \ln b \; .
\end{split}
\end{equation}

By plugging \eqref{eq:ng-dent-exp-mvn-dent-s2} and \eqref{eq:ng-dent-gam-dent} into \eqref{eq:ng-dent-NG-dent1}, one arrives at the differential entropy given by \eqref{eq:ng-dent-NG-dent}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P238 | shortcut: ng-dent | author: JoramSoch | date: 2021-07-08, 10:51.
\vspace{1em}



\subsubsection[\textbf{Kullback-Leibler divergence}]{Kullback-Leibler divergence} \label{sec:ng-kl}
\setcounter{equation}{0}

\textbf{Theorem:} Let $x$ be an $n \times 1$ random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}) and let $y$ be a positive random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}). Assume two normal-gamma distributions ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:ng}) $P$ and $Q$ specifying the joint distribution of $x$ and $y$ as

\begin{equation} \label{eq:ng-kl-NGs}
\begin{split}
P: \; (x,y) &\sim \mathrm{NG}(\mu_1, \Lambda_1^{-1}, a_1, b_1) \\
Q: \; (x,y) &\sim \mathrm{NG}(\mu_2, \Lambda_2^{-1}, a_2, b_2) \; .
\end{split}
\end{equation}

Then, the Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) of $P$ from $Q$ is given by

\begin{equation} \label{eq:ng-kl-NG-KL}
\begin{split}
\mathrm{KL}[P\,||\,Q] &= \frac{1}{2} \frac{a_1}{b_1} \left[ (\mu_2 - \mu_1)^\mathrm{T} \Lambda_2 (\mu_2 - \mu_1) \right] + \frac{1}{2} \, \mathrm{tr}(\Lambda_2 \Lambda_1^{-1}) - \frac{1}{2} \ln \frac{|\Lambda_2|}{|\Lambda_1|} - \frac{n}{2} \\
&+ a_2 \, \ln \frac{b_1}{b_2} - \ln \frac{\Gamma(a_1)}{\Gamma(a_2)} + (a_1 - a_2) \, \psi(a_1) - (b_1 - b_2) \, \frac{a_1}{b_1} \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Proof:} The probabibility density function of the normal-gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:ng-pdf}) is

\begin{equation} \label{eq:ng-kl-NG-pdf}
p(x,y) = p(x|y) \cdot p(y) = \mathcal{N}(x; \mu, (y \Lambda)^{-1}) \cdot \mathrm{Gam}(y; a, b) \; .
\end{equation}

The Kullback-Leibler divergence of the multivariate normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mvn-kl}) is

\begin{equation} \label{eq:ng-kl-mvn-KL}
\mathrm{KL}[P\,||\,Q] = \frac{1}{2} \left[ (\mu_2 - \mu_1)^\mathrm{T} \Sigma_2^{-1} (\mu_2 - \mu_1) + \mathrm{tr}(\Sigma_2^{-1} \Sigma_1) - \ln \frac{|\Sigma_1|}{|\Sigma_2|} - n \right]
\end{equation}

and the Kullback-Leibler divergence of the univariate gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-kl}) is

\begin{equation} \label{eq:ng-kl-gam-KL}
\mathrm{KL}[P\,||\,Q] = a_2 \, \ln \frac{b_1}{b_2} - \ln \frac{\Gamma(a_1)}{\Gamma(a_2)} + (a_1 - a_2) \, \psi(a_1) - (b_1 - b_2) \, \frac{a_1}{b_1}
\end{equation}

where $\Gamma(x)$ is the gamma function and $\psi(x)$ is the digamma function.

\vspace{1em}
The KL divergence for a continuous random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) is given by 

\begin{equation} \label{eq:ng-kl-KL-cont}
\mathrm{KL}[P\,||\,Q] = \int_{\mathcal{Z}} p(z) \, \ln \frac{p(z)}{q(z)} \, \mathrm{d}z
\end{equation}

which, applied to the normal-gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:ng}) over $x$ and $y$, yields

\begin{equation} \label{eq:ng-kl-NG-KL0}
\mathrm{KL}[P\,||\,Q] = \int_{0}^{\infty} \int_{\mathbb{R}^n} p(x,y) \, \ln \frac{p(x,y)}{q(x,y)} \, \mathrm{d}x \, \mathrm{d}y \; .
\end{equation}

Using the law of conditional probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-cond}), this can be evaluated as follows:

\begin{equation} \label{eq:ng-kl-NG-KL1}
\begin{split}
\mathrm{KL}[P\,||\,Q] &= \int_{0}^{\infty} \int_{\mathbb{R}^n} p(x|y) \, p(y) \, \ln \frac{p(x|y) \, p(y)}{q(x|y) \, q(y)} \, \mathrm{d}x \, \mathrm{d}y \\
&= \int_{0}^{\infty} \int_{\mathbb{R}^n} p(x|y)\, p(y) \, \ln \frac{p(x|y)}{q(x|y)} \, \mathrm{d}x \, \mathrm{d}y + \int_{0}^{\infty} \int_{\mathbb{R}^n} p(x|y)\, p(y) \, \ln \frac{p(y)}{q(y)} \, \mathrm{d}x \, \mathrm{d}y \\
&= \int_{0}^{\infty} p(y) \int_{\mathbb{R}^n} p(x|y) \, \ln \frac{p(x|y)}{q(x|y)} \, \mathrm{d}x \, \mathrm{d}y + \int_{0}^{\infty} p(y) \, \ln \frac{p(y)}{q(y)} \int_{\mathbb{R}^n} p(x|y) \, \mathrm{d}x \, \mathrm{d}y \\
&= \left\langle \mathrm{KL}[p(x|y)\,||\,q(x|y)] \right\rangle_{p(y)} + \mathrm{KL}[p(y)\,||\,q(y)] \; .
\end{split}
\end{equation}

In other words, the KL divergence between two normal-gamma distributions over $x$ and $y$ is equal to the sum of a multivariate normal KL divergence regarding $x$ conditional on $y$, expected over $y$, and a univariate gamma KL divergence regarding $y$.

\vspace{1em}
From equations \eqref{eq:ng-kl-NG-pdf} and \eqref{eq:ng-kl-mvn-KL}, the first term becomes

\begin{equation} \label{eq:ng-kl-exp-mvn-KL-s1}
\begin{split}
&\left\langle \mathrm{KL}[p(x|y)\,||\,q(x|y)] \right\rangle_{p(y)} \\
&= \left\langle \frac{1}{2} \left[ (\mu_2 - \mu_1)^\mathrm{T} (y \Lambda_2) (\mu_2 - \mu_1) + \mathrm{tr}\left( (y \Lambda_2) (y \Lambda_1)^{-1} \right) - \ln \frac{|(y \Lambda_1)^{-1}|}{|(y \Lambda_2)^{-1}|} - n \right] \right\rangle_{p(y)} \\
&= \left\langle \frac{y}{2} (\mu_2 - \mu_1)^\mathrm{T} \Lambda_2 (\mu_2 - \mu_1) + \frac{1}{2} \, \mathrm{tr}(\Lambda_2 \Lambda_1^{-1}) - \frac{1}{2} \ln \frac{|\Lambda_2|}{|\Lambda_1|} - \frac{n}{2} \right\rangle_{p(y)} \\
\end{split}
\end{equation}

and using the relation ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-mean}) $y \sim \mathrm{Gam}(a,b) \Rightarrow \left\langle y \right\rangle = a/b$, we have

\begin{equation} \label{eq:ng-kl-exp-mvn-KL-s2}
\begin{split}
\left\langle \mathrm{KL}[p(x|y)\,||\,q(x|y)] \right\rangle_{p(y)} = \frac{1}{2} \frac{a_1}{b_1} (\mu_2 - \mu_1)^\mathrm{T} \Lambda_2 (\mu_2 - \mu_1) + \frac{1}{2} \, \mathrm{tr}(\Lambda_2 \Lambda_1^{-1}) - \frac{1}{2} \ln \frac{|\Lambda_2|}{|\Lambda_1|} - \frac{n}{2} \; .
\end{split}
\end{equation}

By plugging \eqref{eq:ng-kl-exp-mvn-KL-s2} and \eqref{eq:ng-kl-gam-KL} into \eqref{eq:ng-kl-NG-KL1}, one arrives at the KL divergence given by \eqref{eq:ng-kl-NG-KL}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Soch J, Allefeld A (2016): "Kullback-Leibler Divergence for the Normal-Gamma Distribution"; in: \textit{arXiv math.ST}, 1611.01437; URL: \url{https://arxiv.org/abs/1611.01437}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P6 | shortcut: ng-kl | author: JoramSoch | date: 2019-12-06, 09:35.
\vspace{1em}



\subsubsection[\textbf{Marginal distributions}]{Marginal distributions} \label{sec:ng-marg}
\setcounter{equation}{0}

\textbf{Theorem:} Let $x$ and $y$ follow a normal-gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:ng}):

\begin{equation} \label{eq:ng-marg-ng}
x,y \sim \mathrm{NG}(\mu, \Lambda, a, b) \; .
\end{equation}

Then, the marginal distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-marg}) of $y$ is a gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:gam})

\begin{equation} \label{eq:ng-marg-ng-marg-y}
y \sim \mathrm{Gam}(a, b)
\end{equation}

and the marginal distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-marg}) of $x$ is a multivariate t-distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mvt})

\begin{equation} \label{eq:ng-marg-ng-marg-x}
x \sim t\left( \mu, \left(\frac{a}{b} \Lambda \right)^{-1}, 2a \right) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The probability density function of the normal-gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:ng-pdf}) is given by

\begin{equation} \label{eq:ng-marg-ng-pdf}
\begin{split}
p(x,y) &= p(x|y) \cdot p(y) \\
p(x|y) &= \mathcal{N}(x; \mu, (y \Lambda)^{-1}) \\
p(y) &= \mathrm{Gam}(y; a, b) \; .
\end{split}
\end{equation}

\vspace{1em}
Using the law of marginal probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}), the marginal distribution of $y$ can be derived as

\begin{equation} \label{eq:ng-marg-ng-marg-y-qed}
\begin{split}
p(y) &= \int p(x,y) \, \mathrm{d}x \\
&= \int \mathcal{N}(x; \mu, (y \Lambda)^{-1}) \, \mathrm{Gam}(y; a, b) \, \mathrm{d}x \\
&= \mathrm{Gam}(y; a, b) \int \mathcal{N}(x; \mu, (y \Lambda)^{-1}) \, \mathrm{d}x \\
&= \mathrm{Gam}(y; a, b)
\end{split}
\end{equation}

which is the probability density function of the gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-pdf}) with shape parameter $a$ and rate parameter $b$.

\vspace{1em}
Using the law of marginal probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}), the marginal distribution of $x$ can be derived as

\begin{equation} \label{eq:ng-marg-ng-marg-x-qed}
\begin{split}
p(x) &= \int p(x,y) \, \mathrm{d}y \\
&= \int \mathcal{N}(x; \mu, (y \Lambda)^{-1}) \, \mathrm{Gam}(y; a, b) \, \mathrm{d}y \\
&= \int \sqrt{\frac{|y \Lambda|}{(2 \pi)^n}} \, \exp \left[ -\frac{1}{2} (x-\mu)^\mathrm{T} (y \Lambda) (x-\mu) \right] \cdot \frac{b^a}{\Gamma(a)} \, y^{a-1} \exp[-b y] \, \mathrm{d}y \\
&= \int \sqrt{\frac{y^n |\Lambda|}{(2 \pi)^n}} \, \exp \left[ -\frac{1}{2} (x-\mu)^\mathrm{T} (y \Lambda) (x-\mu) \right] \cdot \frac{b^a}{\Gamma(a)} \, y^{a-1} \exp[-b y] \, \mathrm{d}y \\
&= \int \sqrt{\frac{|\Lambda|}{(2 \pi)^n}} \cdot \frac{b^a}{\Gamma(a)} \cdot y^{a+\frac{n}{2}-1} \cdot \exp \left[ -\left( b + \frac{1}{2} (x-\mu)^\mathrm{T} \Lambda (x-\mu) \right) y \right] \mathrm{d}y \\
&= \int \sqrt{\frac{|\Lambda|}{(2 \pi)^n}} \cdot \frac{b^a}{\Gamma(a)} \cdot \frac{\Gamma\left( a+\frac{n}{2} \right)}{\left( b + \frac{1}{2} (x-\mu)^\mathrm{T} \Lambda (x-\mu) \right)^{a+\frac{n}{2}}} \cdot \mathrm{Gam}\left( y; a+\frac{n}{2}, b + \frac{1}{2} (x-\mu)^\mathrm{T} \Lambda (x-\mu) \right) \mathrm{d}y \\
&= \sqrt{\frac{|\Lambda|}{(2 \pi)^n}} \cdot \frac{b^a}{\Gamma(a)} \cdot \frac{\Gamma\left( a+\frac{n}{2} \right)}{\left( b + \frac{1}{2} (x-\mu)^\mathrm{T} \Lambda (x-\mu) \right)^{a+\frac{n}{2}}} \int \mathrm{Gam}\left( y; a+\frac{n}{2}, b + \frac{1}{2} (x-\mu)^\mathrm{T} \Lambda (x-\mu) \right) \mathrm{d}y \\
&= \sqrt{\frac{|\Lambda|}{(2 \pi)^n}} \cdot \frac{b^a}{\Gamma(a)} \cdot \frac{\Gamma\left( a+\frac{n}{2} \right)}{\left( b + \frac{1}{2} (x-\mu)^\mathrm{T} \Lambda (x-\mu) \right)^{a+\frac{n}{2}}} \\
&= \frac{\sqrt{|\Lambda|}}{(2 \pi)^\frac{n}{2}} \cdot \frac{\Gamma\left( \frac{2a+n}{2} \right)}{\Gamma\left( \frac{2a}{2} \right)} \cdot b^a \cdot \left( b + \frac{1}{2} (x-\mu)^\mathrm{T} \Lambda (x-\mu) \right)^{-\left( a+\frac{n}{2} \right)} \\
&= \frac{\sqrt{|\Lambda|}}{\pi^\frac{n}{2}} \cdot \frac{\Gamma\left( \frac{2a+n}{2} \right)}{\Gamma\left( \frac{2a}{2} \right)} \cdot \left( \frac{1}{b} \right)^{-a} \cdot \left( b + \frac{1}{2} (x-\mu)^\mathrm{T} \Lambda (x-\mu) \right)^{-a} \cdot 2^{-\frac{n}{2}} \cdot \left( b + \frac{1}{2} (x-\mu)^\mathrm{T} \Lambda (x-\mu) \right)^{-\frac{n}{2}} \\
&= \frac{\sqrt{|\Lambda|}}{\pi^\frac{n}{2}} \cdot \frac{\Gamma\left( \frac{2a+n}{2} \right)}{\Gamma\left( \frac{2a}{2} \right)} \cdot \left( 1 + \frac{1}{2b} (x-\mu)^\mathrm{T} \Lambda (x-\mu) \right)^{-a} \cdot \left( 2b + (x-\mu)^\mathrm{T} \Lambda (x-\mu) \right)^{-\frac{n}{2}} \\
&= \frac{\sqrt{|\Lambda|}}{\pi^\frac{n}{2}} \cdot \frac{\Gamma\left( \frac{2a+n}{2} \right)}{\Gamma\left( \frac{2a}{2} \right)} \cdot \left( \frac{1}{2a} \right)^{-a} \cdot \left( 2a + (x-\mu)^\mathrm{T} \left( \frac{a}{b}\Lambda \right) (x-\mu) \right)^{-a} \cdot \left( \frac{b}{a} \right)^{-\frac{n}{2}} \cdot \left( 2a + (x-\mu)^\mathrm{T} \left( \frac{a}{b}\Lambda \right) (x-\mu) \right)^{-\frac{n}{2}} \\
&= \frac{\sqrt{\left( \frac{a}{b} \right)^n |\Lambda|}}{(2a)^{-a}\,\pi^\frac{n}{2}} \cdot \frac{\Gamma\left( \frac{2a+n}{2} \right)}{\Gamma\left( \frac{2a}{2} \right)} \cdot \left( 2a + (x-\mu)^\mathrm{T} \left( \frac{a}{b}\Lambda \right) (x-\mu) \right)^{-a} \cdot \left( 2a + (x-\mu)^\mathrm{T} \left( \frac{a}{b}\Lambda \right) (x-\mu) \right)^{-\frac{n}{2}} \\
&= \frac{\sqrt{\left( \frac{a}{b} \right)^n |\Lambda|}}{(2a)^{-a}\,\pi^\frac{n}{2}} \cdot \frac{\Gamma\left( \frac{2a+n}{2} \right)}{\Gamma\left( \frac{2a}{2} \right)} \cdot (2a)^{-a} \cdot \left( 1 + \frac{1}{2a} (x-\mu)^\mathrm{T} \left( \frac{a}{b}\Lambda \right) (x-\mu) \right)^{-a} \cdot (2a)^{-\frac{n}{2}} \cdot \left( 1 + \frac{1}{2a} (x-\mu)^\mathrm{T} \left( \frac{a}{b}\Lambda \right) (x-\mu) \right)^{-\frac{n}{2}} \\
&= \frac{\sqrt{\left( \frac{a}{b} \right)^n |\Lambda|}}{(2a)^\frac{n}{2}\,\pi^\frac{n}{2}} \cdot \frac{\Gamma\left( \frac{2a+n}{2} \right)}{\Gamma\left( \frac{2a}{2} \right)} \cdot \left( 1 + \frac{1}{2a} (x-\mu)^\mathrm{T} \left( \frac{a}{b}\Lambda \right) (x-\mu) \right)^{-\frac{2a+n}{2}} \\
&= \sqrt{\frac{\left| \frac{a}{b}\,\Lambda \right|}{(2a\,\pi)^n}} \cdot \frac{\Gamma\left( \frac{2a+n}{2} \right)}{\Gamma\left( \frac{2a}{2} \right)} \cdot \left( 1 + \frac{1}{2a} (x-\mu)^\mathrm{T} \left( \frac{a}{b}\Lambda \right) (x-\mu) \right)^{-\frac{2a+n}{2}} \\
\end{split}
\end{equation}

which is the probability density function of a multivariate t-distribution ($\rightarrow$ Proof "mvt-pdf") with mean vector $\mu$, shape matrix $\left( \frac{a}{b}\Lambda \right)^{-1}$ and $2a$ degrees of freedom.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P36 | shortcut: ng-marg | author: JoramSoch | date: 2020-01-29, 21:42.
\vspace{1em}



\subsubsection[\textbf{Conditional distributions}]{Conditional distributions} \label{sec:ng-cond}
\setcounter{equation}{0}

\textbf{Theorem:} Let $x$ and $y$ follow a normal-gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:ng}):

\begin{equation} \label{eq:ng-cond-ng}
x,y \sim \mathrm{NG}(\mu, \Lambda, a, b) \; .
\end{equation}

Then,

1) the conditional distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-cond}) of $x$ given $y$ is a multivariate normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mvn})

\begin{equation} \label{eq:ng-cond-ng-cond-x-y}
x|y \sim \mathcal{N}(\mu, (y \Lambda)^{-1}) \; ;
\end{equation}

2) the conditional distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-cond}) of a subset vector $x_1$, given the complement vector $x_2$ and $y$, is also a multivariate normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mvn})

\begin{equation} \label{eq:ng-cond-ng-cond-x1-x2-y}
x_1|x_2,y \sim \mathcal{N}(\mu_{1|2}(y), \Sigma_{1|2}(y))
\end{equation}

with the conditional mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) and covariance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cov})

\begin{equation} \label{eq:ng-cond-ng-cond-x1-x2-y-hyp}
\begin{split}
\mu_{1|2}(y) &= \mu_1 + \Sigma_{12} \Sigma_{22}^{-1} (x_2 - \mu_2) \\
\Sigma_{1|2}(y) &= \Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{12}
\end{split}
\end{equation}

where $\mu_1$, $\mu_2$ and $\Sigma_{11}$, $\Sigma_{12}$, $\Sigma_{22}$, $\Sigma_{21}$ are block-wise components ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mvn-cond}) of $\mu$ and $\Sigma(y) = (y \Lambda)^{-1}$;

3) the conditional distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-cond}) of $y$ given $x$ is a gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:gam})

\begin{equation} \label{eq:ng-cond-ng-cond-y-x}
y|x \sim \mathrm{Gam}\left( a + \frac{n}{2}, b + \frac{1}{2} (x-\mu)^\mathrm{T} \Lambda (x-\mu) \right)
\end{equation}

where $n$ is the dimensionality of $x$.


\vspace{1em}
\textbf{Proof:}

1) This follows from the definition of the normal-gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:ng}):

\begin{equation} \label{eq:ng-cond-ng-pdf}
\begin{split}
p(x,y) &= p(x|y) \cdot p(y) \\
&= \mathcal{N}(x; \mu, (y \Lambda)^{-1}) \cdot \mathrm{Gam}(y; a, b) \; .
\end{split}
\end{equation}

2) This follows from \eqref{eq:ng-cond-ng-cond-x-y} and the conditional distributions of the multivariate normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mvn-cond}):

\begin{equation} \label{eq:ng-cond-mvn-cond}
\begin{split}
x &\sim \mathcal{N}(\mu, \Sigma) \\
\Rightarrow x_1|x_2 &\sim \mathcal{N}(\mu_{1|2}, \Sigma_{1|2}) \\
\mu_{1|2} &= \mu_1 + \Sigma_{12} \Sigma_{22}^{-1} (x_2 - \mu_2) \\
\Sigma_{1|2} &= \Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21} \; .
\end{split}
\end{equation}

3) The conditional density of $y$ given $x$ follows from Bayes' theorem ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:bayes-th}) as

\begin{equation} \label{eq:ng-cond-ng-cond-y-x-s1}
p(y|x) = \frac{p(x|y) \cdot p(y)}{p(x)} \; .
\end{equation}

The conditional distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-cond}) of $x$ given $y$ is a multivariate normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:ng-pdf})

\begin{equation} \label{eq:ng-cond-ng-x-y-pdf}
p(x|y) = \mathcal{N}(x; \mu, (y \Lambda)^{-1}) = \sqrt{\frac{|y \Lambda|}{(2 \pi)^n}} \exp \left[ -\frac{1}{2} (x-\mu)^\mathrm{T} (y \Lambda) (x-\mu) \right] \; ,
\end{equation}

the marginal distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-marg}) of $y$ is a gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:ng-marg})

\begin{equation} \label{eq:ng-cond-ng-y-pdf}
p(y) = \mathrm{Gam}(y; a, b) = \frac{b^a}{\Gamma(a)} y^{a-1} \exp\left[ -by \right]
\end{equation}

and the marginal distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-marg}) of $x$ is a multivariate t-distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:ng-marg})

\begin{equation} \label{eq:ng-cond-ng-x-pdf}
\begin{split}
p(x) &= t\left( x; \mu, \left(\frac{a}{b} \Lambda \right)^{-1}, 2a \right) \\
&= \sqrt{\frac{\left| \frac{a}{b}\,\Lambda \right|}{(2a\,\pi)^n}} \cdot \frac{\Gamma\left( \frac{2a+n}{2} \right)}{\Gamma\left( \frac{2a}{2} \right)} \cdot \left( 1 + \frac{1}{2a} (x-\mu)^\mathrm{T} \left( \frac{a}{b}\Lambda \right) (x-\mu) \right)^{-\frac{2a+n}{2}} \\
&= \sqrt{\frac{|\Lambda|}{(2 \pi)^n}} \cdot \frac{\Gamma\left( a+\frac{n}{2} \right)}{\Gamma(a)} \cdot b^a \cdot \left( b + \frac{1}{2} (x-\mu)^\mathrm{T} \Lambda (x-\mu) \right)^{-\left( a+\frac{n}{2} \right)} \; .
\end{split}
\end{equation}

Plugging \eqref{eq:ng-cond-ng-x-y-pdf}, \eqref{eq:ng-cond-ng-y-pdf} and \eqref{eq:ng-cond-ng-x-pdf} into \eqref{eq:ng-cond-ng-cond-y-x-s1}, we obtain

\begin{equation} \label{eq:ng-cond-ng-cond-y-x-s2}
\begin{split}
p(y|x) &= \frac{\sqrt{\frac{|y \Lambda|}{(2 \pi)^n}} \exp \left[ -\frac{1}{2} (x-\mu)^\mathrm{T} (y \Lambda) (x-\mu) \right] \cdot \frac{b^a}{\Gamma(a)} y^{a-1} \exp\left[ -by \right]}{\sqrt{\frac{|\Lambda|}{(2 \pi)^n}} \cdot \frac{\Gamma\left( a+\frac{n}{2} \right)}{\Gamma(a)} \cdot b^a \cdot \left( b + \frac{1}{2} (x-\mu)^\mathrm{T} \Lambda (x-\mu) \right)^{-\left( a+\frac{n}{2} \right)}} \\
&= y^{\frac{n}{2}} \cdot \exp \left[ -\frac{1}{2} (x-\mu)^\mathrm{T} (y \Lambda) (x-\mu) \right] \cdot y^{a-1} \cdot \exp\left[ -by \right] \cdot \frac{1}{\Gamma\left( a+\frac{n}{2} \right)} \cdot \left( b + \frac{1}{2} (x-\mu)^\mathrm{T} \Lambda (x-\mu) \right)^{a+\frac{n}{2}} \\
&= \frac{\left( b + \frac{1}{2} (x-\mu)^\mathrm{T} \Lambda (x-\mu) \right)^{a+\frac{n}{2}}}{\Gamma\left( a+\frac{n}{2} \right)} \cdot y^{a+\frac{n}{2}-1} \cdot \exp \left[ -\left( b + \frac{1}{2} (x-\mu)^\mathrm{T} \Lambda (x-\mu) \right) \right]
\end{split}
\end{equation}

which is the probability density function of a gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-pdf}) with shape and rate parameters

\begin{equation} \label{eq:ng-cond-ng-cond-y-x-hyp}
a + \frac{n}{2} \quad \text{and} \quad b + \frac{1}{2} (x-\mu)^\mathrm{T} \Lambda (x-\mu) \; ,
\end{equation}

such that

\begin{equation} \label{eq:ng-cond-ng-cond-y-x-qed}
p(y|x) = \mathrm{Gam}\left( y; a + \frac{n}{2}, b + \frac{1}{2} (x-\mu)^\mathrm{T} \Lambda (x-\mu) \right) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P146 | shortcut: ng-cond | author: JoramSoch | date: 2020-08-05, 06:54.
\vspace{1em}



\subsection{Dirichlet distribution}

\subsubsection[\textit{Definition}]{Definition} \label{sec:dir}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a $k \times 1$ random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}). Then, $X$ is said to follow a Dirichlet distribution with concentration parameters $\alpha = \left[ \alpha_1, \ldots, \alpha_k \right]$

\begin{equation} \label{eq:dir-Dir}
X \sim \mathrm{Dir}(\alpha) \; ,
\end{equation}

if and only if its probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) is given by

\begin{equation} \label{eq:dir-beta-pdf}
\mathrm{Dir}(x; \alpha) = \frac{\Gamma\left( \sum_{i=1}^k \alpha_i \right)}{\prod_{i=1}^k \Gamma(\alpha_i)} \, \prod_{i=1}^k {x_i}^{\alpha_i-1}
\end{equation}

where $\alpha_i > 0$ for all $i = 1, \ldots, k$, and the density is zero, if $x_i \notin [0,1]$ for any $i = 1, \ldots, k$ or $\sum_{i=1}^k x_i \neq 1$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Dirichlet distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-05-10; URL: \url{https://en.wikipedia.org/wiki/Dirichlet_distribution#Probability_density_function}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D54 | shortcut: dir | author: JoramSoch | date: 2020-05-10, 20:36.
\vspace{1em}



\subsubsection[\textbf{Probability density function}]{Probability density function} \label{sec:dir-pdf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}) following a Dirichlet distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:dir}):

\begin{equation} \label{eq:dir-pdf-Dir}
X \sim \mathrm{Dir}(\alpha) \; .
\end{equation}

Then, the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $X$ is

\begin{equation} \label{eq:dir-pdf-Dir-pdf}
f_X(x) = \frac{\Gamma\left( \sum_{i=1}^k \alpha_i \right)}{\prod_{i=1}^k \Gamma(\alpha_i)} \, \prod_{i=1}^k {x_i}^{\alpha_i-1} \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} This follows directly from the definition of the Dirichlet distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:dir}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P95 | shortcut: dir-pdf | author: JoramSoch | date: 2020-05-05, 21:22.
\vspace{1em}



\subsubsection[\textbf{Kullback-Leibler divergence}]{Kullback-Leibler divergence} \label{sec:dir-kl}
\setcounter{equation}{0}

\textbf{Theorem:} Let $x$ be an $k \times 1$ random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}). Assume two Dirichlet distributions ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:dir}) $P$ and $Q$ specifying the probability distribution of $x$ as

\begin{equation} \label{eq:dir-kl-dirs}
\begin{split}
P: \; x &\sim \mathrm{Dir}(\alpha_1) \\
Q: \; x &\sim \mathrm{Dir}(\alpha_2) \; .
\end{split}
\end{equation}

Then, the Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) of $P$ from $Q$ is given by

\begin{equation} \label{eq:dir-kl-dir-KL}
\mathrm{KL}[P\,||\,Q] = \ln \frac{\Gamma\left(\sum_{i=1}^{k} \alpha_{1i}\right)}{\Gamma\left(\sum_{i=1}^{k} \alpha_{2i}\right)} + \sum_{i=1}^{k} \ln \frac{\Gamma(\alpha_{2i})}{\Gamma(\alpha_{1i})} + \sum_{i=1}^{k} \left( \alpha_{1i} - \alpha_{2i} \right) \left[ \psi(\alpha_{1i}) - \psi\left(\sum_{i=1}^{k} \alpha_{1i}\right) \right] \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The KL divergence for a continuous random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) is given by 

\begin{equation} \label{eq:dir-kl-KL-cont}
\mathrm{KL}[P\,||\,Q] = \int_{\mathcal{X}} p(x) \, \ln \frac{p(x)}{q(x)} \, \mathrm{d}x
\end{equation}

which, applied to the Dirichlet distributions ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mvn}) in \eqref{eq:dir-kl-dirs}, yields

\begin{equation} \label{eq:dir-kl-dir-KL-s1}
\begin{split}
\mathrm{KL}[P\,||\,Q] &= \int_{\mathcal{X}^k} \mathrm{Dir}(x; \alpha_1) \, \ln \frac{\mathrm{Dir}(x; \alpha_1)}{\mathrm{Dir}(x; \alpha_2)} \, \mathrm{d}x \\
&= \left\langle \ln \frac{\mathrm{Dir}(x; \alpha_1)}{\mathrm{Dir}(x; \alpha_2)} \right\rangle_{p(x)}
\end{split}
\end{equation}

where $\mathcal{X}^k$ is the set $\left\lbrace x \in \mathbb{R}^k \; \vert \; \sum_{i=1}^{k} x_i = 1, \; 0 \leq x_i \leq 1, \; i = 1,\ldots,k \right\rbrace$.

Using the probability density function of the Dirichlet distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:dir-pdf}), this becomes:

\begin{equation} \label{eq:dir-kl-dir-KL-s2}
\begin{split}
\mathrm{KL}[P\,||\,Q] &= \left\langle \ln \frac{ \frac{\Gamma\left( \sum_{i=1}^k \alpha_{1i} \right)}{\prod_{i=1}^k \Gamma(\alpha_{1i})} \, \prod_{i=1}^k {x_i}^{\alpha_{1i}-1} }{ \frac{\Gamma\left( \sum_{i=1}^k \alpha_{2i} \right)}{\prod_{i=1}^k \Gamma(\alpha_{2i})} \, \prod_{i=1}^k {x_i}^{\alpha_{2i}-1} } \right\rangle_{p(x)} \\
&= \left\langle \ln \left( \frac{\Gamma\left( \sum_{i=1}^k \alpha_{1i} \right)}{\Gamma\left( \sum_{i=1}^k \alpha_{2i} \right)} \cdot \frac{\prod_{i=1}^k \Gamma(\alpha_{2i})}{\prod_{i=1}^k \Gamma(\alpha_{1i})} \cdot \prod_{i=1}^k {x_i}^{\alpha_{1i}-\alpha_{2i}} \right) \right\rangle_{p(x)} \\
&= \left\langle \ln \frac{\Gamma\left( \sum_{i=1}^k \alpha_{1i} \right)}{\Gamma\left( \sum_{i=1}^k \alpha_{2i} \right)} + \sum_{i=1}^k \ln \frac{\Gamma(\alpha_{2i})}{\Gamma(\alpha_{1i})} + \sum_{i=1}^k (\alpha_{1i}-\alpha_{2i}) \cdot \ln (x_i) \right\rangle_{p(x)} \\
&= \ln \frac{\Gamma\left( \sum_{i=1}^k \alpha_{1i} \right)}{\Gamma\left( \sum_{i=1}^k \alpha_{2i} \right)} + \sum_{i=1}^k \ln \frac{\Gamma(\alpha_{2i})}{\Gamma(\alpha_{1i})} + \sum_{i=1}^k (\alpha_{1i}-\alpha_{2i}) \cdot \left\langle \ln x_i \right\rangle_{p(x)} \; .
\end{split}
\end{equation}

Using the expected value of a logarithmized Dirichlet variate ($\rightarrow$ Proof "dir-logmean")

\begin{equation} \label{eq:dir-kl-dir-logmean}
x \sim \mathrm{Dir}(\alpha) \quad \Rightarrow \quad \left\langle \ln x_i \right\rangle = \psi(\alpha_i) - \psi\left(\sum_{i=1}^{k} \alpha_i\right) \; ,
\end{equation}

the Kullback-Leibler divergence from \eqref{eq:dir-kl-dir-KL-s2} becomes:

\begin{equation} \label{eq:dir-kl-dir-KL-s3}
\mathrm{KL}[P\,||\,Q] = \ln \frac{\Gamma\left( \sum_{i=1}^k \alpha_{1i} \right)}{\Gamma\left( \sum_{i=1}^k \alpha_{2i} \right)} + \sum_{i=1}^k \ln \frac{\Gamma(\alpha_{2i})}{\Gamma(\alpha_{1i})} + \sum_{i=1}^k (\alpha_{1i}-\alpha_{2i}) \cdot \left[ \psi(\alpha_{1i}) - \psi\left(\sum_{i=1}^{k} \alpha_{1i}\right) \right]
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Penny, William D. (2001): "KL-Divergences of Normal, Gamma, Dirichlet and Wishart densities"; in: \textit{University College, London}, p. 2, eqs. 8-9; URL: \url{https://www.fil.ion.ucl.ac.uk/~wpenny/publications/densities.ps}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P294 | shortcut: dir-kl | author: JoramSoch | date: 2021-12-02, 14:28.
\vspace{1em}



\subsubsection[\textbf{Exceedance probabilities}]{Exceedance probabilities} \label{sec:dir-ep}
\setcounter{equation}{0}

\textbf{Theorem:} Let $r = [r_1, \ldots, r_k]$ be a random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}) following a Dirichlet distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:dir}) with concentration parameters $\alpha = [\alpha_1, \ldots, \alpha_k]$:

\begin{equation} \label{eq:dir-ep-r-Dir}
r \sim \mathrm{Dir}(\alpha) \; .
\end{equation}

\vspace{1em}
1) If $k = 2$, then the exceedance probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-exc}) for $r_1$ is

\begin{equation} \label{eq:dir-ep-Dir2-EP}
\varphi_1 = 1 - \frac{\mathrm{B}\left( \frac{1}{2};\alpha_1,\alpha_2 \right)}{\mathrm{B}(\alpha_1,\alpha_2)}
\end{equation}

where $\mathrm{B}(x,y)$ is the beta function and $\mathrm{B}(x;a,b)$ is the incomplete beta function.

\vspace{1em}
2) If $k > 2$, then the exceedance probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-exc}) for $r_i$ is

\begin{equation} \label{eq:dir-ep-Dir-EP}
\varphi_i = \int_0^\infty \prod_{j \neq i} \left( \frac{\gamma(\alpha_j,q_i)}{\Gamma(\alpha_j)} \right) \, \frac{q_i^{\alpha_i-1} \exp[-q_i]}{\Gamma(\alpha_i)} \, \mathrm{d}q_i \; .
\end{equation}

where $\Gamma(x)$ is the gamma function and $\gamma(s,x)$ is the lowerr incomplete gamma function.


\vspace{1em}
\textbf{Proof:} In the context of the Dirichlet distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:dir}), the exceedance probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-exc}) for a particular $r_i$ is defined as:

\begin{equation} \label{eq:dir-ep-Dir-EP-def}
\begin{split}
\varphi_i &= p \Bigl( \forall j \in \left\lbrace 1, \ldots, k \Bigm| j \neq i \right\rbrace: \, r_i > r_j |\alpha \bigr) \\
&= p \Bigl( \bigwedge_{j \neq i} r_i > r_j \Bigm| \alpha \Bigr) \; .
\end{split}
\end{equation}

The probability density function of the Dirichlet distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:dir-pdf}) is given by:

\begin{equation} \label{eq:dir-ep-Dir-pdf}
\mathrm{Dir}(r; \alpha) = \frac{\Gamma\left( \sum_{i=1}^k \alpha_i \right)}{\prod_{i=1}^k \Gamma(\alpha_i)} \, \prod_{i=1}^k {r_i}^{\alpha_i-1} \; .
\end{equation}

Note that the probability density function is only calculated, if

\begin{equation} \label{eq:dir-ep-Dir-req}
r_i \in [0,1] \quad \text{for} \quad i = 1,\ldots,k \quad \text{and} \quad \sum_{i=1}^k r_i = 1 \; ,
\end{equation}

and defined to be zero otherwise ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:dir}).

\vspace{1em}
1) If $k = 2$, the probability density function of the Dirichlet distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:dir-pdf}) reduces to

\begin{equation} \label{eq:dir-ep-Dir2-pdf}
p(r) = \frac{\Gamma(\alpha_1 + \alpha_2)}{\Gamma(\alpha_1) \, \Gamma(\alpha_2)} \, r_1^{\alpha_1-1} \, r_2^{\alpha_2-1}
\end{equation}

which is equivalent to the probability density function of the beta distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:beta-pdf})

\begin{equation} \label{eq:dir-ep-Beta-pdf}
p(r_1) = \frac{r_1^{\alpha_1-1} \, (1-r_1)^{\alpha_2-1}}{\mathrm{B}(\alpha_1,\alpha_2)}
\end{equation}

with the beta function given by

\begin{equation} \label{eq:dir-ep-beta-fct}
\mathrm{B}(x,y) = \frac{\Gamma(x) \, \Gamma(y)}{\Gamma(x + y)} \; .
\end{equation}

With \eqref{eq:dir-ep-Dir-req}, the exceedance probability for this bivariate case simplifies to

\begin{equation} \label{eq:dir-ep-Dir2-EP-def}
\varphi_1 = p(r_1 > r_2) = p(r_1 > 1 - r_1) = p(r_1 > 1/2) = \int_{\frac{1}{2}}^1 p(r_1) \, \mathrm{d}r_1 \; .
\end{equation}

Using the cumulative distribution function of the beta distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:beta-cdf}), it evaluates to

\begin{equation} \label{eq:dir-ep-Dir2-EP-qed}
\varphi_1 = 1 - \int_0^{\frac{1}{2}} p(r_1) \, \mathrm{d}r_1 = 1 - \frac{\mathrm{B}\left( \frac{1}{2};\alpha_1,\alpha_2 \right)}{\mathrm{B}(\alpha_1,\alpha_2)}
\end{equation}

with the incomplete beta function

\begin{equation} \label{eq:dir-ep-inc-beta-fct}
\mathrm{B}(x; a, b) = \int_0^x x^{a-1} \, (1-x)^{b-1} \, \mathrm{d}x \; .
\end{equation}

\vspace{1em}
2) If $k > 2$, there is no similarly simple expression, because in general

\begin{equation} \label{eq:dir-ep-Dir-EP-ineq}
\varphi_i = p(r_i = \mathrm{max}(r)) > p(r_i > 1/2) \quad \text{for} \quad i = 1, \ldots, k \; ,
\end{equation}

i.e. exceedance probabilities cannot be evaluated using a simple threshold on $r_i$, because $r_i$ might be the maximal element in $r$ without being larger than $1/2$. Instead, we make use of the relationship between the Dirichlet and the gamma distribution ($\rightarrow$ Proof "gam-dir") which states that

\begin{equation} \label{eq:dir-ep-Gam-Dir}
\begin{split}
& Y_1 \sim \mathrm{Gam}(\alpha_1,\beta), \, \ldots, \, Y_k \sim \mathrm{Gam}(\alpha_k,\beta), \, Y_s = \sum_{i=1}^k Y_j \\
\Rightarrow \; & X = (X_1, \ldots, X_k) = \left( \frac{Y_1}{Y_s}, \ldots, \frac{Y_k}{Y_s} \right) \sim \mathrm{Dir}(\alpha_1, \ldots, \alpha_k) \; .
\end{split}
\end{equation}

The probability density function of the gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-pdf}) is given by

\begin{equation} \label{eq:dir-ep-Gam-pdf}
\mathrm{Gam}(x; a, b) = \frac{ {b}^{a} }{\Gamma(a)} \, x^{a-1} \, \exp[-b x] \quad \text{for} \quad x > 0 \; .
\end{equation}

Consider the gamma random variables ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:gam})

\begin{equation} \label{eq:dir-ep-Gam-Dir-A}
q_1 \sim \mathrm{Gam}(\alpha_1,1), \, \ldots, \, q_k \sim \mathrm{Gam}(\alpha_k,1), \, q_s = \sum_{j=1}^k q_j
\end{equation}

and the Dirichlet random vector ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:dir})

\begin{equation} \label{eq:dir-ep-Gam-Dir-B}
r = (r_1, \ldots, r_k) = \left( \frac{q_1}{q_s}, \ldots, \frac{q_k}{q_s} \right) \sim \mathrm{Dir}(\alpha_1, \ldots, \alpha_k) \; .
\end{equation}

Obviously, it holds that

\begin{equation} \label{eq:dir-ep-Gam-Dir-eq}
r_i > r_j \; \Leftrightarrow \; q_i > q_j \quad \text{for} \quad i,j = 1, \ldots, k \quad \text{with} \quad j \neq i \; .
\end{equation}

Therefore, consider the probability that $q_i$ is larger than $q_j$, given $q_i$ is known. This probability is equal to the probability that $q_j$ is smaller than $q_i$, given $q_i$ is known

\begin{equation} \label{eq:dir-ep-Gam-EP0}
p(q_i > q_j|q_i) = p(q_j < q_i|q_i)
\end{equation}

which can be expressed in terms of the cumulative distribution function of the gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-cdf}) as

\begin{equation} \label{eq:dir-ep-Gam-EP1}
p(q_j < q_i|q_i) = \int_0^{q_i} \mathrm{Gam}(q_j;\alpha_j,1) \, \mathrm{d}q_j = \frac{\gamma(\alpha_j,q_i)}{\Gamma(\alpha_j)}
\end{equation}

where $\Gamma(x)$ is the gamma function and $\gamma(s,x)$ is the lower incomplete gamma function. Since the gamma variates are independent of each other, these probabilties factorize:

\begin{equation} \label{eq:dir-ep-Gam-EP2}
p(\forall_{j \neq i} \left[ q_i > q_j \right]|q_i) = \prod_{j \neq i} p(q_i > q_j|q_i) = \prod_{j \neq i} \frac{\gamma(\alpha_j,q_i)}{\Gamma(\alpha_j)} \; .
\end{equation}

In order to obtain the exceedance probability $\varphi_i$, the dependency on $q_i$ in this probability still has to be removed. From equations \eqref{eq:dir-ep-Dir-EP-def} and \eqref{eq:dir-ep-Gam-Dir-eq}, it follows that

\begin{equation} \label{eq:dir-ep-Dir-EP2a}
\varphi_i = p(\forall_{j \neq i} \left[ r_i > r_j \right]) = p(\forall_{j \neq i} \left[ q_i > q_j \right]) \; .
\end{equation}

Using the law of marginal probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}), we have

\begin{equation} \label{eq:dir-ep-Dir-EP2b}
\varphi_i = \int_0^\infty p(\forall_{j \neq i} \left[ q_i > q_j \right]|q_i) \, p(q_i) \, \mathrm{d}q_i \; .
\end{equation}

With \eqref{eq:dir-ep-Gam-EP2} and \eqref{eq:dir-ep-Gam-Dir-A}, this becomes

\begin{equation} \label{eq:dir-ep-Dir-EP2c}
\varphi_i = \int_0^\infty \prod_{j \neq i} \left( p(q_i > q_j|q_i) \right) \cdot \mathrm{Gam}(q_i;\alpha_i,1) \, \mathrm{d}q_i \; .
\end{equation}

And with \eqref{eq:dir-ep-Gam-EP1} and \eqref{eq:dir-ep-Gam-pdf}, it becomes

\begin{equation} \label{eq:dir-ep-Dir-EP-qed}
\varphi_i = \int_0^\infty \prod_{j \neq i} \left( \frac{\gamma(\alpha_j,q_i)}{\Gamma(\alpha_j)} \right) \cdot \frac{q_i^{\alpha_i-1} \exp[-q_i]}{\Gamma(\alpha_i)} \, \mathrm{d}q_i \; .
\end{equation}

In other words, the exceedance probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-exc}) for one element from a Dirichlet-distributed ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:dir}) random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}) is an integral from zero to infinity where the first term in the integrand conforms to a product of gamma ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:gam}) cumulative distribution functions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) and the second term is a gamma ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:gam}) probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}).



\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Soch J, Allefeld C (2016): "Exceedance Probabilities for the Dirichlet Distribution"; in: \textit{arXiv stat.AP}, 1611.01439; URL: \url{https://arxiv.org/abs/1611.01439}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P181 | shortcut: dir-ep | author: JoramSoch | date: 2020-10-22, 08:04.
\vspace{1em}



\pagebreak
\section{Matrix-variate continuous distributions}

\subsection{Matrix-normal distribution}

\subsubsection[\textit{Definition}]{Definition} \label{sec:matn}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be an $n \times p$ random matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rmat}). Then, $X$ is said to be matrix-normally distributed with mean $M$, covariance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:covmat}) across rows $U$ and covariance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:covmat}) across columns $V$

\begin{equation} \label{eq:matn-matn}
X \sim \mathcal{MN}(M, U, V) \; ,
\end{equation}

if and only if its probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) is given by

\begin{equation} \label{eq:matn-matn-pdf}
\mathcal{MN}(X; M, U, V) = \frac{1}{\sqrt{(2\pi)^{np} |V|^n |U|^p}} \cdot \exp\left[-\frac{1}{2} \mathrm{tr}\left( V^{-1} (X-M)^\mathrm{T} \, U^{-1} (X-M) \right) \right]
\end{equation}

where $M$ is an $n \times p$ real matrix, $U$ is an $n \times n$ positive definite matrix and $V$ is a $p \times p$ positive definite matrix.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Matrix normal distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-01-27; URL: \url{https://en.wikipedia.org/wiki/Matrix_normal_distribution#Definition}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D6 | shortcut: matn | author: JoramSoch | date: 2020-01-27, 14:37.
\vspace{1em}



\subsubsection[\textbf{Probability density function}]{Probability density function} \label{sec:matn-pdf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rmat}) following a matrix-normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:matn}):

\begin{equation} \label{eq:matn-pdf-matn}
X \sim \mathcal{MN}(M, U, V) \; .
\end{equation}

Then, the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $X$ is

\begin{equation} \label{eq:matn-pdf-matn-pdf}
f(X) = \frac{1}{\sqrt{(2\pi)^{np} |V|^n |U|^p}} \cdot \exp\left[-\frac{1}{2} \mathrm{tr}\left( V^{-1} (X-M)^\mathrm{T} \, U^{-1} (X-M) \right) \right] \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} This follows directly from the definition of the matrix-normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:matn}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P70 | shortcut: matn-pdf | author: JoramSoch | date: 2020-03-02, 21:03.
\vspace{1em}



\subsubsection[\textbf{Equivalence to multivariate normal distribution}]{Equivalence to multivariate normal distribution} \label{sec:matn-mvn}
\setcounter{equation}{0}

\textbf{Theorem:} The matrix $X$ is matrix-normally distributed ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:matn})

\begin{equation} \label{eq:matn-mvn-matn}
X \sim \mathcal{MN}(M, U, V) \; ,
\end{equation}

if and only if $\mathrm{vec}(X)$ is multivariate normally distributed ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mvn})

\begin{equation} \label{eq:matn-mvn-mvn}
\mathrm{vec}(X) \sim \mathcal{N}(\mathrm{vec}(M), V \otimes U)
\end{equation}

where $\mathrm{vec}(X)$ is the vectorization operator and $\otimes$ is the Kronecker product.


\vspace{1em}
\textbf{Proof:} The probability density function of the matrix-normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:matn-pdf}) with $n \times p$ mean $M$, $n \times n$ covariance across rows $U$ and $p \times p$ covariance across columns $V$ is

\begin{equation} \label{eq:matn-mvn-matn-pdf}
\mathcal{MN}(X; M, U, V) = \frac{1}{\sqrt{(2\pi)^{np} |V|^n |U|^p}} \cdot \exp\left[-\frac{1}{2} \mathrm{tr}\left( V^{-1} (X-M)^\mathrm{T} \, U^{-1} (X-M) \right) \right] \; .
\end{equation}

Using the trace property $\mathrm{tr}(ABC) = \mathrm{tr}(BCA)$, we have:

\begin{equation} \label{eq:matn-mvn-matn-mvn-s1}
\mathcal{MN}(X; M, U, V) = \frac{1}{\sqrt{(2\pi)^{np} |V|^n |U|^p}} \cdot \exp\left[-\frac{1}{2} \mathrm{tr}\left( (X-M)^\mathrm{T} \, U^{-1} (X-M) \, V^{-1} \right) \right] \; .
\end{equation}

Using the trace-vectorization relation $\mathrm{tr}(A^\mathrm{T} B) = \mathrm{vec}(A)^\mathrm{T} \, \mathrm{vec}(B)$, we have:

\begin{equation} \label{eq:matn-mvn-matn-mvn-s2}
\mathcal{MN}(X; M, U, V) = \frac{1}{\sqrt{(2\pi)^{np} |V|^n |U|^p}} \cdot \exp\left[-\frac{1}{2} \mathrm{vec}(X-M)^\mathrm{T} \, \mathrm{vec}\left( U^{-1} (X-M) \, V^{-1} \right) \right] \; .
\end{equation}

Using the vectorization-Kronecker relation $\mathrm{vec}(ABC) = \left( C^\mathrm{T} \otimes A \right) \mathrm{vec}(B)$, we have:

\begin{equation} \label{eq:matn-mvn-matn-mvn-s3}
\mathcal{MN}(X; M, U, V) = \frac{1}{\sqrt{(2\pi)^{np} |V|^n |U|^p}} \cdot \exp\left[-\frac{1}{2} \mathrm{vec}(X-M)^\mathrm{T} \, \left( V^{-1} \otimes U^{-1} \right) \mathrm{vec}(X-M) \right] \; .
\end{equation}

Using the Kronecker product property $\left( A^{-1} \otimes B^{-1} \right) = \left( A \otimes B \right)^{-1}$, we have:

\begin{equation} \label{eq:matn-mvn-matn-mvn-s4}
\mathcal{MN}(X; M, U, V) = \frac{1}{\sqrt{(2\pi)^{np} |V|^n |U|^p}} \cdot \exp\left[-\frac{1}{2} \mathrm{vec}(X-M)^\mathrm{T} \, \left( V \otimes U \right)^{-1} \mathrm{vec}(X-M) \right] \; .
\end{equation}

Using the vectorization property $\mathrm{vec}(A+B) = \mathrm{vec}(A) + \mathrm{vec}(B)$, we have:

\begin{equation} \label{eq:matn-mvn-matn-mvn-s5}
\mathcal{MN}(X; M, U, V) = \frac{1}{\sqrt{(2\pi)^{np} |V|^n |U|^p}} \cdot \exp\left[-\frac{1}{2} \left[ \mathrm{vec}(X) - \mathrm{vec}(M) \right]^\mathrm{T} \, \left( V \otimes U \right)^{-1} \left[ \mathrm{vec}(X) - \mathrm{vec}(M) \right] \right] \; .
\end{equation}

Using the Kronecker-determinant relation $\lvert A \otimes B \rvert = \lvert A \rvert^m \lvert B \rvert^n$, we have:

\begin{equation} \label{eq:matn-mvn-matn-mvn-s6}
\mathcal{MN}(X; M, U, V) = \frac{1}{\sqrt{(2\pi)^{np} |V \otimes U|}} \cdot \exp\left[-\frac{1}{2} \left[ \mathrm{vec}(X) - \mathrm{vec}(M) \right]^\mathrm{T} \, \left( V \otimes U \right)^{-1} \left[ \mathrm{vec}(X) - \mathrm{vec}(M) \right] \right] \; .
\end{equation}

This is the probability density function of the multivariate normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mvn-pdf}) with the $np \times 1$ mean vector $\mathrm{vec}(M)$ and the $np \times np$ covariance matrix $V \otimes U$:

\begin{equation} \label{eq:matn-mvn-matn-mvn}
\mathcal{MN}(X; M, U, V) = \mathcal{N}(\mathrm{vec}(X); \mathrm{vec}(M), V \otimes U) \; .
\end{equation}

By showing that the probability density functions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) are identical, it is proven that the associated probability distributions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist}) are equivalent.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Matrix normal distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-01-20; URL: \url{https://en.wikipedia.org/wiki/Matrix_normal_distribution#Proof}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P26 | shortcut: matn-mvn | author: JoramSoch | date: 2020-01-20, 21:09.
\vspace{1em}



\subsubsection[\textbf{Kullback-Leibler divergence}]{Kullback-Leibler divergence} \label{sec:matn-kl}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be an $n \times p$ random matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rmat}). Assume two matrix-normal distributions ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:matn}) $P$ and $Q$ specifying the probability distribution of $X$ as

\begin{equation} \label{eq:matn-kl-matns}
\begin{split}
P: \; X &\sim \mathcal{MN}(M_1, U_1, V_1) \\
Q: \; X &\sim \mathcal{MN}(M_2, U_2, V_2) \; .
\end{split}
\end{equation}

Then, the Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) of $P$ from $Q$ is given by

\begin{equation} \label{eq:matn-kl-matn-KL}
\begin{split}
\mathrm{KL}[P\,||\,Q] &= \frac{1}{2} \left[ \mathrm{vec}(M_2 - M_1)^\mathrm{T} \mathrm{vec}\left(U_2^{-1} (M_2 - M_1) V_2^{-1}\right) \right. \\
&+ \left. \mathrm{tr}\left( (V_2^{-1}V_1) \otimes (U_2^{-1}U_1) \right) - n \ln \frac{|V_1|}{|V_2|} - p \ln \frac{|U_1|}{|U_2|} - n p \right] \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Proof:} The matrix-normal distribution is equivalent to the multivariate normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:matn-mvn}),

\begin{equation} \label{eq:matn-kl-matn-mvn}
X \sim \mathcal{MN}(M, U, V) \quad \Leftrightarrow \quad \mathrm{vec}(X) \sim \mathcal{N}(\mathrm{vec}(M), V \otimes U) \; ,
\end{equation}

and the Kullback-Leibler divergence for the multivariate normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mvn-kl}) is

\begin{equation} \label{eq:matn-kl-mvn-KL}
\mathrm{KL}[P\,||\,Q] = \frac{1}{2} \left[ (\mu_2 - \mu_1)^T \Sigma_2^{-1} (\mu_2 - \mu_1) + \mathrm{tr}(\Sigma_2^{-1} \Sigma_1) - \ln \frac{|\Sigma_1|}{|\Sigma_2|} - n \right]
\end{equation}

where $X$ is an $n \times 1$ random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}).

Thus, we can plug the distribution parameters from \eqref{eq:matn-kl-matns} into the KL divergence in \eqref{eq:matn-kl-mvn-KL} using the relationship given by \eqref{eq:matn-kl-matn-mvn}

\begin{equation} \label{eq:matn-kl-matn-KL-s1}
\begin{split}
\mathrm{KL}[P\,||\,Q] &= \frac{1}{2} \left[ (\mathrm{vec}(M_2) - \mathrm{vec}(M_1))^T (V_2 \otimes U_2)^{-1} (\mathrm{vec}(M_2) - \mathrm{vec}(M_1)) \right. \\
&+ \left. \mathrm{tr}\left( (V_2 \otimes U_2)^{-1} (V_1 \otimes U_1) \right) - \ln \frac{|V_1 \otimes U_1|}{|V_2 \otimes U_2|} - n p \right] \; .
\end{split}
\end{equation}

Using the vectorization operator and Kronecker product properties

\begin{equation} \label{eq:matn-kl-vec-add}
\mathrm{vec}(A) + \mathrm{vec}(B) = \mathrm{vec}(A+B)
\end{equation}

\begin{equation} \label{eq:matn-kl-kron-inv}
(A \otimes B)^{-1} = A^{-1} \otimes B^{-1}
\end{equation}

\begin{equation} \label{eq:matn-kl-kron-prod}
(A \otimes B) (C \otimes D) = (AC) \otimes (BD)
\end{equation}

\begin{equation} \label{eq:matn-kl-kron-det}
|A \otimes B| = |A|^m \, |B|^n \quad \text{where} \quad A \in \mathbb{R}^{n \times n} \quad \text{and} \quad B \in \mathbb{R}^{m \times m} \; ,
\end{equation}

the Kullback-Leibler divergence from \eqref{eq:matn-kl-matn-KL-s1} becomes:

\begin{equation} \label{eq:matn-kl-matn-KL-s2}
\begin{split}
\mathrm{KL}[P\,||\,Q] &= \frac{1}{2} \left[ \mathrm{vec}(M_2 - M_1)^\mathrm{T} \, (V_2^{-1} \otimes U_2^{-1}) \, \mathrm{vec}(M_2 - M_1) \right. \\
&+ \left. \mathrm{tr}\left( (V_2^{-1}V_1) \otimes (U_2^{-1}U_1) \right) - n \ln \frac{|V_1|}{|V_2|} - p \ln \frac{|U_1|}{|U_2|} - n p \right] \; .
\end{split}
\end{equation}

Using the relationship between Kronecker product and vectorization operator

\begin{equation} \label{eq:matn-kl-kron-vec}
(C^\mathrm{T} \otimes A) \, \mathrm{vec}(B) = \mathrm{vec}(ABC) \; ,
\end{equation}

we finally have:

\begin{equation} \label{eq:matn-kl-matn-KL-s3}
\begin{split}
\mathrm{KL}[P\,||\,Q] &= \frac{1}{2} \left[ \mathrm{vec}(M_2 - M_1)^\mathrm{T} \mathrm{vec}\left(U_2^{-1} (M_2 - M_1) V_2^{-1}\right) \right. \\
&+ \left. \mathrm{tr}\left( (V_2^{-1}V_1) \otimes (U_2^{-1}U_1) \right) - n \ln \frac{|V_1|}{|V_2|} - p \ln \frac{|U_1|}{|U_2|} - n p \right] \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P296 | shortcut: matn-kl | author: JoramSoch | date: 2021-12-02, 20:22.
\vspace{1em}



\subsubsection[\textbf{Linear transformation}]{Linear transformation} \label{sec:matn-ltt}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be an $n \times p$ random matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rmat}) following a matrix-normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:matn}):

\begin{equation} \label{eq:matn-ltt-matn}
X \sim \mathcal{MN}(M, U, V) \; .
\end{equation}

Then, a linear transformation of $X$ is also matrix-normally distributed

\begin{equation} \label{eq:matn-ltt-matn-trans}
Y = AXB + C \sim \mathcal{MN}(AMB+C, AUA^\mathrm{T}, B^\mathrm{T}VB)
\end{equation}

where $A$ us ab $r \times n$ matrix of full rank $r \leq b$ and $B$ is a $p \times s$ matrix of full rank $s \leq p$ and $C$ is an $r \times s$ matrix.


\vspace{1em}
\textbf{Proof:} The matrix-normal distribution is equivalent to the multivariate normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:matn-mvn}),

\begin{equation} \label{eq:matn-ltt-matn-mvn}
X \sim \mathcal{MN}(M, U, V) \quad \Leftrightarrow \quad \mathrm{vec}(X) \sim \mathcal{N}(\mathrm{vec}(M), V \otimes U) \; ,
\end{equation}

and the linear transformation theorem for the multivariate normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mvn-ltt}) states:

\begin{equation} \label{eq:matn-ltt-mvn-ltt}
x \sim \mathcal{N}(\mu, \Sigma) \quad \Rightarrow \quad y = Ax + b \sim \mathcal{N}(A\mu + b, A \Sigma A^\mathrm{T}) \; .
\end{equation}

The vectorization of $Y = AXB + C$ is

\begin{equation} \label{eq:matn-ltt-vec-Y-s1}
\begin{split}
\mathrm{vec}(Y) &= \mathrm{vec}(AXB + C) \\
&= \mathrm{vec}(AXB) + \mathrm{vec}(C) \\
&= (B^\mathrm{T} \otimes A)\mathrm{vec}(X) + \mathrm{vec}(C) \; .
\end{split}
\end{equation}

Using \eqref{eq:matn-ltt-matn-mvn} and \eqref{eq:matn-ltt-mvn-ltt}, we have

\begin{equation} \label{eq:matn-ltt-vec-Y-s2}
\begin{split}
\mathrm{vec}(Y) &\sim \mathcal{N}((B^\mathrm{T} \otimes A) \mathrm{vec}(M) + \mathrm{vec}(C), (B^\mathrm{T} \otimes A) (V \otimes U) (B^\mathrm{T} \otimes A)^\mathrm{T}) \\
&= \mathcal{N}(\mathrm{vec}(AMB) + \mathrm{vec}(C), (B^\mathrm{T}V \otimes AU) (B^\mathrm{T} \otimes A)^\mathrm{T}) \\
&= \mathcal{N}(\mathrm{vec}(AMB + C), B^\mathrm{T}VB \otimes AUA^\mathrm{T}) \; .
\end{split}
\end{equation}

Using \eqref{eq:matn-ltt-matn-mvn}, we finally have:

\begin{equation} \label{eq:matn-ltt-matn-ltt-qed}
Y \sim \mathcal{MN}(AMB + C, AUA^\mathrm{T} ,B^\mathrm{T}VB) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P145 | shortcut: matn-ltt | author: JoramSoch | date: 2020-08-03, 22:24.
\vspace{1em}



\subsubsection[\textbf{Transposition}]{Transposition} \label{sec:matn-trans}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rmat}) following a matrix-normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:matn}):

\begin{equation} \label{eq:matn-trans-matn}
X \sim \mathcal{MN}(M, U, V) \; .
\end{equation}

Then, the transpose of $X$ also has a matrix-normal distribution:

\begin{equation} \label{eq:matn-trans-matn-trans}
X^\mathrm{T} \sim \mathcal{MN}(M^\mathrm{T}, V, U) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The probability density function of the matrix-normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:matn-pdf}) is:

\begin{equation} \label{eq:matn-trans-matn-pdf-X}
f(X) = \mathcal{MN}(X; M, U, V) = \frac{1}{\sqrt{(2\pi)^{np} |V|^n |U|^p}} \cdot \exp\left[-\frac{1}{2} \mathrm{tr}\left( V^{-1} (X-M)^\mathrm{T} \, U^{-1} (X-M) \right) \right] \; .
\end{equation}

Define $Y = X^\mathrm{T}$. Then, $X = Y^\mathrm{T}$ and we can substitute:

\begin{equation} \label{eq:matn-trans-matn-pdf-Y-s1}
f(Y) = \frac{1}{\sqrt{(2\pi)^{np} |V|^n |U|^p}} \cdot \exp\left[-\frac{1}{2} \mathrm{tr}\left( V^{-1} (Y^\mathrm{T}-M)^\mathrm{T} \, U^{-1} (Y^\mathrm{T}-M) \right) \right] \; .
\end{equation}

Using $(A+B)^\mathrm{T} = (A^\mathrm{T} + B^\mathrm{T})$, we have:

\begin{equation} \label{eq:matn-trans-matn-pdf-Y-s2}
f(Y) = \frac{1}{\sqrt{(2\pi)^{np} |V|^n |U|^p}} \cdot \exp\left[-\frac{1}{2} \mathrm{tr}\left( V^{-1} (Y-M^\mathrm{T}) \, U^{-1} (Y-M^\mathrm{T})^\mathrm{T} \right) \right] \; .
\end{equation}

Using $\mathrm{tr}(ABC) = \mathrm{tr}(CAB)$, we obtain

\begin{equation} \label{eq:matn-trans-matn-pdf-Y-s3}
f(Y) = \frac{1}{\sqrt{(2\pi)^{np} |V|^n |U|^p}} \cdot \exp\left[-\frac{1}{2} \mathrm{tr}\left( U^{-1} (Y-M^\mathrm{T})^\mathrm{T} \, V^{-1} (Y-M^\mathrm{T}) \right) \right]
\end{equation}

which is the probability density function of a matrix-normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:matn-pdf}) with mean $M^T$, covariance across rows $V$ and covariance across columns $U$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P144 | shortcut: matn-trans | author: JoramSoch | date: 2020-08-03, 22:21.
\vspace{1em}



\subsubsection[\textbf{Drawing samples}]{Drawing samples} \label{sec:matn-samp}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X \in \mathbb{R}^{n \times p}$ be a random matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rmat}) with all entries independently following a standard normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:snorm}). Moreover, let $A \in \mathbb{R}^{n \times n}$ and $B \in \mathbb{R}^{p \times p}$, such that $A A^\mathrm{T} = U$ and $B^\mathrm{T} B = V$. Then, $Y = M + A X B$ follows a matrix-normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:matn}) with mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean-rmat}) $M$, covariance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:covmat}) across rows $U$ and covariance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:covmat}) across rows $U$:

\begin{equation} \label{eq:matn-samp-matn-samp}
Y = M + A X B \sim \mathcal{MN}(M, U, V) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} If all entries of $X$ are independent and standard normally distributed ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:snorm})

\begin{equation} \label{eq:matn-samp-xij-dist}
x_{ij} \sim \mathcal{N}(0, 1) \quad \text{ind. for all} \quad i = 1,\ldots,n \quad \text{and} \quad j = 1,\ldots,p \; ,
\end{equation}

this implies a multivariate normal distribution with diagonal covariance matrix ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mvn-ind}):

\begin{equation} \label{eq:matn-samp-vecX-dist}
\begin{split}
\mathrm{vec}(X) &\sim \mathcal{N}\left(\mathrm{vec}(0_{np}), I_{np} \right) \\
&\sim \mathcal{N}\left(\mathrm{vec}(0_{np}), I_p \otimes I_n \right) \; .
\end{split}
\end{equation}

where $0_{np}$ is an $n \times p$ matrix of zeros and $I_n$ is the $n \times n$ identity matrix.

Due to the relationship between multivariate and matrix-normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:matn-mvn}), we have:

\begin{equation} \label{eq:matn-samp-X-dist}
X \sim \mathcal{MN}(0_{np}, I_n, I_p) \; .
\end{equation}

Thus, with the linear transformation theorem for the matrix-normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:matn-ltt}), it follows that

\begin{equation} \label{eq:matn-samp-matn-samp-qed}
\begin{split}
Y = M + AXB &\sim \mathcal{MN}\left(M + A 0_{np} B, A I_n A^\mathrm{T}, B^\mathrm{T} I_p B \right) \\
&\sim \mathcal{MN}\left(M, A A^\mathrm{T}, B^\mathrm{T} B \right) \\
&\sim \mathcal{MN}\left(M, U, V \right) \; .
\end{split}
\end{equation}

Thus, given $X$ defined by \eqref{eq:matn-samp-xij-dist}, $Y$ defined by \eqref{eq:matn-samp-matn-samp} is a sample ($\rightarrow$ Definition "samp") from $\mathcal{N}\left(M, U, V \right)$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Matrix normal distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-12-07; URL: \url{https://en.wikipedia.org/wiki/Matrix_normal_distribution#Drawing_values_from_the_distribution}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P297 | shortcut: matn-samp | author: JoramSoch | date: 2021-12-07, 08:43.
\vspace{1em}



\subsection{Wishart distribution}

\subsubsection[\textit{Definition}]{Definition} \label{sec:wish}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be an $n \times p$ matrix following a matrix-normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:matn}) with mean zero, independence across rows and covariance across columns $V$:

\begin{equation} \label{eq:wish-matn}
X \sim \mathcal{MN}(0, I_n, V) \; .
\end{equation}

Define the scatter matrix $S$ as the product of the transpose of $X$ with itself:

\begin{equation} \label{eq:wish-scat-mat}
S = X^T X = \sum_{i=1}^n x_i^\mathrm{T} x_i \; .
\end{equation}

Then, the matrix $S$ is said to follow a Wishart distribution with scale matrix $V$ and degrees of freedom $n$

\begin{equation} \label{eq:wish-wish}
S \sim \mathcal{W}(V, n)
\end{equation}

where $n > p - 1$ and $V$ is a positive definite symmetric covariance matrix.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Wishart distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-03-22; URL: \url{https://en.wikipedia.org/wiki/Wishart_distribution#Definition}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D43 | shortcut: wish | author: JoramSoch | date: 2020-03-22, 17:15.
\vspace{1em}



\subsubsection[\textbf{Kullback-Leibler divergence}]{Kullback-Leibler divergence} \label{sec:wish-kl}
\setcounter{equation}{0}

\textbf{Theorem:} Let $S$ be a $p \times p$ random matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rmat}). Assume two Wishart distributions ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:wish}) $P$ and $Q$ specifying the probability distribution of $S$ as

\begin{equation} \label{eq:wish-kl-wishs}
\begin{split}
P: \; S &\sim \mathcal{W}(V_1, n_1) \\
Q: \; S &\sim \mathcal{W}(V_2, n_2) \; .
\end{split}
\end{equation}

Then, the Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) of $P$ from $Q$ is given by

\begin{equation} \label{eq:wish-kl-wish-KL}
\mathrm{KL}[P\,||\,Q] = \frac{1}{2} \left[ n_2 \left( \ln |V_2| - \ln |V_1| \right) + n_1 \mathrm{tr}(V_2^{-1} V_1) + 2 \ln \frac{\Gamma_p\left(\frac{n_2}{2}\right)}{\Gamma_p\left(\frac{n_1}{2}\right)} + (n_1-n_2) \psi_p\left(\frac{n_1}{2}\right) - n_1 p \right]
\end{equation}

where $\Gamma_p(x)$ is the multivariate gamma function

\begin{equation} \label{eq:wish-kl-mult-gam-fct}
\Gamma_p(x) = \pi^{p(p-1)/4} \, \prod_{j=1}^k \Gamma\left(x - \frac{j-1}{2}\right)
\end{equation}

and $\psi_p(x)$ is the multivariate digamma function

\begin{equation} \label{eq:wish-kl-mult-psi-fct}
\psi_p(x) = \frac{\mathrm{d}\ln \Gamma_p(x)}{\mathrm{d}x} = \sum_{j=1}^k \psi\left(x - \frac{j-1}{2}\right) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The KL divergence for a continuous random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) is given by 

\begin{equation} \label{eq:wish-kl-KL-cont}
\mathrm{KL}[P\,||\,Q] = \int_{\mathcal{X}} p(x) \, \ln \frac{p(x)}{q(x)} \, \mathrm{d}x
\end{equation}

which, applied to the Wishart distributions ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:wish}) in \eqref{eq:wish-kl-wishs}, yields

\begin{equation} \label{eq:wish-kl-wish-KL-s1}
\begin{split}
\mathrm{KL}[P\,||\,Q] &= \int_{\mathcal{S}^p} \mathcal{W}(S; V_1, n_1) \, \ln \frac{\mathcal{W}(S; V_1, n_1)}{\mathcal{W}(S; V_2, n_2)} \, \mathrm{d}S \\
&= \left\langle \ln \frac{\mathcal{W}(S; \alpha_1)}{\mathcal{W}(S; \alpha_1)} \right\rangle_{p(S)}
\end{split}
\end{equation}

where $\mathcal{S}^p$ is the set of all positive-definite symmetric $p \times p$ matrices.

Using the probability density function of the Wishart distribution ($\rightarrow$ Proof "wish-pdf"), this becomes:

\begin{equation} \label{eq:wish-kl-wish-KL-s2}
\begin{split}
\mathrm{KL}[P\,||\,Q] &= \left\langle \ln \frac{\frac{1}{\sqrt{2^{n_1 p} |V_1|^{n_1}} \Gamma_p \left( \frac{n_1}{2} \right)} \cdot |S|^{(n_1-p-1)/2} \cdot \exp\left[ -\frac{1}{2} \mathrm{tr}\left( V_1^{-1} S \right) \right]}{\frac{1}{\sqrt{2^{n_2 p} |V_2|^{n_2}} \Gamma_p \left( \frac{n_2}{2} \right)} \cdot |S|^{(n_2-p-1)/2} \cdot \exp\left[ -\frac{1}{2} \mathrm{tr}\left( V_2^{-1} S \right) \right]} \right\rangle_{p(S)} \\
&= \left\langle \ln \left( \sqrt{2^{(n_2-n_1)p} \cdot \frac{|V_2|^{n_2}}{|V_1|^{n_1}}} \cdot \frac{\Gamma_p\left( \frac{n_2}{2} \right)}{\Gamma_p\left( \frac{n_1}{2} \right)} \cdot |S|^{(n_1-n_2)/2} \cdot \exp\left[ -\frac{1}{2} \mathrm{tr}\left( V_1^{-1} S \right) -\frac{1}{2} \mathrm{tr}\left( V_2^{-1} S \right) \right] \right) \right\rangle_{p(S)} \\
&= \left\langle \frac{(n_2-n_1)p}{2} \ln 2 + \frac{n_2}{2} \ln |V_2| - \frac{n_1}{2} \ln |V_1| + \ln \frac{\Gamma_p\left( \frac{n_2}{2} \right)}{\Gamma_p\left( \frac{n_1}{2} \right)} \right. \\
&+ \left. \quad \frac{n_1-n_2}{2} \ln |S| - \frac{1}{2} \mathrm{tr}\left( V_1^{-1} S \right) - \frac{1}{2} \mathrm{tr}\left( V_2^{-1} S \right) \right\rangle_{p(S)} \\
&= \frac{(n_2-n_1)p}{2} \ln 2 + \frac{n_2}{2} \ln |V_2| - \frac{n_1}{2} \ln |V_1| + \ln \frac{\Gamma_p\left( \frac{n_2}{2} \right)}{\Gamma_p\left( \frac{n_1}{2} \right)} \\
&+ \frac{n_1-n_2}{2} \left\langle \ln |S| \right\rangle_{p(S)} - \frac{1}{2} \left\langle \mathrm{tr}\left( V_1^{-1} S \right) \right\rangle_{p(S)} - \frac{1}{2} \left\langle \mathrm{tr}\left( V_2^{-1} S \right) \right\rangle_{p(S)} \; .
\end{split}
\end{equation}

Using the expected value of a Wishart random matrix ($\rightarrow$ Proof "wish-mean")

\begin{equation} \label{eq:wish-kl-wish-mean}
S \sim \mathcal{W}(V,n) \quad \Rightarrow \quad \left\langle S \right\rangle = n V \; ,
\end{equation}

such that the expected value of the matrix trace ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-tr}) becomes

\begin{equation} \label{eq:wish-kl-wish-trmean}
\left\langle \mathrm{tr}(AS) \right\rangle = \mathrm{tr}\left( \left\langle AS \right\rangle \right) = \mathrm{tr}\left( A \left\langle S \right\rangle \right) = \mathrm{tr}\left( A \cdot (nV) \right) = n \cdot \mathrm{tr}(AV) \; ,
\end{equation}

and the expected value of a Wishart log-determinant ($\rightarrow$ Proof "wish-logdetmean")

\begin{equation} \label{eq:wish-kl-wish-logdetmean}
S \sim \mathcal{W}(V,n) \quad \Rightarrow \quad \left\langle \ln |S| \right\rangle = \psi_p\left(\frac{n}{2}\right) + p \cdot \ln 2 + \ln |V| \; ,
\end{equation}

the Kullback-Leibler divergence from \eqref{eq:wish-kl-wish-KL-s2} becomes:

\begin{equation} \label{eq:wish-kl-wish-KL-s3}
\begin{split}
\mathrm{KL}[P\,||\,Q] &= \frac{(n_2-n_1)p}{2} \ln 2 + \frac{n_2}{2} \ln |V_2| - \frac{n_1}{2} \ln |V_1| + \ln \frac{\Gamma_p\left( \frac{n_2}{2} \right)}{\Gamma_p\left( \frac{n_1}{2} \right)} \\
&+ \frac{n_1-n_2}{2} \left[ \psi_p\left(\frac{n_1}{2}\right) + p \cdot \ln 2 + \ln |V_1| \right] - \frac{n_1}{2} \mathrm{tr}\left( V_1^{-1} V_1 \right) - \frac{n_1}{2} \mathrm{tr}\left( V_2^{-1} V_1 \right) \\
&= \frac{n_2}{2} \left( \ln |V_2| - \ln |V_1| \right) + \ln \frac{\Gamma_p\left( \frac{n_2}{2} \right)}{\Gamma_p\left( \frac{n_1}{2} \right)} + \frac{n_1-n_2}{2} \psi_p\left(\frac{n_1}{2}\right) - \frac{n_1}{2} \mathrm{tr}\left( I_p \right) - \frac{n_1}{2} \mathrm{tr}\left( V_2^{-1} V_1 \right) \\
& = \frac{1}{2} \left[ n_2 \left( \ln |V_2| - \ln |V_1| \right) + n_1 \mathrm{tr}(V_2^{-1} V_1) + 2 \ln \frac{\Gamma_p\left(\frac{n_2}{2}\right)}{\Gamma_p\left(\frac{n_1}{2}\right)} + (n_1-n_2) \psi_p\left(\frac{n_1}{2}\right) - n_1 p \right] \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Penny, William D. (2001): "KL-Divergences of Normal, Gamma, Dirichlet and Wishart densities"; in: \textit{University College, London}, pp. 2-3, eqs. 13/15; URL: \url{https://www.fil.ion.ucl.ac.uk/~wpenny/publications/densities.ps}.
\item Wikipedia (2021): "Wishart distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-12-02; URL: \url{https://en.wikipedia.org/wiki/Wishart_distribution#KL-divergence}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P295 | shortcut: wish-kl | author: JoramSoch | date: 2021-12-02, 15:33.
\vspace{1em}





% Chapter 3 %
\chapter{Statistical Models} \label{sec:Statistical Models} \newpage

\pagebreak
\section{Univariate normal data}

\subsection{Univariate Gaussian}

\subsubsection[\textit{Definition}]{Definition} \label{sec:ug}
\setcounter{equation}{0}

\textbf{Definition:} A univariate Gaussian data set is given by a set of real numbers $y = \left\lbrace y_1, \ldots, y_n \right\rbrace$, independent and identically distributed according to a normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}) with unknown mean $\mu$ and unknown variance $\sigma^2$:

\begin{equation} \label{eq:ug-ug}
y_i \sim \mathcal{N}(\mu, \sigma^2), \quad i = 1, \ldots, n \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Bishop, Christopher M. (2006): "Example: The univariate Gaussian"; in: \textit{Pattern Recognition for Machine Learning}, ch. 10.1.3, p. 470, eq. 10.21; URL: \url{http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D124 | shortcut: ug | author: JoramSoch | date: 2021-03-03, 07:21.
\vspace{1em}



\subsubsection[\textbf{Maximum likelihood estimation}]{Maximum likelihood estimation} \label{sec:ug-mle}
\setcounter{equation}{0}

\textbf{Theorem:} Let there be a univariate Gaussian data set ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:ug}) $y = \left\lbrace y_1, \ldots, y_n \right\rbrace$:

\begin{equation} \label{eq:ug-mle-ug}
y_i \sim \mathcal{N}(\mu, \sigma^2), \quad i = 1, \ldots, n \; .
\end{equation}

Then, the maximum likelihood estimates ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mle}) for mean $\mu$ and variance $\sigma^2$ are given by

\begin{equation} \label{eq:ug-mle-ug-MLE}
\begin{split}
\hat{\mu} &= \frac{1}{n} \sum_{i=1}^n y_i \\
\hat{\sigma}^2 &= \frac{1}{n} \sum_{i=1}^n (y_i - \bar{y})^2 \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Proof:} The likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) for each observation is given by the probability density function of the normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-pdf})

\begin{equation} \label{eq:ug-mle-ug-yi}
p(y_i|\mu,\sigma^2) = \mathcal{N}(x; \mu, \sigma^2) = \frac{1}{\sqrt{2 \pi \sigma^2}} \cdot \exp \left[ -\frac{1}{2} \left( \frac{y_i-\mu}{\sigma} \right)^2 \right]
\end{equation}

and because observations are independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}), the likelihood function for all observations is the product of the individual ones:

\begin{equation} \label{eq:ug-mle-ug-LF-s1}
p(y|\mu,\sigma^2) = \prod_{i=1}^n p(y_i|\mu) = \sqrt{ \frac{1}{(2 \pi \sigma^2)^n} } \cdot \exp \left[ -\frac{1}{2} \sum_{i=1}^{n} \left( \frac{y_i-\mu}{\sigma} \right)^2 \right] \; .
\end{equation}

This can be developed into

\begin{equation} \label{eq:ug-mle-ug-LF-s2}
\begin{split}
p(y|\mu,\sigma^2) &= \left( \frac{1}{2 \pi \sigma^2} \right)^{n/2} \cdot \exp \left[ -\frac{1}{2} \sum_{i=1}^{n} \left( \frac{y_i^2 - 2 y_i \mu + \mu^2}{\sigma^2} \right) \right] \\
&= \left( \frac{1}{2 \pi \sigma^2} \right)^{n/2} \cdot \exp \left[ -\frac{1}{2 \sigma^2} \left( y^\mathrm{T} y - 2 n \bar{y} \mu + n \mu^2 \right) \right]
\end{split}
\end{equation}

where $\bar{y} = \frac{1}{n} \sum_{i=1}^{n} y_i$ is the mean of data points and $y^\mathrm{T} y = \sum_{i=1}^{n} y_i^2$ is the sum of squared data points.

Thus, the log-likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:llf}) is

\begin{equation} \label{eq:ug-mle-ug-LL}
\mathrm{LL}(\mu,\sigma^2) = \log p(y|\mu,\sigma^2) = -\frac{n}{2} \log (2 \pi \sigma^2) - \frac{1}{2 \sigma^2} \left( y^\mathrm{T} y - 2 n \bar{y} \mu + n \mu^2 \right) \; .
\end{equation}

\vspace{1em}
The derivative of the log-likelihood function \eqref{eq:ug-mle-ug-LL} with respect to $\mu$ is

\begin{equation} \label{eq:ug-mle-dLL-dmu}
\frac{\mathrm{d}\mathrm{LL}(\mu,\sigma^2)}{\mathrm{d}\mu} = \frac{n \bar{y}}{\sigma^2} - \frac{n \mu}{\sigma^2} = \frac{n}{\sigma^2} (\bar{y}-\mu)
\end{equation}

and setting this derivative to zero gives the MLE for $\mu$:

\begin{equation} \label{eq:ug-mle-mu-MLE}
\begin{split}
\frac{\mathrm{d}\mathrm{LL}(\hat{\mu},\sigma^2)}{\mathrm{d}\mu} &= 0 \\
0 &= \frac{n}{\sigma^2} (\bar{y}-\hat{\mu}) \\
0 &= \bar{y}-\hat{\mu} \\
\hat{\mu} &= \bar{y} \\
\hat{\mu} &= \frac{1}{n} \sum_{i=1}^n y_i \; .
\end{split}
\end{equation}

\vspace{1em}
The derivative of the log-likelihood function \eqref{eq:ug-mle-ug-LL} at $\hat{\mu}$ with respect to $\sigma^2$ is

\begin{equation} \label{eq:ug-mle-dLL-ds2}
\begin{split}
\frac{\mathrm{d}\mathrm{LL}(\hat{\mu},\sigma^2)}{\mathrm{d}\sigma^2} &= -\frac{n}{2} \frac{1}{\sigma^2} + \frac{1}{2 (\sigma^2)^2} \left( y^\mathrm{T} y - 2 n \bar{y} \hat{\mu} + n \hat{\mu}^2 \right) \\
&= -\frac{n}{2 \sigma^2} + \frac{1}{2 (\sigma^2)^2} \sum_{i=1}^n \left( y_i^2 - 2 y_i \hat{\mu} + \hat{\mu}^2 \right) \\
&= -\frac{n}{2 \sigma^2} + \frac{1}{2 (\sigma^2)^2} \sum_{i=1}^n (y_i - \hat{\mu})^2
\end{split}
\end{equation}

and setting this derivative to zero gives the MLE for $\sigma^2$:

\begin{equation} \label{eq:ug-mle-s2-MLE}
\begin{split}
\frac{\mathrm{d}\mathrm{LL}(\hat{\mu},\hat{\sigma}^2)}{\mathrm{d}\sigma^2} &= 0 \\
0 &= \frac{1}{2 (\hat{\sigma}^2)^2} \sum_{i=1}^n (y_i - \hat{\mu})^2 \\
\frac{n}{2 \hat{\sigma}^2} &= \frac{1}{2 (\hat{\sigma}^2)^2} \sum_{i=1}^n (y_i - \hat{\mu})^2 \\
\frac{2 (\hat{\sigma}^2)^2}{n} \cdot \frac{n}{2 \hat{\sigma}^2} &= \frac{2 (\hat{\sigma}^2)^2}{n} \cdot \frac{1}{2 (\hat{\sigma}^2)^2} \sum_{i=1}^n (y_i - \hat{\mu})^2 \\
\hat{\sigma}^2 &= \frac{1}{n} \sum_{i=1}^n (y_i - \hat{\mu})^2 \\
\hat{\sigma}^2 &= \frac{1}{n} \sum_{i=1}^n (y_i - \bar{y})^2 \\
\end{split}
\end{equation}

\vspace{1em}
Together, \eqref{eq:ug-mle-mu-MLE} and \eqref{eq:ug-mle-s2-MLE} constitute the MLE for the univariate Gaussian.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Bishop CM (2006): "Bayesian inference for the Gaussian"; in: \textit{Pattern Recognition for Machine Learning}, pp. 93-94, eqs. 2.121, 2.122; URL: \url{http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P223 | shortcut: ug-mle | author: JoramSoch | date: 2021-04-16, 11:03.
\vspace{1em}



\subsubsection[\textbf{One-sample t-test}]{One-sample t-test} \label{sec:ug-ttest1}
\setcounter{equation}{0}

\textbf{Theorem:} Let

\begin{equation} \label{eq:ug-ttest1-ug}
y_i \sim \mathcal{N}(\mu, \sigma^2), \quad i = 1, \ldots, n
\end{equation}

be a univariate Gaussian data set ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:ug}) with unknown mean $\mu$ and unknown variance $\sigma^2$. Then, the test statistic ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:tstat})

\begin{equation} \label{eq:ug-ttest1-t}
t = \frac{\bar{y}-\mu_0}{s / \sqrt{n}}
\end{equation}

with sample mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean-samp}) $\bar{y}$ and sample variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var-samp}) $s^2$ follows a Student's t-distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:t}) with $n-1$ degrees of freedom ($\rightarrow$ Definition "dof")

\begin{equation} \label{eq:ug-ttest1-t-dist}
t \sim \mathrm{t}(n-1)
\end{equation}

under the null hypothesis ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:h0})

\begin{equation} \label{eq:ug-ttest1-ttest1-h0}
H_0: \; \mu = \mu_0 \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The sample mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean-samp}) is given by

\begin{equation} \label{eq:ug-ttest1-mean-samp}
\bar{y} = \frac{1}{n} \sum_{i=1}^{n} y_i
\end{equation}

and the sample variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var-samp}) is given by

\begin{equation} \label{eq:ug-ttest1-var-samp}
s^2 = \frac{1}{n-1} \sum_{i=1}^{n} (y_i - \bar{y})^2 \; .
\end{equation}

Using the linearity of the expected value ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-lin}), the additivity of the variance under independence ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:var-add}) and scaling of the variance upon multiplication ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:var-scal}), the sample mean follows a normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm})

\begin{equation} \label{eq:ug-ttest1-mean-samp-dist}
\bar{y} = \frac{1}{n} \sum_{i=1}^{n} y_i \sim \mathcal{N}\left( \frac{1}{n} n \mu, \left(\frac{1}{n}\right)^2 n \sigma^2 \right) = \mathcal{N}\left( \mu, \sigma^2/n \right)
\end{equation}

and additionally using the invariance of the variance under addition ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:var-inv}) and applying the null hypothesis from \eqref{eq:ug-ttest1-ttest1-h0}, the distribution of $Z = \sqrt{n}(\bar{y}-\mu_0)/\sigma$ becomes standard normal ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:snorm})

\begin{equation} \label{eq:ug-ttest1-Z-dist}
Z = \frac{\sqrt{n}(\bar{y}-\mu_0)}{\sigma} \sim \mathcal{N}\left( \frac{\sqrt{n}}{\sigma} (\mu - \mu_0), \left(\frac{\sqrt{n}}{\sigma}\right)^2 \frac{\sigma^2}{n} \right) \overset{H_0}{=} \mathcal{N}\left( 0, 1 \right) \; .
\end{equation}

Because sample variances calculated from independent normal random variables follow a chi-squared distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-chi2}), the distribution of $V = (n-1)\,s^2/\sigma^2$ is

\begin{equation} \label{eq:ug-ttest1-V-dist}
V = \frac{(n-1)\,s^2}{\sigma^2} \sim \chi^2\left(n-1\right) \; .
\end{equation}

Finally, since the ratio of a standard normal random variable and the square root of a chi-squared random variable follows a t-distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:t}), the distribution of the test statistic ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:tstat}) is given by

\begin{equation} \label{eq:ug-ttest1-t-dist-qed}
t = \frac{\bar{y}-\mu_0}{s / \sqrt{n}} = \frac{Z}{\sqrt{V / (n-1)}} \sim \mathrm{t}(n-1) \; .
\end{equation}

This means that the null hypothesis ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:h0}) can be rejected when $t$ is as extreme or more extreme than the critical value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cval}) obtained from the Student's t-distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:t}) with $n-1$ degrees of freedom ($\rightarrow$ Definition "dof") using a significance level ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:alpha}) $\alpha$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Student's t-distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-03-12; URL: \url{https://en.wikipedia.org/wiki/Student%27s_t-distribution#Derivation}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P204 | shortcut: ug-ttest1 | author: JoramSoch | date: 2021-03-12, 08:43.
\vspace{1em}



\subsubsection[\textbf{Two-sample t-test}]{Two-sample t-test} \label{sec:ug-ttest2}
\setcounter{equation}{0}

\textbf{Theorem:} Let

\begin{equation} \label{eq:ug-ttest2-ug}
\begin{split}
y_{1i} &\sim \mathcal{N}(\mu_1, \sigma^2), \quad i = 1, \ldots, n_1 \\
y_{2i} &\sim \mathcal{N}(\mu_2, \sigma^2), \quad i = 1, \ldots, n_2
\end{split}
\end{equation}

be a univariate Gaussian data set ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:ug}) representing two groups of unequal size $n_1$ and $n_2$ with unknown means $\mu_1$ and $\mu_2$ and equal unknown variance $\sigma^2$. Then, the test statistic ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:tstat})

\begin{equation} \label{eq:ug-ttest2-t}
t = \frac{(\bar{y}_1-\bar{y}_2)-\mu_\Delta}{s_p \cdot \sqrt{\frac{1}{n_1}+\frac{1}{n_2}}}
\end{equation}

with sample means ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean-samp}) $\bar{y}_1$ and $\bar{y}_2$ and pooled standard deviation ($\rightarrow$ Definition "std-pool") $s_p$ follows a Student's t-distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:t}) with $n_1+n_2-1$ degrees of freedom ($\rightarrow$ Definition "dof")

\begin{equation} \label{eq:ug-ttest2-t-dist}
t \sim \mathrm{t}(n_1+n_2-1)
\end{equation}

under the null hypothesis ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:h0})

\begin{equation} \label{eq:ug-ttest2-ttest2-h0}
H_0: \; \mu_1-\mu_2 = \mu_\Delta \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The sample means ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean-samp}) are given by

\begin{equation} \label{eq:ug-ttest2-mean-samp}
\begin{split}
\bar{y}_1 &= \frac{1}{n_1} \sum_{i=1}^{n_1} y_{1i} \\
\bar{y}_2 &= \frac{1}{n_2} \sum_{i=1}^{n_2} y_{2i}
\end{split}
\end{equation}

and the pooled standard deviation ($\rightarrow$ Definition "std-pool") is given by

\begin{equation} \label{eq:ug-ttest2-std-pool}
s_p = \sqrt{ \frac{(n_1-1) s^2_1 + (n_2-1) s^2_2}{n_1+n_2-2} }
\end{equation}

with the sample variances ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var-samp})

\begin{equation} \label{eq:ug-ttest2-var-samp}
\begin{split}
s^2_1 &= \frac{1}{n_1-1} \sum_{i=1}^{n_1} (y_{1i} - \bar{y}_1)^2 \\
s^2_2 &= \frac{1}{n_2-1} \sum_{i=1}^{n_2} (y_{2i} - \bar{y}_2)^2 \; .
\end{split}
\end{equation}

Using the linearity of the expected value ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-lin}), the additivity of the variance under independence ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:var-add}) and scaling of the variance upon multiplication ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:var-scal}), the sample means follow a normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm})

\begin{equation} \label{eq:ug-ttest2-mean-samp-dist}
\begin{split}
\bar{y}_1 &= \frac{1}{n_1} \sum_{i=1}^{n_1} y_{1i} \sim \mathcal{N}\left( \frac{1}{n_1} n_1 \mu_1, \left(\frac{1}{n_1}\right)^2 n_1 \sigma^2 \right) = \mathcal{N}\left( \mu_1, \sigma^2/n_1 \right) \\
\bar{y}_2 &= \frac{1}{n_2} \sum_{i=1}^{n_2} y_{2i} \sim \mathcal{N}\left( \frac{1}{n_2} n_2 \mu_2, \left(\frac{1}{n_2}\right)^2 n_2 \sigma^2 \right) = \mathcal{N}\left( \mu_2, \sigma^2/n_2 \right)
\end{split}
\end{equation}

and additionally using the invariance of the variance under addition ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:var-inv}) and applying the null hypothesis from \eqref{eq:ug-ttest2-ttest2-h0}, the distribution of $Z = ( ( \bar{y}_1 - \bar{y}_2 ) - \mu_{\Delta} ) / ( \sigma \sqrt{1/n_1+1/n_2} )$ becomes standard normal ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:snorm})

\begin{equation} \label{eq:ug-ttest2-Z-dist}
Z = \frac{(\bar{y}_1-\bar{y}_2)-\mu_\Delta}{\sigma \cdot \sqrt{\frac{1}{n_1}+\frac{1}{n_2}}} \sim \mathcal{N}\left( \frac{(\mu_1-\mu_2)-\mu_\Delta}{\sigma \cdot \sqrt{\frac{1}{n_1}+\frac{1}{n_2}}}, \left(\frac{1}{\sigma \cdot \sqrt{\frac{1}{n_1}+\frac{1}{n_2}}}\right)^2 \left( \frac{\sigma^2}{n_1} + \frac{\sigma^2}{n_2} \right) \right) \overset{H_0}{=} \mathcal{N}\left( 0, 1 \right) \; .
\end{equation}

Because sample variances calculated from independent normal random variables follow a chi-squared distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-chi2}), the distribution of $V = (n_1+n_2-2)\,s_p^2/\sigma^2$ is

\begin{equation} \label{eq:ug-ttest2-V-dist}
V = \frac{(n_1+n_2-1)\,s_p^2}{\sigma^2} \sim \chi^2\left(n_1+n_2-2\right) \; .
\end{equation}

Finally, since the ratio of a standard normal random variable and the square root of a chi-squared random variable follows a t-distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:t}), the distribution of the test statistic ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:tstat}) is given by

\begin{equation} \label{eq:ug-ttest2-t-dist-qed}
t = \frac{(\bar{y}_1-\bar{y}_2)-\mu_\Delta}{s_p \cdot \sqrt{\frac{1}{n_1}+\frac{1}{n_2}}} = \frac{Z}{\sqrt{V / (n_1+n_2-2)}} \sim \mathrm{t}(n_1+n_2-2) \; .
\end{equation}

This means that the null hypothesis ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:h0}) can be rejected when $t$ is as extreme or more extreme than the critical value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cval}) obtained from the Student's t-distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:t}) with $n_1+n_2-2$ degrees of freedom ($\rightarrow$ Definition "dof") using a significance level ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:alpha}) $\alpha$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Student's t-distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-03-12; URL: \url{https://en.wikipedia.org/wiki/Student%27s_t-distribution#Derivation}.
\item Wikipedia (2021): "Student's t-test"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-03-12; URL: \url{https://en.wikipedia.org/wiki/Student%27s_t-test#Equal_or_unequal_sample_sizes,_similar_variances_(1/2_%3C_sX1/sX2_%3C_2)}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P205 | shortcut: ug-ttest2 | author: JoramSoch | date: 2021-03-12, 09:20.
\vspace{1em}



\subsubsection[\textbf{Paired t-test}]{Paired t-test} \label{sec:ug-ttestp}
\setcounter{equation}{0}

\textbf{Theorem:} Let $y_{i1}$ and $y_{i2}$ with $i = 1, \ldots, n$ be paired observations, such that

\begin{equation} \label{eq:ug-ttestp-ug}
y_{i1} \sim \mathcal{N}(y_{i2} + \mu, \sigma^2), \quad i = 1, \ldots, n
\end{equation}

is a univariate Gaussian data set ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:ug}) with unknown shift $\mu$ and unknown variance $\sigma^2$. Then, the test statistic ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:tstat})

\begin{equation} \label{eq:ug-ttestp-t}
t = \frac{\bar{d}-\mu_0}{s_d / \sqrt{n}} \quad \text{where} \quad d_i = y_{i1} - y_{i2}
\end{equation}

with sample mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean-samp}) $\bar{d}$ and sample variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var-samp}) $s^2_d$ follows a Student's t-distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:t}) with $n-1$ degrees of freedom ($\rightarrow$ Definition "dof")

\begin{equation} \label{eq:ug-ttestp-t-dist}
t \sim \mathrm{t}(n-1)
\end{equation}

under the null hypothesis ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:h0})

\begin{equation} \label{eq:ug-ttestp-ttestp-h0}
H_0: \; \mu = \mu_0 \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} Define the pair-wise difference $d_i = y_{i1} - y_{i2}$ which is, according to the linearity of the expected value ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-lin}) and the invariance of the variance under addition ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:var-inv}), distributed as

\begin{equation} \label{eq:ug-ttestp-d-dist}
d_i = y_{i1} - y_{i2} \sim \mathcal{N}(\mu, \sigma^2), \quad i = 1, \ldots, n \; .
\end{equation}

Therefore, $d_1, \ldots, d_n$ satisfy the conditions of the one-sample t-test ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:ug-ttest1}) which results in the test statistic given by \eqref{eq:ug-ttestp-t}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Student's t-test"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-03-12; URL: \url{https://en.wikipedia.org/wiki/Student%27s_t-test#Dependent_t-test_for_paired_samples}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P206 | shortcut: ug-ttestp | author: JoramSoch | date: 2021-03-12, 09:34.
\vspace{1em}



\subsubsection[\textbf{Conjugate prior distribution}]{Conjugate prior distribution} \label{sec:ug-prior}
\setcounter{equation}{0}

\textbf{Theorem:} Let

\begin{equation} \label{eq:ug-prior-ug}
y = \left\lbrace y_1, \ldots, y_n \right\rbrace, \quad y_i \sim \mathcal{N}(\mu, \sigma^2), \quad i = 1, \ldots, n
\end{equation}

be a univariate Gaussian data set ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:ug}) with unknown mean $\mu$ and unknown variance $\sigma^2$. Then, the conjugate prior ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior-conj}) for this model is a normal-gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:ng})

\begin{equation} \label{eq:ug-prior-UG-NG-prior}
p(\mu,\tau) = \mathcal{N}(\mu; \mu_0, (\tau \lambda_0)^{-1}) \cdot \mathrm{Gam}(\tau; a_0, b_0)
\end{equation}

where $\tau = 1/\sigma^2$ is the inverse variance or precision.


\vspace{1em}
\textbf{Proof:} By definition, a conjugate prior ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior-conj}) is a prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) that, when combined with the likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}), leads to a posterior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) that belongs to the same family of probability distributions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist}). This is fulfilled when the prior density and the likelihood function are proportional to the model model parameters in the same way, i.e. the model parameters appear in the same functional form in both.

Equation \eqref{eq:ug-prior-ug} implies the following likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf})

\begin{equation} \label{eq:ug-prior-UG-LF-class}
\begin{split}
p(y|\mu,\sigma^2) &= \prod_{i=1}^{n} \mathcal{N}(y_i; \mu, \sigma^2) \\
&= \prod_{i=1}^{n} \frac{1}{\sqrt{2 \pi} \sigma} \cdot \exp\left[ -\frac{1}{2} \left( \frac{y_i-\mu}{\sigma} \right)^2 \right] \\
&= \frac{1}{(\sqrt{2 \pi \sigma^2})^n} \cdot \exp\left[ -\frac{1}{2 \sigma^2} \sum_{i=1}^{n} \left( y_i-\mu \right)^2 \right]
\end{split}
\end{equation}

which, for mathematical convenience, can also be parametrized as

\begin{equation} \label{eq:ug-prior-UG-LF-Bayes}
\begin{split}
p(y|\mu,\tau) &= \prod_{i=1}^{n} \mathcal{N}(y_i; \mu, \tau^{-1}) \\
&= \prod_{i=1}^{n} \sqrt{\frac{\tau}{2 \pi}} \cdot \exp\left[ -\frac{\tau}{2} \left( y_i-\mu \right)^2 \right] \\
&= \left( \sqrt{\frac{\tau}{2 \pi}} \right)^n \cdot \exp\left[ -\frac{\tau}{2} \sum_{i=1}^{n} \left( y_i-\mu \right)^2 \right]
\end{split}
\end{equation}

using the inverse variance or precision $\tau = 1/\sigma^2$.

\vspace{1em}
Seperating constant and variable terms, we have:

\begin{equation} \label{eq:ug-prior-UG-LF-s1}
p(y|\mu,\tau) = \sqrt{\frac{1}{(2 \pi)^n}} \cdot \tau^{n/2} \cdot \exp\left[ -\frac{\tau}{2} \sum_{i=1}^{n} \left( y_i-\mu \right)^2 \right] \; .
\end{equation}

Expanding the product in the exponent, we have

\begin{equation} \label{eq:ug-prior-UG-LF-s2}
\begin{split}
p(y|\mu,\tau) &= \sqrt{\frac{1}{(2 \pi)^n}} \cdot \tau^{n/2} \cdot \exp\left[ -\frac{\tau}{2} \sum_{i=1}^{n} \left( y_i^2 - 2 \mu y_i + \mu^2 \right) \right] \\
&= \sqrt{\frac{1}{(2 \pi)^n}} \cdot \tau^{n/2} \cdot \exp\left[ -\frac{\tau}{2} \left( \sum_{i=1}^{n} y_i^2 - 2 \mu \sum_{i=1}^{n} y_i + n \mu^2 \right) \right] \\
&= \sqrt{\frac{1}{(2 \pi)^n}} \cdot \tau^{n/2} \cdot \exp\left[ -\frac{\tau}{2} \left( y^\mathrm{T} y - 2 \mu n \bar{y} + n \mu^2 \right) \right] \\
&= \sqrt{\frac{1}{(2 \pi)^n}} \cdot \tau^{n/2} \cdot \exp\left[ -\frac{\tau n}{2} \left( \frac{1}{n} y^\mathrm{T} y - 2 \mu \bar{y} + \mu^2 \right) \right]
\end{split}
\end{equation}

where $\bar{y} = \frac{1}{n} \sum_{i=1}^{n} y_i$ is the mean of data points and $y^\mathrm{T} y = \sum_{i=1}^{n} y_i^2$ is the sum of squared data points.

Completing the square over $\mu$, finally gives

\begin{equation} \label{eq:ug-prior-UG-LF-s3}
p(y|\mu,\tau) = \sqrt{\frac{1}{(2 \pi)^n}} \cdot \tau^{n/2} \cdot \exp\left[ -\frac{\tau n}{2} \left( (\mu-\bar{y})^2 - \bar{y}^2 + \frac{1}{n} y^\mathrm{T} y \right) \right]
\end{equation}

\vspace{1em}
In other words, the likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) is proportional to a power of $\tau$ times an exponential of $\tau$ and an exponential of a squared form of $\mu$, weighted by $\tau$:

\begin{equation} \label{eq:ug-prior-UG-LF-s4}
p(y|\mu,\tau) \propto \tau^{n/2} \cdot \exp\left[ -\frac{\tau}{2} \left( y^\mathrm{T} y - n \bar{y}^2 \right) \right] \cdot \exp\left[ -\frac{\tau n}{2} \left( \mu-\bar{y} \right)^2 \right] \; .
\end{equation}

The same is true for a normal-gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:ng}) over $\mu$ and $\tau$

\begin{equation} \label{eq:ug-prior-UG-prior-s1}
p(\mu,\tau) = \mathcal{N}(\mu; \mu_0, (\tau \lambda_0)^{-1}) \cdot \mathrm{Gam}(\tau; a_0, b_0)
\end{equation}

the probability density function of which ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:ng-pdf})

\begin{equation} \label{eq:ug-prior-UG-prior-s2}
p(\mu,\tau) = \sqrt{\frac{\tau \lambda_0}{2 \pi}} \cdot \exp\left[ -\frac{\tau \lambda_0}{2} \left( \mu-\mu_0 \right)^2 \right] \cdot \frac{ {b_0}^{a_0} }{\Gamma(a_0)} \, \tau^{a_0-1} \exp[-b_0 \tau]
\end{equation}

exhibits the same proportionality

\begin{equation} \label{eq:ug-prior-UG-prior-s3}
p(\mu,\tau) \propto \tau^{a_0+1/2-1} \cdot \exp[-\tau b_0] \cdot \exp\left[ -\frac{\tau \lambda_0}{2} \left( \mu-\mu_0 \right)^2 \right]
\end{equation}

and is therefore conjugate relative to the likelihood.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Bishop CM (2006): "Bayesian inference for the Gaussian"; in: \textit{Pattern Recognition for Machine Learning}, pp. 97-102, eq. 2.154; URL: \url{http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P201 | shortcut: ug-prior | author: JoramSoch | date: 2021-03-03, 08:54.
\vspace{1em}



\subsubsection[\textbf{Posterior distribution}]{Posterior distribution} \label{sec:ug-post}
\setcounter{equation}{0}

\textbf{Theorem:} Let

\begin{equation} \label{eq:ug-post-ug}
y = \left\lbrace y_1, \ldots, y_n \right\rbrace, \quad y_i \sim \mathcal{N}(\mu, \sigma^2), \quad i = 1, \ldots, n
\end{equation}

be a univariate Gaussian data set ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:ug}) with unknown mean $\mu$ and unknown variance $\sigma^2$. Moreover, assume a normal-gamma prior distribution ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:ug-prior}) over the model parameters $\mu$ and $\tau = 1/\sigma^2$:

\begin{equation} \label{eq:ug-post-UG-NG-prior}
p(\mu,\tau) = \mathcal{N}(\mu; \mu_0, (\tau \lambda_0)^{-1}) \cdot \mathrm{Gam}(\tau; a_0, b_0) \; .
\end{equation}

Then, the posterior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) is also a normal-gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:ng})

\begin{equation} \label{eq:ug-post-UG-NG-post}
p(\mu,\tau|y) = \mathcal{N}(\mu; \mu_n, (\tau \lambda_n)^{-1}) \cdot \mathrm{Gam}(\tau; a_n, b_n)
\end{equation}

and the posterior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) are given by

\begin{equation} \label{eq:ug-post-UG-NG-post-par}
\begin{split}
\mu_n &= \frac{\lambda_0 \mu_0 + n \bar{y}}{\lambda_0 + n} \\
\lambda_n &= \lambda_0 + n \\
a_n &= a_0 + \frac{n}{2} \\
b_n &= b_0 + \frac{1}{2} (y^\mathrm{T} y + \lambda_0 \mu_0^2 - \lambda_n \mu_n^2) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Proof:} According to Bayes' theorem ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:bayes-th}), the posterior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) is given by

\begin{equation} \label{eq:ug-post-UG-NG-BT}
p(\mu,\tau|y) = \frac{p(y|\mu,\tau) \, p(\mu,\tau)}{p(y)} \; .
\end{equation}

Since $p(y)$ is just a normalization factor, the posterior is proportional ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:post-jl}) to the numerator:

\begin{equation} \label{eq:ug-post-UG-NG-post-JL}
p(\mu,\tau|y) \propto p(y|\mu,\tau) \, p(\mu,\tau) = p(y,\mu,\tau) \; .
\end{equation}

Equation \eqref{eq:ug-post-ug} implies the following likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf})

\begin{equation} \label{eq:ug-post-UG-LF-class}
\begin{split}
p(y|\mu,\sigma^2) &= \prod_{i=1}^{n} \mathcal{N}(y_i; \mu, \sigma^2) \\
&= \prod_{i=1}^{n} \frac{1}{\sqrt{2 \pi} \sigma} \cdot \exp\left[ -\frac{1}{2} \left( \frac{y_i-\mu}{\sigma} \right)^2 \right] \\
&= \frac{1}{(\sqrt{2 \pi \sigma^2})^n} \cdot \exp\left[ -\frac{1}{2 \sigma^2} \sum_{i=1}^{n} \left( y_i-\mu \right)^2 \right]
\end{split}
\end{equation}

which, for mathematical convenience, can also be parametrized as

\begin{equation} \label{eq:ug-post-UG-LF-Bayes}
\begin{split}
p(y|\mu,\tau) &= \prod_{i=1}^{n} \mathcal{N}(y_i; \mu, \tau^{-1}) \\
&= \prod_{i=1}^{n} \sqrt{\frac{\tau}{2 \pi}} \cdot \exp\left[ -\frac{\tau}{2} \left( y_i-\mu \right)^2 \right] \\
&= \left( \sqrt{\frac{\tau}{2 \pi}} \right)^n \cdot \exp\left[ -\frac{\tau}{2} \sum_{i=1}^{n} \left( y_i-\mu \right)^2 \right]
\end{split}
\end{equation}

using the inverse variance or precision $\tau = 1/\sigma^2$.

\vspace{1em}
Combining the likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) \eqref{eq:ug-post-UG-LF-Bayes} with the prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) \eqref{eq:ug-post-UG-NG-prior}, the joint likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:jl}) of the model is given by

\begin{equation} \label{eq:ug-post-UG-NG-JL-s1}
\begin{split}
p(y,\mu,\tau) = \; & p(y|\mu,\tau) \, p(\mu,\tau) \\
= \; & \left( \sqrt{\frac{\tau}{2 \pi}} \right)^n \cdot \exp\left[ -\frac{\tau}{2} \sum_{i=1}^{n} \left( y_i-\mu \right)^2 \right] \cdot \\
& \sqrt{\frac{\tau \lambda_0}{2 \pi}} \cdot \exp\left[ -\frac{\tau \lambda_0}{2} \left( \mu-\mu_0 \right)^2 \right] \cdot \\
& \frac{ {b_0}^{a_0} }{\Gamma(a_0)} \, \tau^{a_0-1} \exp[-b_0 \tau] \; .
\end{split}
\end{equation}

Collecting identical variables gives:

\begin{equation} \label{eq:ug-post-UG-NG-JL-s2}
\begin{split}
p(y,\mu,\tau) = \; & \sqrt{\frac{\tau^{n+1} \lambda_0}{(2 \pi)^{n+1}}} \, \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \, \tau^{a_0-1} \exp[-b_0 \tau] \cdot \\
& \exp\left[ -\frac{\tau}{2} \left( \sum_{i=1}^{n} \left( y_i-\mu \right)^2 + \lambda_0 \left( \mu-\mu_0 \right)^2 \right) \right] \; .
\end{split}
\end{equation}

Expanding the products in the exponent ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:ug-prior}) gives

\begin{equation} \label{eq:ug-post-UG-NG-JL-s3}
\begin{split}
p(y,\mu,\tau) = \; & \sqrt{\frac{\tau^{n+1} \lambda_0}{(2 \pi)^{n+1}}} \, \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \, \tau^{a_0-1} \exp[-b_0 \tau] \cdot \\
& \exp\left[ -\frac{\tau}{2} \left( (y^\mathrm{T} y - 2 \mu n \bar{y} + n \mu^2) + \lambda_0 (\mu^2 - 2 \mu \mu_0 + \mu_0^2) \right) \right]
\end{split}
\end{equation}

where $\bar{y} = \frac{1}{n} \sum_{i=1}^{n} y_i$ and $y^\mathrm{T} y = \sum_{i=1}^{n} y_i^2$, such that

\begin{equation} \label{eq:ug-post-UG-NG-JL-s4}
\begin{split}
p(y,\mu,\tau) = \; & \sqrt{\frac{\tau^{n+1} \lambda_0}{(2 \pi)^{n+1}}} \, \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \, \tau^{a_0-1} \exp[-b_0 \tau] \cdot \\
& \exp\left[ -\frac{\tau}{2} \left( \mu^2 (\lambda_0 + n) - 2 \mu (\lambda_0 \mu_0 + n \bar{y}) + (y^\mathrm{T} y + \lambda_0 \mu_0^2) \right) \right]
\end{split}
\end{equation}

Completing the square over $\mu$, we finally have

\begin{equation} \label{eq:ug-post-UG-NG-JL-s5}
\begin{split}
p(y,\mu,\tau) = \; & \sqrt{\frac{\tau^{n+1} \lambda_0}{(2 \pi)^{n+1}}} \, \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \, \tau^{a_0-1} \exp[-b_0 \tau] \cdot \\
& \exp\left[ -\frac{\tau \lambda_n}{2} \left( \mu - \mu_n \right)^2 -\frac{\tau}{2} \left( y^\mathrm{T} y + \lambda_0 \mu_0^2 - \lambda_n \mu_n^2 \right) \right]
\end{split}
\end{equation}

with the posterior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post})

\begin{equation} \label{eq:ug-post-UG-NG-post-mu-par}
\begin{split}
\mu_n &= \frac{\lambda_0 \mu_0 + n \bar{y}}{\lambda_0 + n} \\
\lambda_n &= \lambda_0 + n \; .
\end{split}
\end{equation}

Ergo, the joint likelihood is proportional to

\begin{equation} \label{eq:ug-post-UG-NG-JL-s6}
p(y,\mu,\tau) \propto \tau^{1/2} \cdot \exp\left[ -\frac{\tau \lambda_n}{2} \left( \mu - \mu_n \right)^2 \right] \cdot \tau^{a_n-1} \cdot \exp\left[ -b_n \tau \right]
\end{equation}

with the posterior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post})

\begin{equation} \label{eq:ug-post-UG-NG-post-tau-par}
\begin{split}
a_n &= a_0 + \frac{n}{2} \\
b_n &= b_0 + \frac{1}{2} \left( y^\mathrm{T} y + \lambda_0 \mu_0^2 - \lambda_n \mu_n^2 \right) \; .
\end{split}
\end{equation}

From the term in \eqref{eq:ug-post-UG-NG-JL-s5}, we can isolate the posterior distribution over $\mu$ given $\tau$:

\begin{equation} \label{eq:ug-post-UG-NG-post-mu}
p(\mu|\tau,y) = \mathcal{N}(\mu; \mu_n, (\tau \lambda_n)^{-1}) \; .
\end{equation}

From the remaining term, we can isolate the posterior distribution over $\tau$:

\begin{equation} \label{eq:ug-post-UG-NG-post-tau}
p(\tau|y) = \mathrm{Gam}(\tau; a_n, b_n) \; .
\end{equation}

Together, \eqref{eq:ug-post-UG-NG-post-mu} and \eqref{eq:ug-post-UG-NG-post-tau} constitute the joint ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) posterior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) of $\mu$ and $\tau$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Bishop CM (2006): "Bayesian inference for the Gaussian"; in: \textit{Pattern Recognition for Machine Learning}, pp. 97-102, eq. 2.154; URL: \url{http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P202 | shortcut: ug-post | author: JoramSoch | date: 2021-03-03, 09:53.
\vspace{1em}



\subsubsection[\textbf{Log model evidence}]{Log model evidence} \label{sec:ug-lme}
\setcounter{equation}{0}

\textbf{Theorem:} Let

\begin{equation} \label{eq:ug-lme-ug}
m: \; y = \left\lbrace y_1, \ldots, y_n \right\rbrace, \quad y_i \sim \mathcal{N}(\mu, \sigma^2), \quad i = 1, \ldots, n
\end{equation}

be a univariate Gaussian data set ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:ug}) with unknown mean $\mu$ and unknown variance $\sigma^2$. Moreover, assume a normal-gamma prior distribution ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:ug-prior}) over the model parameters $\mu$ and $\tau = 1/\sigma^2$:

\begin{equation} \label{eq:ug-lme-UG-NG-prior}
p(\mu,\tau) = \mathcal{N}(\mu; \mu_0, (\tau \lambda_0)^{-1}) \cdot \mathrm{Gam}(\tau; a_0, b_0) \; .
\end{equation}

Then, the log model evidence ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme}) for this model is

\begin{equation} \label{eq:ug-lme-UG-NG-LME}
\log p(y|m) = - \frac{n}{2} \log (2 \pi)  + \frac{1}{2} \log \frac{\lambda_0}{\lambda_n} + \log \Gamma(a_n) - \log \Gamma(a_0) + a_0 \log b_0 - a_n \log b_n
\end{equation}

where the posterior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) are given by

\begin{equation} \label{eq:ug-lme-UG-NG-post-par}
\begin{split}
\mu_n &= \frac{\lambda_0 \mu_0 + n \bar{y}}{\lambda_0 + n} \\
\lambda_n &= \lambda_0 + n \\
a_n &= a_0 + \frac{n}{2} \\
b_n &= b_0 + \frac{1}{2} (y^\mathrm{T} y + \lambda_0 \mu_0^2 - \lambda_n \mu_n^2) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Proof:} According to the law of marginal probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}), the model evidence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ml}) for this model is:

\begin{equation} \label{eq:ug-lme-UG-NG-ME-s1}
p(y|m) = \iint p(y|\mu,\tau) \, p(\mu,\tau) \, \mathrm{d}\mu \, \mathrm{d}\tau \; .
\end{equation}

According to the law of conditional probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-cond}), the integrand is equivalent to the joint likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:jl}):

\begin{equation} \label{eq:ug-lme-UG-NG-ME-s2}
p(y|m) = \iint p(y,\mu,\tau) \, \mathrm{d}\mu \, \mathrm{d}\tau \; .
\end{equation}

Equation \eqref{eq:ug-lme-ug} implies the following likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf})

\begin{equation} \label{eq:ug-lme-UG-LF-class}
\begin{split}
p(y|\mu,\sigma^2) &= \prod_{i=1}^{n} \mathcal{N}(y_i; \mu, \sigma^2) \\
&= \prod_{i=1}^{n} \frac{1}{\sqrt{2 \pi} \sigma} \cdot \exp\left[ -\frac{1}{2} \left( \frac{y_i-\mu}{\sigma} \right)^2 \right] \\
&= \frac{1}{(\sqrt{2 \pi \sigma^2})^n} \cdot \exp\left[ -\frac{1}{2 \sigma^2} \sum_{i=1}^{n} \left( y_i-\mu \right)^2 \right]
\end{split}
\end{equation}

which, for mathematical convenience, can also be parametrized as

\begin{equation} \label{eq:ug-lme-UG-LF-Bayes}
\begin{split}
p(y|\mu,\tau) &= \prod_{i=1}^{n} \mathcal{N}(y_i; \mu, \tau^{-1}) \\
&= \prod_{i=1}^{n} \sqrt{\frac{\tau}{2 \pi}} \cdot \exp\left[ -\frac{\tau}{2} \left( y_i-\mu \right)^2 \right] \\
&= \left( \sqrt{\frac{\tau}{2 \pi}} \right)^n \cdot \exp\left[ -\frac{\tau}{2} \sum_{i=1}^{n} \left( y_i-\mu \right)^2 \right]
\end{split}
\end{equation}

using the inverse variance or precision $\tau = 1/\sigma^2$.

\vspace{1em}
When deriving the posterior distribution ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:ug-post}) $p(\mu,\tau|y)$, the joint likelihood $p(y,\mu,\tau)$ is obtained as

\begin{equation} \label{eq:ug-lme-UG-NG-LME-s1}
\begin{split}
p(y,\mu,\tau) = \; & \sqrt{\frac{\tau^{n+1} \lambda_0}{(2 \pi)^{n+1}}} \, \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \, \tau^{a_0-1} \exp[-b_0 \tau] \cdot \\
& \exp\left[ -\frac{\tau \lambda_n}{2} \left( \mu - \mu_n \right)^2 -\frac{\tau}{2} \left( y^\mathrm{T} y + \lambda_0 \mu_0^2 - \lambda_n \mu_n^2 \right) \right] \; .
\end{split}
\end{equation}

Using the probability density function of the normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-pdf}), we can rewrite this as

\begin{equation} \label{eq:ug-lme-UG-NG-LME-s2}
\begin{split}
p(y,\mu,\tau) = \; & \sqrt{\frac{\tau^{n}}{(2 \pi)^{n}}} \sqrt{\frac{\tau \lambda_0}{2 \pi}} \sqrt{\frac{2 \pi}{\tau \lambda_n}} \, \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \, \tau^{a_0-1} \exp[-b_0 \tau] \cdot \\
& \mathcal{N}(\mu; \mu_n, (\tau \lambda_n)^{-1}) \, \exp\left[ -\frac{\tau}{2} \left( y^\mathrm{T} y + \lambda_0 \mu_0^2 - \lambda_n \mu_n^2 \right) \right] \; .
\end{split}
\end{equation}

Now, $\mu$ can be integrated out easily:

\begin{equation} \label{eq:ug-lme-UG-NG-LME-s3}
\begin{split}
\int p(y,\mu,\tau) \, \mathrm{d}\mu = \; & \sqrt{\frac{1}{(2 \pi)^{n}}} \sqrt{\frac{\lambda_0}{\lambda_n}} \, \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \, \tau^{a_0+n/2-1} \exp[-b_0 \tau] \cdot \\
& \exp\left[ -\frac{\tau}{2} \left( y^\mathrm{T} y + \lambda_0 \mu_0^2 - \lambda_n \mu_n^2 \right) \right] \; .
\end{split}
\end{equation}

Using the probability density function of the gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-pdf}), we can rewrite this as

\begin{equation} \label{eq:ug-lme-UG-NG-LME-s4}
\int p(y,\mu,\tau) \, \mathrm{d}\mu = \sqrt{\frac{1}{(2 \pi)^{n}}} \sqrt{\frac{\lambda_0}{\lambda_n}} \, \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \, \frac{\Gamma(a_n)}{ {b_n}^{a_n}} \, \mathrm{Gam}(\tau; a_n, b_n) \; .
\end{equation}

Finally, $\tau$ can also be integrated out:

\begin{equation} \label{eq:ug-lme-UG-NG-LME-s5}
\iint p(y,\mu,\tau) \, \mathrm{d}\mu \, \mathrm{d}\tau = \sqrt{\frac{1}{(2 \pi)^{n}}} \sqrt{\frac{\lambda_0}{\lambda_n}} \, \frac{\Gamma(a_n)}{\Gamma(a_0)} \, \frac{ {b_0}^{a_0}}{ {b_n}^{a_n}} \; .
\end{equation}

Thus, the log model evidence ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme}) of this model is given by

\begin{equation} \label{eq:ug-lme-UG-NG-LME-s6}
\log p(y|m) = - \frac{n}{2} \log (2 \pi)  + \frac{1}{2} \log \frac{\lambda_0}{\lambda_n} + \log \Gamma(a_n) - \log \Gamma(a_0) + a_0 \log b_0 - a_n \log b_n \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Bishop CM (2006): "Bayesian linear regression"; in: \textit{Pattern Recognition for Machine Learning}, pp. 152-161, ex. 3.23, eq. 3.118; URL: \url{http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P203 | shortcut: ug-lme | author: JoramSoch | date: 2021-03-03, 10:25.
\vspace{1em}



\subsubsection[\textbf{Accuracy and complexity}]{Accuracy and complexity} \label{sec:ug-anc}
\setcounter{equation}{0}

\textbf{Theorem:} Let

\begin{equation} \label{eq:ug-anc-ug}
m: \; y = \left\lbrace y_1, \ldots, y_n \right\rbrace, \quad y_i \sim \mathcal{N}(\mu, \sigma^2), \quad i = 1, \ldots, n
\end{equation}

be a univariate Gaussian data set ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:ug}) with unknown mean $\mu$ and unknown variance $\sigma^2$. Moreover, assume a normal-gamma prior distribution ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:ug-prior}) over the model parameters $\mu$ and $\tau = 1/\sigma^2$:

\begin{equation} \label{eq:ug-anc-UG-NG-prior}
p(\mu,\tau) = \mathcal{N}(\mu; \mu_0, (\tau \lambda_0)^{-1}) \cdot \mathrm{Gam}(\tau; a_0, b_0) \; .
\end{equation}

Then, accuracy and complexity ($\rightarrow$ Proof \ref{sec:Model Selection}/\ref{sec:lme-anc}) of this model are

\begin{equation} \label{eq:ug-anc-UG-NG-AnC}
\begin{split}
\mathrm{Acc}(m) &= - \frac{1}{2} \frac{a_n}{b_n} \left( y^\mathrm{T} y - 2 n \bar{y} \mu_n + n \mu_n^2 \right) - \frac{1}{2} n \lambda_n^{-1} + \frac{n}{2} \left(\psi(a_n) - \log(b_n)\right) - \frac{n}{2} \log (2 \pi) \\
\mathrm{Com}(m) &= \frac{1}{2} \frac{a_n}{b_n} \left[ \lambda_0 (\mu_0 - \mu_n)^2 - 2 (b_n - b_0) \right] + \frac{1}{2} \frac{\lambda_0}{\lambda_n} - \frac{1}{2} \log \frac{\lambda_0}{\lambda_n} - \frac{1}{2} \\
&+ a_0 \cdot \log \frac{b_n}{b_0} - \log \frac{\Gamma(a_n)}{\Gamma(a_0)} + (a_n - a_0) \cdot \psi(a_n)
\end{split}
\end{equation}

where $\mu_n$ and $\lambda_n$ as well as $a_n$ and $b_n$ are the posterior hyperparameters for the univariate Gaussian ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:ug-post}) and $\bar{y}$ is the sample mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean-samp}).


\vspace{1em}
\textbf{Proof:} Model accuracy and complexity are defined as ($\rightarrow$ Proof \ref{sec:Model Selection}/\ref{sec:lme-anc})

\begin{equation} \label{eq:ug-anc-lme-anc}
\begin{split}
\mathrm{LME}(m) &= \mathrm{Acc}(m) - \mathrm{Com}(m) \\
\mathrm{Acc}(m) &= \left\langle \log p(y|\mu,m) \right\rangle_{p(\mu|y,m)} \\
\mathrm{Com}(m) &= \mathrm{KL} \left[ p(\mu|y,m) \, || \, p(\mu|m) \right] \; .
\end{split}
\end{equation}

\vspace{1em}
The accuracy term is the expectation ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of the log-likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:llf}) $\log p(y|\mu,\tau)$ with respect to the posterior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) $p(\mu,\tau|y)$. With the log-likelihood function for the univariate Gaussian ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:ug-mle}) and the posterior distribution for the univariate Gaussian ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:ug-post}), the model accuracy of $m$ evaluates to:

\begin{equation} \label{eq:ug-anc-UG-NG-Acc}
\begin{split}
\mathrm{Acc}(m) &= \left\langle \log p(y|\mu,\tau) \right\rangle_{p(\mu,\tau|y)} \\
&= \left\langle \left\langle \log p(y|\mu,\tau) \right\rangle_{p(\mu|\tau,y)} \right\rangle_{p(\tau|y)} \\
&= \left\langle \left\langle \frac{n}{2} \log (\tau) - \frac{n}{2} \log (2 \pi) - \frac{\tau}{2} \left( y^\mathrm{T} y - 2 n \bar{y} \mu + n \mu^2 \right) \right\rangle_{\mathcal{N}(\mu_n, (\tau \lambda_n)^{-1})} \right\rangle_{\mathrm{Gam}(a_n, b_n)} \\
&= \left\langle \frac{n}{2} \log (\tau) - \frac{n}{2} \log (2 \pi) - \frac{\tau}{2} \left( y^\mathrm{T} y - 2 n \bar{y} \mu_n + n \mu_n^2 \right) - \frac{1}{2} n \lambda_n^{-1} \right\rangle_{\mathrm{Gam}(a_n, b_n)} \\
&= \frac{n}{2} \left(\psi(a_n) - \log(b_n)\right) - \frac{n}{2} \log (2 \pi) - \frac{1}{2} \frac{a_n}{b_n} \left( y^\mathrm{T} y - 2 n \bar{y} \mu_n + n \mu_n^2 \right) - \frac{1}{2} n \lambda_n^{-1} \\
&= - \frac{1}{2} \frac{a_n}{b_n} \left( y^\mathrm{T} y - 2 n \bar{y} \mu_n + n \mu_n^2 \right) - \frac{1}{2} n \lambda_n^{-1} + \frac{n}{2} \left(\psi(a_n) - \log(b_n)\right) - \frac{n}{2} \log (2 \pi) \\
\end{split}
\end{equation}

\vspace{1em}
The complexity penalty is the Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) of the posterior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) $p(\mu,\tau|y)$ from the prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) $p(\mu,\tau)$. With the prior distribution ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:ug-prior}) given by \eqref{eq:ug-anc-UG-NG-prior}, the posterior distribution for the univariate Gaussian ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:ug-post}) and the Kullback-Leibler divergence of the normal-gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:ng-kl}), the model complexity of $m$ evaluates to:

\begin{equation} \label{eq:ug-anc-UG-NG-Com}
\begin{split}
\mathrm{Com}(m) &= \mathrm{KL} \left[ p(\mu,\tau|y) \, || \, p(\mu,\tau) \right] \\
&= \mathrm{KL} \left[ \mathrm{NG}(\mu_n, \lambda_n^{-1}, a_n, b_n) \, || \,  \mathrm{NG}(\mu_0, \lambda_0^{-1}, a_0, b_0) \right] \\
&= \frac{1}{2} \frac{a_n}{b_n} \left[ \lambda_0 (\mu_0 - \mu_n)^2 \right] + \frac{1}{2} \frac{\lambda_0}{\lambda_n} - \frac{1}{2} \log \frac{\lambda_0}{\lambda_n} - \frac{1}{2} \\
&+ a_0 \cdot \log \frac{b_n}{b_0} - \log \frac{\Gamma(a_n)}{\Gamma(a_0)} + (a_n - a_0) \cdot \psi(a_n) - (b_n - b_0) \cdot \frac{a_n}{b_n} \\
&= \frac{1}{2} \frac{a_n}{b_n} \left[ \lambda_0 (\mu_0 - \mu_n)^2 - 2 (b_n - b_0) \right] + \frac{1}{2} \frac{\lambda_0}{\lambda_n} - \frac{1}{2} \log \frac{\lambda_0}{\lambda_n} - \frac{1}{2} \\
&+ a_0 \cdot \log \frac{b_n}{b_0} - \log \frac{\Gamma(a_n)}{\Gamma(a_0)} + (a_n - a_0) \cdot \psi(a_n) \; .
\end{split}
\end{equation}

A control calculation confirms that

\begin{equation} \label{eq:ug-anc-UG-NG-AnC-LME}
\mathrm{Acc}(m) - \mathrm{Com}(m) = \mathrm{LME}(m)
\end{equation}

where $\mathrm{LME}(m)$ is the log model evidence for the univariate Gaussian ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:ug-lme}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P240 | shortcut: ug-anc | author: JoramSoch | date: 2021-07-14, 08:26.
\vspace{1em}



\subsection{Univariate Gaussian with known variance}

\subsubsection[\textit{Definition}]{Definition} \label{sec:ugkv}
\setcounter{equation}{0}

\textbf{Definition:} A univariate Gaussian data set with known variance is given by a set of real numbers $y = \left\lbrace y_1, \ldots, y_n \right\rbrace$, independent and identically distributed according to a normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}) with unknown mean $\mu$ and known variance $\sigma^2$:

\begin{equation} \label{eq:ugkv-ug}
y_i \sim \mathcal{N}(\mu, \sigma^2), \quad i = 1, \ldots, n \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Bishop, Christopher M. (2006): "Bayesian inference for the Gaussian"; in: \textit{Pattern Recognition for Machine Learning}, ch. 2.3.6, p. 97, eq. 2.137; URL: \url{http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D136 | shortcut: ugkv | author: JoramSoch | date: 2021-03-23, 16:12.
\vspace{1em}



\subsubsection[\textbf{Maximum likelihood estimation}]{Maximum likelihood estimation} \label{sec:ugkv-mle}
\setcounter{equation}{0}

\textbf{Theorem:} Let there be univariate Gaussian data with known variance ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:ugkv}) $y = \left\lbrace y_1, \ldots, y_n \right\rbrace$:

\begin{equation} \label{eq:ugkv-mle-ugkv}
y_i \sim \mathcal{N}(\mu, \sigma^2), \quad i = 1, \ldots, n \; .
\end{equation}

Then, the maximum likelihood estimate ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mle}) for the mean $\mu$ is given by

\begin{equation} \label{eq:ugkv-mle-ugkv-MLE}
\hat{\mu} = \bar{y}
\end{equation}

where $\bar{y}$ is the sample mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean-samp})

\begin{equation} \label{eq:ugkv-mle-y-mean}
\bar{y} = \frac{1}{n} \sum_{i=1}^n y_i \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) for each observation is given by the probability density function of the normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-pdf})

\begin{equation} \label{eq:ugkv-mle-ugkv-yi}
p(y_i|\mu) = \mathcal{N}(x; \mu, \sigma^2) = \frac{1}{\sqrt{2 \pi \sigma^2}} \cdot \exp \left[ -\frac{1}{2} \left( \frac{y_i-\mu}{\sigma} \right)^2 \right]
\end{equation}

and because observations are independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}), the likelihood function for all observations is the product of the individual ones:

\begin{equation} \label{eq:ugkv-mle-ugkv-LF-s1}
p(y|\mu) = \prod_{i=1}^n p(y_i|\mu) = \sqrt{ \frac{1}{(2 \pi \sigma^2)^n} } \cdot \exp \left[ -\frac{1}{2} \sum_{i=1}^{n} \left( \frac{y_i-\mu}{\sigma} \right)^2 \right] \; .
\end{equation}

This can be developed into

\begin{equation} \label{eq:ugkv-mle-ugkv-LF-s2}
\begin{split}
p(y|\mu) &= \left( \frac{1}{2 \pi \sigma^2} \right)^{n/2} \cdot \exp \left[ -\frac{1}{2} \sum_{i=1}^{n} \left( \frac{y_i^2 - 2 y_i \mu + \mu^2}{\sigma^2} \right) \right] \\
&= \left( \frac{1}{2 \pi \sigma^2} \right)^{n/2} \cdot \exp \left[ -\frac{1}{2 \sigma^2} \left( y^\mathrm{T} y - 2 n \bar{y} \mu + n \mu^2 \right) \right]
\end{split}
\end{equation}

where $\bar{y} = \frac{1}{n} \sum_{i=1}^{n} y_i$ is the mean of data points and $y^\mathrm{T} y = \sum_{i=1}^{n} y_i^2$ is the sum of squared data points.

Thus, the log-likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:llf}) is

\begin{equation} \label{eq:ugkv-mle-ugkv-LL}
\mathrm{LL}(\mu) = \log p(y|\mu) = -\frac{n}{2} \log (2 \pi \sigma^2) - \frac{1}{2 \sigma^2} \left( y^\mathrm{T} y - 2 n \bar{y} \mu + n \mu^2 \right) \; .
\end{equation}

The derivatives of the log-likelihood with respect to $\mu$ are

\begin{equation} \label{eq:ugkv-mle-ugkv-dLLdl-d2LLdl2}
\begin{split}
\frac{\mathrm{d}\mathrm{LL}(\mu)}{\mathrm{d}\mu} &= \frac{n \bar{y}}{\sigma^2} - \frac{n \mu}{\sigma^2} = \frac{n}{\sigma^2} (\bar{y}-\mu) \\
\frac{\mathrm{d}^2\mathrm{LL}(\mu)}{\mathrm{d}\mu^2} &= - \frac{n}{\sigma^2} \; . \\
\end{split}
\end{equation}

Setting the first derivative to zero, we obtain:

\begin{equation} \label{eq:ugkv-mle-ugkv-dLLdl}
\begin{split}
\frac{\mathrm{d}\mathrm{LL}(\hat{\mu})}{\mathrm{d}\mu} &= 0 \\
0 &= \frac{n}{\sigma^2} (\bar{y}-\hat{\mu}) \\
0 &= \bar{y}-\hat{\mu} \\
\hat{\mu} &= \bar{y} \\
\end{split}
\end{equation}

Plugging this value into the second derivative, we confirm:

\begin{equation} \label{eq:ugkv-mle-ugkv-d2LLdl2}
\frac{\mathrm{d}^2\mathrm{LL}(\hat{\mu})}{\mathrm{d}\mu^2} = -\frac{n}{\sigma^2} < 0 \; .
\end{equation}

This demonstrates that the estimate $\hat{\mu} = \bar{y}$ maximizes the likelihood $p(y \vert \mu)$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Bishop, Christopher M. (2006): "Bayesian inference for the Gaussian"; in: \textit{Pattern Recognition for Machine Learning}, ch. 2.3.6, p. 98, eq. 2.143; URL: \url{http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P207 | shortcut: ugkv-mle | author: JoramSoch | date: 2021-03-24, 03:48.
\vspace{1em}



\subsubsection[\textbf{One-sample z-test}]{One-sample z-test} \label{sec:ugkv-ztest1}
\setcounter{equation}{0}

\textbf{Theorem:} Let

\begin{equation} \label{eq:ugkv-ztest1-ugkv}
y_i \sim \mathcal{N}(\mu, \sigma^2), \quad i = 1, \ldots, n
\end{equation}

be a univariate Gaussian data set ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:ugkv}) with unknown mean $\mu$ and known variance $\sigma^2$. Then, the test statistic ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:tstat})

\begin{equation} \label{eq:ugkv-ztest1-z}
z = \sqrt{n} \, \frac{\bar{y}-\mu_0}{\sigma}
\end{equation}

with sample mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean-samp}) $\bar{y}$ follows a standard normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:snorm})

\begin{equation} \label{eq:ugkv-ztest1-z-dist}
z \sim \mathcal{N}(0, 1)
\end{equation}

under the null hypothesis ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:h0})

\begin{equation} \label{eq:ugkv-ztest1-ztest1-h0}
H_0: \; \mu = \mu_0 \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The sample mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean-samp}) is given by

\begin{equation} \label{eq:ugkv-ztest1-mean-samp}
\bar{y} = \frac{1}{n} \sum_{i=1}^{n} y_i \; .
\end{equation}

Using the linearity of the expected value ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-lin}), the additivity of the variance under independence ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:var-add}) and scaling of the variance upon multiplication ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:var-scal}), the sample mean follows a normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm})

\begin{equation} \label{eq:ugkv-ztest1-mean-samp-dist}
\bar{y} = \frac{1}{n} \sum_{i=1}^{n} y_i \sim \mathcal{N}\left( \frac{1}{n} n \mu, \left(\frac{1}{n}\right)^2 n \sigma^2 \right) = \mathcal{N}\left( \mu, \sigma^2/n \right)
\end{equation}

and additionally using the invariance of the variance under addition ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:var-inv}), the distribution of $z = \sqrt{n/\sigma^2} (\bar{y}-\mu_0)$ becomes

\begin{equation} \label{eq:ugkv-ztest1-z-dist-s1}
z = \sqrt{\frac{n}{\sigma^2}} (\bar{y} - \mu_0) \sim \mathcal{N}\left( \sqrt{\frac{n}{\sigma^2}} (\mu - \mu_0), \left(\sqrt{\frac{n}{\sigma^2}}\right)^2 \frac{\sigma^2}{n} \right) = \mathcal{N}\left( \sqrt{n} \, \frac{\mu-\mu_0}{\sigma}, 1 \right) \; ,
\end{equation}

such that, under the null hypothesis in \eqref{eq:ugkv-ztest1-ztest1-h0}, we have:

\begin{equation} \label{eq:ugkv-ztest1-z-dist-s2}
z \sim \mathcal{N}(0, 1), \quad \text{if } \mu = \mu_0 \; .
\end{equation}

This means that the null hypothesis ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:h0}) can be rejected when $z$ is as extreme or more extreme than the critical value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cval}) obtained from the standard normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:snorm}) using a significance level ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:alpha}) $\alpha$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Z-test"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-03-24; URL: \url{https://en.wikipedia.org/wiki/Z-test#Use_in_location_testing}.
\item Wikipedia (2021): "GauÃŸ-Test"; in: \textit{Wikipedia â€“ Die freie EnzyklopÃ¤die}, retrieved on 2021-03-24; URL: \url{https://de.wikipedia.org/wiki/Gau%C3%9F-Test#Einstichproben-Gau%C3%9F-Test}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P208 | shortcut: ugkv-ztest1 | author: JoramSoch | date: 2021-03-24, 04:23.
\vspace{1em}



\subsubsection[\textbf{Two-sample z-test}]{Two-sample z-test} \label{sec:ugkv-ztest2}
\setcounter{equation}{0}

\textbf{Theorem:} Let

\begin{equation} \label{eq:ugkv-ztest2-ugkv}
\begin{split}
y_{1i} &\sim \mathcal{N}(\mu_1, \sigma_1^2), \quad i = 1, \ldots, n_1 \\
y_{2i} &\sim \mathcal{N}(\mu_2, \sigma_2^2), \quad i = 1, \ldots, n_2
\end{split}
\end{equation}

be a univariate Gaussian data set ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:ug}) representing two groups of unequal size $n_1$ and $n_2$ with unknown means $\mu_1$ and $\mu_2$ and unknown variances $\sigma_1^2$ and $\sigma_2^2$. Then, the test statistic ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:tstat})

\begin{equation} \label{eq:ugkv-ztest2-z}
z = \frac{(\bar{y}_1-\bar{y}_2)-\mu_\Delta}{\sqrt{\frac{\sigma_1^2}{n_1}+\frac{\sigma_2^2}{n_2}}}
\end{equation}

with sample means ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean-samp}) $\bar{y}_1$ and $\bar{y}_2$ follows a standard normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:snorm})

\begin{equation} \label{eq:ugkv-ztest2-z-dist}
z \sim \mathcal{N}(0, 1)
\end{equation}

under the null hypothesis ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:h0})

\begin{equation} \label{eq:ugkv-ztest2-ztest2-h0}
H_0: \; \mu_1-\mu_2 = \mu_\Delta \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The sample means ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean-samp}) are given by

\begin{equation} \label{eq:ugkv-ztest2-mean-samp}
\begin{split}
\bar{y}_1 &= \frac{1}{n_1} \sum_{i=1}^{n_1} y_{1i} \\
\bar{y}_2 &= \frac{1}{n_2} \sum_{i=1}^{n_2} y_{2i} \; .
\end{split}
\end{equation}

Using the linearity of the expected value ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-lin}), the additivity of the variance under independence ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:var-add}) and scaling of the variance upon multiplication ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:var-scal}), the sample means follow a normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm})

\begin{equation} \label{eq:ugkv-ztest2-mean-samp-dist}
\begin{split}
\bar{y}_1 &= \frac{1}{n_1} \sum_{i=1}^{n_1} y_{1i} \sim \mathcal{N}\left( \frac{1}{n_1} n_1 \mu_1, \left(\frac{1}{n_1}\right)^2 n_1 \sigma^2 \right) = \mathcal{N}\left( \mu_1, \sigma_1^2/n_1 \right) \\
\bar{y}_2 &= \frac{1}{n_2} \sum_{i=1}^{n_2} y_{2i} \sim \mathcal{N}\left( \frac{1}{n_2} n_2 \mu_2, \left(\frac{1}{n_2}\right)^2 n_2 \sigma^2 \right) = \mathcal{N}\left( \mu_2, \sigma_2^2/n_2 \right)
\end{split}
\end{equation}

and additionally using the invariance of the variance under addition ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:var-inv}), the distribution of $z = [(\bar{y}_1-\bar{y}_2)-\mu_\Delta]/\sigma_\Delta$ becomes

\begin{equation} \label{eq:ugkv-ztest2-z-dist-s1}
z = \frac{(\bar{y}_1-\bar{y}_2)-\mu_\Delta}{\sigma_\Delta} \sim \mathcal{N}\left( \frac{(\mu_1-\mu_2)-\mu_\Delta}{\sigma_\Delta}, \left(\frac{1}{\sigma_\Delta}\right)^2 \sigma_\Delta^2 \right) = \mathcal{N}\left( \frac{(\mu_1-\mu_2)-\mu_\Delta}{\sigma_\Delta}, 1 \right)
\end{equation}

where $\sigma_\Delta$ is the pooled standard deviation ($\rightarrow$ Definition "std-pool")

\begin{equation} \label{eq:ugkv-ztest2-std-pool}
\sigma_\Delta = \sqrt{\frac{\sigma_1^2}{n_1}+\frac{\sigma_2^2}{n_2}} \; ,
\end{equation}

such that, under the null hypothesis in \eqref{eq:ugkv-ztest2-ztest2-h0}, we have:

\begin{equation} \label{eq:ugkv-ztest2-z-dist-s2}
z \sim \mathcal{N}(0, 1), \quad \text{if } \mu_\Delta = \mu_1-\mu_2 \; .
\end{equation}

This means that the null hypothesis ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:h0}) can be rejected when $z$ is as extreme or more extreme than the critical value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cval}) obtained from the standard normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:snorm}) using a significance level ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:alpha}) $\alpha$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Z-test"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-03-24; URL: \url{https://en.wikipedia.org/wiki/Z-test#Use_in_location_testing}.
\item Wikipedia (2021): "GauÃŸ-Test"; in: \textit{Wikipedia â€“ Die freie EnzyklopÃ¤die}, retrieved on 2021-03-24; URL: \url{https://de.wikipedia.org/wiki/Gau%C3%9F-Test#Zweistichproben-Gau%C3%9F-Test_f%C3%BCr_unabh%C3%A4ngige_Stichproben}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P209 | shortcut: ugkv-ztest2 | author: JoramSoch | date: 2021-03-24, 04:38.
\vspace{1em}



\subsubsection[\textbf{Paired z-test}]{Paired z-test} \label{sec:ugkv-ztestp}
\setcounter{equation}{0}

\textbf{Theorem:} Let $y_{i1}$ and $y_{i2}$ with $i = 1, \ldots, n$ be paired observations, such that

\begin{equation} \label{eq:ugkv-ztestp-ugkv}
y_{i1} \sim \mathcal{N}(y_{i2} + \mu, \sigma^2), \quad i = 1, \ldots, n
\end{equation}

is a univariate Gaussian data set ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:ugkv}) with unknown shift $\mu$ and known variance $\sigma^2$. Then, the test statistic ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:tstat})

\begin{equation} \label{eq:ugkv-ztestp-z}
z = \sqrt{n} \, \frac{\bar{d}-\mu_0}{\sigma} \quad \text{where} \quad d_i = y_{i1} - y_{i2}
\end{equation}

with sample mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean-samp}) $\bar{d}$ follows a standard normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:snorm})

\begin{equation} \label{eq:ugkv-ztestp-z-dist}
z \sim \mathcal{N}(0, 1)
\end{equation}

under the null hypothesis ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:h0})

\begin{equation} \label{eq:ugkv-ztestp-ztestp-h0}
H_0: \; \mu = \mu_0 \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} Define the pair-wise difference $d_i = y_{i1} - y_{i2}$ which is, according to the linearity of the expected value ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-lin}) and the invariance of the variance under addition ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:var-inv}), distributed as

\begin{equation} \label{eq:ugkv-ztestp-d-dist}
d_i = y_{i1} - y_{i2} \sim \mathcal{N}(\mu, \sigma^2), \quad i = 1, \ldots, n \; .
\end{equation}

Therefore, $d_1, \ldots, d_n$ satisfy the conditions of the one-sample z-test ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:ugkv-ztest1}) which results in the test statistic given by \eqref{eq:ugkv-ztestp-z}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Z-test"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-03-24; URL: \url{https://en.wikipedia.org/wiki/Z-test#Use_in_location_testing}.
\item Wikipedia (2021): "GauÃŸ-Test"; in: \textit{Wikipedia â€“ Die freie EnzyklopÃ¤die}, retrieved on 2021-03-24; URL: \url{https://de.wikipedia.org/wiki/Gau%C3%9F-Test#Zweistichproben-Gau%C3%9F-Test_f%C3%BCr_abh%C3%A4ngige_(verbundene)_Stichproben}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P210 | shortcut: ugkv-ztestp | author: JoramSoch | date: 2021-03-24, 05:10.
\vspace{1em}



\subsubsection[\textbf{Conjugate prior distribution}]{Conjugate prior distribution} \label{sec:ugkv-prior}
\setcounter{equation}{0}

\textbf{Theorem:} Let

\begin{equation} \label{eq:ugkv-prior-ugkv}
y = \left\lbrace y_1, \ldots, y_n \right\rbrace, \quad y_i \sim \mathcal{N}(\mu, \sigma^2), \quad i = 1, \ldots, n
\end{equation}

be a univariate Gaussian data set ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:ugkv}) with unknown mean $\mu$ and known variance $\sigma^2$. Then, the conjugate prior ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior-conj}) for this model is a normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm})

\begin{equation} \label{eq:ugkv-prior-UGkv-prior}
p(\mu) = \mathcal{N}(\mu; \mu_0, \lambda_0^{-1})
\end{equation}

with prior ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) $\mu_0$ and prior ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) precision ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prec}) $\lambda_0$.


\vspace{1em}
\textbf{Proof:} By definition, a conjugate prior ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior-conj}) is a prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) that, when combined with the likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}), leads to a posterior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) that belongs to the same family of probability distributions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist}). This is fulfilled when the prior density and the likelihood function are proportional to the model model parameters in the same way, i.e. the model parameters appear in the same functional form in both.

Equation \eqref{eq:ugkv-prior-ugkv} implies the following likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf})

\begin{equation} \label{eq:ugkv-prior-UGkv-LF-class}
\begin{split}
p(y|\mu) &= \prod_{i=1}^{n} \mathcal{N}(y_i; \mu, \sigma^2) \\
&= \prod_{i=1}^{n} \frac{1}{\sqrt{2 \pi} \sigma} \cdot \exp\left[ -\frac{1}{2} \left( \frac{y_i-\mu}{\sigma} \right)^2 \right] \\
&= \left( \sqrt{\frac{1}{2 \pi \sigma^2}} \right)^n \cdot \exp\left[ -\frac{1}{2 \sigma^2} \sum_{i=1}^{n} \left( y_i-\mu \right)^2 \right]
\end{split}
\end{equation}

which, for mathematical convenience, can also be parametrized as

\begin{equation} \label{eq:ugkv-prior-UGkv-LF-Bayes}
\begin{split}
p(y|\mu) &= \prod_{i=1}^{n} \mathcal{N}(y_i; \mu, \tau^{-1}) \\
&= \prod_{i=1}^{n} \sqrt{\frac{\tau}{2 \pi}} \cdot \exp\left[ -\frac{\tau}{2} \left( y_i-\mu \right)^2 \right] \\
&= \left( \sqrt{\frac{\tau}{2 \pi}} \right)^n \cdot \exp\left[ -\frac{\tau}{2} \sum_{i=1}^{n} \left( y_i-\mu \right)^2 \right]
\end{split}
\end{equation}

using the inverse variance or precision $\tau = 1/\sigma^2$.

\vspace{1em}
Expanding the product in the exponent, we have

\begin{equation} \label{eq:ugkv-prior-UGkv-LF-s2}
\begin{split}
p(y|\mu) &= \left( \frac{\tau}{2 \pi} \right)^{n/2} \cdot \exp\left[ -\frac{\tau}{2} \sum_{i=1}^{n} \left( y_i^2 - 2 \mu y_i + \mu^2 \right) \right] \\
&= \left( \frac{\tau}{2 \pi} \right)^{n/2} \cdot \exp\left[ -\frac{\tau}{2} \left( \sum_{i=1}^{n} y_i^2 - 2 \mu \sum_{i=1}^{n} y_i + n \mu^2 \right) \right] \\
&= \left( \frac{\tau}{2 \pi} \right)^{n/2} \cdot \exp\left[ -\frac{\tau}{2} \left( y^\mathrm{T} y - 2 \mu n \bar{y} + n \mu^2 \right) \right] \\
&= \left( \frac{\tau}{2 \pi} \right)^{n/2} \cdot \exp\left[ -\frac{\tau n}{2} \left( \frac{1}{n} y^\mathrm{T} y - 2 \mu \bar{y} + \mu^2 \right) \right]
\end{split}
\end{equation}

where $\bar{y} = \frac{1}{n} \sum_{i=1}^{n} y_i$ is the mean of data points and $y^\mathrm{T} y = \sum_{i=1}^{n} y_i^2$ is the sum of squared data points.

Completing the square over $\mu$, finally gives

\begin{equation} \label{eq:ugkv-prior-UGkv-LF-s3}
p(y|\mu) = \left( \frac{\tau}{2 \pi} \right)^{n/2} \cdot \exp\left[ -\frac{\tau n}{2} \left( (\mu-\bar{y})^2 - \bar{y}^2 + \frac{1}{n} y^\mathrm{T} y \right) \right]
\end{equation}

\vspace{1em}
In other words, the likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) is proportional to an exponential of a squared form of $\mu$, weighted by some constant:

\begin{equation} \label{eq:ugkv-prior-UGkv-LF-s4}
p(y|\mu) \propto \exp\left[ -\frac{\tau n}{2} \left( \mu-\bar{y} \right)^2 \right] \; .
\end{equation}

The same is true for a normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}) over $\mu$

\begin{equation} \label{eq:ugkv-prior-UGkv-prior-s1}
p(\mu) = \mathcal{N}(\mu; \mu_0, \lambda_0^{-1})
\end{equation}

the probability density function of which ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-pdf})

\begin{equation} \label{eq:ugkv-prior-UGkv-prior-s2}
p(\mu) = \sqrt{\frac{\lambda_0}{2 \pi}} \cdot \exp\left[ -\frac{\lambda_0}{2} \left( \mu-\mu_0 \right)^2 \right]
\end{equation}

exhibits the same proportionality

\begin{equation} \label{eq:ugkv-prior-UGkv-prior-s3}
p(\mu) \propto \exp\left[ -\frac{\lambda_0}{2} \left( \mu-\mu_0 \right)^2 \right]
\end{equation}

and is therefore conjugate relative to the likelihood.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Bishop, Christopher M. (2006): "Bayesian inference for the Gaussian"; in: \textit{Pattern Recognition for Machine Learning}, ch. 2.3.6, pp. 97-98, eq. 2.138; URL: \url{http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P211 | shortcut: ugkv-prior | author: JoramSoch | date: 2021-03-24, 05:57.
\vspace{1em}



\subsubsection[\textbf{Posterior distribution}]{Posterior distribution} \label{sec:ugkv-post}
\setcounter{equation}{0}

\textbf{Theorem:} Let

\begin{equation} \label{eq:ugkv-post-ugkv}
y = \left\lbrace y_1, \ldots, y_n \right\rbrace, \quad y_i \sim \mathcal{N}(\mu, \sigma^2), \quad i = 1, \ldots, n
\end{equation}

be a univariate Gaussian data set ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:ugkv}) with unknown mean $\mu$ and known variance $\sigma^2$. Moreover, assume a normal distribution ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:ugkv-prior}) over the model parameter $\mu$:

\begin{equation} \label{eq:ugkv-post-UGkv-prior}
p(\mu) = \mathcal{N}(\mu; \mu_0, \lambda_0^{-1}) \; .
\end{equation}

Then, the posterior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) is also a normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm})

\begin{equation} \label{eq:ugkv-post-UGkv-post}
p(\mu|y) = \mathcal{N}(\mu; \mu_n, \lambda_n^{-1})
\end{equation}

and the posterior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) are given by

\begin{equation} \label{eq:ugkv-post-UGkv-post-par}
\begin{split}
\mu_n &= \frac{\lambda_0 \mu_0 + \tau n \bar{y}}{\lambda_0 + \tau n} \\
\lambda_n &= \lambda_0 + \tau n
\end{split}
\end{equation}

with the sample mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean-samp}) $\bar{y}$ and the inverse variance or precision ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prec}) $\tau = 1/\sigma^2$.


\vspace{1em}
\textbf{Proof:} According to Bayes' theorem ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:bayes-th}), the posterior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) is given by

\begin{equation} \label{eq:ugkv-post-UGkv-BT}
p(\mu|y) = \frac{p(y|\mu) \, p(\mu)}{p(y)} \; .
\end{equation}

Since $p(y)$ is just a normalization factor, the posterior is proportional ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:post-jl}) to the numerator:

\begin{equation} \label{eq:ugkv-post-UGkv-post-JL}
p(\mu|y) \propto p(y|\mu) \, p(\mu) = p(y,\mu) \; .
\end{equation}

Equation \eqref{eq:ugkv-post-ugkv} implies the following likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf})

\begin{equation} \label{eq:ugkv-post-UGkv-LF-class}
\begin{split}
p(y|\mu) &= \prod_{i=1}^{n} \mathcal{N}(y_i; \mu, \sigma^2) \\
&= \prod_{i=1}^{n} \frac{1}{\sqrt{2 \pi} \sigma} \cdot \exp\left[ -\frac{1}{2} \left( \frac{y_i-\mu}{\sigma} \right)^2 \right] \\
&= \left( \sqrt{\frac{1}{2 \pi \sigma^2}} \right)^n \cdot \exp\left[ -\frac{1}{2 \sigma^2} \sum_{i=1}^{n} \left( y_i-\mu \right)^2 \right]
\end{split}
\end{equation}

which, for mathematical convenience, can also be parametrized as

\begin{equation} \label{eq:ugkv-post-UGkv-LF-Bayes}
\begin{split}
p(y|\mu) &= \prod_{i=1}^{n} \mathcal{N}(y_i; \mu, \tau^{-1}) \\
&= \prod_{i=1}^{n} \sqrt{\frac{\tau}{2 \pi}} \cdot \exp\left[ -\frac{\tau}{2} \left( y_i-\mu \right)^2 \right] \\
&= \left( \sqrt{\frac{\tau}{2 \pi}} \right)^n \cdot \exp\left[ -\frac{\tau}{2} \sum_{i=1}^{n} \left( y_i-\mu \right)^2 \right]
\end{split}
\end{equation}

using the inverse variance or precision $\tau = 1/\sigma^2$.

\vspace{1em}
Combining the likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) \eqref{eq:ugkv-post-UGkv-LF-Bayes} with the prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) \eqref{eq:ugkv-post-UGkv-prior}, the joint likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:jl}) of the model is given by

\begin{equation} \label{eq:ugkv-post-UGkv-JL-s1}
\begin{split}
p(y,\mu) = \; & p(y|\mu) \, p(\mu) \\
= \; & \left( \sqrt{\frac{\tau}{2 \pi}} \right)^n \cdot \exp\left[ -\frac{\tau}{2} \sum_{i=1}^{n} \left( y_i-\mu \right)^2 \right] \cdot \sqrt{\frac{\lambda_0}{2 \pi}} \cdot \exp\left[ -\frac{\lambda_0}{2} \left( \mu-\mu_0 \right)^2 \right] \; .
\end{split}
\end{equation}

Rearranging the terms, we then have:

\begin{equation} \label{eq:ugkv-post-UGkv-JL-s2}
p(y,\mu) = \left( \frac{\tau}{2 \pi} \right)^{n/2} \cdot \sqrt{\frac{\lambda_0}{2 \pi}} \cdot \exp\left[ -\frac{\tau}{2} \sum_{i=1}^{n} \left( y_i-\mu \right)^2 - \frac{\lambda_0}{2} \left( \mu-\mu_0 \right)^2 \right] \; .
\end{equation}

Expanding the products in the exponent ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:ugkv-prior}) gives

\begin{equation} \label{eq:ugkv-post-UGkv-JL-s3}
\begin{split}
p(y,\mu) &= \left( \frac{\tau}{2 \pi} \right)^\frac{n}{2} \cdot \left( \frac{\lambda_0}{2 \pi} \right)^\frac{1}{2} \cdot \exp \left[ -\frac{1}{2} \left( \sum_{i=1}^n \tau (y_i-\mu)^2 + \lambda_0 (\mu-\mu_0)^2 \right) \right] \\
&= \left( \frac{\tau}{2 \pi} \right)^\frac{n}{2} \cdot \left( \frac{\lambda_0}{2 \pi} \right)^\frac{1}{2} \cdot \exp \left[ -\frac{1}{2} \left( \sum_{i=1}^n \tau (y_i^2 - 2 y_i \mu + \mu^2) + \lambda_0 (\mu^2 - 2 \mu \mu_0 + \mu_0^2) \right) \right] \\
&= \left( \frac{\tau}{2 \pi} \right)^\frac{n}{2} \cdot \left( \frac{\lambda_0}{2 \pi} \right)^\frac{1}{2} \cdot \exp \left[ -\frac{1}{2} \left( \tau (y^\mathrm{T} y - 2 n \bar{y} \mu + n \mu^2) + \lambda_0 (\mu^2 - 2 \mu \mu_0 + \mu_0^2) \right) \right] \\
&= \left( \frac{\tau}{2 \pi} \right)^\frac{n}{2} \cdot \left( \frac{\lambda_0}{2 \pi} \right)^\frac{1}{2} \cdot \exp \left[ -\frac{1}{2} \left( \mu^2 (\tau n + \lambda_0) - 2 \mu (\tau n \bar{y} + \lambda_0 \mu_0) + (\tau y^\mathrm{T} y + \lambda_0 \mu_0^2) \right) \right] \\
\end{split}
\end{equation}

where $\bar{y} = \frac{1}{n} \sum_{i=1}^{n} y_i$ and $y^\mathrm{T} y = \sum_{i=1}^{n} y_i^2$. Completing the square in $\mu$ then yields

\begin{equation} \label{eq:ugkv-post-UGkv-JL-s4}
p(y,\mu) = \left( \frac{\tau}{2 \pi} \right)^\frac{n}{2} \cdot \left( \frac{\lambda_0}{2 \pi} \right)^\frac{1}{2} \cdot \exp \left[ -\frac{\lambda_n}{2} (\mu - \mu_n)^2 + f_n \right]
\end{equation}

with the posterior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post})

\begin{equation} \label{eq:ugkv-post-UGkv-post-mu-par}
\begin{split}
\mu_n &= \frac{\lambda_0 \mu_0 + \tau n \bar{y}}{\lambda_0 + \tau n} \\
\lambda_n &= \lambda_0 + \tau n
\end{split}
\end{equation}

and the remaining independent term

\begin{equation} \label{eq:ugkv-post-UGkv-JL-fn}
f_n = -\frac{1}{2} \left( \tau y^\mathrm{T} y + \lambda_0 \mu_0^2 - \lambda_n \mu_n^2 \right) \; .
\end{equation}

Ergo, the joint likelihood in \eqref{eq:ugkv-post-UGkv-JL-s4} is proportional to

\begin{equation} \label{eq:ugkv-post-UGkv-JL-s5}
p(y,\mu) \propto \exp \left[ -\frac{\lambda_n}{2} (\mu - \mu_n)^2 \right] \; ,
\end{equation}

such that the posterior distribution over $\mu$ is given by

\begin{equation} \label{eq:ugkv-post-UGkv-post-mu}
p(\mu|y) = \mathcal{N}(\mu; \mu_n, \lambda_n^{-1}) \; .
\end{equation}

with the posterior hyperparameters given in \eqref{eq:ugkv-post-UGkv-post-mu-par}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Bishop, Christopher M. (2006): "Bayesian inference for the Gaussian"; in: \textit{Pattern Recognition for Machine Learning}, ch. 2.3.6, p. 98, eqs. 2.139-2.142; URL: \url{http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P212 | shortcut: ugkv-post | author: JoramSoch | date: 2021-03-24, 06:10.
\vspace{1em}



\subsubsection[\textbf{Log model evidence}]{Log model evidence} \label{sec:ugkv-lme}
\setcounter{equation}{0}

\textbf{Theorem:} Let

\begin{equation} \label{eq:ugkv-lme-ug}
m: \; y = \left\lbrace y_1, \ldots, y_n \right\rbrace, \quad y_i \sim \mathcal{N}(\mu, \sigma^2), \quad i = 1, \ldots, n
\end{equation}

be a univariate Gaussian data set ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:ugkv}) with unknown mean $\mu$ and known variance $\sigma^2$. Moreover, assume a normal distribution ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:ugkv-prior}) over the model parameter $\mu$:

\begin{equation} \label{eq:ugkv-lme-UGkv-prior}
p(\mu) = \mathcal{N}(\mu; \mu_0, \lambda_0^{-1}) \; .
\end{equation}

Then, the log model evidence ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme}) for this model is

\begin{equation} \label{eq:ugkv-lme-UGkv-LME}
\log p(y|m) = \frac{n}{2} \log\left( \frac{\tau}{2 \pi} \right) + \frac{1}{2} \log\left( \frac{\lambda_0}{\lambda_n} \right) - \frac{1}{2} \left( \tau y^T y + \lambda_0 \mu_0^2 - \lambda_n \mu_n^2 \right) \; .
\end{equation}

where the posterior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) are given by

\begin{equation} \label{eq:ugkv-lme-UGkv-post-par}
\begin{split}
\mu_n &= \frac{\lambda_0 \mu_0 + \tau n \bar{y}}{\lambda_0 + \tau n} \\
\lambda_n &= \lambda_0 + \tau n
\end{split}
\end{equation}

with the sample mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean-samp}) $\bar{y}$ and the inverse variance or precision ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prec}) $\tau = 1/\sigma^2$.


\vspace{1em}
\textbf{Proof:} According to the law of marginal probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}), the model evidence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ml}) for this model is:

\begin{equation} \label{eq:ugkv-lme-UGkv-ME-s1}
p(y|m) = \int p(y|\mu) \, p(\mu) \, \mathrm{d}\mu \; .
\end{equation}

According to the law of conditional probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-cond}), the integrand is equivalent to the joint likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:jl}):

\begin{equation} \label{eq:ugkv-lme-UGkv-ME-s2}
p(y|m) = \int p(y,\mu) \, \mathrm{d}\mu \; .
\end{equation}

Equation \eqref{eq:ugkv-lme-ug} implies the following likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf})

\begin{equation} \label{eq:ugkv-lme-UG-LF-class}
\begin{split}
p(y|\mu,\sigma^2) &= \prod_{i=1}^{n} \mathcal{N}(y_i; \mu, \sigma^2) \\
&= \prod_{i=1}^{n} \frac{1}{\sqrt{2 \pi} \sigma} \cdot \exp\left[ -\frac{1}{2} \left( \frac{y_i-\mu}{\sigma} \right)^2 \right] \\
&= \left( \sqrt{\frac{1}{2 \pi \sigma^2}} \right)^n \cdot \exp\left[ -\frac{1}{2 \sigma^2} \sum_{i=1}^{n} \left( y_i-\mu \right)^2 \right]
\end{split}
\end{equation}

which, for mathematical convenience, can also be parametrized as

\begin{equation} \label{eq:ugkv-lme-UG-LF-Bayes}
\begin{split}
p(y|\mu,\tau) &= \prod_{i=1}^{n} \mathcal{N}(y_i; \mu, \tau^{-1}) \\
&= \prod_{i=1}^{n} \sqrt{\frac{\tau}{2 \pi}} \cdot \exp\left[ -\frac{\tau}{2} \left( y_i-\mu \right)^2 \right] \\
&= \left( \sqrt{\frac{\tau}{2 \pi}} \right)^n \cdot \exp\left[ -\frac{\tau}{2} \sum_{i=1}^{n} \left( y_i-\mu \right)^2 \right]
\end{split}
\end{equation}

using the inverse variance or precision $\tau = 1/\sigma^2$.

\vspace{1em}
When deriving the posterior distribution ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:ugkv-post}) $p(\mu|y)$, the joint likelihood $p(y,\mu)$ is obtained as

\begin{equation} \label{eq:ugkv-lme-UGkv-LME-s1}
p(y,\mu) = \left( \frac{\tau}{2 \pi} \right)^\frac{n}{2} \cdot \sqrt{\frac{\lambda_0}{2 \pi}} \cdot \exp \left[ -\frac{\lambda_n}{2} (\mu - \mu_n)^2 -\frac{1}{2} \left( \tau y^\mathrm{T} y + \lambda_0 \mu_0^2 - \lambda_n \mu_n^2 \right) \right] \; .
\end{equation}

Using the probability density function of the normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-pdf}), we can rewrite this as

\begin{equation} \label{eq:ugkv-lme-UGkv-LME-s2}
p(y,\mu) =  \left( \frac{\tau}{2 \pi} \right)^\frac{n}{2} \cdot \sqrt{\frac{\lambda_0}{2 \pi}} \cdot \sqrt{\frac{2 \pi}{\lambda_n}} \cdot \mathcal{N}(\mu; \lambda_n^{-1}) \cdot \exp \left[ -\frac{1}{2} \left( \tau y^\mathrm{T} y + \lambda_0 \mu_0^2 - \lambda_n \mu_n^2 \right) \right] \; .
\end{equation}

Now, $\mu$ can be integrated out using the properties of the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}):

\begin{equation} \label{eq:ugkv-lme-UGkv-LME-s3}
p(y|m) = \int p(y,\mu) \, \mathrm{d}\mu = \left( \frac{\tau}{2 \pi} \right)^\frac{n}{2} \cdot \sqrt{\frac{\lambda_0}{\lambda_n}} \cdot \exp \left[ -\frac{1}{2} \left( \tau y^\mathrm{T} y + \lambda_0 \mu_0^2 - \lambda_n \mu_n^2 \right) \right] \; .
\end{equation}

Thus, the log model evidence ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme}) of this model is given by

\begin{equation} \label{eq:ugkv-lme-UGkv-LME-s4}
\log p(y|m) = \frac{n}{2} \log\left( \frac{\tau}{2 \pi} \right) + \frac{1}{2} \log\left( \frac{\lambda_0}{\lambda_n} \right) - \frac{1}{2} \left( \tau y^T y + \lambda_0 \mu_0^2 - \lambda_n \mu_n^2 \right) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P213 | shortcut: ugkv-lme | author: JoramSoch | date: 2021-03-24, 06:45.
\vspace{1em}



\subsubsection[\textbf{Accuracy and complexity}]{Accuracy and complexity} \label{sec:ugkv-anc}
\setcounter{equation}{0}

\textbf{Theorem:} Let

\begin{equation} \label{eq:ugkv-anc-ugkv}
y = \left\lbrace y_1, \ldots, y_n \right\rbrace, \quad y_i \sim \mathcal{N}(\mu, \sigma^2), \quad i = 1, \ldots, n
\end{equation}

be a univariate Gaussian data set ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:ugkv}) with unknown mean $\mu$ and known variance $\sigma^2$. Moreover, assume a statistical model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:fpm}) imposing a normal distribution ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:ugkv-prior}) as the prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) on the model parameter $\mu$:

\begin{equation} \label{eq:ugkv-anc-m}
m: \; y_i \sim \mathcal{N}(\mu, \sigma^2), \; \mu \sim \mathcal{N}(\mu_0, \lambda_0^{-1}) \; .
\end{equation}

Then, accuracy and complexity ($\rightarrow$ Proof \ref{sec:Model Selection}/\ref{sec:lme-anc}) of this model are

\begin{equation} \label{eq:ugkv-anc-UGkv-anc}
\begin{split}
\mathrm{Acc}(m) &= \frac{n}{2} \log\left( \frac{\tau}{2 \pi} \right) - \frac{1}{2} \left[ \tau y^\mathrm{T} y - 2 \, \tau n \bar{y} \mu_n + \tau n \mu_n^2 + \frac{\tau n}{\lambda_n} \right] \\
\mathrm{Com}(m) &= \frac{1}{2} \left[ \frac{\lambda_0}{\lambda_n} + \lambda_0 (\mu_0 - \mu_n)^2 - 1 + \log\left( \frac{\lambda_0}{\lambda_n} \right) \right]
\end{split}
\end{equation}

where $\mu_n$ and $\lambda_n$ are the posterior hyperparameters for the univariate Gaussian with known variance ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:ugkv-post}), $\tau = 1/\sigma^2$ is the inverse variance or precision ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prec}) and $\bar{y}$ is the sample mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean-samp}).


\vspace{1em}
\textbf{Proof:} Model accuracy and complexity are defined as ($\rightarrow$ Proof \ref{sec:Model Selection}/\ref{sec:lme-anc})

\begin{equation} \label{eq:ugkv-anc-lme-anc}
\begin{split}
\mathrm{LME}(m) &= \mathrm{Acc}(m) - \mathrm{Com}(m) \\
\mathrm{Acc}(m) &= \left\langle \log p(y|\mu,m) \right\rangle_{p(\mu|y,m)} \\
\mathrm{Com}(m) &= \mathrm{KL} \left[ p(\mu|y,m) \, || \, p(\mu|m) \right] \; .
\end{split}
\end{equation}

\vspace{1em}
The accuracy term is the expectation ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of the log-likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:llf}) $\log p(y|\mu)$ with respect to the posterior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) $p(\mu|y)$. With the log-likelihood function for the univariate Gaussian with known variance ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:ugkv-mle}) and the posterior distribution for the univariate Gaussian with known variance ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:ugkv-post}), the model accuracy of $m$ evaluates to:

\begin{equation} \label{eq:ugkv-anc-UGkv-Acc}
\begin{split}
\mathrm{Acc}(m) &= \left\langle \log p(y|\mu) \right\rangle_{p(\mu|y)} \\
&= \left\langle \frac{n}{2} \log\left( \frac{\tau}{2 \pi} \right) - \frac{\tau}{2} \left( y^\mathrm{T} y - 2 n \bar{y} \mu + n \mu^2 \right) \right\rangle_{\mathcal{N}(\mu_n, \lambda_n^{-1})} \\
&= \frac{n}{2} \log\left( \frac{\tau}{2 \pi} \right) - \frac{1}{2} \left[ \tau y^\mathrm{T} y - 2 \tau n \bar{y} \mu_n + \tau n \mu_n^2 + \frac{\tau n}{\lambda_n} \right] \; .
\end{split}
\end{equation}

\vspace{1em}
The complexity penalty is the Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) of the posterior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) $p(\mu|y)$ from the prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) $p(\mu)$. With the prior distribution ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:ugkv-prior}) given by \eqref{eq:ugkv-anc-m}, the posterior distribution for the univariate Gaussian with known variance ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:ugkv-post}) and the Kullback-Leibler divergence of the normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-kl}), the model complexity of $m$ evaluates to:

\begin{equation} \label{eq:ugkv-anc-UGkv-Com}
\begin{split}
\mathrm{Com}(m) &= \mathrm{KL} \left[ p(\mu|y) \, || \, p(\mu) \right] \\
&= \mathrm{KL} \left[ \mathcal{N}(\mu_n, \lambda_n^{-1}) \, || \, \mathcal{N}(\mu_0, \lambda_0^{-1}) \right] \\
&= \frac{1}{2} \left[ \frac{\lambda_0}{\lambda_n} + \lambda_0 (\mu_0 - \mu_n)^2 - 1 + \log\left( \frac{\lambda_0}{\lambda_n} \right) \right] \; .
\end{split}
\end{equation}

A control calculation confirms that

\begin{equation} \label{eq:ugkv-anc-UGkv-anc-lme}
\mathrm{Acc}(m) - \mathrm{Com}(m) = \mathrm{LME}(m)
\end{equation}

where $\mathrm{LME}(m)$ is the log model evidence for the univariate Gaussian with known variance ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:ugkv-lme}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P214 | shortcut: ugkv-anc | author: JoramSoch | date: 2021-03-24, 07:49.
\vspace{1em}



\subsubsection[\textbf{Log Bayes factor}]{Log Bayes factor} \label{sec:ugkv-lbf}
\setcounter{equation}{0}

\textbf{Theorem:} Let

\begin{equation} \label{eq:ugkv-lbf-ugkv}
y = \left\lbrace y_1, \ldots, y_n \right\rbrace, \quad y_i \sim \mathcal{N}(\mu, \sigma^2), \quad i = 1, \ldots, n
\end{equation}

be a univariate Gaussian data set ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:ugkv}) with unknown mean $\mu$ and known variance $\sigma^2$. Moreover, assume two statistical models ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:fpm}), one assuming that $\mu$ is zero (null model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:h0})), the other imposing a normal distribution ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:ugkv-prior}) as the prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) on the model parameter $\mu$ (alternative ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:h1})):

\begin{equation} \label{eq:ugkv-lbf-UGkv-m01}
\begin{split}
m_0&: \; y_i \sim \mathcal{N}(\mu, \sigma^2), \; \mu = 0 \\
m_1&: \; y_i \sim \mathcal{N}(\mu, \sigma^2), \; \mu \sim \mathcal{N}(\mu_0, \lambda_0^{-1}) \; .
\end{split}
\end{equation}

Then, the log Bayes factor ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lbf}) in favor of $m_1$ against $m_0$ is

\begin{equation} \label{eq:ugkv-lbf-UGkv-LBF}
\mathrm{LBF}_{10} = \frac{1}{2} \log\left( \frac{\lambda_0}{\lambda_n} \right) - \frac{1}{2} \left( \lambda_0 \mu_0^2 - \lambda_n \mu_n^2 \right)
\end{equation}

where $\mu_n$ and $\lambda_n$ are the posterior hyperparameters for the univariate Gaussian with known variance ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:ugkv-post}) which are functions of the inverse variance or precision ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prec}) $\tau = 1/\sigma^2$ and the sample mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean-samp}) $\bar{y}$.


\vspace{1em}
\textbf{Proof:} The log Bayes factor is equal to the difference of two log model evidences ($\rightarrow$ Proof \ref{sec:Model Selection}/\ref{sec:lbf-lme}):

\begin{equation} \label{eq:ugkv-lbf-LBF-LME}
\mathrm{LBF}_{12} = \mathrm{LME}(m_1) - \mathrm{LME}(m_2) \; .
\end{equation}

The LME of the alternative $m_1$ is equal to the log model evidence for the univariate Gaussian with known variance ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:ugkv-lme}):

\begin{equation} \label{eq:ugkv-lbf-UGkv-LME-m1}
\mathrm{LME}(m_1) = \frac{n}{2} \log\left( \frac{\tau}{2 \pi} \right) + \frac{1}{2} \log\left( \frac{\lambda_0}{\lambda_n} \right) - \frac{1}{2} \left( \tau y^\mathrm{T} y + \lambda_0 \mu_0^2 - \lambda_n \mu_n^2 \right) \; .
\end{equation}

Because the null model $m_0$ has no free parameter, its log model evidence ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme}) (logarithmized marginal likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ml})) is equal to the log-likelihood function for the univariate Gaussian with known variance ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:ugkv-mle}) at the value $\mu = 0$:

\begin{equation} \label{eq:ugkv-lbf-UGkv-LME-m0}
\mathrm{LME}(m_0) = \log p(y|\mu=0) = \frac{n}{2} \log\left( \frac{\tau}{2 \pi} \right) - \frac{1}{2} \left( \tau y^\mathrm{T} y \right) \; .
\end{equation}

Subtracting the two LMEs from each other, the LBF emerges as

\begin{equation} \label{eq:ugkv-lbf-UGkv-LBF-m10}
\mathrm{LBF}_{10} = \mathrm{LME}(m_1) - \mathrm{LME}(m_0) = \frac{1}{2} \log\left( \frac{\lambda_0}{\lambda_n} \right) - \frac{1}{2} \left( \lambda_0 \mu_0^2 - \lambda_n \mu_n^2 \right)
\end{equation}

where the posterior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) are given by ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:ugkv-post})

\begin{equation} \label{eq:ugkv-lbf-UGkv-post-par}
\begin{split}
\mu_n &= \frac{\lambda_0 \mu_0 + \tau n \bar{y}}{\lambda_0 + \tau n} \\
\lambda_n &= \lambda_0 + \tau n
\end{split}
\end{equation}

with the sample mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean-samp}) $\bar{y}$ and the inverse variance or precision ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prec}) $\tau = 1/\sigma^2$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P215 | shortcut: ugkv-lbf | author: JoramSoch | date: 2021-03-24, 09:05.
\vspace{1em}



\subsubsection[\textbf{Expectation of log Bayes factor}]{Expectation of log Bayes factor} \label{sec:ugkv-lbfmean}
\setcounter{equation}{0}

\textbf{Theorem:} Let

\begin{equation} \label{eq:ugkv-lbfmean-ugkv}
y = \left\lbrace y_1, \ldots, y_n \right\rbrace, \quad y_i \sim \mathcal{N}(\mu, \sigma^2), \quad i = 1, \ldots, n
\end{equation}

be a univariate Gaussian data set ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:ugkv}) with unknown mean $\mu$ and known variance $\sigma^2$. Moreover, assume two statistical models ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:fpm}), one assuming that $\mu$ is zero (null model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:h0})), the other imposing a normal distribution ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:ugkv-prior}) as the prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) on the model parameter $\mu$ (alternative ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:h1})):

\begin{equation} \label{eq:ugkv-lbfmean-UGkv-m01}
\begin{split}
m_0&: \; y_i \sim \mathcal{N}(\mu, \sigma^2), \; \mu = 0 \\
m_1&: \; y_i \sim \mathcal{N}(\mu, \sigma^2), \; \mu \sim \mathcal{N}(\mu_0, \lambda_0^{-1}) \; .
\end{split}
\end{equation}

Then, under the null hypothesis ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:h0}) that $m_0$ generated the data, the expectation ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of the log Bayes factor ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lbf}) in favor of $m_1$ with $\mu_0 = 0$ against $m_0$ is

\begin{equation} \label{eq:ugkv-lbfmean-UGkv-LBF}
\left\langle \mathrm{LBF}_{10} \right\rangle = \frac{1}{2} \log\left( \frac{\lambda_0}{\lambda_n} \right) + \frac{1}{2} \left( \frac{\lambda_n - \lambda_0}{\lambda_n} \right)
\end{equation}

where $\lambda_n$ is the posterior precision for the univariate Gaussian with known variance ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:ugkv-post}).


\vspace{1em}
\textbf{Proof:} The log Bayes factor for the univariate Gaussian with known variance ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:ugkv-lbf}) is

\begin{equation} \label{eq:ugkv-lbfmean-UGkv-LBF-m10-s1}
\mathrm{LBF}_{10} = \frac{1}{2} \log\left( \frac{\lambda_0}{\lambda_n} \right) - \frac{1}{2} \left( \lambda_0 \mu_0^2 - \lambda_n \mu_n^2 \right)
\end{equation}

where the posterior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) are given by ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:ugkv-post})

\begin{equation} \label{eq:ugkv-lbfmean-UGkv-post-par}
\begin{split}
\mu_n &= \frac{\lambda_0 \mu_0 + \tau n \bar{y}}{\lambda_0 + \tau n} \\
\lambda_n &= \lambda_0 + \tau n
\end{split}
\end{equation}

with the sample mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean-samp}) $\bar{y}$ and the inverse variance or precision ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prec}) $\tau = 1/\sigma^2$. Plugging $\mu_n$ from \eqref{eq:ugkv-lbfmean-UGkv-post-par} into \eqref{eq:ugkv-lbfmean-UGkv-LBF-m10-s1}, we obtain:

\begin{equation} \label{eq:ugkv-lbfmean-UGkv-LBF-m10-s2}
\begin{split}
\mathrm{LBF}_{10} &= \frac{1}{2} \log\left( \frac{\lambda_0}{\lambda_n} \right) - \frac{1}{2} \left( \lambda_0 \mu_0^2 - \lambda_n \, \frac{(\lambda_0 \mu_0 + \tau n \bar{y})^2}{\lambda_n^2} \right) \\
&= \frac{1}{2} \log\left( \frac{\lambda_0}{\lambda_n} \right) - \frac{1}{2} \left( \lambda_0 \mu_0^2 - \frac{1}{\lambda_n} (\lambda_0^2 \mu_0^2 - 2 \tau n \lambda_0 \mu_0 \bar{y} + \tau^2 (n \bar{y})^2) \right)
\end{split}
\end{equation}

Because $m_1$ uses a zero-mean prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) with prior mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) $\mu_0 = 0$ per construction, the log Bayes factor simplifies to:

\begin{equation} \label{eq:ugkv-lbfmean-UGkv-LBF-m10-s3}
\mathrm{LBF}_{10} = \frac{1}{2} \log\left( \frac{\lambda_0}{\lambda_n} \right) + \frac{1}{2} \left( \frac{\tau^2 (n \bar{y})^2}{\lambda_n} \right) \; .
\end{equation}

From \eqref{eq:ugkv-lbfmean-ugkv}, we know that the data are distributed as $y_i \sim \mathcal{N}(\mu, \sigma^2)$, such that we can derive the expectation ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of $(n \bar{y})^2$ as follows:

\begin{equation} \label{eq:ugkv-lbfmean-UGkv-E(ny2)}
\begin{split}
\left\langle (n \bar{y})^2 \right\rangle = \left\langle \sum_{i=1}^n \sum_{j=1}^n y_i y_j \right\rangle &= \left\langle n y_i^2 + (n^2-n) [y_i y_j]_{i \neq j} \right\rangle \\
&= n (\mu^2 + \sigma^2) + (n^2 - n) \mu^2 \\
&= n^2 \mu^2 + n \sigma^2 \; .
\end{split}
\end{equation}

Applying this expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) to \eqref{eq:ugkv-lbfmean-UGkv-LBF-m10-s3}, the expected LBF emerges as:

\begin{equation} \label{eq:ugkv-lbfmean-UGkv-LBF-m10-s4}
\begin{split}
\left\langle \mathrm{LBF}_{10} \right\rangle &= \frac{1}{2} \log\left( \frac{\lambda_0}{\lambda_n} \right) + \frac{1}{2} \left( \frac{\tau^2 (n^2 \mu^2 + n \sigma^2)}{\lambda_n} \right) \\
&= \frac{1}{2} \log\left( \frac{\lambda_0}{\lambda_n} \right) + \frac{1}{2} \left( \frac{(\tau n \mu)^2 + \tau n}{\lambda_n} \right)
\end{split}
\end{equation}

Under the null hypothesis ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:h0}) that $m_0$ generated the data, the unknown mean is $\mu = 0$, such that the log Bayes factor further simplifies to:

\begin{equation} \label{eq:ugkv-lbfmean-UGkv-LBF-m10-s5}
\left\langle \mathrm{LBF}_{10} \right\rangle = \frac{1}{2} \log\left( \frac{\lambda_0}{\lambda_n} \right) + \frac{1}{2} \left( \frac{\tau n}{\lambda_n} \right) \; .
\end{equation}

Finally, plugging $\lambda_n$ from \eqref{eq:ugkv-lbfmean-UGkv-post-par} into \eqref{eq:ugkv-lbfmean-UGkv-LBF-m10-s5}, we obtain:

\begin{equation} \label{eq:ugkv-lbfmean-UGkv-LBF-m10-s6}
\left\langle \mathrm{LBF}_{10} \right\rangle = \frac{1}{2} \log\left( \frac{\lambda_0}{\lambda_n} \right) + \frac{1}{2} \left( \frac{\lambda_n - \lambda_0}{\lambda_n} \right) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P216 | shortcut: ugkv-lbfmean | author: JoramSoch | date: 2021-03-24, 10:03.
\vspace{1em}



\subsubsection[\textbf{Cross-validated log model evidence}]{Cross-validated log model evidence} \label{sec:ugkv-cvlme}
\setcounter{equation}{0}

\textbf{Theorem:} Let

\begin{equation} \label{eq:ugkv-cvlme-ugkv}
y = \left\lbrace y_1, \ldots, y_n \right\rbrace, \quad y_i \sim \mathcal{N}(\mu, \sigma^2), \quad i = 1, \ldots, n
\end{equation}

be a univariate Gaussian data set ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:ugkv}) with unknown mean $\mu$ and known variance $\sigma^2$. Moreover, assume two statistical models ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:fpm}), one assuming that $\mu$ is zero (null model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:h0})), the other imposing a normal distribution ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:ugkv-prior}) as the prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) on the model parameter $\mu$ (alternative ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:h1})):

\begin{equation}\label{eq:ugkv-cvlme-UGkv-m01}
\begin{split}
m_0&: \; y_i \sim \mathcal{N}(\mu, \sigma^2), \; \mu = 0 \\
m_1&: \; y_i \sim \mathcal{N}(\mu, \sigma^2), \; \mu \sim \mathcal{N}(\mu_0, \lambda_0^{-1}) \; .
\end{split}
\end{equation}

Then, the cross-validated log model evidences ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:cvlme}) of $m_0$ and $m_1$ are

\begin{equation} \label{eq:ugkv-cvlme-UGkv-cvLME-m01}
\begin{split}
\mathrm{cvLME}(m_0) &= \frac{n}{2} \log\left( \frac{\tau}{2 \pi} \right) - \frac{1}{2} \left( \tau y^\mathrm{T} y \right) \\
\mathrm{cvLME}(m_1) &= \frac{n}{2} \log \left( \frac{\tau}{2 \pi} \right) + \frac{S}{2} \log \left( \frac{S-1}{S} \right) - \frac{\tau}{2} \left[ y^\mathrm{T} y + \sum_{i=1}^S \left( \frac{\left(n_1 \bar{y}_1^{(i)}\right)^2}{n_1} - \frac{(n \bar{y})^2}{n} \right) \right]
\end{split}
\end{equation}

where $\bar{y}$ is the sample mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean-samp}), $\tau = 1/\sigma^2$ is the inverse variance or precision ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prec}), $y_1^{(i)}$ are the training data in the $i$-th cross-validation fold and $S$ is the number of data subsets ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:cvlme}).


\vspace{1em}
\textbf{Proof:} For evaluation of the cross-validated log model evidences ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:cvlme}) (cvLME), we assume that $n$ data points are divided into $S \mid n$ data subsets without remainder. Then, the number of training data points $n_1$ and test data points $n_2$ are given by

\begin{equation} \label{eq:ugkv-cvlme-CV-n12}
\begin{split}
n &= n_1 + n_2 \\
n_1 &= \frac{S-1}{S} n \\
n_2 &= \frac{1}{S} n \; ,
\end{split}
\end{equation}

such that training data $y_1$ and test data $y_2$ in the $i$-th cross-validation fold are

\begin{equation} \label{eq:ugkv-cvlme-CV-y12}
\begin{split}
y &= \left\lbrace y_1, \ldots, y_n \right\rbrace \\
y_1^{(i)} &= \left\lbrace x \in y \mid x \notin y_2^{(i)} \right\rbrace = y \backslash y_2^{(i)} \\
y_2^{(i)} &= \left\lbrace y_{(i-1) \cdot n_2 + 1}, \ldots, y_{i \cdot n_2} \right\rbrace \; .
\end{split}
\end{equation}

\vspace{1em}
First, we consider the null model $m_0$ assuming $\mu = 0$. Because this model has no free parameter, nothing is estimated from the training data and the assumed parameter value is applied to the test data. Consequently, the out-of-sample log model evidence ($\rightarrow$ Definition "ooslme") (oosLME) is equal to the log-likelihood function ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:ugkv-mle}) of the test data at $\mu = 0$:

\begin{equation} \label{eq:ugkv-cvlme-UGkv-m0-oosLME}
\mathrm{oosLME}_i(m_0) = \log p\left( \left. y_2^{(i)} \right| \mu=0 \right) = \frac{n_2}{2} \log \left( \frac{\tau}{2 \pi} \right) - \frac{1}{2} \left[ \tau {y_2^{(i)}}^\mathrm{T} y_2^{(i)} \right] \; .
\end{equation}

By definition, the cross-validated log model evidence is the sum of out-of-sample log model evidences ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:cvlme}) over cross-validation folds, such that the cvLME of $m_0$ is:

\begin{equation} \label{eq:ugkv-cvlme-UGkv-m0-cvLME}
\begin{split}
\mathrm{cvLME}(m_0) &= \sum_{i=1}^S \mathrm{oosLME}_i(m_0) \\
&= \sum_{i=1}^S \left( \frac{n_2}{2} \log \left( \frac{\tau}{2 \pi} \right) - \frac{1}{2} \left[ \tau {y_2^{(i)}}^\mathrm{T} y_2^{(i)} \right] \right) \\
&= \frac{n}{2} \log \left( \frac{\tau}{2 \pi} \right) - \frac{1}{2} \left[ \tau y^\mathrm{T} y \right] \; .
\end{split}
\end{equation}

\vspace{1em}
Next, we have a look at the alternative $m_1$ assuming $\mu \neq 0$. First, the training data $y_1^{(i)}$ are analyzed using a non-informative prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior-inf}) and applying the posterior distribution for the univariate Gaussian with known variance ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:ugkv-post}):

\begin{equation} \label{eq:ugkv-cvlme-UGkv-m1-y1}
\begin{split}
\mu_0^{(1)} &= 0 \\
\lambda_0^{(1)} &= 0 \\
\mu_n^{(1)} &= \frac{\tau n_1 \bar{y}_1^{(i)} + \lambda_0^{(1)} \mu_0^{(1)}}{\tau n_1 + \lambda_0^{(1)}} = \bar{y}_1^{(i)} \\
\lambda_n^{(1)} &= \tau n_1 + \lambda_0^{(1)} = \tau n_1 \; .
\end{split}
\end{equation}

This results in a posterior characterized by $\mu_n^{(1)}$ and $\lambda_n^{(1)}$. Then, the test data $y_2^{(i)}$ are analyzed using this posterior as an informative prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior-inf}), again applying the posterior distribution for the univariate Gaussian with known variance ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:ugkv-post}):

\begin{equation} \label{eq:ugkv-cvlme-UGkv-m1-y2}
\begin{split}
\mu_0^{(2)} &= \mu_n^{(1)} = \bar{y}_1^{(i)} \\
\lambda_0^{(2)} &= \lambda_n^{(1)} = \tau n_1 \\
\mu_n^{(2)} &= \frac{\tau n_2 \bar{y}_2^{(i)} + \lambda_0^{(2)} \mu_0^{(2)}}{\tau n_2 + \lambda_0^{(2)}} = \bar{y} \\
\lambda_n^{(2)} &= \tau n_2 + \lambda_0^{(2)} = \tau n \; .
\end{split}
\end{equation}

In the test data, we now have a prior characterized by $\mu_0^{(2)}$/$\lambda_0^{(2)}$ and a posterior characterized $\mu_n^{(2)}$/$\lambda_n^{(2)}$. Applying the log model evidence for the univariate Gaussian with known variance ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:ugkv-lme}), the out-of-sample log model evidence ($\rightarrow$ Definition "ooslme") (oosLME) therefore follows as

\begin{equation} \label{eq:ugkv-cvlme-UGkv-m1-oosLME}
\begin{split}
\mathrm{oosLME}_i(m_1) &= \frac{n_2}{2} \log \left( \frac{\tau}{2 \pi} \right) + \frac{1}{2} \log \left( \frac{\lambda_0^{(2)}}{\lambda_n^{(2)}} \right) - \frac{1}{2} \left[ \tau {y_2^{(i)}}^\mathrm{T} y_2^{(i)} + \lambda_0^{(2)} {\mu_0^{(2)}}^2 - \lambda_n^{(2)} {\mu_n^{(2)}}^2 \right] \\
&= \frac{n_2}{2} \log \left( \frac{\tau}{2 \pi} \right) + \frac{1}{2} \log \left( \frac{n_1}{n} \right) - \frac{1}{2} \left[ \tau {y_2^{(i)}}^\mathrm{T} y_2^{(i)} + \frac{\tau}{n_1}\left(n_1 \bar{y}_1^{(i)}\right)^2 - \frac{\tau}{n}(n \bar{y})^2 \right] \; .
\end{split}
\end{equation}

Again, because the cross-validated log model evidence is the sum of out-of-sample log model evidences ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:cvlme}) over cross-validation folds, the cvLME of $m_1$ becomes:

\begin{equation} \label{eq:ugkv-cvlme-UGkv-m1-cvLME}
\begin{split}
\mathrm{cvLME}(m_1) &= \sum_{i=1}^S \mathrm{oosLME}_i(m_1) \\
&= \sum_{i=1}^S \left( \frac{n_2}{2} \log \left( \frac{\tau}{2 \pi} \right) + \frac{1}{2} \log \left( \frac{n_1}{n} \right) - \frac{1}{2} \left[ \tau {y_2^{(i)}}^\mathrm{T} y_2^{(i)} + \frac{\tau}{n_1}\left(n_1 \bar{y}_1^{(i)}\right)^2 - \frac{\tau}{n}(n \bar{y})^2 \right] \right) \\
&= \frac{S \cdot n_2}{2} \log \left( \frac{\tau}{2 \pi} \right) + \frac{S}{2} \log \left( \frac{n_1}{n} \right) - \frac{\tau}{2} \sum_{i=1}^S \left[ {y_2^{(i)}}^\mathrm{T} y_2^{(i)} + \frac{\left(n_1 \bar{y}_1^{(i)}\right)^2}{n_1} - \frac{(n \bar{y})^2}{n} \right] \\
&= \frac{n}{2} \log \left( \frac{\tau}{2 \pi} \right) + \frac{S}{2} \log \left( \frac{S-1}{S} \right) - \frac{\tau}{2} \left[ y^\mathrm{T} y + \sum_{i=1}^S \left( \frac{\left(n_1 \bar{y}_1^{(i)}\right)^2}{n_1} - \frac{(n \bar{y})^2}{n} \right) \right] \; .
\end{split}
\end{equation}

Together, \eqref{eq:ugkv-cvlme-UGkv-m0-cvLME} and \eqref{eq:ugkv-cvlme-UGkv-m1-cvLME} conform to the results given in \eqref{eq:ugkv-cvlme-UGkv-cvLME-m01}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P217 | shortcut: ugkv-cvlme | author: JoramSoch | date: 2021-03-24, 10:57.
\vspace{1em}



\subsubsection[\textbf{Cross-validated log Bayes factor}]{Cross-validated log Bayes factor} \label{sec:ugkv-cvlbf}
\setcounter{equation}{0}

\textbf{Theorem:} Let

\begin{equation} \label{eq:ugkv-cvlbf-ugkv}
y = \left\lbrace y_1, \ldots, y_n \right\rbrace, \quad y_i \sim \mathcal{N}(\mu, \sigma^2), \quad i = 1, \ldots, n
\end{equation}

be a univariate Gaussian data set ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:ugkv}) with unknown mean $\mu$ and known variance $\sigma^2$. Moreover, assume two statistical models ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:fpm}), one assuming that $\mu$ is zero (null model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:h0})), the other imposing a normal distribution ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:ugkv-prior}) as the prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) on the model parameter $\mu$ (alternative ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:h1})):

\begin{equation} \label{eq:ugkv-cvlbf-UGkv-m01}
\begin{split}
m_0&: \; y_i \sim \mathcal{N}(\mu, \sigma^2), \; \mu = 0 \\
m_1&: \; y_i \sim \mathcal{N}(\mu, \sigma^2), \; \mu \sim \mathcal{N}(\mu_0, \lambda_0^{-1}) \; .
\end{split}
\end{equation}

Then, the cross-validated ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:cvlme}) log Bayes factor ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lbf}) in favor of $m_1$ against $m_0$ is

\begin{equation} \label{eq:ugkv-cvlbf-UGkv-cvLBF}
\mathrm{cvLBF}_{10} = \frac{S}{2} \log \left( \frac{S-1}{S} \right) - \frac{\tau}{2} \sum_{i=1}^S \left( \frac{\left(n_1 \bar{y}_1^{(i)}\right)^2}{n_1} - \frac{(n \bar{y})^2}{n} \right)
\end{equation}

where $\bar{y}$ is the sample mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean-samp}), $\tau = 1/\sigma^2$ is the inverse variance or precision ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prec}), $y_1^{(i)}$ are the training data in the $i$-th cross-validation fold and $S$ is the number of data subsets ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:cvlme}).


\vspace{1em}
\textbf{Proof:} The relationship between log Bayes factor and log model evidences ($\rightarrow$ Proof \ref{sec:Model Selection}/\ref{sec:lbf-lme}) also holds for cross-validated log bayes factor ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lbf}) (cvLBF) and cross-validated log model evidences ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:cvlme}) (cvLME):

\begin{equation} \label{eq:ugkv-cvlbf-cvLBF-cvLME}
\mathrm{cvLBF}_{12} = \mathrm{cvLME}(m_1) - \mathrm{cvLME}(m_2) \; .
\end{equation}

The cross-validated log model evidences ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:cvlme}) of $m_0$ and $m_1$ are given by ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:ugkv-cvlme})

\begin{equation} \label{eq:ugkv-cvlbf-UGkv-cvLME-m01}
\begin{split}
\mathrm{cvLME}(m_0) &= \frac{n}{2} \log\left( \frac{\tau}{2 \pi} \right) - \frac{1}{2} \left( \tau y^\mathrm{T} y \right) \\
\mathrm{cvLME}(m_1) &= \frac{n}{2} \log \left( \frac{\tau}{2 \pi} \right) + \frac{S}{2} \log \left( \frac{S-1}{S} \right) - \frac{\tau}{2} \left[ y^\mathrm{T} y + \sum_{i=1}^S \left( \frac{\left(n_1 \bar{y}_1^{(i)}\right)^2}{n_1} - \frac{(n \bar{y})^2}{n} \right) \right] \; .
\end{split}
\end{equation}

Subtracting the two cvLMEs from each other, the cvLBF emerges as

\begin{equation} \label{eq:ugkv-cvlbf-UGkv-cvLBF-qed}
\begin{split}
\mathrm{cvLBF}_{10} &= \mathrm{cvLME}(m_1) - \mathrm{LME}(m_0) \\
&= \left( \frac{n}{2} \log \left( \frac{\tau}{2 \pi} \right) + \frac{S}{2} \log \left( \frac{S-1}{S} \right) - \frac{\tau}{2} \left[ y^\mathrm{T} y + \sum_{i=1}^S \left( \frac{\left(n_1 \bar{y}_1^{(i)}\right)^2}{n_1} - \frac{(n \bar{y})^2}{n} \right) \right] \right) \\
&- \left( \frac{n}{2} \log \left( \frac{\tau}{2 \pi} \right) - \frac{1}{2} \left( \tau y^\mathrm{T} y \right) \right) \\
&= \frac{S}{2} \log \left( \frac{S-1}{S} \right) - \frac{\tau}{2} \sum_{i=1}^S \left( \frac{\left(n_1 \bar{y}_1^{(i)}\right)^2}{n_1} - \frac{(n \bar{y})^2}{n} \right) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P218 | shortcut: ugkv-cvlbf | author: JoramSoch | date: 2021-03-24, 11:13.
\vspace{1em}



\subsubsection[\textbf{Expectation of cross-validated log Bayes factor}]{Expectation of cross-validated log Bayes factor} \label{sec:ugkv-cvlbfmean}
\setcounter{equation}{0}

\textbf{Theorem:} Let

\begin{equation} \label{eq:ugkv-cvlbfmean-ugkv}
y = \left\lbrace y_1, \ldots, y_n \right\rbrace, \quad y_i \sim \mathcal{N}(\mu, \sigma^2), \quad i = 1, \ldots, n
\end{equation}

be a univariate Gaussian data set ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:ugkv}) with unknown mean $\mu$ and known variance $\sigma^2$. Moreover, assume two statistical models ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:fpm}), one assuming that $\mu$ is zero (null model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:h0})), the other imposing a normal distribution ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:ugkv-prior}) as the prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) on the model parameter $\mu$ (alternative ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:h1})):

\begin{equation} \label{eq:ugkv-cvlbfmean-UGkv-m01}
\begin{split}
m_0&: \; y_i \sim \mathcal{N}(\mu, \sigma^2), \; \mu = 0 \\
m_1&: \; y_i \sim \mathcal{N}(\mu, \sigma^2), \; \mu \sim \mathcal{N}(\mu_0, \lambda_0^{-1}) \; .
\end{split}
\end{equation}

Then, the expectation ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of the cross-validated ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:cvlme}) log Bayes factor ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lbf}) (cvLBF) in favor of $m_1$ against $m_0$ is

\begin{equation} \label{eq:ugkv-cvlbfmean-UGkv-cvLBF}
\left\langle \mathrm{cvLBF}_{10} \right\rangle = \frac{S}{2} \log \left( \frac{S-1}{S} \right) + \frac{1}{2} \left[ \tau n \mu^2 \right]
\end{equation}

where $\tau = 1/\sigma^2$ is the inverse variance or precision ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prec}) and $S$ is the number of data subsets ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:cvlme}).


\vspace{1em}
\textbf{Proof:} The cross-validated log Bayes factor for the univariate Gaussian with known variance ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:ugkv-cvlbf}) is

\begin{equation} \label{eq:ugkv-cvlbfmean-UGkv-cvLBF-m10-s1}
\mathrm{cvLBF}_{10} = \frac{S}{2} \log \left( \frac{S-1}{S} \right) - \frac{\tau}{2} \sum_{i=1}^S \left( \frac{\left(n_1 \bar{y}_1^{(i)}\right)^2}{n_1} - \frac{(n \bar{y})^2}{n} \right)
\end{equation}

From \eqref{eq:ugkv-cvlbfmean-ugkv}, we know that the data are distributed as $y_i \sim \mathcal{N}(\mu, \sigma^2)$, such that we can derive the expectation ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of $(n \bar{y})^2$ and $\left(n_1 \bar{y}_1^{(i)}\right)^2$ as follows:

\begin{equation} \label{eq:ugkv-cvlbfmean-UGkv-E(ny2)}
\begin{split}
\left\langle (n \bar{y})^2 \right\rangle = \left\langle \sum_{i=1}^n \sum_{j=1}^n y_i y_j \right\rangle &= \left\langle n y_i^2 + (n^2-n) [y_i y_j]_{i \neq j} \right\rangle \\
&= n (\mu^2 + \sigma^2) + (n^2 - n) \mu^2 \\
&= n^2 \mu^2 + n \sigma^2 \; .
\end{split}
\end{equation}

Applying this expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) to \eqref{eq:ugkv-cvlbfmean-UGkv-cvLBF-m10-s1}, the expected cvLBF emerges as:

\begin{equation} \label{eq:ugkv-cvlbfmean-UGkv-cvLBF-m10-s2}
\begin{split}
\left\langle \mathrm{cvLBF}_{10} \right\rangle &= \left\langle \frac{S}{2} \log \left( \frac{S-1}{S} \right) - \frac{\tau}{2} \sum_{i=1}^S \left( \frac{\left(n_1 \bar{y}_1^{(i)}\right)^2}{n_1} - \frac{(n \bar{y})^2}{n} \right) \right\rangle \\
&= \frac{S}{2} \log \left( \frac{S-1}{S} \right) - \frac{\tau}{2} \sum_{i=1}^S \left( \frac{\left\langle \left(n_1 \bar{y}_1^{(i)}\right)^2 \right\rangle}{n_1} - \frac{\left\langle (n \bar{y})^2 \right\rangle}{n} \right) \\
&\overset{\eqref{eq:ugkv-cvlbfmean-UGkv-E(ny2)}}{=} \frac{S}{2} \log \left( \frac{S-1}{S} \right) - \frac{\tau}{2} \sum_{i=1}^S \left( \frac{n_1^2 \mu^2 + n_1 \sigma^2}{n_1} - \frac{n^2 \mu^2 + n \sigma^2}{n} \right) \\
&= \frac{S}{2} \log \left( \frac{S-1}{S} \right) - \frac{\tau}{2} \sum_{i=1}^S \left( [n_1 \mu^2 + \sigma^2] - [n \mu^2 + \sigma^2] \right) \\
&= \frac{S}{2} \log \left( \frac{S-1}{S} \right) - \frac{\tau}{2} \sum_{i=1}^S (n_1 - n) \mu^2
\end{split}
\end{equation}

Because it holds that ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:ugkv-cvlme}) $n_1 + n_2 = n$ and $n_2 = n/S$, we finally have:

\begin{equation} \label{eq:ugkv-cvlbfmean-UGkv-cvLBF-m10-s3}
\begin{split}
\left\langle \mathrm{cvLBF}_{10} \right\rangle &= \frac{S}{2} \log \left( \frac{S-1}{S} \right) - \frac{\tau}{2} \sum_{i=1}^S (-n_2) \mu^2 \\
&= \frac{S}{2} \log \left( \frac{S-1}{S} \right) + \frac{1}{2} \left[ \tau n \mu^2 \right] \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P219 | shortcut: ugkv-cvlbfmean | author: JoramSoch | date: 2021-03-24, 12:27.
\vspace{1em}



\subsection{Simple linear regression}

\subsubsection[\textit{Definition}]{Definition} \label{sec:slr}
\setcounter{equation}{0}

\textbf{Definition:} Let $y$ and $x$ be two $n \times 1$ vectors.

Then, a statement asserting a linear relationship between $x$ and $y$

\begin{equation} \label{eq:slr-slr-model}
y = \beta_0 + \beta_1 x + \varepsilon \; ,
\end{equation}

together with a statement asserting a normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mvn}) for $\varepsilon$

\begin{equation} \label{eq:slr-slr-noise}
\varepsilon \sim \mathcal{N}(0, \sigma^2 V)
\end{equation}

is called a univariate simple regression model or simply, "simple linear regression".

\begin{itemize}

\item $y$ is called "dependent variable", "measured data" or "signal";

\item $x$ is called "independent variable", "predictor" or "covariate";

\item $V$ is called "covariance matrix" or "covariance structure";

\item $\beta_1$ is called "slope of the regression line ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:regline})";

\item $\beta_0$ is called "intercept of the regression line ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:regline})";

\item $\varepsilon$ is called "noise", "errors" or "error terms";

\item $\sigma^2$ is called "noise variance" or "error variance";

\item $n$ is the number of observations.

\end{itemize}

When the covariance structure $V$ is equal to the $n \times n$ identity matrix, this is called simple linear regression with independent and identically distributed (i.i.d.) observations:

\begin{equation} \label{eq:slr-mlr-noise-iid}
V = I_n \quad \Rightarrow \quad \varepsilon \sim \mathcal{N}(0, \sigma^2 I_n) \quad \Rightarrow \quad \varepsilon_i \overset{\text{i.i.d.}}{\sim} \mathcal{N}(0, \sigma^2) \; .
\end{equation}

In this case, the linear regression model can also be written as

\begin{equation} \label{eq:slr-slr-model-sum}
y_i = \beta_0 + \beta_1 x_i + \varepsilon_i, \; \varepsilon_i \sim \mathcal{N}(0, \sigma^2) \; .
\end{equation}

Otherwise, it is called simple linear regression with correlated observations.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Simple linear regression"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-10-27; URL: \url{https://en.wikipedia.org/wiki/Simple_linear_regression#Fitting_the_regression_line}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D163 | shortcut: slr | author: JoramSoch | date: 2021-10-27, 07:07.
\vspace{1em}



\subsubsection[\textbf{Special case of multiple linear regression}]{Special case of multiple linear regression} \label{sec:slr-mlr}
\setcounter{equation}{0}

\textbf{Theorem:} Simple linear regression ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:slr}) is a special case of multiple linear regression ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}) with design matrix $X$ and regression coefficients $\beta$

\begin{equation} \label{eq:slr-mlr-slr-mlr}
X = \left[ \begin{matrix} 1_n & x \end{matrix} \right] \quad \text{and} \quad \beta = \left[ \begin{matrix} \beta_0 \\ \beta_1 \end{matrix} \right]
\end{equation}

where $1_n$ is an $n \times 1$ vector of ones, $x$ is the $n \times 1$ single predictor variable, $\beta_0$ is the intercept and $\beta_1$ is the slope of the regression line ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:regline}).


\vspace{1em}
\textbf{Proof:} Without loss of generality, consider the simple linear regression case with uncorrelated errors ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:slr}):

\begin{equation} \label{eq:slr-mlr-slr}
y_i = \beta_0 + \beta_1 x_i + \varepsilon_i, \; \varepsilon_i \sim \mathcal{N}(0, \sigma^2), \; i = 1,\ldots,n \; .
\end{equation}

In matrix notation and using the multivariate normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mvn}), this can also be written as

\begin{equation} \label{eq:slr-mlr-slr-mlr-s1}
\begin{split}
y &= \beta_0 1_n + \beta_1 x + \varepsilon, \; \varepsilon \sim \mathcal{N}(0, I_n) \\
y &= \left[ \begin{matrix} 1_n & x \end{matrix} \right] \left[ \begin{matrix} \beta_0 \\ \beta_1 \end{matrix} \right] + \varepsilon, \; \varepsilon \sim \mathcal{N}(0, I_n) \; .
\end{split}
\end{equation}

Comparing with the multiple linear regression equations for uncorrelated errors ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}), we finally note:

\begin{equation} \label{eq:slr-mlr-slr-mlr-s3}
y = X\beta + \varepsilon \quad \text{with} \quad X = \left[ \begin{matrix} 1_n & x \end{matrix} \right] \quad \text{and} \quad \beta = \left[ \begin{matrix} \beta_0 \\ \beta_1 \end{matrix} \right] \; .
\end{equation}

In the case of correlated observations ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:slr}), the error distribution changes to ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}):

\begin{equation} \label{eq:slr-mlr-mlr-noise}
\varepsilon \sim \mathcal{N}(0, \sigma^2 V) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P281 | shortcut: slr-mlr | author: JoramSoch | date: 2021-11-09, 07:57.
\vspace{1em}



\subsubsection[\textbf{Ordinary least squares}]{Ordinary least squares} \label{sec:slr-ols}
\setcounter{equation}{0}

\textbf{Theorem:} Given a simple linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:slr}) with independent observations

\begin{equation} \label{eq:slr-ols-slr}
y = \beta_0 + \beta_1 x + \varepsilon, \; \varepsilon_i \sim \mathcal{N}(0, \sigma^2), \; i = 1,\ldots,n \; ,
\end{equation}

the parameters minimizing the residual sum of squares ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:rss}) are given by

\begin{equation} \label{eq:slr-ols-slr-ols}
\begin{split}
\hat{\beta}_0 &= \bar{y} - \hat{\beta}_1 \bar{x} \\
\hat{\beta}_1 &= \frac{s_{xy}}{s_x^2}
\end{split}
\end{equation}

where $\bar{x}$ and $\bar{y}$ are the sample means ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean-samp}), $s_x^2$ is the sample variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var-samp}) of $x$ and $s_{xy}$ is the sample covariance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cov-samp}) between $x$ and $y$.


\vspace{1em}
\textbf{Proof:} The residual sum of squares ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:rss}) is defined as

\begin{equation} \label{eq:slr-ols-rss}
\mathrm{RSS}(\beta_0,\beta_1) = \sum_{i=1}^n \varepsilon_i^2 = \sum_{i=1}^n (y_i - \beta_0 - \beta_1 x_i)^2 \; .
\end{equation}

The derivatives of $\mathrm{RSS}(\beta_0,\beta_1)$ with respect to $\beta_0$ and $\beta_1$ are

\begin{equation} \label{eq:slr-ols-rss-der}
\begin{split}
\frac{\mathrm{d}\mathrm{RSS}(\beta_0,\beta_1)}{\mathrm{d}\beta_0} &= \sum_{i=1}^n 2 (y_i - \beta_0 - \beta_1 x_i) (-1) \\
&= -2 \sum_{i=1}^n (y_i - \beta_0 - \beta_1 x_i) \\
\frac{\mathrm{d}\mathrm{RSS}(\beta_0,\beta_1)}{\mathrm{d}\beta_1} &= \sum_{i=1}^n 2 (y_i - \beta_0 - \beta_1 x_i) (-x_i) \\
&= -2 \sum_{i=1}^n (x_i y_i - \beta_0 x_i - \beta_1 x_i^2)
\end{split}
\end{equation}

and setting these derivatives to zero

\begin{equation} \label{eq:slr-ols-rss-der-zero}
\begin{split}
0 &= -2 \sum_{i=1}^n (y_i - \hat{\beta}_0 - \hat{\beta}_1 x_i) \\
0 &= -2 \sum_{i=1}^n (x_i y_i - \hat{\beta}_0 x_i - \hat{\beta}_1 x_i^2)
\end{split}
\end{equation}

yields the following equations:

\begin{equation} \label{eq:slr-ols-slr-norm-eq}
\begin{split}
\hat{\beta}_1 \sum_{i=1}^n x_i + \hat{\beta}_0 \cdot n &= \sum_{i=1}^n y_i \\
\hat{\beta}_1 \sum_{i=1}^n x_i^2 + \hat{\beta}_0 \sum_{i=1}^n x_i &= \sum_{i=1}^n x_i y_i \; .
\end{split}
\end{equation}

From the first equation, we can derive the estimate for the intercept:

\begin{equation} \label{eq:slr-ols-slr-ols-int}
\begin{split}
\hat{\beta}_0 &= \frac{1}{n} \sum_{i=1}^n y_i - \hat{\beta}_1 \cdot \frac{1}{n} \sum_{i=1}^n x_i \\
&= \bar{y} - \hat{\beta}_1 \bar{x} \; .
\end{split}
\end{equation}

From the second equation, we can derive the estimate for the slope:

\begin{equation} \label{eq:slr-ols-slr-ols-sl}
\begin{split}
\hat{\beta}_1 \sum_{i=1}^n x_i^2 + \hat{\beta}_0 \sum_{i=1}^n x_i &= \sum_{i=1}^n x_i y_i \\
\hat{\beta}_1 \sum_{i=1}^n x_i^2 + \left( \bar{y} - \hat{\beta}_1 \bar{x} \right) \sum_{i=1}^n x_i &\overset{\eqref{eq:slr-ols-slr-ols-int}}{=} \sum_{i=1}^n x_i y_i \\
\hat{\beta}_1 \left( \sum_{i=1}^n x_i^2 - \bar{x} \sum_{i=1}^n x_i \right) &= \sum_{i=1}^n x_i y_i - \bar{y} \sum_{i=1}^n x_i \\
\hat{\beta}_1 &= \frac{\sum_{i=1}^n x_i y_i - \bar{y} \sum_{i=1}^n x_i}{\sum_{i=1}^n x_i^2 - \bar{x} \sum_{i=1}^n x_i} \; .
\end{split}
\end{equation}

Note that the numerator can be rewritten as

\begin{equation} \label{eq:slr-ols-slr-ols-sl-num}
\begin{split}
\sum_{i=1}^n x_i y_i - \bar{y} \sum_{i=1}^n x_i &= \sum_{i=1}^n x_i y_i - n \bar{x} \bar{y} \\
&= \sum_{i=1}^n x_i y_i - n \bar{x} \bar{y} - n \bar{x} \bar{y} + n \bar{x} \bar{y} \\
&= \sum_{i=1}^n x_i y_i - \bar{y} \sum_{i=1}^n x_i - \bar{x} \sum_{i=1}^n y_i + \sum_{i=1}^n \bar{x} \bar{y} \\
&= \sum_{i=1}^n \left( x_i y_i - x_i \bar{y} - \bar{x} y_i + \bar{x} \bar{y} \right) \\
&= \sum_{i=1}^n (x_i - \bar{x}) (y_i - \bar{y})
\end{split}
\end{equation}

and that the denominator can be rewritten as

\begin{equation} \label{eq:slr-ols-slr-ols-sl-den}
\begin{split}
\sum_{i=1}^n x_i^2 - \bar{x} \sum_{i=1}^n x_i &= \sum_{i=1}^n x_i^2 - n \bar{x}^2 \\
&= \sum_{i=1}^n x_i^2 - 2 n \bar{x} \bar{x} + n \bar{x}^2 \\
&= \sum_{i=1}^n x_i^2 - 2 \bar{x} \sum_{i=1}^n x_i - \sum_{i=1}^n \bar{x}^2 \\
&= \sum_{i=1}^n \left( x_i^2 - 2 \bar{x} x_i + \bar{x}^2 \right) \\
&= \sum_{i=1}^n (x_i - \bar{x})^2 \; .
\end{split}
\end{equation}

With \eqref{eq:slr-ols-slr-ols-sl-num} and \eqref{eq:slr-ols-slr-ols-sl-den}, the estimate from \eqref{eq:slr-ols-slr-ols-sl} can be simplified as follows:

\begin{equation} \label{eq:slr-ols-slr-ols-sl-qed}
\begin{split}
\hat{\beta}_1 &= \frac{\sum_{i=1}^n x_i y_i - \bar{y} \sum_{i=1}^n x_i}{\sum_{i=1}^n x_i^2 - \bar{x} \sum_{i=1}^n x_i} \\
&= \frac{\sum_{i=1}^n (x_i - \bar{x}) (y_i - \bar{y})}{\sum_{i=1}^n (x_i - \bar{x})^2} \\
&= \frac{\frac{1}{n-1} \sum_{i=1}^n (x_i - \bar{x}) (y_i - \bar{y})}{\frac{1}{n-1} \sum_{i=1}^n (x_i - \bar{x})^2} \\
&= \frac{s_{xy}}{s_x^2} \; .
\end{split}
\end{equation}

Together, \eqref{eq:slr-ols-slr-ols-int} and \eqref{eq:slr-ols-slr-ols-sl-qed} constitute the ordinary least squares parameter estimates for simple linear regression.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Penny, William (2006): "Linear regression"; in: \textit{Mathematics for Brain Imaging}, ch. 1.2.2, pp. 14-16, eqs. 1.24/1.25; URL: \url{https://ueapsylabs.co.uk/sites/wpenny/mbi/mbi_course.pdf}.
\item Wikipedia (2021): "Proofs involving ordinary least squares"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-10-27; URL: \url{https://en.wikipedia.org/wiki/Proofs_involving_ordinary_least_squares#Derivation_of_simple_linear_regression_estimators}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P271 | shortcut: slr-ols | author: JoramSoch | date: 2021-10-27, 08:56.
\vspace{1em}



\subsubsection[\textbf{Ordinary least squares}]{Ordinary least squares} \label{sec:slr-ols2}
\setcounter{equation}{0}

\textbf{Theorem:} Given a simple linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:slr}) with independent observations

\begin{equation} \label{eq:slr-ols2-slr}
y_i = \beta_0 + \beta_1 x_i + \varepsilon_i, \; \varepsilon_i \sim \mathcal{N}(0, \sigma^2), \; i = 1,\ldots,n \; ,
\end{equation}

the parameters minimizing the residual sum of squares ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:rss}) are given by

\begin{equation} \label{eq:slr-ols2-slr-ols}
\begin{split}
\hat{\beta}_0 &= \bar{y} - \hat{\beta}_1 \bar{x} \\
\hat{\beta}_1 &= \frac{s_{xy}}{s_x^2}
\end{split}
\end{equation}

where $\bar{x}$ and $\bar{y}$ are the sample means ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean-samp}), $s_x^2$ is the sample variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var-samp}) of $x$ and $s_{xy}$ is the sample covariance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cov-samp}) between $x$ and $y$.


\vspace{1em}
\textbf{Proof:} Simple linear regression is a special case of multiple linear regression ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:slr-mlr}) with

\begin{equation} \label{eq:slr-ols2-slr-mlr}
X = \left[ \begin{matrix} 1_n & x \end{matrix} \right] \quad \text{and} \quad \beta = \left[ \begin{matrix} \beta_0 \\ \beta_1 \end{matrix} \right]
\end{equation}

and ordinary least sqaures estimates ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mlr-ols}) are given by

\begin{equation} \label{eq:slr-ols2-mlr-ols}
\hat{\beta} = (X^\mathrm{T} X)^{-1} X^\mathrm{T} y \; .
\end{equation}

Writing out equation \eqref{eq:slr-ols2-mlr-ols}, we have

\begin{equation} \label{eq:slr-ols2-slr-ols-b}
\begin{split}
\hat{\beta} &= \left( \left[ \begin{matrix} 1_n^\mathrm{T} \\ x^\mathrm{T} \end{matrix} \right] \left[ \begin{matrix} 1_n & x \end{matrix} \right] \right)^{-1} \left[ \begin{matrix} 1_n^\mathrm{T} \\ x^\mathrm{T} \end{matrix} \right] y \\
&= \left( \left[ \begin{matrix} n & n\bar{x} \\ n\bar{x} & x^\mathrm{T} x \end{matrix} \right] \right)^{-1} \left[ \begin{matrix} n \bar{y} \\ x^\mathrm{T} y \end{matrix} \right] \\
&= \frac{1}{n x^\mathrm{T} x - (n\bar{x})^2} \left[ \begin{matrix} x^\mathrm{T} x & -n\bar{x} \\ -n\bar{x} & n \end{matrix} \right]  \left[ \begin{matrix} n \bar{y} \\ x^\mathrm{T} y \end{matrix} \right] \\
&= \frac{1}{n x^\mathrm{T} x - (n\bar{x})^2} \left[ \begin{matrix} n \bar{y} \, x^\mathrm{T} x - n \bar{x} \, x^\mathrm{T} y \\ n \, x^\mathrm{T} y - (n \bar{x})(n \bar{y}) \end{matrix} \right] \; .
\end{split}
\end{equation}

Thus, the second entry of $\hat{\beta}$ is equal to ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:slr-ols}):

\begin{equation} \label{eq:slr-ols2-slr-ols-b1}
\begin{split}
\hat{\beta}_1 &= \frac{n \, x^\mathrm{T} y - (n \bar{x})(n \bar{y})}{n x^\mathrm{T} x - (n\bar{x})^2} \\
&= \frac{x^\mathrm{T} y - n \bar{x} \bar{y}}{x^\mathrm{T} x - n \bar{x}^2} \\
&= \frac{\sum_{i=1}^n x_i y_i - \sum_{i=1}^n \bar{x} \bar{y}}{\sum_{i=1}^n x_i^2 - \sum_{i=1}^n \bar{x}^2} \\
&= \frac{\sum_{i=1}^n (x_i - \bar{x}) (y_i - \bar{y})}{\sum_{i=1}^n (x_i - \bar{x})^2} \\
&= \frac{s_{xy}}{s_x^2} \; .
\end{split}
\end{equation}

Moreover, the first entry of $\hat{\beta}$ is equal to:

\begin{equation} \label{eq:slr-ols2-slr-ols-b2}
\begin{split}
\hat{\beta}_0 &= \frac{n \bar{y} \, x^\mathrm{T} x - n \bar{x} \, x^\mathrm{T} y}{n x^\mathrm{T} x - (n\bar{x})^2} \\
&= \frac{\bar{y} \, x^\mathrm{T} x - \bar{x} \, x^\mathrm{T} y}{x^\mathrm{T} x - n \bar{x}^2} \\
&= \frac{\bar{y} \, x^\mathrm{T} x - \bar{x} \, x^\mathrm{T} y + n \bar{x}^2 \bar{y} - n \bar{x}^2 \bar{y}}{x^\mathrm{T} x - n \bar{x}^2} \\
&= \frac{\bar{y} (x^\mathrm{T} x - n \bar{x}^2) - \bar{x} (x^\mathrm{T} y - n \bar{x} \bar{y})}{x^\mathrm{T} x - n \bar{x}^2} \\
&= \frac{\bar{y} (x^\mathrm{T} x - n \bar{x}^2)}{x^\mathrm{T} x - n \bar{x}^2} - \frac{\bar{x} (x^\mathrm{T} y - n \bar{x} \bar{y})}{x^\mathrm{T} x - n \bar{x}^2} \\
&= \bar{y} - \bar{x} \, \frac{\sum_{i=1}^n x_i y_i - \sum_{i=1}^n \bar{x} \bar{y}}{\sum_{i=1}^n x_i^2 - \sum_{i=1}^n \bar{x}^2} \\
&= \bar{y} - \hat{\beta}_1 \bar{x} \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P288 | shortcut: slr-ols2 | author: JoramSoch | date: 2021-11-16, 09:36.
\vspace{1em}



\subsubsection[\textbf{Expectation of estimates}]{Expectation of estimates} \label{sec:slr-olsmean}
\setcounter{equation}{0}

\textbf{Theorem:} Assume a simple linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:slr}) with independent observations

\begin{equation} \label{eq:slr-olsmean-slr}
y = \beta_0 + \beta_1 x + \varepsilon, \; \varepsilon_i \sim \mathcal{N}(0, \sigma^2), \; i = 1,\ldots,n
\end{equation}

and consider estimation using ordinary least squares ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:slr-ols}). Then, the expected values ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of the estimated parameters are

\begin{equation} \label{eq:slr-olsmean-slr-ols-mean}
\begin{split}
\mathrm{E}(\hat{\beta}_0) &= \beta_0 \\
\mathrm{E}(\hat{\beta}_1) &= \beta_1
\end{split}
\end{equation}

which means that the ordinary least squares solution ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:slr-ols}) produces unbiased estimators ($\rightarrow$ Definition "est-unb").


\vspace{1em}
\textbf{Proof:} According to the simple linear regression model in \eqref{eq:slr-olsmean-slr}, the expectation of a single data point is

\begin{equation} \label{eq:slr-olsmean-E-yi}
\mathrm{E}(y_i) = \beta_0 + \beta_1 x_i \; .
\end{equation}

The ordinary least squares estimates for simple linear regression ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:slr-ols}) are given by

\begin{equation} \label{eq:slr-olsmean-slr-ols}
\begin{split}
\hat{\beta}_0 &= \frac{1}{n} \sum_{i=1}^n y_i - \hat{\beta}_1 \cdot \frac{1}{n} \sum_{i=1}^n x_i \\
\hat{\beta}_1 &= \frac{\sum_{i=1}^n (x_i - \bar{x}) (y_i - \bar{y})}{\sum_{i=1}^n (x_i - \bar{x})^2} \; .
\end{split}
\end{equation}

If we define the following quantity

\begin{equation} \label{eq:slr-olsmean-ci}
c_i = \frac{x_i - \bar{x}}{\sum_{i=1}^n (x_i - \bar{x})^2} \; ,
\end{equation}

we note that

\begin{equation} \label{eq:slr-olsmean-sum-ci}
\begin{split}
\sum_{i=1}^n c_i &= \frac{\sum_{i=1}^n (x_i - \bar{x})}{\sum_{i=1}^n (x_i - \bar{x})^2} = \frac{\sum_{i=1}^n x_i - n \bar{x}}{\sum_{i=1}^n (x_i - \bar{x})^2} \\
&= \frac{n \bar{x} - n \bar{x}}{\sum_{i=1}^n (x_i - \bar{x})^2} = 0 \; , \\
\end{split}
\end{equation}

and

\begin{equation} \label{eq:slr-olsmean-sum-ci-xi}
\begin{split}
\sum_{i=1}^n c_i x_i &= \frac{\sum_{i=1}^n (x_i - \bar{x}) x_i}{\sum_{i=1}^n (x_i - \bar{x})^2} = \frac{\sum_{i=1}^n \left( x_i^2 - \bar{x} x_i \right)}{\sum_{i=1}^n (x_i - \bar{x})^2} \\
&= \frac{\sum_{i=1}^n x_i^2 - 2 n \bar{x} \bar{x} + n \bar{x}^2}{\sum_{i=1}^n (x_i - \bar{x})^2} = \frac{\sum_{i=1}^n \left( x_i^2 - 2 \bar{x} x_i + \bar{x}^2 \right)}{\sum_{i=1}^n (x_i - \bar{x})^2} \\
&= \frac{\sum_{i=1}^n (x_i - \bar{x})^2}{\sum_{i=1}^n (x_i - \bar{x})^2} = 1 \; .
\end{split}
\end{equation}

With \eqref{eq:slr-olsmean-ci}, the estimate for the slope from \eqref{eq:slr-olsmean-slr-ols} becomes

\begin{equation} \label{eq:slr-olsmean-slr-ols-sl}
\begin{split}
\hat{\beta}_1 &= \frac{\sum_{i=1}^n (x_i - \bar{x}) (y_i - \bar{y})}{\sum_{i=1}^n (x_i - \bar{x})^2} \\
&= \sum_{i=1}^n c_i (y_i - \bar{y}) \\
&= \sum_{i=1}^n c_i y_i - \bar{y} \sum_{i=1}^n c_i
\end{split}
\end{equation}

and with \eqref{eq:slr-olsmean-E-yi}, \eqref{eq:slr-olsmean-sum-ci} and \eqref{eq:slr-olsmean-sum-ci-xi}, its expectation becomes:

\begin{equation} \label{eq:slr-olsmean-E-b1}
\begin{split}
\mathrm{E}(\hat{\beta}_1) &= \mathrm{E}\left( \sum_{i=1}^n c_i y_i - \bar{y} \sum_{i=1}^n c_i \right) \\
&= \sum_{i=1}^n c_i \mathrm{E}(y_i) - \bar{y} \sum_{i=1}^n c_i \\
&= \beta_1 \sum_{i=1}^n c_i x_i + \beta_0 \sum_{i=1}^n c_i - \bar{y} \sum_{i=1}^n c_i \\
&= \beta_1 \; .
\end{split}
\end{equation}

Finally, with \eqref{eq:slr-olsmean-E-yi} and \eqref{eq:slr-olsmean-E-b1}, the expectation of the intercept estimate from \eqref{eq:slr-olsmean-slr-ols} becomes

\begin{equation} \label{eq:slr-olsmean-E-b0}
\begin{split}
\mathrm{E}(\hat{\beta}_0) &= \mathrm{E}\left( \frac{1}{n} \sum_{i=1}^n y_i - \hat{\beta}_1 \cdot \frac{1}{n} \sum_{i=1}^n x_i \right) \\
&= \frac{1}{n} \sum_{i=1}^n \mathrm{E}(y_i) - \mathrm{E}(\hat{\beta}_1) \cdot \bar{x} \\
&= \frac{1}{n} \sum_{i=1}^n (\beta_0 + \beta_1 x_i) - \beta_1 \cdot \bar{x} \\
&= \beta_0 + \beta_1 \bar{x} - \beta_1 \bar{x} \\
&= \beta_0 \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Penny, William (2006): "Finding the uncertainty in estimating the slope"; in: \textit{Mathematics for Brain Imaging}, ch. 1.2.4, pp. 18-20, eq. 1.37; URL: \url{https://ueapsylabs.co.uk/sites/wpenny/mbi/mbi_course.pdf}.
\item Wikipedia (2021): "Proofs involving ordinary least squares"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-10-27; URL: \url{https://en.wikipedia.org/wiki/Proofs_involving_ordinary_least_squares#Unbiasedness_and_variance_of_%7F'%22%60UNIQ--postMath-00000037-QINU%60%22'%7F}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P272 | shortcut: slr-olsmean | author: JoramSoch | date: 2021-10-27, 09:54.
\vspace{1em}



\subsubsection[\textbf{Variance of estimates}]{Variance of estimates} \label{sec:slr-olsvar}
\setcounter{equation}{0}

\textbf{Theorem:} Assume a simple linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:slr}) with independent observations

\begin{equation} \label{eq:slr-olsvar-slr}
y = \beta_0 + \beta_1 x + \varepsilon, \; \varepsilon_i \sim \mathcal{N}(0, \sigma^2), \; i = 1,\ldots,n
\end{equation}

and consider estimation using ordinary least squares ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:slr-ols}). Then, the variances ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) of the estimated parameters are

\begin{equation} \label{eq:slr-olsvar-slr-ols-var}
\begin{split}
\mathrm{Var}(\hat{\beta}_0) &= \frac{x^\mathrm{T} x}{n} \cdot \frac{\sigma^2}{(n-1) s_x^2} \\
\mathrm{Var}(\hat{\beta}_1) &= \frac{\sigma^2}{(n-1) s_x^2}
\end{split}
\end{equation}

where $s_x^2$ is the sample variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var-samp}) of $x$ and $x^\mathrm{T} x$ is the sum of squared values of the covariate.


\vspace{1em}
\textbf{Proof:} According to the simple linear regression model in \eqref{eq:slr-olsvar-slr}, the variance of a single data point is

\begin{equation} \label{eq:slr-olsvar-Var-yi}
\mathrm{Var}(y_i) = \mathrm{Var}(\varepsilon_i) = \sigma^2 \; .
\end{equation}

The ordinary least squares estimates for simple linear regression ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:slr-ols}) are given by

\begin{equation} \label{eq:slr-olsvar-slr-ols}
\begin{split}
\hat{\beta}_0 &= \frac{1}{n} \sum_{i=1}^n y_i - \hat{\beta}_1 \cdot \frac{1}{n} \sum_{i=1}^n x_i \\
\hat{\beta}_1 &= \frac{\sum_{i=1}^n (x_i - \bar{x}) (y_i - \bar{y})}{\sum_{i=1}^n (x_i - \bar{x})^2} \; .
\end{split}
\end{equation}

If we define the following quantity

\begin{equation} \label{eq:slr-olsvar-ci}
c_i = \frac{x_i - \bar{x}}{\sum_{i=1}^n (x_i - \bar{x})^2} \; ,
\end{equation}

we note that

\begin{equation} \label{eq:slr-olsvar-sum-ci2}
\begin{split}
\sum_{i=1}^n c_i^2 &= \sum_{i=1}^n \left( \frac{x_i - \bar{x}}{\sum_{i=1}^n (x_i - \bar{x})^2} \right)^2 \\
&= \frac{\sum_{i=1}^n (x_i - \bar{x})^2}{\left[ \sum_{i=1}^n (x_i - \bar{x})^2 \right]^2} \\
&= \frac{1}{\sum_{i=1}^n (x_i - \bar{x})^2} \; .
\end{split}
\end{equation}

With \eqref{eq:slr-olsvar-ci}, the estimate for the slope from \eqref{eq:slr-olsvar-slr-ols} becomes

\begin{equation} \label{eq:slr-olsvar-slr-ols-sl}
\begin{split}
\hat{\beta}_1 &= \frac{\sum_{i=1}^n (x_i - \bar{x}) (y_i - \bar{y})}{\sum_{i=1}^n (x_i - \bar{x})^2} \\
&= \sum_{i=1}^n c_i (y_i - \bar{y}) \\
&= \sum_{i=1}^n c_i y_i - \bar{y} \sum_{i=1}^n c_i
\end{split}
\end{equation}

and with \eqref{eq:slr-olsvar-Var-yi} and \eqref{eq:slr-olsvar-sum-ci2} as well as invariance ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:var-inv}), scaling ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:var-scal}) and additivity ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:var-add}) of the variance, the variance of $\hat{\beta}_1$ is:

\begin{equation} \label{eq:slr-olsvar-Var-b1}
\begin{split}
\mathrm{Var}(\hat{\beta}_1) &= \mathrm{Var}\left( \sum_{i=1}^n c_i y_i - \bar{y} \sum_{i=1}^n c_i \right) \\
&= \mathrm{Var}\left( \sum_{i=1}^n c_i y_i \right) \\
&= \sum_{i=1}^n c_i^2 \mathrm{Var}(y_i) \\
&= \sigma^2 \sum_{i=1}^n c_i^2 \\
&= \sigma^2 \frac{1}{\sum_{i=1}^n (x_i - \bar{x})^2} \\
&= \frac{\sigma^2}{(n-1) \frac{1}{n-1} \sum_{i=1}^n (x_i - \bar{x})^2} \\
&= \frac{\sigma^2}{(n-1) s_x^2} \; .
\end{split}
\end{equation}

Finally, with \eqref{eq:slr-olsvar-Var-yi} and \eqref{eq:slr-olsvar-Var-b1}, the variance of the intercept estimate from \eqref{eq:slr-olsvar-slr-ols} becomes:

\begin{equation} \label{eq:slr-olsvar-Var-b0-s1}
\begin{split}
\mathrm{Var}(\hat{\beta}_0) &= \mathrm{Var}\left( \frac{1}{n} \sum_{i=1}^n y_i - \hat{\beta}_1 \cdot \frac{1}{n} \sum_{i=1}^n x_i \right) \\
&= \mathrm{Var}\left( \frac{1}{n} \sum_{i=1}^n y_i \right) + \mathrm{Var}\left( \hat{\beta}_1 \cdot \bar{x} \right) \\
&= \left( \frac{1}{n} \right)^2 \sum_{i=1}^n \mathrm{Var}(y_i) + \bar{x}^2 \cdot \mathrm{Var}(\hat{\beta}_1) \\
&= \frac{1}{n^2} \sum_{i=1}^n \sigma^2 + \bar{x}^2 \frac{\sigma^2}{(n-1) s_x^2} \\
&= \frac{\sigma^2}{n} + \frac{\sigma^2 \bar{x}^2 }{(n-1) s_x^2} \; .
\end{split}
\end{equation}

Applying the formula for the sample variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var-samp}) $s_x^2$, we finally get:

\begin{equation} \label{eq:slr-olsvar-Var-b0-s2}
\begin{split}
\mathrm{Var}(\hat{\beta}_0) &= \sigma^2 \left( \frac{1}{n} + \frac{\bar{x}^2}{\sum_{i=1}^n (x_i - \bar{x})^2} \right) \\
&= \sigma^2 \left( \frac{\frac{1}{n}\sum_{i=1}^n (x_i - \bar{x})^2}{\sum_{i=1}^n (x_i - \bar{x})^2} + \frac{\bar{x}^2}{\sum_{i=1}^n (x_i - \bar{x})^2} \right) \\
&= \sigma^2 \left( \frac{\frac{1}{n}\sum_{i=1}^n \left( x_i^2 - 2 \bar{x} x_i + \bar{x}^2 \right) + \bar{x}^2}{\sum_{i=1}^n (x_i - \bar{x})^2} \right) \\
&= \sigma^2 \left( \frac{\left( \frac{1}{n}\sum_{i=1}^n x_i^2 - 2 \bar{x} \frac{1}{n}\sum_{i=1}^n x_i + \bar{x}^2 \right) + \bar{x}^2}{\sum_{i=1}^n (x_i - \bar{x})^2} \right) \\
&= \sigma^2 \left( \frac{\frac{1}{n}\sum_{i=1}^n x_i^2 - 2 \bar{x}^2 + 2 \bar{x}^2}{\sum_{i=1}^n (x_i - \bar{x})^2} \right) \\
&= \sigma^2 \left( \frac{\frac{1}{n}\sum_{i=1}^n x_i^2}{(n-1) \frac{1}{n-1} \sum_{i=1}^n (x_i - \bar{x})^2} \right) \\
&= \frac{x^\mathrm{T} x}{n} \cdot \frac{\sigma^2}{(n-1) s_x^2} \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Penny, William (2006): "Finding the uncertainty in estimating the slope"; in: \textit{Mathematics for Brain Imaging}, ch. 1.2.4, pp. 18-20, eq. 1.37; URL: \url{https://ueapsylabs.co.uk/sites/wpenny/mbi/mbi_course.pdf}.
\item Wikipedia (2021): "Proofs involving ordinary least squares"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-10-27; URL: \url{https://en.wikipedia.org/wiki/Proofs_involving_ordinary_least_squares#Unbiasedness_and_variance_of_%7F'%22%60UNIQ--postMath-00000037-QINU%60%22'%7F}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P273 | shortcut: slr-olsvar | author: JoramSoch | date: 2021-10-27, 11:53.
\vspace{1em}



\subsubsection[\textbf{Distribution of estimates}]{Distribution of estimates} \label{sec:slr-olsdist}
\setcounter{equation}{0}

\textbf{Theorem:} Assume a simple linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:slr}) with independent observations

\begin{equation} \label{eq:slr-olsdist-slr}
y = \beta_0 + \beta_1 x + \varepsilon, \; \varepsilon_i \sim \mathcal{N}(0, \sigma^2)
\end{equation}

and consider estimation using ordinary least squares ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:slr-ols}). Then, the estimated parameters are normally distributed ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mvn}) as

\begin{equation} \label{eq:slr-olsdist-slr-olsdist}
\left[ \begin{matrix} \hat{\beta}_0 \\ \hat{\beta}_1 \end{matrix} \right] \sim \mathcal{N}\left( \left[ \begin{matrix} \beta_0 \\ \beta_1 \end{matrix} \right], \, \frac{\sigma^2}{(n-1) \, s_x^2} \cdot \left[ \begin{matrix} x^\mathrm{T}x/n & -\bar{x} \\ -\bar{x} & 1 \end{matrix} \right] \right)
\end{equation}

where $\bar{x}$ is the sample mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean-samp}) and $s_x^2$ is the sample variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var-samp}) of $x$.


\vspace{1em}
\textbf{Proof:} Simple linear regression is a special case of multiple linear regression ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:slr-mlr}) with

\begin{equation} \label{eq:slr-olsdist-slr-mlr}
X = \left[ \begin{matrix} 1_n & x \end{matrix} \right] \quad \text{and} \quad \beta = \left[ \begin{matrix} \beta_0 \\ \beta_1 \end{matrix} \right] \; ,
\end{equation}

such that \eqref{eq:slr-olsdist-slr} can also be written as

\begin{equation} \label{eq:slr-olsdist-mlr}
y = X\beta + \varepsilon, \; \varepsilon \sim \mathcal{N}(0, \sigma^2 I_n)
\end{equation}

and ordinary least sqaures estimates ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mlr-ols}) are given by

\begin{equation} \label{eq:slr-olsdist-mlr-ols}
\hat{\beta} = (X^\mathrm{T} X)^{-1} X^\mathrm{T} y \; .
\end{equation}

From \eqref{eq:slr-olsdist-mlr} and the linear transformation theorem for the multivariate normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mvn-ltt}), it follows that

\begin{equation} \label{eq:slr-olsdist-y-dist}
y \sim \mathcal{N}\left( X\beta, \, \sigma^2 I_n \right) \; .
\end{equation}

From \eqref{eq:slr-olsdist-mlr-ols}, in combination with \eqref{eq:slr-olsdist-y-dist} and the transformation theorem ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mvn-ltt}), it follows that

\begin{equation} \label{eq:slr-olsdist-b-est-dist}
\begin{split}
\hat{\beta} &\sim \mathcal{N}\left( (X^\mathrm{T} X)^{-1} X^\mathrm{T} X\beta, \, \sigma^2 (X^\mathrm{T} X)^{-1} X^\mathrm{T} I_n X (X^\mathrm{T} X)^{-1} \right) \\
&\sim \mathcal{N}\left( \beta, \, \sigma^2 (X^\mathrm{T} X)^{-1} \right) \; .
\end{split}
\end{equation}

Applying \eqref{eq:slr-olsdist-slr-mlr}, the covariance matrix ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mvn}) can be further developed as follows:

\begin{equation} \label{eq:slr-olsdist-b-est-cov}
\begin{split}
\sigma^2 (X^\mathrm{T} X)^{-1} &= \sigma^2 \left( \left[ \begin{matrix} 1_n^\mathrm{T} \\ x^\mathrm{T} \end{matrix} \right] \left[ \begin{matrix} 1_n & x \end{matrix} \right] \right)^{-1} \\
&= \sigma^2 \left( \left[ \begin{matrix} n & n\bar{x} \\ n\bar{x} & x^\mathrm{T} x \end{matrix} \right] \right)^{-1} \\
&= \frac{\sigma^2}{n x^\mathrm{T} x - (n\bar{x})^2} \left[ \begin{matrix} x^\mathrm{T} x & -n\bar{x} \\ -n\bar{x} & n \end{matrix} \right] \\
&= \frac{\sigma^2}{x^\mathrm{T} x - n\bar{x}^2} \left[ \begin{matrix} x^\mathrm{T} x/n & -\bar{x} \\ -\bar{x} & 1 \end{matrix} \right] \; .
\end{split}
\end{equation}

Note that the denominator in the first factor is equal to

\begin{equation} \label{eq:slr-olsdist-b-est-cov-den}
\begin{split}
x^\mathrm{T} x - n\bar{x}^2 &= x^\mathrm{T} x - 2 n\bar{x}^2 + n\bar{x}^2 \\
&= \sum_{i=1}^{n} x_i^2 - 2 n \bar{x} \frac{1}{n} \sum_{i=1}^{n} x_i + \sum_{i=1}^{n} \bar{x}^2 \\
&= \sum_{i=1}^{n} x_i^2 - 2 \sum_{i=1}^{n} x_i \bar{x} + \sum_{i=1}^{n} \bar{x}^2 \\
&= \sum_{i=1}^{n} \left( x_i^2 - 2 x_i \bar{x} + \bar{x}^2 \right) \\
&= \sum_{i=1}^{n} \left( x_i^2 - \bar{x} \right)^2 \\
&= (n-1) \, s_x^2 \; .
\end{split}
\end{equation}

Thus, combining \eqref{eq:slr-olsdist-b-est-dist}, \eqref{eq:slr-olsdist-b-est-cov} and \eqref{eq:slr-olsdist-b-est-cov-den}, we have

\begin{equation} \label{eq:slr-olsdist-slr-olsdist-qed}
\hat{\beta} \sim \mathcal{N}\left( \beta, \, \frac{\sigma^2}{(n-1) \, s_x^2} \cdot \left[ \begin{matrix} x^\mathrm{T}x/n & -\bar{x} \\ -\bar{x} & 1 \end{matrix} \right] \right)
\end{equation}

which is equivalent to equation \eqref{eq:slr-olsdist-slr-olsdist}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Proofs involving ordinary least squares"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-11-09; URL: \url{https://en.wikipedia.org/wiki/Proofs_involving_ordinary_least_squares#Unbiasedness_and_variance_of_%7F'%22%60UNIQ--postMath-00000037-QINU%60%22'%7F}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P282 | shortcut: slr-olsdist | author: JoramSoch | date: 2021-11-09, 09:09.
\vspace{1em}



\subsubsection[\textbf{Effects of mean-centering}]{Effects of mean-centering} \label{sec:slr-meancent}
\setcounter{equation}{0}

\textbf{Theorem:} In simple linear regression ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:slr}), when the independent variable $y$ and/or the dependent variable $x$ are mean-centered ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}), the ordinary least squares ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:slr-ols}) estimate for the intercept changes, but that of the slope does not.

\vspace{1em}
\textbf{Proof:}

1) Under unaltered $y$ and $x$, ordinary least squares estimates for simple linear regression ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:slr-ols}) are

\begin{equation} \label{eq:slr-meancent-slr-ols}
\begin{split}
\hat{\beta}_0 &= \bar{y} - \hat{\beta}_1 \bar{x} \\
\hat{\beta}_1 &= \frac{\sum_{i=1}^n (x_i - \bar{x}) (y_i - \bar{y})}{\sum_{i=1}^n (x_i - \bar{x})^2} = \frac{s_{xy}}{s_x^2}
\end{split}
\end{equation}

with sample means ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean-samp}) $\bar{x}$ and $\bar{y}$, sample variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var-samp}) $s_x^2$ and sample covariance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cov-samp}) $s_{xy}$, such that $\beta_0$ estimates "the mean $y$ at $x = 0$".

\vspace{1em}
2) Let $\tilde{x}$ be the mean-centered covariate vector ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:slr}):

\begin{equation} \label{eq:slr-meancent-slr-meancent-x}
\tilde{x}_i = x_i - \bar{x} \quad \Rightarrow \quad \bar{\tilde{x}} = 0 \; .
\end{equation}

Under this condition, the parameter estimates become

\begin{equation} \label{eq:slr-meancent-slr-ols-meancent-x}
\begin{split}
\hat{\beta}_0 &= \bar{y} - \hat{\beta}_1 \bar{\tilde{x}} \\
&= \bar{y} \\
\hat{\beta}_1 &= \frac{\sum_{i=1}^n (\tilde{x}_i - \bar{\tilde{x}}) (y_i - \bar{y})}{\sum_{i=1}^n (\tilde{x}_i - \bar{\tilde{x}})^2} \\
&= \frac{\sum_{i=1}^n (x_i - \bar{x}) (y_i - \bar{y})}{\sum_{i=1}^n (x_i - \bar{x})^2} = \frac{s_{xy}}{s_x^2}
\end{split}
\end{equation}

and we can see that $\hat{\beta}_1(\tilde{x},y) = \hat{\beta}_1(x,y)$, but $\hat{\beta}_0(\tilde{x},y) \neq \hat{\beta}_0(x,y)$, specifically $\beta_0$ now estimates "the mean $y$ at the mean $x$".


\vspace{1em} 
3) Let $\tilde{y}$ be the mean-centered data vector ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:slr}):

\begin{equation} \label{eq:slr-meancent-slr-meancent-y}
\tilde{y}_i = y_i - \bar{y} \quad \Rightarrow \quad \bar{\tilde{y}} = 0 \; .
\end{equation}

Under this condition, the parameter estimates become

\begin{equation} \label{eq:slr-meancent-slr-ols-meancent-y}
\begin{split}
\hat{\beta}_0 &= \bar{\tilde{y}} - \hat{\beta}_1 \bar{x} \\
&= - \hat{\beta}_1 \bar{x} \\
\hat{\beta}_1 &= \frac{\sum_{i=1}^n (x_i - \bar{x}) (\tilde{y}_i - \bar{\tilde{y}})}{\sum_{i=1}^n (x_i - \bar{x})^2} \\
&= \frac{\sum_{i=1}^n (x_i - \bar{x}) (y_i - \bar{y})}{\sum_{i=1}^n (x_i - \bar{x})^2} = \frac{s_{xy}}{s_x^2}
\end{split}
\end{equation}

and we can see that $\hat{\beta}_1(x,\tilde{y}) = \hat{\beta}_1(x,y)$, but $\hat{\beta}_0(x,\tilde{y}) \neq \hat{\beta}_0(x,y)$, specifically $\beta_0$ now estimates "the mean $x$, multiplied with the negative slope".

\vspace{1em} 
4) Finally, consider mean-centering both $x$ and $y$::

\begin{equation} \label{eq:slr-meancent-slr-meancent-xy}
\begin{split}
\tilde{x}_i = x_i - \bar{x} \quad &\Rightarrow \quad \bar{\tilde{x}} = 0 \\
\tilde{y}_i = y_i - \bar{y} \quad &\Rightarrow \quad \bar{\tilde{y}} = 0 \; .
\end{split}
\end{equation}

Under this condition, the parameter estimates become

\begin{equation} \label{eq:slr-meancent-slr-ols-meancent-xy}
\begin{split}
\hat{\beta}_0 &= \bar{\tilde{y}} - \hat{\beta}_1 \bar{\tilde{x}} \\
&= 0 \\
\hat{\beta}_1 &= \frac{\sum_{i=1}^n (\tilde{x}_i - \bar{\tilde{x}}) (\tilde{y}_i - \bar{\tilde{y}})}{\sum_{i=1}^n (\tilde{x}_i - \bar{\tilde{x}})^2} \\
&= \frac{\sum_{i=1}^n (x_i - \bar{x}) (y_i - \bar{y})}{\sum_{i=1}^n (x_i - \bar{x})^2} = \frac{s_{xy}}{s_x^2}
\end{split}
\end{equation}

and we can see that $\hat{\beta}_1(\tilde{x},\tilde{y}) = \hat{\beta}_1(x,y)$, but $\hat{\beta}_0(\tilde{x},\tilde{y}) \neq \hat{\beta}_0(x,y)$, specifically $\beta_0$ is now forced to become zero.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P274 | shortcut: slr-meancent | author: JoramSoch | date: 2021-10-27, 12:38.
\vspace{1em}



\subsubsection[\textit{Regression line}]{Regression line} \label{sec:regline}
\setcounter{equation}{0}

\textbf{Definition:} Let there be a simple linear regression with independent observations ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:slr}) using dependent variable $y$ and independent variable $x$:

\begin{equation} \label{eq:regline-slr}
y_i = \beta_0 + \beta_1 x_i + \varepsilon_i, \; \varepsilon_i \sim \mathcal{N}(0, \sigma^2) \; .
\end{equation}

Then, given some parameters $\beta_0, \beta_1 \in \mathbb{R}$, the set

\begin{equation} \label{eq:regline-regline}
L(\beta_0, \beta_1) = \left\lbrace (x,y) \in \mathbb{R}^2 \mid y = \beta_0 + \beta_1 x \right\rbrace
\end{equation}

is called a "regression line" and the set

\begin{equation} \label{eq:regline-regline-ols}
L(\hat{\beta}_0, \hat{\beta}_1)
\end{equation}

is called the "fitted regression line", with estimated regression coefficients $\hat{\beta}_0, \hat{\beta}_1$, e.g. obtained via ordinary least squares ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:slr-ols}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Simple linear regression"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-10-27; URL: \url{https://en.wikipedia.org/wiki/Simple_linear_regression#Fitting_the_regression_line}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D164 | shortcut: regline | author: JoramSoch | date: 2021-10-27, 07:30.
\vspace{1em}



\subsubsection[\textbf{Regression line includes center of mass}]{Regression line includes center of mass} \label{sec:slr-comp}
\setcounter{equation}{0}

\textbf{Theorem:} In simple linear regression ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:slr}), the regression line ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:regline}) estimated using ordinary least squares ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:slr-ols}) includes the point $M(\bar{x},\bar{y})$.

\vspace{1em}
\textbf{Proof:} The fitted regression line ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:regline}) is described by the equation

\begin{equation} \label{eq:slr-comp-slr-ols-regline}
y = \hat{\beta}_0 + \hat{\beta}_1 x \quad \text{where} \quad x,y \in \mathbb{R} \; .
\end{equation}

Plugging in the coordinates of $M$ and the ordinary least squares estimate of the intercept ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:slr-ols}), we obtain

\begin{equation} \label{eq:slr-comp-slr-ols}
\begin{split}
\bar{y} &= \hat{\beta}_0 + \hat{\beta}_1 \bar{x} \\
\bar{y} &= \bar{y} - \hat{\beta}_1 \bar{x} + \hat{\beta}_1 \bar{x} \\
\bar{y} &= \bar{y} \; .
\end{split}
\end{equation}

which is a true statement. Thus, the regression line ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:regline}) goes through the center of mass point $(\bar{x},\bar{y})$, if the model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:slr}) includes an intercept term $\beta_0$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Simple linear regression"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-10-27; URL: \url{https://en.wikipedia.org/wiki/Simple_linear_regression#Numerical_properties}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P275 | shortcut: slr-comp | author: JoramSoch | date: 2021-10-27, 12:52.
\vspace{1em}



\subsubsection[\textbf{Projection of data point to regression line}]{Projection of data point to regression line} \label{sec:slr-proj}
\setcounter{equation}{0}

\textbf{Theorem:} Consider simple linear regression ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:slr}) and an estimated regression line ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:regline}) specified by

\begin{equation} \label{eq:slr-proj-slr-regline}
y = \hat{\beta}_0 + \hat{\beta}_1 x \quad \text{where} \quad x,y \in \mathbb{R} \; .
\end{equation}

For any given data point $O(x_o \vert y_o)$, the point on the regression line $P(x_p \vert y_p)$ that is closest to this data point is given by:

\begin{equation} \label{eq:slr-proj-slr-proj}
P\left(w \mid \hat{\beta}_0 + \hat{\beta}_1 w\right) \quad \text{with} \quad w = \frac{x_0 + (y_o - \hat{\beta}_0) \hat{\beta}_1}{1 + \hat{\beta}_1^2} \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The intersection point of the regression line ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:regline}) with the y-axis is

\begin{equation} \label{eq:slr-proj-S}
S(0 \vert \hat{\beta}_0) \; .
\end{equation}

Let $a$ be a vector describing the direction of the regression line, let $b$ be the vector pointing from $S$ to $O$ and let $p$ be the vector pointing from $S$ to $P$.

Because $\hat{\beta}_1$ is the slope of the regression line, we have

\begin{equation} \label{eq:slr-proj-a}
a = \left( \begin{matrix} 1 \\ \hat{\beta}_1 \end{matrix} \right) \; .
\end{equation}

Moreover, with the points $O$ and $S$, we have

\begin{equation} \label{eq:slr-proj-b}
b = \left( \begin{matrix} x_o \\ y_o \end{matrix} \right) - \left( \begin{matrix} 0 \\ \hat{\beta}_0 \end{matrix} \right) = \left( \begin{matrix} x_o \\ y_o - \hat{\beta}_0 \end{matrix} \right) \; .
\end{equation}

Because $P$ is located on the regression line, $p$ is collinear with $a$ and thus a scalar multiple of this vector:

\begin{equation} \label{eq:slr-proj-p}
p = w \cdot a \; .
\end{equation}

Moreover, as $P$ is the point on the regression line which is closest to $O$, this means that the vector $b-p$ is orthogonal to $a$, such that the inner product of these two vectors is equal to zero:

\begin{equation} \label{eq:slr-proj-a-b-p-orth}
a^\mathrm{T} (b-p) = 0 \; .
\end{equation}

Rearranging this equation gives

\begin{equation} \label{eq:slr-proj-w}
\begin{split}
a^\mathrm{T} (b-p) &= 0 \\
a^\mathrm{T} (b - w \cdot a) &= 0 \\
a^\mathrm{T} b - w \cdot a^\mathrm{T} a &= 0 \\
w \cdot a^\mathrm{T} a &= a^\mathrm{T} b \\
w &= \frac{a^\mathrm{T} b}{a^\mathrm{T} a} \; .
\end{split}
\end{equation}

With \eqref{eq:slr-proj-a} and \eqref{eq:slr-proj-b}, $w$ can be calculated as

\begin{equation} \label{eq:slr-proj-w-qed}
\begin{split}
w &= \frac{a^\mathrm{T} b}{a^\mathrm{T} a} \\
w &= \frac{\left( \begin{matrix} 1 \\ \hat{\beta}_1 \end{matrix} \right)^\mathrm{T} \left( \begin{matrix} x_o \\ y_o - \hat{\beta}_0 \end{matrix} \right)}{\left( \begin{matrix} 1 \\ \hat{\beta}_1 \end{matrix} \right)^\mathrm{T} \left( \begin{matrix} 1 \\ \hat{\beta}_1 \end{matrix} \right)} \\
w &= \frac{x_0 + (y_o - \hat{\beta}_0) \hat{\beta}_1}{1 + \hat{\beta}_1^2}
\end{split}
\end{equation}

Finally, with the point $S$ \eqref{eq:slr-proj-S} and the vector $p$ \eqref{eq:slr-proj-p}, the coordinates of $P$ are obtained as

\begin{equation} \label{eq:slr-proj-P-qed}
\left( \begin{matrix} x_p \\ y_p \end{matrix} \right) = \left( \begin{matrix} 0 \\ \hat{\beta}_0 \end{matrix} \right) + w \cdot \left( \begin{matrix} 1 \\ \hat{\beta}_1 \end{matrix} \right) = \left( \begin{matrix} w \\ \hat{\beta}_0 + \hat{\beta}_1 w \end{matrix} \right) \; .
\end{equation}

Together, \eqref{eq:slr-proj-P-qed} and \eqref{eq:slr-proj-w-qed} constitute the proof of equation \eqref{eq:slr-proj-slr-proj}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Penny, William (2006): "Projections"; in: \textit{Mathematics for Brain Imaging}, ch. 1.4.10, pp. 34-35, eqs. 1.87/1.88; URL: \url{https://ueapsylabs.co.uk/sites/wpenny/mbi/mbi_course.pdf}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P283 | shortcut: slr-proj | author: JoramSoch | date: 2021-11-09, 10:16.
\vspace{1em}



\subsubsection[\textbf{Sums of squares}]{Sums of squares} \label{sec:slr-sss}
\setcounter{equation}{0}

\textbf{Theorem:} Under ordinary least squares ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:slr-ols}) for simple linear regression ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:slr}), total ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:tss}), explained ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:ess}) and residual ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:rss}) sums of squares are given by

\begin{equation} \label{eq:slr-sss-slr-sss}
\begin{split}
\mathrm{TSS} &= (n-1) \, s_y^2 \\
\mathrm{ESS} &= (n-1) \, \frac{s_{xy}^2}{s_x^2} \\
\mathrm{RSS} &= (n-1) \left( s_y^2 - \frac{s_{xy}^2}{s_x^2} \right)
\end{split}
\end{equation}

where $s_x^2$ and $s_y^2$ are the sample variances ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var-samp}) of $x$ and $y$ and $s_{xy}$ is the sample covariance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cov-samp}) between $x$ and $y$.


\vspace{1em}
\textbf{Proof:} The ordinary least squares parameter estimates ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:slr-ols}) are given by

\begin{equation} \label{eq:slr-sss-slr-ols}
\hat{\beta}_0 = \bar{y} - \hat{\beta}_1 \bar{x} \quad \text{and} \quad \hat{\beta}_1 = \frac{s_{xy}}{s_x^2} \; .
\end{equation}

\vspace{1em}
1) The total sum of squares ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:tss}) is defined as

\begin{equation} \label{eq:slr-sss-TSS}
\mathrm{TSS} = \sum_{i=1}^{n} (y_i - \bar{y})^2
\end{equation}

which can be reformulated as follows:

\begin{equation} \label{eq:slr-sss-TSS-qed}
\begin{split}
\mathrm{TSS} &= \sum_{i=1}^{n} (y_i - \bar{y})^2 \\
&= (n-1) \frac{1}{n-1} \sum_{i=1}^{n} (y_i - \bar{y})^2 \\
&= (n-1) s_y^2 \; .
\end{split}
\end{equation}

\vspace{1em}
2) The explained sum of squares ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:ess}) is defined as

\begin{equation} \label{eq:slr-sss-ESS}
\mathrm{ESS} = \sum_{i=1}^n (\hat{y}_i - \bar{y})^2 \quad \text{where} \quad \hat{y}_i = \hat{\beta}_0 + \hat{\beta}_1 x_i
\end{equation}

which, with the OLS parameter estimats, becomes:

\begin{equation} \label{eq:slr-sss-ESS-qed}
\begin{split}
\mathrm{ESS} &= \sum_{i=1}^n (\hat{y}_i - \bar{y})^2 \\
&= \sum_{i=1}^n (\hat{\beta}_0 + \hat{\beta}_1 x_i - \bar{y})^2 \\
&\overset{\eqref{eq:slr-sss-slr-ols}}{=} \sum_{i=1}^n (\bar{y} - \hat{\beta}_1 \bar{x} + \hat{\beta}_1 x_i - \bar{y})^2 \\
&= \sum_{i=1}^n \left( \hat{\beta}_1 (x_i - \bar{x}) \right)^2 \\
&\overset{\eqref{eq:slr-sss-slr-ols}}{=} \sum_{i=1}^n \left( \frac{s_{xy}}{s_x^2} (x_i - \bar{x}) \right)^2 \\
&= \left( \frac{s_{xy}}{s_x^2} \right)^2 \sum_{i=1}^n (x_i - \bar{x})^2 \\
&= \left( \frac{s_{xy}}{s_x^2} \right)^2 (n-1) s_x^2 \\
&= (n-1) \, \frac{s_{xy}^2}{s_x^2} \; .
\end{split}
\end{equation}

\vspace{1em}
3) The residual sum of squares ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:rss}) is defined as

\begin{equation} \label{eq:slr-sss-RSS}
\mathrm{RSS} = \sum_{i=1}^n (y_i - \hat{y}_i)^2 \quad \text{where} \quad \hat{y}_i = \hat{\beta}_0 + \hat{\beta}_1 x_i
\end{equation}

which, with the OLS parameter estimats, becomes:

\begin{equation} \label{eq:slr-sss-RSS-qed}
\begin{split}
\mathrm{RSS} &= \sum_{i=1}^n (y_i - \hat{y}_i)^2 \\
&= \sum_{i=1}^n (y_i - \hat{\beta}_0 - \hat{\beta}_1 x_i)^2 \\
&\overset{\eqref{eq:slr-sss-slr-ols}}{=} \sum_{i=1}^n (y_i - \bar{y} + \hat{\beta}_1 \bar{x} - \hat{\beta}_1 x_i)^2 \\
&= \sum_{i=1}^n \left( (y_i - \bar{y}) - \hat{\beta}_1 (x_i - \bar{x}) \right)^2 \\
&= \sum_{i=1}^n \left( (y_i - \bar{y})^2 - 2 \hat{\beta}_1 (x_i - \bar{x}) (y_i - \bar{y}) + \hat{\beta}_1^2 (x_i - \bar{x})^2 \right) \\
&= \sum_{i=1}^n (y_i - \bar{y})^2 - 2 \hat{\beta}_1 \sum_{i=1}^n (x_i - \bar{x}) (y_i - \bar{y}) + \hat{\beta}_1^2 \sum_{i=1}^n (x_i - \bar{x})^2 \\
&= (n-1) \, s_y^2 - 2 (n-1) \, \hat{\beta}_1 \, s_{xy} + (n-1) \, \hat{\beta}_1^2 \, s_x^2 \\
&\overset{\eqref{eq:slr-sss-slr-ols}}{=} (n-1) \, s_y^2 - 2 (n-1) \left( \frac{s_{xy}}{s_x^2} \right) s_{xy} + (n-1) \left( \frac{s_{xy}}{s_x^2} \right)^2 s_x^2 \\
&= (n-1) \, s_y^2 - (n-1) \, \frac{s_{xy}^2}{s_x^2} \\
&= (n-1) \left( s_y^2 - \frac{s_{xy}^2}{s_x^2} \right) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P284 | shortcut: slr-sss | author: JoramSoch | date: 2021-11-09, 11:34.
\vspace{1em}



\subsubsection[\textbf{Transformation matrices}]{Transformation matrices} \label{sec:slr-mat}
\setcounter{equation}{0}

\textbf{Theorem:} Under ordinary least squares ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:slr-ols}) for simple linear regression ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:slr}), estimation ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:emat}), projection ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:pmat}) and residual-forming ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:rfmat}) matrices are given by

\begin{equation} \label{eq:slr-mat-slr-mat}
\begin{split}
E &= \frac{1}{(n-1)\,s_x^2} \left[ \begin{matrix} (x^\mathrm{T} x/n) \, 1_n^\mathrm{T} - \bar{x} \, x^\mathrm{T} \\ - \bar{x} \, 1_n^\mathrm{T} + x^\mathrm{T} \end{matrix} \right] \\
P &= \frac{1}{(n-1)\,s_x^2} \left[ \begin{matrix} (x^\mathrm{T} x/n) - 2 \bar{x} x_1 + x_1^2 & \cdots & (x^\mathrm{T} x/n) - \bar{x} (x_1 + x_n) + x_1 x_n \\ \vdots & \ddots & \vdots \\ (x^\mathrm{T} x/n) - \bar{x} (x_1 + x_n) + x_1 x_n & \cdots & (x^\mathrm{T} x/n) - 2 \bar{x} x_n + x_n^2 \end{matrix} \right] \\
R &= \frac{1}{(n-1)\,s_x^2} \left[ \begin{matrix} (n-1) (x^\mathrm{T} x/n) + \bar{x} (2 x_1 - n\bar{x}) - x_1^2 & \cdots & -(x^\mathrm{T} x/n) + \bar{x} (x_1 + x_n) - x_1 x_n \\ \vdots & \ddots & \vdots \\ -(x^\mathrm{T} x/n) + \bar{x} (x_1 + x_n) - x_1 x_n & \cdots &  (n-1) (x^\mathrm{T} x/n) + \bar{x} (2 x_n - n\bar{x}) - x_n^2 \end{matrix} \right]
\end{split}
\end{equation}

where $1_n$ is an $n \times 1$ vector of ones, $x$ is the $n \times 1$ single predictor variable, $\bar{x}$ is the sample mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean-samp}) of $x$ and $s_x^2$ is the sample variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var-samp}) of $x$.


\vspace{1em}
\textbf{Proof:} Simple linear regression is a special case of multiple linear regression ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:slr-mlr}) with

\begin{equation} \label{eq:slr-mat-slr-mlr}
X = \left[ \begin{matrix} 1_n & x \end{matrix} \right] \quad \text{and} \quad \beta = \left[ \begin{matrix} \beta_0 \\ \beta_1 \end{matrix} \right] \; ,
\end{equation}

such that the simple linear regression model can also be written as

\begin{equation} \label{eq:slr-mat-mlr}
y = X\beta + \varepsilon, \; \varepsilon \sim \mathcal{N}(0, \sigma^2 I_n) \; .
\end{equation}

Moreover, we note the following equality ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:slr-olsdist}):

\begin{equation} \label{eq:slr-mat-b-est-cov-den}
x^\mathrm{T} x - n\bar{x}^2 = (n-1) \, s_x^2 \; .
\end{equation}

\vspace{1em}
1) The estimation matrix is given by ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mlr-mat})

\begin{equation} \label{eq:slr-mat-E}
E = (X^\mathrm{T} X)^{-1} X^\mathrm{T}
\end{equation}

which is a $2 \times n$ matrix and can be reformulated as follows:

\begin{equation} \label{eq:slr-mat-E-qed}
\begin{split}
E &= (X^\mathrm{T} X)^{-1} X^\mathrm{T} \\
&= \left( \left[ \begin{matrix} 1_n^\mathrm{T} \\ x^\mathrm{T} \end{matrix} \right] \left[ \begin{matrix} 1_n & x \end{matrix} \right] \right)^{-1} \left[ \begin{matrix} 1_n^\mathrm{T} \\ x^\mathrm{T} \end{matrix} \right] \\
&= \left( \left[ \begin{matrix} n & n\bar{x} \\ n\bar{x} & x^\mathrm{T} x \end{matrix} \right] \right)^{-1} \left[ \begin{matrix} 1_n^\mathrm{T} \\ x^\mathrm{T} \end{matrix} \right] \\
&= \frac{1}{n x^\mathrm{T} x - (n\bar{x})^2} \left[ \begin{matrix} x^\mathrm{T} x & -n\bar{x} \\ -n\bar{x} & n \end{matrix} \right] \left[ \begin{matrix} 1_n^\mathrm{T} \\ x^\mathrm{T} \end{matrix} \right] \\
&= \frac{1}{x^\mathrm{T} x - n\bar{x}^2} \left[ \begin{matrix} x^\mathrm{T} x/n & -\bar{x} \\ -\bar{x} & 1 \end{matrix} \right] \left[ \begin{matrix} 1_n^\mathrm{T} \\ x^\mathrm{T} \end{matrix} \right] \\
&\overset{\eqref{eq:slr-mat-b-est-cov-den}}{=} \frac{1}{(n-1)\,s_x^2} \left[ \begin{matrix} (x^\mathrm{T} x/n) \, 1_n^\mathrm{T} - \bar{x} \, x^\mathrm{T} \\ - \bar{x} \, 1_n^\mathrm{T} + x^\mathrm{T} \end{matrix} \right] \; .
\end{split}
\end{equation}

\vspace{1em}
2) The projection matrix is given by ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mlr-mat})

\begin{equation} \label{eq:slr-mat-P}
P = X (X^\mathrm{T} X)^{-1} X^\mathrm{T} = X \, E
\end{equation}

which is an $n \times n$ matrix and can be reformulated as follows:

\begin{equation} \label{eq:slr-mat-P-qed}
\begin{split}
P &= X \, E = \left[ \begin{matrix} 1_n & x \end{matrix} \right] \left[ \begin{matrix} e_1 \\ e_2 \end{matrix} \right] \\
&= \frac{1}{(n-1)\,s_x^2} \left[ \begin{matrix} 1 & x_1 \\ \vdots & \vdots \\ 1 & x_n \end{matrix} \right] \left[ \begin{matrix} (x^\mathrm{T} x/n) - \bar{x} x_1 & \cdots & (x^\mathrm{T} x/n) - \bar{x} x_n \\ -\bar{x} + x_1 & \cdots & -\bar{x} + x_n \end{matrix} \right] \\
&= \frac{1}{(n-1)\,s_x^2} \left[ \begin{matrix} (x^\mathrm{T} x/n) - 2 \bar{x} x_1 + x_1^2 & \cdots & (x^\mathrm{T} x/n) - \bar{x} (x_1 + x_n) + x_1 x_n \\ \vdots & \ddots & \vdots \\ (x^\mathrm{T} x/n) - \bar{x} (x_1 + x_n) + x_1 x_n & \cdots & (x^\mathrm{T} x/n) - 2 \bar{x} x_n + x_n^2 \end{matrix} \right] \; .
\end{split}
\end{equation}

\vspace{1em}
3) The residual-forming matrix is given by ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mlr-mat})

\begin{equation} \label{eq:slr-mat-R}
R = I_n - X (X^\mathrm{T} X)^{-1} X^\mathrm{T} = I_n - P
\end{equation}

which also is an $n \times n$ matrix and can be reformulated as follows:

\begin{equation} \label{eq:slr-mat-R-qed}
\begin{split}
R &= I_n - P = \left[ \begin{matrix} 1 & \cdots & 0 \\ \vdots & \ddots & \vdots \\ 0 & \cdots & 1 \end{matrix} \right] - \left[ \begin{matrix} p_{11} & \cdots & p_{1n} \\ \vdots & \ddots & \vdots \\ p_{n1} & \cdots & p_{nn} \end{matrix} \right] \\
&\overset{\eqref{eq:slr-mat-b-est-cov-den}}{=} \frac{1}{(n-1)\,s_x^2} \left[ \begin{matrix} x^\mathrm{T} x - n\bar{x}^2 & \cdots & 0 \\ \vdots & \ddots & \vdots \\ 0 & \cdots & x^\mathrm{T} x - n\bar{x}^2 \end{matrix} \right] \\
&- \frac{1}{(n-1)\,s_x^2} \left[ \begin{matrix} (x^\mathrm{T} x/n) - 2 \bar{x} x_1 + x_1^2 & \cdots & (x^\mathrm{T} x/n) - \bar{x} (x_1 + x_n) + x_1 x_n \\ \vdots & \ddots & \vdots \\ (x^\mathrm{T} x/n) - \bar{x} (x_1 + x_n) + x_1 x_n & \cdots & (x^\mathrm{T} x/n) - 2 \bar{x} x_n + x_n^2 \end{matrix} \right] \\
&= \frac{1}{(n-1)\,s_x^2} \left[ \begin{matrix} (n-1) (x^\mathrm{T} x/n) + \bar{x} (2 x_1 - n\bar{x}) - x_1^2 & \cdots & -(x^\mathrm{T} x/n) + \bar{x} (x_1 + x_n) - x_1 x_n \\ \vdots & \ddots & \vdots \\ -(x^\mathrm{T} x/n) + \bar{x} (x_1 + x_n) - x_1 x_n & \cdots &  (n-1) (x^\mathrm{T} x/n) + \bar{x} (2 x_n - n\bar{x}) - x_n^2 \end{matrix} \right] \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P285 | shortcut: slr-mat | author: JoramSoch | date: 2021-11-09, 15:19.
\vspace{1em}



\subsubsection[\textbf{Weighted least squares}]{Weighted least squares} \label{sec:slr-wls}
\setcounter{equation}{0}

\textbf{Theorem:} Given a simple linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:slr}) with correlated observations

\begin{equation} \label{eq:slr-wls-slr}
y = \beta_0 + \beta_1 x + \varepsilon, \; \varepsilon \sim \mathcal{N}(0, \sigma^2 V) \; ,
\end{equation}

the parameters minimizing the weighted residual sum of squares ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:rss}) are given by

\begin{equation} \label{eq:slr-wls-slr-wls}
\begin{split}
\hat{\beta}_0 &= \frac{x^\mathrm{T} V^{-1} x \, 1_n^\mathrm{T} V^{-1} y - 1_n^\mathrm{T} V^{-1} x \, x^\mathrm{T} V^{-1} y}{x^\mathrm{T} V^{-1} x \, 1_n^\mathrm{T} V^{-1} 1_n - 1_n^\mathrm{T} V^{-1} x \, x^\mathrm{T} V^{-1} 1_n} \\
\hat{\beta}_1 &= \frac{1_n^\mathrm{T} V^{-1} 1_n \, x^\mathrm{T} V^{-1} y - x^\mathrm{T} V^{-1} 1_n \, 1_n^\mathrm{T} V^{-1} y}{1_n^\mathrm{T} V^{-1} 1_n \, x^\mathrm{T} V^{-1} x - x^\mathrm{T} V^{-1} 1_n \, 1_n^\mathrm{T} V^{-1} x}
\end{split}
\end{equation}

where $1_n$ is an $n \times 1$ vector of ones.


\vspace{1em}
\textbf{Proof:} Let there be an $n \times n$ square matrix $W$, such that

\begin{equation} \label{eq:slr-wls-W-def}
W V W^\mathrm{T} = I_n \; .
\end{equation}

Since $V$ is a covariance matrix and thus symmetric, $W$ is also symmetric and can be expressed as the matrix square root of the inverse of $V$:

\begin{equation} \label{eq:slr-wls-W-V}
W V W = I_n \quad \Leftrightarrow \quad V = W^{-1} W^{-1} \quad \Leftrightarrow \quad V^{-1} = W W \quad \Leftrightarrow \quad W = V^{-1/2} \; .
\end{equation}

Because $\beta_0$ is a scalar, \eqref{eq:slr-wls-slr} may also be written as

\begin{equation} \label{eq:slr-wls-slr-s1}
y = \beta_0 1_n + \beta_1 x + \varepsilon, \; \varepsilon \sim \mathcal{N}(0, \sigma^2 V) \; ,
\end{equation}

Left-multiplying \eqref{eq:slr-wls-slr-s1} with $W$, the linear transformation theorem ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mvn-ltt}) implies that

\begin{equation} \label{eq:slr-wls-slr-s2}
W y = \beta_0 W 1_n + \beta_1 W x + W \varepsilon, \; W \varepsilon \sim \mathcal{N}(0, \sigma^2 W V W^\mathrm{T}) \; .
\end{equation}

Applying \eqref{eq:slr-wls-W-def}, we see that \eqref{eq:slr-wls-slr-s2} is actually a linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}) with independent observations

\begin{equation} \label{eq:slr-wls-slr-s3}
\tilde{y} = \left[ \begin{matrix} \tilde{x}_0 & \tilde{x} \end{matrix} \right] \left[ \begin{matrix} \beta_0 \\ \beta_1 \end{matrix} \right] + \tilde{\varepsilon}, \; \tilde{\varepsilon} \sim \mathcal{N}(0, \sigma^2 I_n)
\end{equation}

where $\tilde{y} = Wy$, $\tilde{x}_0 = W 1_n$, $\tilde{x} = W x$ and $\tilde{\varepsilon} = W\varepsilon$, such that we can apply the ordinary least squares solution ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mlr-ols}) giving:

\begin{equation} \label{eq:slr-wls-slr-wls-s1}
\begin{split}
\hat{\beta} &= (\tilde{X}^\mathrm{T} \tilde{X})^{-1} \tilde{X}^\mathrm{T} \tilde{y} \\
&= \left( \left[ \begin{matrix} \tilde{x}_0^\mathrm{T} \\ \tilde{x}^\mathrm{T} \end{matrix} \right] \left[ \begin{matrix} \tilde{x}_0 & \tilde{x} \end{matrix} \right] \right)^{-1} \left[ \begin{matrix} \tilde{x}_0^\mathrm{T} \\ \tilde{x}^\mathrm{T} \end{matrix} \right] \tilde{y} \\
&= \left[ \begin{matrix} \tilde{x}_0^\mathrm{T} \tilde{x}_0 & \tilde{x}_0^\mathrm{T} \tilde{x} \\ \tilde{x}^\mathrm{T} \tilde{x}_0 & \tilde{x}^\mathrm{T} \tilde{x} \end{matrix} \right]^{-1} \left[ \begin{matrix} \tilde{x}_0^\mathrm{T} \\ \tilde{x}^\mathrm{T} \end{matrix} \right] \tilde{y} \; .
\end{split}
\end{equation}

Applying the inverse of a $2 \times 2$ matrix, this reformulates to:

\begin{equation} \label{eq:slr-wls-slr-wls-s2}
\begin{split}
\hat{\beta} &= \frac{1}{\tilde{x}_0^\mathrm{T} \tilde{x}_0 \, \tilde{x}^\mathrm{T} \tilde{x} - \tilde{x}_0^\mathrm{T} \tilde{x} \, \tilde{x}^\mathrm{T} \tilde{x}_0} \left[ \begin{matrix} \tilde{x}^\mathrm{T} \tilde{x} & -\tilde{x}_0^\mathrm{T} \tilde{x} \\ -\tilde{x}^\mathrm{T} \tilde{x}_0 & \tilde{x}_0^\mathrm{T} \tilde{x}_0 \end{matrix} \right]^{-1} \left[ \begin{matrix} \tilde{x}_0^\mathrm{T} \\ \tilde{x}^\mathrm{T} \end{matrix} \right] \tilde{y} \\
&= \frac{1}{\tilde{x}_0^\mathrm{T} \tilde{x}_0 \, \tilde{x}^\mathrm{T} \tilde{x} - \tilde{x}_0^\mathrm{T} \tilde{x} \, \tilde{x}^\mathrm{T} \tilde{x}_0} \left[ \begin{matrix} \tilde{x}^\mathrm{T} \tilde{x} \, \tilde{x}_0^\mathrm{T} - \tilde{x}_0^\mathrm{T} \tilde{x} \, \tilde{x}^\mathrm{T} \\ \tilde{x}_0^\mathrm{T} \tilde{x}_0 \, \tilde{x}^\mathrm{T} - \tilde{x}^\mathrm{T} \tilde{x}_0 \, \tilde{x}_0^\mathrm{T} \end{matrix} \right] \tilde{y} \\
&= \frac{1}{\tilde{x}_0^\mathrm{T} \tilde{x}_0 \, \tilde{x}^\mathrm{T} \tilde{x} - \tilde{x}_0^\mathrm{T} \tilde{x} \, \tilde{x}^\mathrm{T} \tilde{x}_0} \left[ \begin{matrix} \tilde{x}^\mathrm{T} \tilde{x} \, \tilde{x}_0^\mathrm{T} \tilde{y} - \tilde{x}_0^\mathrm{T} \tilde{x} \, \tilde{x}^\mathrm{T} \tilde{y} \\ \tilde{x}_0^\mathrm{T} \tilde{x}_0 \, \tilde{x}^\mathrm{T} \tilde{y} - \tilde{x}^\mathrm{T} \tilde{x}_0 \, \tilde{x}_0^\mathrm{T} \tilde{y} \end{matrix} \right] \; .
\end{split}
\end{equation}

Applying $\tilde{x}_0 = W 1_n$, $\tilde{x} = W x$ and $W^\mathrm{T} W = W W = V^{-1}$, we finally have

\begin{equation} \label{eq:slr-wls-slr-wls-s3}
\begin{split}
\hat{\beta} &= \frac{1}{1_n^\mathrm{T} W^\mathrm{T} W 1_n \, x^\mathrm{T} W^\mathrm{T} W x - 1_n^\mathrm{T} W^\mathrm{T} W x \, x^\mathrm{T} W^\mathrm{T} W 1_n} \left[ \begin{matrix} x^\mathrm{T} W^\mathrm{T} W x \, 1_n^\mathrm{T} W^\mathrm{T} W y - 1_n^\mathrm{T} W^\mathrm{T} W x \, x^\mathrm{T} W^\mathrm{T} W y \\ 1_n^\mathrm{T} W^\mathrm{T} W 1_n \, x^\mathrm{T} W^\mathrm{T} W y - x^\mathrm{T} W^\mathrm{T} W 1_n \, 1_n^\mathrm{T} W^\mathrm{T} W y \end{matrix} \right] \\
&= \frac{1}{x^\mathrm{T} V^{-1} x \, 1_n^\mathrm{T} V^{-1} 1_n - 1_n^\mathrm{T} V^{-1} x \, x^\mathrm{T} V^{-1} 1_n} \left[ \begin{matrix} x^\mathrm{T} V^{-1} x \, 1_n^\mathrm{T} V^{-1} y - 1_n^\mathrm{T} V^{-1} x \, x^\mathrm{T} V^{-1} y \\ 1_n^\mathrm{T} V^{-1} 1_n \, x^\mathrm{T} V^{-1} y - x^\mathrm{T} V^{-1} 1_n \, 1_n^\mathrm{T} V^{-1} y \end{matrix} \right] \\
&= \left[ \begin{matrix} \frac{x^\mathrm{T} V^{-1} x \, 1_n^\mathrm{T} V^{-1} y - 1_n^\mathrm{T} V^{-1} x \, x^\mathrm{T} V^{-1} y}{x^\mathrm{T} V^{-1} x \, 1_n^\mathrm{T} V^{-1} 1_n - 1_n^\mathrm{T} V^{-1} x \, x^\mathrm{T} V^{-1} 1_n} \\ 
\frac{1_n^\mathrm{T} V^{-1} 1_n \, x^\mathrm{T} V^{-1} y - x^\mathrm{T} V^{-1} 1_n \, 1_n^\mathrm{T} V^{-1} y}{1_n^\mathrm{T} V^{-1} 1_n \, x^\mathrm{T} V^{-1} x - x^\mathrm{T} V^{-1} 1_n \, 1_n^\mathrm{T} V^{-1} x} \end{matrix} \right]
\end{split}
\end{equation}

which corresponds to the weighted least squares solution \eqref{eq:slr-wls-slr-wls}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P286 | shortcut: slr-wls | author: JoramSoch | date: 2021-11-16, 07:16.
\vspace{1em}



\subsubsection[\textbf{Weighted least squares}]{Weighted least squares} \label{sec:slr-wls2}
\setcounter{equation}{0}

\textbf{Theorem:} Given a simple linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:slr}) with correlated observations

\begin{equation} \label{eq:slr-wls2-slr}
y = \beta_0 + \beta_1 x + \varepsilon, \; \varepsilon \sim \mathcal{N}(0, \sigma^2 V) \; ,
\end{equation}

the parameters minimizing the weighted residual sum of squares ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:rss}) are given by

\begin{equation} \label{eq:slr-wls2-slr-wls}
\begin{split}
\hat{\beta}_0 &= \frac{x^\mathrm{T} V^{-1} x \, 1_n^\mathrm{T} V^{-1} y - 1_n^\mathrm{T} V^{-1} x \, x^\mathrm{T} V^{-1} y}{x^\mathrm{T} V^{-1} x \, 1_n^\mathrm{T} V^{-1} 1_n - 1_n^\mathrm{T} V^{-1} x \, x^\mathrm{T} V^{-1} 1_n} \\
\hat{\beta}_1 &= \frac{1_n^\mathrm{T} V^{-1} 1_n \, x^\mathrm{T} V^{-1} y - x^\mathrm{T} V^{-1} 1_n \, 1_n^\mathrm{T} V^{-1} y}{1_n^\mathrm{T} V^{-1} 1_n \, x^\mathrm{T} V^{-1} x - x^\mathrm{T} V^{-1} 1_n \, 1_n^\mathrm{T} V^{-1} x}
\end{split}
\end{equation}

where $1_n$ is an $n \times 1$ vector of ones.


\vspace{1em}
\textbf{Proof:} Simple linear regression is a special case of multiple linear regression ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:slr-mlr}) with

\begin{equation} \label{eq:slr-wls2-slr-mlr}
X = \left[ \begin{matrix} 1_n & x \end{matrix} \right] \quad \text{and} \quad \beta = \left[ \begin{matrix} \beta_0 \\ \beta_1 \end{matrix} \right]
\end{equation}

and weighted least sqaures estimates ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mlr-wls}) are given by

\begin{equation} \label{eq:slr-wls2-mlr-wls}
\hat{\beta} = (X^\mathrm{T} V^{-1} X)^{-1} X^\mathrm{T} V^{-1} y \; .
\end{equation}

Writing out equation \eqref{eq:slr-wls2-mlr-wls}, we have

\begin{equation} \label{eq:slr-wls2-slr-wls-b}
\begin{split}
\hat{\beta} &= \left( \left[ \begin{matrix} 1_n^\mathrm{T} \\ x^\mathrm{T} \end{matrix} \right] V^{-1} \left[ \begin{matrix} 1_n & x \end{matrix} \right] \right)^{-1} \left[ \begin{matrix} 1_n^\mathrm{T} \\ x^\mathrm{T} \end{matrix} \right] V^{-1} y \\
&= \left[ \begin{matrix} 1_n^\mathrm{T} V^{-1} 1_n & 1_n^\mathrm{T} V^{-1} x \\ x^\mathrm{T} V^{-1} 1_n & x^\mathrm{T} V^{-1} x \end{matrix} \right]^{-1} \left[ \begin{matrix} 1_n^\mathrm{T} V^{-1} y \\ x^\mathrm{T} V^{-1} y \end{matrix} \right] \\
&= \frac{1}{x^\mathrm{T} V^{-1} x \, 1_n^\mathrm{T} V^{-1} 1_n - 1_n^\mathrm{T} V^{-1} x \, x^\mathrm{T} V^{-1} 1_n} \left[ \begin{matrix} x^\mathrm{T} V^{-1} x & -1_n^\mathrm{T} V^{-1} x \\ -x^\mathrm{T} V^{-1} 1_n & 1_n^\mathrm{T} V^{-1} 1_n \end{matrix} \right] \left[ \begin{matrix} 1_n^\mathrm{T} V^{-1} y \\ x^\mathrm{T} V^{-1} y \end{matrix} \right] \\
&= \frac{1}{x^\mathrm{T} V^{-1} x \, 1_n^\mathrm{T} V^{-1} 1_n - 1_n^\mathrm{T} V^{-1} x \, x^\mathrm{T} V^{-1} 1_n} \left[ \begin{matrix} x^\mathrm{T} V^{-1} x \, 1_n^\mathrm{T} V^{-1} y - 1_n^\mathrm{T} V^{-1} x \, x^\mathrm{T} V^{-1} y \\ 1_n^\mathrm{T} V^{-1} 1_n \, x^\mathrm{T} V^{-1} y - x^\mathrm{T} V^{-1} 1_n \, 1_n^\mathrm{T} V^{-1} y \end{matrix} \right] \; .
\end{split}
\end{equation}

Thus, the first entry of $\hat{\beta}$ is equal to:

\begin{equation} \label{eq:slr-wls2-slr-wls-b1}
\hat{\beta}_0 = \frac{x^\mathrm{T} V^{-1} x \, 1_n^\mathrm{T} V^{-1} y - 1_n^\mathrm{T} V^{-1} x \, x^\mathrm{T} V^{-1} y}{x^\mathrm{T} V^{-1} x \, 1_n^\mathrm{T} V^{-1} 1_n - 1_n^\mathrm{T} V^{-1} x \, x^\mathrm{T} V^{-1} 1_n} \; .
\end{equation}

Moreover, the second entry of $\hat{\beta}$ is equal to ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:slr-wls}):

\begin{equation} \label{eq:slr-wls2-slr-wls-b2}
\hat{\beta}_1 = \frac{1_n^\mathrm{T} V^{-1} 1_n \, x^\mathrm{T} V^{-1} y - x^\mathrm{T} V^{-1} 1_n \, 1_n^\mathrm{T} V^{-1} y}{1_n^\mathrm{T} V^{-1} 1_n \, x^\mathrm{T} V^{-1} x - x^\mathrm{T} V^{-1} 1_n \, 1_n^\mathrm{T} V^{-1} x} \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P289 | shortcut: slr-wls2 | author: JoramSoch | date: 2021-11-16, 11:20.
\vspace{1em}



\subsubsection[\textbf{Maximum likelihood estimation}]{Maximum likelihood estimation} \label{sec:slr-mle}
\setcounter{equation}{0}

\textbf{Theorem:} Given a simple linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}) with independent observations

\begin{equation} \label{eq:slr-mle-slr}
y_i = \beta_0 + \beta_1 x_i + \varepsilon_i, \; \varepsilon_i \sim \mathcal{N}(0, \sigma^2), \; i = 1,\ldots,n \; ,
\end{equation}

the maximum likelihood estimates ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mle}) of $\beta_0$, $\beta_1$ and $\sigma^2$ are given by

\begin{equation} \label{eq:slr-mle-slr-mle}
\begin{split}
\hat{\beta}_0 &= \bar{y} - \hat{\beta}_1 \bar{x} \\
\hat{\beta}_1 &= \frac{s_{xy}}{s_x^2} \\
\hat{\sigma}^2 &= \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{\beta}_0 - \hat{\beta}_1 x_i)^2
\end{split}
\end{equation}

where $\bar{x}$ and $\bar{y}$ are the sample means ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean-samp}), $s_x^2$ is the sample variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var-samp}) of $x$ and $s_{xy}$ is the sample covariance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cov-samp}) between $x$ and $y$.


\vspace{1em}
\textbf{Proof:} With the probability density function of the normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-pdf}) and probability under independence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}), the linear regression equation \eqref{eq:slr-mle-slr} implies the following likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf})

\begin{equation} \label{eq:slr-mle-slr-lf}
\begin{split}
p(y|\beta_0,\beta_1,\sigma^2) &= \prod_{i=1}^n p(y_i|\beta_0,\beta_1,\sigma^2) \\
&= \prod_{i=1}^n \mathcal{N}(y_i; \beta_0 + \beta_1 x_i, \sigma^2) \\
&= \prod_{i=1}^n \frac{1}{\sqrt{2 \pi \sigma}} \cdot \exp \left[ -\frac{(y_i - \beta_0 - \beta_1 x_i)^2}{2 \sigma^2} \right] \\
&= \frac{1}{\sqrt{(2 \pi \sigma^2)^n}} \cdot \exp\left[ -\frac{1}{2 \sigma^2} \sum_{i=1}^n (y_i - \beta_0 - \beta_1 x_i)^2 \right]
\end{split}
\end{equation}

and the log-likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:llf})

\begin{equation} \label{eq:slr-mle-slr-ll}
\begin{split}
\mathrm{LL}(\beta_0,\beta_1,\sigma^2) &= \log p(y|\beta_0,\beta_1,\sigma^2) \\
&= -\frac{n}{2} \log(2\pi) - \frac{n}{2} \log (\sigma^2) -\frac{1}{2 \sigma^2} \sum_{i=1}^n (y_i - \beta_0 - \beta_1 x_i)^2 \; .
\end{split}
\end{equation}

\vspace{1em}
The derivative of the log-likelihood function \eqref{eq:slr-mle-slr-ll} with respect to $\beta_0$ is

\begin{equation} \label{eq:slr-mle-dLL-dbeta0}
\frac{\mathrm{d}\mathrm{LL}(\beta_0,\beta_1,\sigma^2)}{\mathrm{d}\beta_0} = \frac{1}{\sigma^2} \sum_{i=1}^n (y_i - \beta_0 - \beta_1 x_i)
\end{equation}

and setting this derivative to zero gives the MLE for $\beta_0$:

\begin{equation} \label{eq:slr-mle-beta0-mle}
\begin{split}
\frac{\mathrm{d}\mathrm{LL}(\hat{\beta}_0,\hat{\beta}_1,\hat{\sigma}^2)}{\mathrm{d}\beta_0} &= 0 \\
0 &= \frac{1}{\hat{\sigma}^2} \sum_{i=1}^n (y_i - \hat{\beta}_0 - \hat{\beta}_1 x_i) \\
0 &= \sum_{i=1}^n y_i - n \hat{\beta}_0 - \hat{\beta}_1 \sum_{i=1}^n x_i \\
\hat{\beta}_0 &= \frac{1}{n} \sum_{i=1}^n y_i - \hat{\beta}_1 \frac{1}{n} \sum_{i=1}^n x_i \\
\hat{\beta}_0 &= \bar{y} - \hat{\beta}_1 \bar{x} \; .
\end{split}
\end{equation}

\vspace{1em}
The derivative of the log-likelihood function \eqref{eq:slr-mle-slr-ll} at $\hat{\beta}_0$ with respect to $\beta_1$ is

\begin{equation} \label{eq:slr-mle-dLL-dbeta1}
\frac{\mathrm{d}\mathrm{LL}(\hat{\beta}_0,\beta_1,\sigma^2)}{\mathrm{d}\beta_1} = \frac{1}{\sigma^2} \sum_{i=1}^n (x_i y_i - \hat{\beta}_0 x_i - \beta_1 x_i^2) \\
\end{equation}

and setting this derivative to zero gives the MLE for $\beta_1$:

\begin{equation} \label{eq:slr-mle-beta1-mle}
\begin{split}
\frac{\mathrm{d}\mathrm{LL}(\hat{\beta}_0,\hat{\beta}_1,\hat{\sigma}^2)}{\mathrm{d}\beta_1} &= 0 \\
0 &= \frac{1}{\hat{\sigma}^2} \sum_{i=1}^n (x_i y_i - \hat{\beta}_0 x_i - \hat{\beta}_1 x_i^2) \\
0 &= \sum_{i=1}^n x_i y_i - \hat{\beta}_0 \sum_{i=1}^n x_i - \hat{\beta}_1 \sum_{i=1}^n x_i^2) \\
0 &\overset{\eqref{eq:slr-mle-beta0-mle}}{=} \sum_{i=1}^n x_i y_i - (\bar{y} - \hat{\beta}_1 \bar{x}) \sum_{i=1}^n x_i - \hat{\beta}_1 \sum_{i=1}^n x_i^2 \\
0 &= \sum_{i=1}^n x_i y_i - \bar{y} \sum_{i=1}^n x_i + \hat{\beta}_1 \bar{x} \sum_{i=1}^n x_i - \hat{\beta}_1 \sum_{i=1}^n x_i^2 \\
0 &= \sum_{i=1}^n x_i y_i - n \bar{x} \bar{y} + \hat{\beta}_1 n \bar{x}^2 - \hat{\beta}_1 \sum_{i=1}^n x_i^2 \\
\hat{\beta}_1 &= \frac{\sum_{i=1}^n x_i y_i - \sum_{i=1}^n \bar{x} \bar{y}}{\sum_{i=1}^n x_i^2 - \sum_{i=1}^n \bar{x}^2} \\
\hat{\beta}_1 &= \frac{\sum_{i=1}^n (x_i - \bar{x}) (y_i - \bar{y})}{\sum_{i=1}^n (x_i - \bar{x})^2} \\
\hat{\beta}_1 &= \frac{s_{xy}}{s_x^2} \; .
\end{split}
\end{equation}

\vspace{1em}
The derivative of the log-likelihood function \eqref{eq:slr-mle-slr-ll} at $(\hat{\beta}_0,\hat{\beta}_1)$ with respect to $\sigma^2$ is

\begin{equation} \label{eq:slr-mle-dLL-ds2}
\frac{\mathrm{d}\mathrm{LL}(\hat{\beta}_0,\hat{\beta}_1,\sigma^2)}{\mathrm{d}\sigma^2} = - \frac{n}{2\sigma^2} + \frac{1}{2(\sigma^2)^2} \sum_{i=1}^n (y_i - \hat{\beta}_0 - \hat{\beta}_1 x_i)^2
\end{equation}

and setting this derivative to zero gives the MLE for $\sigma^2$:

\begin{equation} \label{eq:slr-mle-s2-mle}
\begin{split}
\frac{\mathrm{d}\mathrm{LL}(\hat{\beta}_0,\hat{\beta}_1,\hat{\sigma}^2)}{\mathrm{d}\sigma^2} &= 0 \\
0 &= - \frac{n}{2\hat{\sigma}^2} + \frac{1}{2(\hat{\sigma}^2)^2} \sum_{i=1}^n (y_i - \hat{\beta}_0 - \hat{\beta}_1 x_i)^2 \\
\frac{n}{2\hat{\sigma}^2} &= \frac{1}{2(\hat{\sigma}^2)^2} \sum_{i=1}^n (y_i - \hat{\beta}_0 - \hat{\beta}_1 x_i)^2 \\
\hat{\sigma}^2 &= \frac{1}{n} \sum_{i=1}^n (y_i - \hat{\beta}_0 - \hat{\beta}_1 x_i)^2 \; .
\end{split}
\end{equation}

\vspace{1em}
Together, \eqref{eq:slr-mle-beta0-mle}, \eqref{eq:slr-mle-beta1-mle} and \eqref{eq:slr-mle-s2-mle} constitute the MLE for simple linear regression.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P287 | shortcut: slr-mle | author: JoramSoch | date: 2021-11-16, 08:34.
\vspace{1em}



\subsubsection[\textbf{Maximum likelihood estimation}]{Maximum likelihood estimation} \label{sec:slr-mle2}
\setcounter{equation}{0}

\textbf{Theorem:} Given a simple linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}) with independent observations

\begin{equation} \label{eq:slr-mle2-slr}
y_i = \beta_0 + \beta_1 x_i + \varepsilon_i, \; \varepsilon_i \sim \mathcal{N}(0, \sigma^2), \; i = 1,\ldots,n \; ,
\end{equation}

the maximum likelihood estimates ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mle}) of $\beta_0$, $\beta_1$ and $\sigma^2$ are given by

\begin{equation} \label{eq:slr-mle2-slr-mle}
\begin{split}
\hat{\beta}_0 &= \bar{y} - \hat{\beta}_1 \bar{x} \\
\hat{\beta}_1 &= \frac{s_{xy}}{s_x^2} \\
\hat{\sigma}^2 &= \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{\beta}_0 - \hat{\beta}_1 x_i)^2
\end{split}
\end{equation}

where $\bar{x}$ and $\bar{y}$ are the sample means ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean-samp}), $s_x^2$ is the sample variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var-samp}) of $x$ and $s_{xy}$ is the sample covariance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cov-samp}) between $x$ and $y$.


\vspace{1em}
\textbf{Proof:} Simple linear regression is a special case of multiple linear regression ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:slr-mlr}) with

\begin{equation} \label{eq:slr-mle2-slr-mlr}
X = \left[ \begin{matrix} 1_n & x \end{matrix} \right] \quad \text{and} \quad \beta = \left[ \begin{matrix} \beta_0 \\ \beta_1 \end{matrix} \right]
\end{equation}

and weighted least sqaures estimates ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mlr-mle}) are given by

\begin{equation} \label{eq:slr-mle2-mlr-mle}
\begin{split}
\hat{\beta} &= (X^\mathrm{T} V^{-1} X)^{-1} X^\mathrm{T} V^{-1} y \\
\hat{\sigma}^2 &= \frac{1}{n} (y-X\hat{\beta})^\mathrm{T} V^{-1} (y-X\hat{\beta}) \; .
\end{split}
\end{equation}

Under independent observations, the covariance matrix is

\begin{equation} \label{eq:slr-mle2-mlr-ind}
V = I_n, \quad \text{such that} \quad V^{-1} = I_n \; .
\end{equation}

Thus, we can write out the estimate of $\beta$

\begin{equation} \label{eq:slr-mle2-slr-mle-b}
\begin{split}
\hat{\beta} &= \left( \left[ \begin{matrix} 1_n^\mathrm{T} \\ x^\mathrm{T} \end{matrix} \right] V^{-1} \left[ \begin{matrix} 1_n & x \end{matrix} \right] \right)^{-1} \left[ \begin{matrix} 1_n^\mathrm{T} \\ x^\mathrm{T} \end{matrix} \right] V^{-1} y \\
&= \left( \left[ \begin{matrix} 1_n^\mathrm{T} \\ x^\mathrm{T} \end{matrix} \right] \left[ \begin{matrix} 1_n & x \end{matrix} \right] \right)^{-1} \left[ \begin{matrix} 1_n^\mathrm{T} \\ x^\mathrm{T} \end{matrix} \right] y
\end{split}
\end{equation}

which is equal to the ordinary least squares solution for simple linear regression ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:slr-ols2}):

\begin{equation} \label{eq:slr-mle2-slr-mle-b-qed}
\begin{split}
\hat{\beta}_0 &= \bar{y} - \hat{\beta}_1 \bar{x} \\
\hat{\beta}_1 &= \frac{s_{xy}}{s_x^2} \; .
\end{split}
\end{equation}

Additionally, we can write out the estimate of $\sigma^2$:

\begin{equation} \label{eq:slr-mle2-slr-mle-s2}
\begin{split}
\hat{\sigma}^2 &= \frac{1}{n} (y-X\hat{\beta})^\mathrm{T} V^{-1} (y-X\hat{\beta}) \\
&= \frac{1}{n} \left( y - \left[ \begin{matrix} 1_n & x \end{matrix} \right] \left[ \begin{matrix} \hat{\beta}_0 \\ \hat{\beta}_1 \end{matrix} \right] \right)^\mathrm{T} \left( y - \left[ \begin{matrix} 1_n & x \end{matrix} \right] \left[ \begin{matrix} \hat{\beta}_0 \\ \hat{\beta}_1 \end{matrix} \right] \right) \\
&= \frac{1}{n} \left( y - \hat{\beta}_0 - \hat{\beta}_1 x \right)^\mathrm{T} \left( y - \hat{\beta}_0 - \hat{\beta}_1 x \right) \\
&= \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{\beta}_0 - \hat{\beta}_1 x_i)^2 \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P290 | shortcut: slr-mle2 | author: JoramSoch | date: 2021-11-16, 11:53.
\vspace{1em}



\subsubsection[\textbf{Sum of residuals is zero}]{Sum of residuals is zero} \label{sec:slr-ressum}
\setcounter{equation}{0}

\textbf{Theorem:} In simple linear regression ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:slr}), the sum of the residuals ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:rss}) is zero when estimated using ordinary least squares ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:slr-ols}).

\vspace{1em}
\textbf{Proof:} The residuals are defined as the estimated error terms ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:slr})

\begin{equation} \label{eq:slr-ressum-slr-res}
\hat{\varepsilon}_i = y_i - \hat{\beta}_0 - \hat{\beta}_1 x_i
\end{equation}

where $\hat{\beta}_0$ and $\hat{\beta}_1$ are parameter estimates obtained using ordinary least squares ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:slr-ols}):

\begin{equation} \label{eq:slr-ressum-slr-ols}
\hat{\beta}_0 = \bar{y} - \hat{\beta}_1 \bar{x} \quad \text{and} \quad \hat{\beta}_1 = \frac{s_{xy}}{s_x^2} \; .
\end{equation}

With that, we can calculate the sum of the residuals:

\begin{equation} \label{eq:slr-ressum-slr-ressum}
\begin{split}
\sum_{i=1}^n \hat{\varepsilon}_i &= \sum_{i=1}^n (y_i - \hat{\beta}_0 - \hat{\beta}_1 x_i) \\
&= \sum_{i=1}^n (y_i - \bar{y} + \hat{\beta}_1 \bar{x} - \hat{\beta}_1 x_i) \\
&= \sum_{i=1}^n y_i - n \bar{y} + \hat{\beta}_1 n \bar{x} - \hat{\beta}_1 \sum_{i=1}^n x_i \\
&= n \bar{y} - n \bar{y} + \hat{\beta}_1 n \bar{x} - \hat{\beta}_1 n \bar{x} \\
&= 0 \; .
\end{split}
\end{equation}

Thus, the sum of the residuals ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:rss}) is zero under ordinary least squares ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:slr-ols}), if the model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:slr}) includes an intercept term $\beta_0$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Simple linear regression"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-10-27; URL: \url{https://en.wikipedia.org/wiki/Simple_linear_regression#Numerical_properties}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P276 | shortcut: slr-ressum | author: JoramSoch | date: 2021-10-27, 13:07.
\vspace{1em}



\subsubsection[\textbf{Correlation with covariate is zero}]{Correlation with covariate is zero} \label{sec:slr-rescorr}
\setcounter{equation}{0}

\textbf{Theorem:} In simple linear regression ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:slr}), the residuals ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:rss}) and the covariate ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:slr}) are uncorrelated ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:corr}) when estimated using ordinary least squares ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:slr-ols}).

\vspace{1em}
\textbf{Proof:} The residuals are defined as the estimated error terms ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:slr})

\begin{equation} \label{eq:slr-rescorr-slr-res}
\hat{\varepsilon}_i = y_i - \hat{\beta}_0 - \hat{\beta}_1 x_i
\end{equation}

where $\hat{\beta}_0$ and $\hat{\beta}_1$ are parameter estimates obtained using ordinary least squares ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:slr-ols}):

\begin{equation} \label{eq:slr-rescorr-slr-ols}
\hat{\beta}_0 = \bar{y} - \hat{\beta}_1 \bar{x} \quad \text{and} \quad \hat{\beta}_1 = \frac{s_{xy}}{s_x^2} \; .
\end{equation}

With that, we can calculate the inner product of the covariate and the residuals vector:

\begin{equation} \label{eq:slr-rescorr-slr-rescorr}
\begin{split}
\sum_{i=1}^n x_i \hat{\varepsilon}_i &= \sum_{i=1}^n x_i (y_i - \hat{\beta}_0 - \hat{\beta}_1 x_i) \\
&= \sum_{i=1}^n \left( x_i y_i - \hat{\beta}_0 x_i - \hat{\beta}_1 x_i^2 \right) \\
&= \sum_{i=1}^n \left( x_i y_i - x_i (\bar{y} - \hat{\beta}_1 \bar{x}) - \hat{\beta}_1 x_i^2 \right) \\
&= \sum_{i=1}^n \left( x_i (y_i - \bar{y}) + \hat{\beta}_1 (\bar{x} x_i - x_i^2 \right) \\
&= \sum_{i=1}^n x_i y_i - \bar{y} \sum_{i=1}^n x_i - \hat{\beta}_1 \left( \sum_{i=1}^n x_i^2 - \bar{x} \sum_{i=1}^n x_i \right) \\
&= \left( \sum_{i=1}^n x_i y_i - n \bar{x} \bar{y} - n \bar{x} \bar{y} + n \bar{x} \bar{y} \right) - \hat{\beta}_1 \left( \sum_{i=1}^n x_i^2 - 2 n \bar{x} \bar{x} + n \bar{x}^2 \right) \\
&= \left( \sum_{i=1}^n x_i y_i - \bar{y} \sum_{i=1}^n x_i - \bar{x} \sum_{i=1}^n y_i + n \bar{x} \bar{y} \right) - \hat{\beta}_1 \left( \sum_{i=1}^n x_i^2 - 2 \bar{x} \sum_{i=1}^n x_i + n \bar{x}^2 \right) \\
&= \sum_{i=1}^n \left( x_i y_i - \bar{y} x_i - \bar{x} y_i + \bar{x} \bar{y} \right) - \hat{\beta}_1 \sum_{i=1}^n \left( x_i^2 - 2 \bar{x} x_i + \bar{x}^2 \right) \\
&= \sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y}) - \hat{\beta}_1 \sum_{i=1}^n (x_i - \bar{x})^2 \\
&= (n-1) s_{xy} - \frac{s_{xy}}{s_x^2} (n-1) s_x^2 \\
&= (n-1) s_{xy} - (n-1) s_{xy} \\
&= 0 \; .
\end{split}
\end{equation}

Because an inner product of zero also implies zero correlation ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:corr}), this demonstrates that residuals ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:rss}) and covariate ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:slr}) values are uncorrelated under ordinary least squares ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:slr-ols}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Simple linear regression"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-10-27; URL: \url{https://en.wikipedia.org/wiki/Simple_linear_regression#Numerical_properties}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P277 | shortcut: slr-rescorr | author: JoramSoch | date: 2021-10-27, 13:07.
\vspace{1em}



\subsubsection[\textbf{Residual variance in terms of sample variance}]{Residual variance in terms of sample variance} \label{sec:slr-resvar}
\setcounter{equation}{0}

\textbf{Theorem:} Assume a simple linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:slr}) with independent observations

\begin{equation} \label{eq:slr-resvar-slr}
y = \beta_0 + \beta_1 x + \varepsilon, \; \varepsilon_i \sim \mathcal{N}(0, \sigma^2), \; i = 1,\ldots,n
\end{equation}

and consider estimation using ordinary least squares ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:slr-ols}). Then, residual variance ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:resvar}) and sample variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var-samp}) are related to each other via the correlation coefficient ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:corr}):

\begin{equation} \label{eq:slr-resvar-slr-vars}
\hat{\sigma}^2 = \left( 1 - r_{xy}^2 \right) s_y^2 \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The residual variance ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:resvar}) can be expressed in terms of the residual sum of squares ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:rss}):

\begin{equation} \label{eq:slr-resvar-slr-res}
\hat{\sigma}^2 = \frac{1}{n-1} \, \mathrm{RSS}(\hat{\beta}_0,\hat{\beta}_1)
\end{equation}

and the residual sum of squares for simple linear regression ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:slr-sss}) is

\begin{equation} \label{eq:slr-resvar-slr-rss}
\mathrm{RSS}(\hat{\beta}_0,\hat{\beta}_1) = (n-1) \left( s_y^2 - \frac{s_{xy}^2}{s_x^2} \right) \; .
\end{equation}

Combining \eqref{eq:slr-resvar-slr-res} and \eqref{eq:slr-resvar-slr-rss}, we obtain:

\begin{equation} \label{eq:slr-resvar-slr-vars-s1}
\begin{split}
\hat{\sigma}^2 &= \left( s_y^2 - \frac{s_{xy}^2}{s_x^2} \right) \\
&= \left( 1 - \frac{s_{xy}^2}{s_x^2 s_y^2} \right) s_y^2 \\
&= \left( 1 - \left( \frac{s_{xy}}{s_x \, s_y} \right)^2 \right) s_y^2 \; .
\end{split}
\end{equation}

Using the relationship between correlation, covariance and standard deviation ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:corr})

\begin{equation} \label{eq:slr-resvar-corr-cov-std}
\mathrm{Corr}(X,Y) = \frac{\mathrm{Cov}(X,Y)}{\sqrt{\mathrm{Var}(X)} \sqrt{\mathrm{Var}(Y)}}
\end{equation}

which also holds for sample correlation, sample covariance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cov-samp}) and sample standard deviation ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:std})

\begin{equation} \label{eq:slr-resvar-corr-cov-std-samp}
r_{xy} = \frac{s_{xy}}{s_x \, s_y} \; ,
\end{equation}

we get the final result:

\begin{equation} \label{eq:slr-resvar-slr-vars-s2}
\hat{\sigma}^2 = \left( 1 - r_{xy}^2 \right) s_y^2 \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Penny, William (2006): "Relation to correlation"; in: \textit{Mathematics for Brain Imaging}, ch. 1.2.3, p. 18, eq. 1.28; URL: \url{https://ueapsylabs.co.uk/sites/wpenny/mbi/mbi_course.pdf}.
\item Wikipedia (2021): "Simple linear regression"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-10-27; URL: \url{https://en.wikipedia.org/wiki/Simple_linear_regression#Numerical_properties}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P278 | shortcut: slr-resvar | author: JoramSoch | date: 2021-10-27, 14:37.
\vspace{1em}



\subsubsection[\textbf{Correlation coefficient in terms of slope estimate}]{Correlation coefficient in terms of slope estimate} \label{sec:slr-corr}
\setcounter{equation}{0}

\textbf{Theorem:} Assume a simple linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:slr}) with independent observations

\begin{equation} \label{eq:slr-corr-slr}
y = \beta_0 + \beta_1 x + \varepsilon, \; \varepsilon_i \sim \mathcal{N}(0, \sigma^2), \; i = 1,\ldots,n
\end{equation}

and consider estimation using ordinary least squares ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:slr-ols}). Then, correlation coefficient ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:corr}) and the estimated value of the slope parameter ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:slr}) are related to each other via the sample standard deviations ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:std}):

\begin{equation} \label{eq:slr-corr-slr-corr}
r_{xy} = \frac{s_x}{s_y} \, \hat{\beta}_1 \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The ordinary least squares estimate of the slope ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:slr-ols}) is given by

\begin{equation} \label{eq:slr-corr-slr-ols-sl}
\hat{\beta}_1 = \frac{s_{xy}}{s_x^2} \; .
\end{equation}

Using the relationship between covariance and correlation ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:cov-corr})

\begin{equation} \label{eq:slr-corr-cov-corr}
\mathrm{Cov}(X,Y) = \sigma_X \, \mathrm{Corr}(X,Y) \, \sigma_Y
\end{equation}

which also holds for sample correlation ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:corr}) and sample covariance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cov-samp})

\begin{equation} \label{eq:slr-corr-cov-corr-samp}
s_{xy} = s_x \, r_{xy} \, s_y \; ,
\end{equation}

we get the final result:

\begin{equation} \label{eq:slr-corr-slr-corr-qed}
\begin{split}
\hat{\beta}_1 &= \frac{s_{xy}}{s_x^2} \\
\hat{\beta}_1 &= \frac{s_x \, r_{xy} \, s_y}{s_x^2} \\
\hat{\beta}_1 &= \frac{s_y}{s_x} \, r_{xy} \\
\Leftrightarrow \quad r_{xy} &= \frac{s_x}{s_y} \, \hat{\beta}_1 \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Penny, William (2006): "Relation to correlation"; in: \textit{Mathematics for Brain Imaging}, ch. 1.2.3, p. 18, eq. 1.27; URL: \url{https://ueapsylabs.co.uk/sites/wpenny/mbi/mbi_course.pdf}.
\item Wikipedia (2021): "Simple linear regression"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-10-27; URL: \url{https://en.wikipedia.org/wiki/Simple_linear_regression#Fitting_the_regression_line}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P279 | shortcut: slr-corr | author: JoramSoch | date: 2021-10-27, 14:58.
\vspace{1em}



\subsubsection[\textbf{Coefficient of determination in terms of correlation coefficient}]{Coefficient of determination in terms of correlation coefficient} \label{sec:slr-rsq}
\setcounter{equation}{0}

\textbf{Theorem:} Assume a simple linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:slr}) with independent observations

\begin{equation} \label{eq:slr-rsq-slr}
y = \beta_0 + \beta_1 x + \varepsilon, \; \varepsilon_i \sim \mathcal{N}(0, \sigma^2), \; i = 1,\ldots,n
\end{equation}

and consider estimation using ordinary least squares ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:slr-ols}). Then, the coefficient of determination ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:rsq}) is equal to the squared correlation coefficient ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:corr}) between $x$ and $y$:

\begin{equation} \label{eq:slr-rsq-slr-R2}
R^2 = r_{xy}^2 \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The ordinary least squares estimates for simple linear regression ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:slr-ols}) are

\begin{equation} \label{eq:slr-rsq-slr-ols}
\begin{split}
\hat{\beta}_0 &= \bar{y} - \hat{\beta}_1 \bar{x} \\
\hat{\beta}_1 &= \frac{s_{xy}}{s_x^2} \; .
\end{split}
\end{equation}

The coefficient of determination ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:rsq}) $R^2$ is defined as the proportion of the variance explained by the independent variables, relative to the total variance in the data. This can be quantified as the ratio of explained sum of squares ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:ess}) to total sum of squares ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:tss}):

\begin{equation} \label{eq:slr-rsq-slr-R2-s1}
R^2 = \frac{\mathrm{ESS}}{\mathrm{TSS}} \; .
\end{equation}

Using the explained and total sum of squares for simple linear regression ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:slr-sss}), we have:

\begin{equation} \label{eq:slr-rsq-slr-R2-s2}
\begin{split}
R^2 &= \frac{\sum_{i=1}^{n} (\hat{y}_i - \bar{y})^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2} \\
&= \frac{\sum_{i=1}^{n} (\hat{\beta}_0 + \hat{\beta}_1 x_i - \bar{y})^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2} \; .
\end{split}
\end{equation}

By applying \eqref{eq:slr-rsq-slr-ols}, we can further develop the coefficient of determination:

\begin{equation} \label{eq:slr-rsq-slr-R2-s3}
\begin{split}
R^2 &= \frac{\sum_{i=1}^{n} (\bar{y} - \hat{\beta}_1 \bar{x} + \hat{\beta}_1 x_i - \bar{y})^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2} \\
&= \frac{\sum_{i=1}^{n} \left( \hat{\beta}_1 (x_i - \bar{x}) \right)^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2} \\
&= \hat{\beta}_1^2 \, \frac{\frac{1}{n-1} \sum_{i=1}^{n} (x_i - \bar{x})^2}{\frac{1}{n-1} \sum_{i=1}^{n} (y_i - \bar{y})^2} \\
&= \hat{\beta}_1^2 \, \frac{s_x^2}{s_y^2} \\ 
&= \left( \frac{s_x}{s_y} \, \hat{\beta}_1 \right)^2 \; .
\end{split}
\end{equation}

Using the relationship between correlation coefficient and slope estimate ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:slr-corr}), we conclude:

\begin{equation} \label{eq:slr-rsq-slr-R2-qed}
R^2 = \left( \frac{s_x}{s_y} \, \hat{\beta}_1 \right)^2 = r_{xy}^2 \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2021): "Simple linear regression"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-10-27; URL: \url{https://en.wikipedia.org/wiki/Simple_linear_regression#Fitting_the_regression_line}.
\item Wikipedia (2021): "Coefficient of determination"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-10-27; URL: \url{https://en.wikipedia.org/wiki/Coefficient_of_determination#As_squared_correlation_coefficient}.
\item Wikipedia (2021): "Correlation"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-10-27; URL: \url{https://en.wikipedia.org/wiki/Correlation#Sample_correlation_coefficient}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P280 | shortcut: slr-rsq | author: JoramSoch | date: 2021-10-27, 15:31.
\vspace{1em}



\subsection{Multiple linear regression}

\subsubsection[\textit{Definition}]{Definition} \label{sec:mlr}
\setcounter{equation}{0}

\textbf{Definition:} Let $y$ be an $n \times 1$ vector and let $X$ be an $n \times p$ matrix.

Then, a statement asserting a linear combination of $X$ into $y$

\begin{equation} \label{eq:mlr-mlr-model}
y = X\beta + \varepsilon \; ,
\end{equation}

together with a statement asserting a normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mvn}) for $\varepsilon$

\begin{equation} \label{eq:mlr-mlr-noise}
\varepsilon \sim \mathcal{N}(0, \sigma^2 V)
\end{equation}

is called a univariate linear regression model or simply, "multiple linear regression".

\begin{itemize}

\item $y$ is called "measured data", "dependent variable" or "measurements";

\item $X$ is called "design matrix", "set of independent variables" or "predictors";

\item $V$ is called "covariance matrix" or "covariance structure";

\item $\beta$ are called "regression coefficients" or "weights";

\item $\varepsilon$ is called "noise", "errors" or "error terms";

\item $\sigma^2$ is called "noise variance" or "error variance";

\item $n$ is the number of observations;

\item $p$ is the number of predictors.

\end{itemize}

Alternatively, the linear combination may also be written as

\begin{equation} \label{eq:mlr-mlr-model-sum}
y = \sum_{i=1}^{p} \beta_i x_i + \varepsilon
\end{equation}

or, when the model includes an intercept term, as

\begin{equation} \label{eq:mlr-mlr-model-sum-base}
y = \beta_0 + \sum_{i=1}^{p} \beta_i x_i + \varepsilon
\end{equation}

which is equivalent to adding a constant regressor $x_0 = 1_n$ to the design matrix $X$.

When the covariance structure $V$ is equal to the $n \times n$ identity matrix, this is called multiple linear regression with independent and identically distributed (i.i.d.) observations:

\begin{equation} \label{eq:mlr-mlr-noise-iid}
V = I_n \quad \Rightarrow \quad \varepsilon \sim \mathcal{N}(0, \sigma^2 I_n) \quad \Rightarrow \quad \varepsilon_i \overset{\text{i.i.d.}}{\sim} \mathcal{N}(0, \sigma^2) \; .
\end{equation}

Otherwise, it is called multiple linear regression with correlated observations.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Linear regression"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-03-21; URL: \url{https://en.wikipedia.org/wiki/Linear_regression#Simple_and_multiple_linear_regression}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D36 | shortcut: mlr | author: JoramSoch | date: 2020-03-21, 20:09.
\vspace{1em}



\subsubsection[\textbf{Ordinary least squares}]{Ordinary least squares} \label{sec:mlr-ols}
\setcounter{equation}{0}

\textbf{Theorem:} Given a linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}) with independent observations

\begin{equation} \label{eq:mlr-ols-MLR}
y = X\beta + \varepsilon, \; \varepsilon_i \overset{\mathrm{i.i.d.}}{\sim} \mathcal{N}(0, \sigma^2) \; ,
\end{equation}

the parameters minimizing the residual sum of squares ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:rss}) are given by

\begin{equation} \label{eq:mlr-ols-OLS}
\hat{\beta} = (X^\mathrm{T} X)^{-1} X^\mathrm{T} y \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} Let $\hat{\beta}$ be the ordinary least squares (OLS) solution and let $\hat{\varepsilon} = y - X\hat{\beta}$ be the resulting vector of residuals. Then, this vector must be orthogonal to the design matrix,

\begin{equation} \label{eq:mlr-ols-X-e-orth}
X^\mathrm{T} \hat{\varepsilon} = 0 \; ,
\end{equation}

because if it wasn't, there would be another solution $\tilde{\beta}$ giving another vector $\tilde{\varepsilon}$ with a smaller residual sum of squares. From \eqref{eq:mlr-ols-X-e-orth}, the OLS formula can be directly derived:

\begin{equation} \label{eq:mlr-ols-OLS-qed}
\begin{split}
X^\mathrm{T} \hat{\varepsilon} &= 0 \\
X^\mathrm{T} \left( y - X\hat{\beta} \right) &= 0 \\
X^\mathrm{T} y - X^\mathrm{T} X\hat{\beta} &= 0 \\
X^\mathrm{T} X\hat{\beta} &= X^\mathrm{T} y \\
\hat{\beta} &= (X^\mathrm{T} X)^{-1} X^\mathrm{T} y \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Stephan, Klaas Enno (2010): "The General Linear Model (GLM)"; in: \textit{Methods and models for fMRI data analysis in neuroeconomics}, Lecture 3, Slides 10/11; URL: \url{http://www.socialbehavior.uzh.ch/teaching/methodsspring10.html}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P2 | shortcut: mlr-ols | author: JoramSoch | date: 2019-09-27, 07:18.
\vspace{1em}



\subsubsection[\textbf{Ordinary least squares}]{Ordinary least squares} \label{sec:mlr-ols2}
\setcounter{equation}{0}

\textbf{Theorem:} Given a linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}) with independent observations

\begin{equation} \label{eq:mlr-ols2-MLR}
y = X\beta + \varepsilon, \; \varepsilon_i \overset{\mathrm{i.i.d.}}{\sim} \mathcal{N}(0, \sigma^2) \; ,
\end{equation}

the parameters minimizing the residual sum of squares ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:rss}) are given by

\begin{equation} \label{eq:mlr-ols2-OLS}
\hat{\beta} = (X^\mathrm{T} X)^{-1} X^\mathrm{T} y \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The residual sum of squares ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:rss}) is defined as

\begin{equation} \label{eq:mlr-ols2-RSS}
\mathrm{RSS}(\beta) = \sum_{i=1}^n \varepsilon_i^2 = \varepsilon^\mathrm{T} \varepsilon = (y-X\beta)^\mathrm{T} (y-X\beta)
\end{equation}

which can be developed into

\begin{equation} \label{eq:mlr-ols2-RSS-dev}
\begin{split}
\mathrm{RSS}(\beta) &= y^\mathrm{T} y - y^\mathrm{T} X \beta - \beta^\mathrm{T} X^\mathrm{T} y + \beta^\mathrm{T} X^\mathrm{T} X \beta \\
&= y^\mathrm{T} y - 2 \beta^\mathrm{T} X^\mathrm{T} y + \beta^\mathrm{T} X^\mathrm{T} X \beta \; .
\end{split}
\end{equation}

The derivative of $\mathrm{RSS}(\beta)$ with respect to $\beta$ is

\begin{equation} \label{eq:mlr-ols2-RSS-der}
\frac{\mathrm{d}\mathrm{RSS}(\beta)}{\mathrm{d}\beta} = - 2 X^\mathrm{T} y + 2 X^\mathrm{T} X \beta
\end{equation}

and setting this deriative to zero, we obtain:

\begin{equation} \label{eq:mlr-ols2-OLS-qed}
\begin{split}
\frac{\mathrm{d}\mathrm{RSS}(\hat{\beta})}{\mathrm{d}\beta} &= 0 \\
0 &= - 2 X^\mathrm{T} y + 2 X^\mathrm{T} X \hat{\beta} \\
X^\mathrm{T} X \hat{\beta} &= X^\mathrm{T} y \\
\hat{\beta} &= (X^\mathrm{T} X)^{-1} X^\mathrm{T} y \; .
\end{split}
\end{equation}

Since the quadratic form $y^\mathrm{T} y$ in \eqref{eq:mlr-ols2-RSS-dev} is positive, $\hat{\beta}$ minimizes $\mathrm{RSS}(\beta)$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Proofs involving ordinary least squares"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-02-03; URL: \url{https://en.wikipedia.org/wiki/Proofs_involving_ordinary_least_squares#Least_squares_estimator_for_%CE%B2}.
\item ad (2015): "Derivation of the Least Squares Estimator for Beta in Matrix Notation"; in: \textit{Economic Theory Blog}, retrieved on 2021-05-27; URL: \url{https://economictheoryblog.com/2015/02/19/ols_estimator/}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P40 | shortcut: mlr-ols2 | author: JoramSoch | date: 2020-02-03, 18:43.
\vspace{1em}



\subsubsection[\textit{Total sum of squares}]{Total sum of squares} \label{sec:tss}
\setcounter{equation}{0}

\textbf{Definition:} Let there be a multiple linear regression with independent observations ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}) using measured data $y$ and design matrix $X$:

\begin{equation} \label{eq:tss-mlr}
y = X\beta + \varepsilon, \; \varepsilon_i \overset{\mathrm{i.i.d.}}{\sim} \mathcal{N}(0, \sigma^2) \; .
\end{equation}

Then, the total sum of squares (TSS) is defined as the sum of squared deviations of the measured signal from the average signal:

\begin{equation} \label{eq:tss-tss}
\mathrm{TSS} = \sum_{i=1}^n (y_i - \bar{y})^2 \quad \text{where} \quad \bar{y} = \frac{1}{n} \sum_{i=1}^n y_i \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Total sum of squares"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-03-21; URL: \url{https://en.wikipedia.org/wiki/Total_sum_of_squares}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D37 | shortcut: tss | author: JoramSoch | date: 2020-03-21, 21:44.
\vspace{1em}



\subsubsection[\textit{Explained sum of squares}]{Explained sum of squares} \label{sec:ess}
\setcounter{equation}{0}

\textbf{Definition:} Let there be a multiple linear regression with independent observations ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}) using measured data $y$ and design matrix $X$:

\begin{equation} \label{eq:ess-mlr}
y = X\beta + \varepsilon, \; \varepsilon_i \overset{\mathrm{i.i.d.}}{\sim} \mathcal{N}(0, \sigma^2) \; .
\end{equation}

Then, the explained sum of squares (ESS) is defined as the sum of squared deviations of the fitted signal from the average signal:

\begin{equation} \label{eq:ess-ess}
\mathrm{ESS} = \sum_{i=1}^n (\hat{y}_i - \bar{y})^2 \quad \text{where} \quad \hat{y} = X \hat{\beta} \quad \text{and} \quad \bar{y} = \frac{1}{n} \sum_{i=1}^n y_i
\end{equation}

with estimated regression coefficients $\hat{\beta}$, e.g. obtained via ordinary least squares ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mlr-ols}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Explained sum of squares"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-03-21; URL: \url{https://en.wikipedia.org/wiki/Explained_sum_of_squares}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D38 | shortcut: ess | author: JoramSoch | date: 2020-03-21, 21:57.
\vspace{1em}



\subsubsection[\textit{Residual sum of squares}]{Residual sum of squares} \label{sec:rss}
\setcounter{equation}{0}

\textbf{Definition:} Let there be a multiple linear regression with independent observations ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}) using measured data $y$ and design matrix $X$:

\begin{equation} \label{eq:rss-mlr}
y = X\beta + \varepsilon, \; \varepsilon_i \overset{\mathrm{i.i.d.}}{\sim} \mathcal{N}(0, \sigma^2) \; .
\end{equation}

Then, the residual sum of squares (RSS) is defined as the sum of squared deviations of the measured signal from the fitted signal:

\begin{equation} \label{eq:rss-rss}
\mathrm{RSS} = \sum_{i=1}^n (y_i - \hat{y}_i)^2 \quad \text{where} \quad \hat{y} = X \hat{\beta}
\end{equation}

with estimated regression coefficients $\hat{\beta}$, e.g. obtained via ordinary least squares ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mlr-ols}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Residual sum of squares"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-03-21; URL: \url{https://en.wikipedia.org/wiki/Residual_sum_of_squares}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D39 | shortcut: rss | author: JoramSoch | date: 2020-03-21, 22:03.
\vspace{1em}



\subsubsection[\textbf{Total, explained and residual sum of squares}]{Total, explained and residual sum of squares} \label{sec:mlr-pss}
\setcounter{equation}{0}

\textbf{Theorem:} Assume a linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}) with independent observations

\begin{equation} \label{eq:mlr-pss-mlr}
y = X\beta + \varepsilon, \; \varepsilon_i \overset{\mathrm{i.i.d.}}{\sim} \mathcal{N}(0, \sigma^2) \; ,
\end{equation}

and let $X$ contain a constant regressor $1_n$ modelling the intercept term. Then, it holds that

\begin{equation} \label{eq:mlr-pss-pss}
\mathrm{TSS} = \mathrm{ESS} + \mathrm{RSS}
\end{equation}

where $\mathrm{TSS}$ is the total sum of squares ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:tss}), $\mathrm{ESS}$ is the explained sum of squares ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:ess}) and $\mathrm{RSS}$ is the residual sum of squares ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:rss}).


\vspace{1em}
\textbf{Proof:} The total sum of squares ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:tss}) is given by

\begin{equation} \label{eq:mlr-pss-TSS}
\mathrm{TSS} = \sum_{i=1}^{n} (y_i - \bar{y})^2
\end{equation}

where $\bar{y}$ is the mean across all $y_i$. The $\mathrm{TSS}$ can be rewritten as

\begin{equation} \label{eq:mlr-pss-TSS-s1}
\begin{split}
\mathrm{TSS} &= \sum_{i=1}^{n} (y_i - \bar{y} + \hat{y}_i - \hat{y}_i)^2 \\
&= \sum_{i=1}^{n} \left( (\hat{y}_i - \bar{y}) + (y_i - \hat{y}_i) \right)^2 \\
&= \sum_{i=1}^{n} \left( (\hat{y}_i - \bar{y}) + \hat{\varepsilon}_i \right)^2 \\
&= \sum_{i=1}^{n} \left( (\hat{y}_i - \bar{y})^2 + 2 \, \hat{\varepsilon}_i (\hat{y}_i - \bar{y}) + \hat{\varepsilon}_i^2 \right) \\
&= \sum_{i=1}^{n} (\hat{y}_i - \bar{y})^2 + \sum_{i=1}^{n} \hat{\varepsilon}_i^2 + 2 \sum_{i=1}^{n} \hat{\varepsilon}_i (\hat{y}_i - \bar{y}) \\
&= \sum_{i=1}^{n} (\hat{y}_i - \bar{y})^2 + \sum_{i=1}^{n} \hat{\varepsilon}_i^2 + 2 \sum_{i=1}^{n} \hat{\varepsilon}_i (x_i \hat{\beta} - \bar{y}) \\
&= \sum_{i=1}^{n} (\hat{y}_i - \bar{y})^2 + \sum_{i=1}^{n} \hat{\varepsilon}_i^2 + 2 \sum_{i=1}^{n} \hat{\varepsilon}_i \left( \sum_{j=1}^{p} x_{ij} \hat{\beta}_j \right) - 2 \sum_{i=1}^{n} \hat{\varepsilon}_i \, \bar{y} \\
&= \sum_{i=1}^{n} (\hat{y}_i - \bar{y})^2 + \sum_{i=1}^{n} \hat{\varepsilon}_i^2 + 2 \sum_{j=1}^{p} \hat{\beta}_j \sum_{i=1}^{n} \hat{\varepsilon}_i x_{ij} - 2 \bar{y} \sum_{i=1}^{n} \hat{\varepsilon}_i \\
\end{split}
\end{equation}

The fact that the design matrix includes a constant regressor ensures that

\begin{equation} \label{eq:mlr-pss-e-est-sum}
\sum_{i=1}^{n} \hat{\varepsilon}_i = \hat{\varepsilon}^\mathrm{T} 1_n = 0
\end{equation}

and because the residuals are orthogonal to the design matrix ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mlr-ols}), we have

\begin{equation} \label{eq:mlr-pss-X-e-orth}
\sum_{i=1}^{n} \hat{\varepsilon}_i x_{ij} = \hat{\varepsilon}^\mathrm{T} x_j = 0 \; .
\end{equation}

Applying \eqref{eq:mlr-pss-e-est-sum} and \eqref{eq:mlr-pss-X-e-orth} to \eqref{eq:mlr-pss-TSS-s1}, this becomes

\begin{equation} \label{eq:mlr-pss-TSS-s2}
\mathrm{TSS} = \sum_{i=1}^{n} (\hat{y}_i - \bar{y})^2 + \sum_{i=1}^{n} \hat{\varepsilon}_i^2
\end{equation}

and, with the definitions of explained ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:ess}) and residual sum of squares ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:rss}), it is

\begin{equation} \label{eq:mlr-pss-TSS-s3}
\mathrm{TSS} = \mathrm{ESS} + \mathrm{RSS} \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Partition of sums of squares"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-03-09; URL: \url{https://en.wikipedia.org/wiki/Partition_of_sums_of_squares#Partitioning_the_sum_of_squares_in_linear_regression}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P76 | shortcut: mlr-pss | author: JoramSoch | date: 2020-03-09, 22:18.
\vspace{1em}



\subsubsection[\textit{Estimation matrix}]{Estimation matrix} \label{sec:emat}
\setcounter{equation}{0}

\textbf{Definition:} In multiple linear regression ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}), the estimation matrix is the matrix $E$ that results in ordinary least squares ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mlr-ols}) or weighted least squares ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mlr-wls}) parameter estimates when right-multiplied with the measured data:

\begin{equation} \label{eq:emat-em}
Ey = \hat{\beta} \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D81 | shortcut: emat | author: JoramSoch | date: 2020-07-22, 05:17.
\vspace{1em}



\subsubsection[\textit{Projection matrix}]{Projection matrix} \label{sec:pmat}
\setcounter{equation}{0}

\textbf{Definition:} In multiple linear regression ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}), the projection matrix is the matrix $P$ that results in the fitted signal explained by estimated parameters ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:emat}) when right-multiplied with the measured data:

\begin{equation} \label{eq:pmat-pm}
Py = \hat{y} = X \hat{\beta} \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Projection matrix"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-07-22; URL: \url{https://en.wikipedia.org/wiki/Projection_matrix#Overview}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D82 | shortcut: pmat | author: JoramSoch | date: 2020-07-22, 05:25.
\vspace{1em}



\subsubsection[\textit{Residual-forming matrix}]{Residual-forming matrix} \label{sec:rfmat}
\setcounter{equation}{0}

\textbf{Definition:} In multiple linear regression ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}), the residual-forming matrix is the matrix $R$ that results in the vector of residuals left over by estimated parameters ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:emat}) when right-multiplied with the measured data:

\begin{equation} \label{eq:rfmat-pm}
Ry = \hat{\varepsilon} = y - \hat{y} = y - X \hat{\beta} \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Projection matrix"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-07-22; URL: \url{https://en.wikipedia.org/wiki/Projection_matrix#Properties}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D83 | shortcut: rfmat | author: JoramSoch | date: 2020-07-22, 05:35.
\vspace{1em}



\subsubsection[\textbf{Estimation, projection and residual-forming matrix}]{Estimation, projection and residual-forming matrix} \label{sec:mlr-mat}
\setcounter{equation}{0}

\textbf{Theorem:} Assume a linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}) with independent observations

\begin{equation} \label{eq:mlr-mat-mlr}
y = X\beta + \varepsilon, \; \varepsilon_i \overset{\mathrm{i.i.d.}}{\sim} \mathcal{N}(0, \sigma^2)
\end{equation}

and consider estimation using ordinary least squares ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mlr-ols}). Then, the estimated parameters, fitted signal and residuals are given by

\begin{equation} \label{eq:mlr-mat-mlr-est}
\begin{split}
\hat{\beta} &= E y \\
\hat{y} &= P y \\
\hat{\varepsilon} &= R y
\end{split}
\end{equation}

where 

\begin{equation} \label{eq:mlr-mat-mlr-mat}
\begin{split}
E &= (X^\mathrm{T} X)^{-1} X^\mathrm{T} \\
P &= X (X^\mathrm{T} X)^{-1} X^\mathrm{T} \\
R &= I_n - X (X^\mathrm{T} X)^{-1} X^\mathrm{T}
\end{split}
\end{equation}

are the estimation matrix ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:emat}), projection matrix ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:pmat}) and residual-forming matrix ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:rfmat}) and $n$ is the number of observations.


\vspace{1em}
\textbf{Proof:}

1) Ordinary least squares parameter estimates of $\beta$ are defined as minimizing the residual sum of squares ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:rss})

\begin{equation} \label{eq:mlr-mat-ols}
\hat{\beta} = \operatorname*{arg\,min}_{\beta} \left[ (y-X\beta)^\mathrm{T} (y-X\beta) \right]
\end{equation}

and the solution to this ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mlr-ols}) is given by

\begin{equation} \label{eq:mlr-mat-b-est-qed}
\begin{split}
\hat{\beta} &= (X^\mathrm{T} X)^{-1} X^\mathrm{T} y \\
&\overset{\eqref{eq:mlr-mat-mlr-mat}}{=} E y \; .
\end{split}
\end{equation}

\vspace{1em}
2) The fitted signal is given by multiplying the design matrix with the estimated regression coefficients

\begin{equation} \label{eq:mlr-mat-y-est}
\hat{y} = X\hat{\beta}
\end{equation}

and using \eqref{eq:mlr-mat-b-est-qed}, this becomes

\begin{equation} \label{eq:mlr-mat-y-est-qed}
\begin{split}
\hat{y} &= X (X^\mathrm{T} X)^{-1} X^\mathrm{T} y \\
&\overset{\eqref{eq:mlr-mat-mlr-mat}}{=} P y \; .
\end{split}
\end{equation}

\vspace{1em}
3) The residuals of the model are calculated by subtracting the fitted signal from the measured signal

\begin{equation} \label{eq:mlr-mat-e-est}
\hat{\varepsilon} = y - \hat{y}
\end{equation}

and using \eqref{eq:mlr-mat-y-est-qed}, this becomes

\begin{equation} \label{eq:mlr-mat-e-est-qed}
\begin{split}
\hat{\varepsilon} &= y - X (X^\mathrm{T} X)^{-1} X^\mathrm{T} y \\
&= (I_n - X (X^\mathrm{T} X)^{-1} X^\mathrm{T}) y \\
&\overset{\eqref{eq:mlr-mat-mlr-mat}}{=} R y \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Stephan, Klaas Enno (2010): "The General Linear Model (GLM)"; in: \textit{Methods and models for fMRI data analysis in neuroeconomics}, Lecture 3, Slide 10; URL: \url{http://www.socialbehavior.uzh.ch/teaching/methodsspring10.html}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P75 | shortcut: mlr-mat | author: JoramSoch | date: 2020-03-09, 21:18.
\vspace{1em}



\subsubsection[\textbf{Idempotence of projection and residual-forming matrix}]{Idempotence of projection and residual-forming matrix} \label{sec:mlr-idem}
\setcounter{equation}{0}

\textbf{Theorem:} The projection matrix ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:pmat}) and the residual-forming matrix ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:rfmat}) are idempotent:

\begin{equation} \label{eq:mlr-idem-P^2-R^2}
\begin{split}
P^2 &= P \\
R^2 &= R \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Proof:}

1) The projection matrix for ordinary least squares is given by ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mlr-mat})

\begin{equation} \label{eq:mlr-idem-P}
P = X (X^\mathrm{T} X)^{-1} X^\mathrm{T} \; ,
\end{equation}

such that

\begin{equation} \label{eq:mlr-idem-P^2}
\begin{split}
P^2 &= X (X^\mathrm{T} X)^{-1} X^\mathrm{T} X (X^\mathrm{T} X)^{-1} X^\mathrm{T} \\
&= X (X^\mathrm{T} X)^{-1} X^\mathrm{T} \\
&\overset{\eqref{eq:mlr-idem-P}}{=} P \; .
\end{split}
\end{equation}

\vspace{1em}
2) The residual-forming matrix for ordinary least squares is given by ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mlr-mat})

\begin{equation} \label{eq:mlr-idem-R}
R = I_n - X (X^\mathrm{T} X)^{-1} X^\mathrm{T} = I_n - P \; ,
\end{equation}

such that

\begin{equation} \label{eq:mlr-idem-R^2}
\begin{split}
R^2 &= (I_n - P) (I_n - P) \\
&= I_n - P - P + P^2 \\
&\overset{\eqref{eq:mlr-idem-P^2}}{=} I_n - 2 P + P \\
&= I_n - P \\
&\overset{\eqref{eq:mlr-idem-R}}{=} R \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Projection matrix"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-07-22; URL: \url{https://en.wikipedia.org/wiki/Projection_matrix#Properties}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P135 | shortcut: mlr-idem | author: JoramSoch | date: 2020-07-22, 06:28.
\vspace{1em}



\subsubsection[\textbf{Weighted least squares}]{Weighted least squares} \label{sec:mlr-wls}
\setcounter{equation}{0}

\textbf{Theorem:} Given a linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}) with correlated observations

\begin{equation} \label{eq:mlr-wls-MLR}
y = X\beta + \varepsilon, \; \varepsilon \sim \mathcal{N}(0, \sigma^2 V) \; ,
\end{equation}

the parameters minimizing the weighted residual sum of squares ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:rss}) are given by

\begin{equation} \label{eq:mlr-wls-WLS}
\hat{\beta} = (X^\mathrm{T} V^{-1} X)^{-1} X^\mathrm{T} V^{-1} y \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} Let there be an $n \times n$ square matrix $W$, such that

\begin{equation} \label{eq:mlr-wls-W-def}
W V W^\mathrm{T} = I_n \; .
\end{equation}

Since $V$ is a covariance matrix and thus symmetric, $W$ is also symmetric and can be expressed as the matrix square root of the inverse of $V$:

\begin{equation} \label{eq:mlr-wls-W-V}
W V W = I_n \quad \Leftrightarrow \quad V = W^{-1} W^{-1} \quad \Leftrightarrow \quad V^{-1} = W W \quad \Leftrightarrow \quad W = V^{-1/2} \; .
\end{equation}

Left-multiplying the linear regression equation \eqref{eq:mlr-wls-MLR} with $W$, the linear transformation theorem ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mvn-ltt}) implies that

\begin{equation} \label{eq:mlr-wls-MLR-W}
Wy = WX\beta + W\varepsilon, \; W\varepsilon \sim \mathcal{N}(0, \sigma^2 W V W^T) \; .
\end{equation}

Applying \eqref{eq:mlr-wls-W-def}, we see that \eqref{eq:mlr-wls-MLR-W} is actually a linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}) with independent observations

\begin{equation} \label{eq:mlr-wls-MLR-W-dev}
\tilde{y} = \tilde{X}\beta + \tilde{\varepsilon}, \; \tilde{\varepsilon} \sim \mathcal{N}(0, \sigma^2 I_n)
\end{equation}

where $\tilde{y} = Wy$, $\tilde{X} = WX$ and $\tilde{\varepsilon} = W\varepsilon$, such that we can apply the ordinary least squares solution ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mlr-ols}) giving

\begin{equation} \label{eq:mlr-wls-WLS-qed}
\begin{split}
\hat{\beta} &= (\tilde{X}^\mathrm{T} \tilde{X})^{-1} \tilde{X}^\mathrm{T} \tilde{y} \\
&= \left( (WX)^\mathrm{T} WX \right)^{-1} (WX)^\mathrm{T} Wy \\
&= \left( X^\mathrm{T} W^\mathrm{T} W X \right)^{-1} X^\mathrm{T} W^\mathrm{T} W y \\
&= \left( X^\mathrm{T} W W X \right)^{-1} X^\mathrm{T} W W y \\
&\overset{\eqref{eq:mlr-wls-W-V}}{=} \left( X^\mathrm{T} V^{-1} X \right)^{-1} X^\mathrm{T} V^{-1} y
\end{split}
\end{equation}

which corresponds to the weighted least squares solution \eqref{eq:mlr-wls-WLS}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Stephan, Klaas Enno (2010): "The General Linear Model (GLM)"; in: \textit{Methods and models for fMRI data analysis in neuroeconomics}, Lecture 3, Slides 20/23; URL: \url{http://www.socialbehavior.uzh.ch/teaching/methodsspring10.html}.
\item Wikipedia (2021): "Weighted least squares"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2021-11-17; URL: \url{https://en.wikipedia.org/wiki/Weighted_least_squares#Motivation}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P77 | shortcut: mlr-wls | author: JoramSoch | date: 2020-03-11, 11:22.
\vspace{1em}



\subsubsection[\textbf{Weighted least squares}]{Weighted least squares} \label{sec:mlr-wls2}
\setcounter{equation}{0}

\textbf{Theorem:} Given a linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}) with correlated observations

\begin{equation} \label{eq:mlr-wls2-MLR}
y = X\beta + \varepsilon, \; \varepsilon \sim \mathcal{N}(0, \sigma^2 V) \; ,
\end{equation}

the parameters minimizing the weighted residual sum of squares ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:rss}) are given by

\begin{equation} \label{eq:mlr-wls2-WLS}
\hat{\beta} = (X^\mathrm{T} V^{-1} X)^{-1} X^\mathrm{T} V^{-1} y \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} Let there be an $n \times n$ square matrix $W$, such that

\begin{equation} \label{eq:mlr-wls2-W-def}
W V W^\mathrm{T} = I_n \; .
\end{equation}

Since $V$ is a covariance matrix and thus symmetric, $W$ is also symmetric and can be expressed the matrix square root of the inverse of $V$:

\begin{equation} \label{eq:mlr-wls2-W-V}
W V W = I_n \quad \Leftrightarrow \quad V = W^{-1} W^{-1} \quad \Leftrightarrow \quad V^{-1} = W W \quad \Leftrightarrow \quad W = V^{-1/2} \; .
\end{equation}

Left-multiplying the linear regression equation \eqref{eq:mlr-wls2-MLR} with $W$, the linear transformation theorem ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mvn-ltt}) implies that

\begin{equation} \label{eq:mlr-wls2-MLR-W}
Wy = WX\beta + W\varepsilon, \; W\varepsilon \sim \mathcal{N}(0, \sigma^2 W V W^T) \; .
\end{equation}

Applying \eqref{eq:mlr-wls2-W-def}, we see that \eqref{eq:mlr-wls2-MLR-W} is actually a linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}) with independent observations

\begin{equation} \label{eq:mlr-wls2-MLR-W-dev}
Wy = WX\beta + W\varepsilon, \; W\varepsilon \sim \mathcal{N}(0, \sigma^2 I_n) \; .
\end{equation}

With this, we can express the weighted residual sum of squares ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:rss}) as

\begin{equation} \label{eq:mlr-wls2-wRSS}
\mathrm{wRSS}(\beta) = \sum_{i=1}^n (W \varepsilon)_i = (W \varepsilon)^\mathrm{T} (W \varepsilon) = (Wy-WX\beta)^\mathrm{T} (Wy-WX\beta)
\end{equation}

which can be developed into

\begin{equation} \label{eq:mlr-wls2-wRSS-dev}
\begin{split}
\mathrm{wRSS}(\beta) &= y^\mathrm{T} W^\mathrm{T} W y - y^\mathrm{T} W^\mathrm{T} W X \beta - \beta^\mathrm{T} X^\mathrm{T} W^\mathrm{T} W y + \beta^\mathrm{T} X^\mathrm{T} W^\mathrm{T} W X \beta \\
&= y^\mathrm{T} W W y - 2 \beta^\mathrm{T} X^\mathrm{T} W W y + \beta^\mathrm{T} X^\mathrm{T} W W X \beta \\
&\overset{\eqref{eq:mlr-wls2-W-V}}{=} y^\mathrm{T} V^{-1} y - 2 \beta^\mathrm{T} X^\mathrm{T} V^{-1} y + \beta^\mathrm{T} X^\mathrm{T} V^{-1} X \beta \; .
\end{split}
\end{equation}

The derivative of $\mathrm{wRSS}(\beta)$ with respect to $\beta$ is

\begin{equation} \label{eq:mlr-wls2-wRSS-der}
\frac{\mathrm{d}\mathrm{wRSS}(\beta)}{\mathrm{d}\beta} = - 2 X^\mathrm{T} V^{-1} y + 2 X^\mathrm{T} V^{-1} X \beta
\end{equation}

and setting this deriative to zero, we obtain:

\begin{equation} \label{eq:mlr-wls2-WLS-qed}
\begin{split}
\frac{\mathrm{d}\mathrm{wRSS}(\hat{\beta})}{\mathrm{d}\beta} &= 0 \\
0 &= - 2 X^\mathrm{T} V^{-1} y + 2 X^\mathrm{T} V^{-1} X \hat{\beta} \\
X^\mathrm{T} V^{-1} X \hat{\beta} &= X^\mathrm{T} V^{-1} y \\
\hat{\beta} &= (X^\mathrm{T} V^{-1} X)^{-1} X^\mathrm{T} V^{-1} y \; .
\end{split}
\end{equation}

Since the quadratic form $y^\mathrm{T} V^{-1} y$ in \eqref{eq:mlr-wls2-wRSS-dev} is positive, $\hat{\beta}$ minimizes $\mathrm{wRSS}(\beta)$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P136 | shortcut: mlr-wls2 | author: JoramSoch | date: 2020-07-22, 06:48.
\vspace{1em}



\subsubsection[\textbf{Maximum likelihood estimation}]{Maximum likelihood estimation} \label{sec:mlr-mle}
\setcounter{equation}{0}

\textbf{Theorem:} Given a linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}) with correlated observations

\begin{equation} \label{eq:mlr-mle-MLR}
y = X\beta + \varepsilon, \; \varepsilon \sim \mathcal{N}(0, \sigma^2 V) \; ,
\end{equation}

the maximum likelihood estimates ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mle}) of $\beta$ and $\sigma^2$ are given  by

\begin{equation} \label{eq:mlr-mle-MLE-MLE}
\begin{split}
\hat{\beta} &= (X^\mathrm{T} V^{-1} X)^{-1} X^\mathrm{T} V^{-1} y \\
\hat{\sigma}^2 &= \frac{1}{n} (y-X\hat{\beta})^\mathrm{T} V^{-1} (y-X\hat{\beta}) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Proof:} With the probability density function of the multivariate normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mvn-pdf}), the linear regression equation \eqref{eq:mlr-mle-MLR} implies the following likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf})

\begin{equation} \label{eq:mlr-mle-MLR-LF}
\begin{split}
p(y|\beta,\sigma^2) &= \mathcal{N}(y; X\beta, \sigma^2 V) \\
&= \sqrt{\frac{1}{(2\pi)^n |\sigma^2 V|}} \cdot \exp\left[ -\frac{1}{2} (y - X\beta)^\mathrm{T} (\sigma^2 V)^{-1} (y - X\beta) \right]
\end{split}
\end{equation}

and, using $\lvert \sigma^2 V \rvert = (\sigma^2)^n \lvert V \rvert$, the log-likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:llf})

\begin{equation} \label{eq:mlr-mle-MLR-LL1}
\begin{split}
\mathrm{LL}(\beta,\sigma^2) = &\log p(y|\beta,\sigma^2) \\
= &- \frac{n}{2} \log(2\pi) - \frac{n}{2} \log (\sigma^2) - \frac{1}{2} \log |V| \\
&- \frac{1}{2 \sigma^2} (y - X\beta)^\mathrm{T} V^{-1} (y - X\beta) \; .
\end{split}
\end{equation}

Substituting the precision matrix $P = V^{-1}$ into \eqref{eq:mlr-mle-MLR-LL1} to ease notation, we have:

\begin{equation} \label{eq:mlr-mle-MLR-LL2}
\begin{split}
\mathrm{LL}(\beta,\sigma^2) = &- \frac{n}{2} \log(2\pi) - \frac{n}{2} \log(\sigma^2) - \frac{1}{2} \log(|V|) \\
&- \frac{1}{2 \sigma^2} \left( y^\mathrm{T} P y - 2 \beta^\mathrm{T} X^\mathrm{T} P y + \beta^\mathrm{T} X^\mathrm{T} P X \beta \right) \; .
\end{split}
\end{equation}

\vspace{1em}
The derivative of the log-likelihood function \eqref{eq:mlr-mle-MLR-LL2} with respect to $\beta$ is

\begin{equation} \label{eq:mlr-mle-dLL-dbeta}
\begin{split}
\frac{\mathrm{d}\mathrm{LL}(\beta,\sigma^2)}{\mathrm{d}\beta} &= \frac{\mathrm{d}}{\mathrm{d}\beta} \left( - \frac{1}{2 \sigma^2} \left( y^\mathrm{T} P y - 2 \beta^\mathrm{T} X^\mathrm{T} P y + \beta^\mathrm{T} X^\mathrm{T} P X \beta \right) \right) \\
&= \frac{1}{2 \sigma^2} \, \frac{\mathrm{d}}{\mathrm{d}\beta} \left( 2 \beta^\mathrm{T} X^\mathrm{T} P y - \beta^\mathrm{T} X^\mathrm{T} P X \beta \right) \\
&= \frac{1}{2 \sigma^2} \left( 2 X^\mathrm{T} P y - 2 X^\mathrm{T} P X \beta \right) \\
&= \frac{1}{\sigma^2} \left( X^\mathrm{T} P y - X^\mathrm{T} P X \beta \right)
\end{split}
\end{equation}

and setting this derivative to zero gives the MLE for $\beta$:

\begin{equation} \label{eq:mlr-mle-beta-MLE}
\begin{split}
\frac{\mathrm{d}\mathrm{LL}(\hat{\beta},\sigma^2)}{\mathrm{d}\beta} &= 0 \\
0 &= \frac{1}{\sigma^2} \left( X^\mathrm{T} P y - X^\mathrm{T} P X \hat{\beta} \right) \\
0 &= X^\mathrm{T} P y - X^\mathrm{T} P X \hat{\beta} \\
X^\mathrm{T} P X \hat{\beta} &= X^\mathrm{T} P y \\
\hat{\beta} &= \left( X^\mathrm{T} P X \right)^{-1} X^\mathrm{T} P y
\end{split}
\end{equation}

\vspace{1em}
The derivative of the log-likelihood function \eqref{eq:mlr-mle-MLR-LL1} at $\hat{\beta}$ with respect to $\sigma^2$ is

\begin{equation} \label{eq:mlr-mle-dLL-ds2}
\begin{split}
\frac{\mathrm{d}\mathrm{LL}(\hat{\beta},\sigma^2)}{\mathrm{d}\sigma^2} &= \frac{\mathrm{d}}{\mathrm{d}\sigma^2} \left( - \frac{n}{2} \log (\sigma^2) - \frac{1}{2 \sigma^2} (y - X\hat{\beta})^\mathrm{T} V^{-1} (y - X\hat{\beta}) \right) \\
&= - \frac{n}{2} \, \frac{1}{\sigma^2} + \frac{1}{2 (\sigma^2)^2} (y - X\hat{\beta})^\mathrm{T} V^{-1} (y - X\hat{\beta}) \\
&= - \frac{n}{2 \sigma^2} + \frac{1}{2 (\sigma^2)^2} (y - X\hat{\beta})^\mathrm{T} V^{-1} (y - X\hat{\beta})
\end{split}
\end{equation}

and setting this derivative to zero gives the MLE for $\sigma^2$:

\begin{equation} \label{eq:mlr-mle-s2-MLE}
\begin{split}
\frac{\mathrm{d}\mathrm{LL}(\hat{\beta},\hat{\sigma}^2)}{\mathrm{d}\sigma^2} &= 0 \\
0 &= - \frac{n}{2 \hat{\sigma}^2} + \frac{1}{2 (\hat{\sigma}^2)^2} (y - X\hat{\beta})^\mathrm{T} V^{-1} (y - X\hat{\beta}) \\
\frac{n}{2 \hat{\sigma}^2} &= \frac{1}{2 (\hat{\sigma}^2)^2} (y - X\hat{\beta})^\mathrm{T} V^{-1} (y - X\hat{\beta}) \\
\frac{2 (\hat{\sigma}^2)^2}{n} \cdot \frac{n}{2 \hat{\sigma}^2} &= \frac{2 (\hat{\sigma}^2)^2}{n} \cdot \frac{1}{2 (\hat{\sigma}^2)^2} (y - X\hat{\beta})^\mathrm{T} V^{-1} (y - X\hat{\beta}) \\
\hat{\sigma}^2 &= \frac{1}{n} (y - X\hat{\beta})^\mathrm{T} V^{-1} (y - X\hat{\beta})
\end{split}
\end{equation}

\vspace{1em}
Together, \eqref{eq:mlr-mle-beta-MLE} and \eqref{eq:mlr-mle-s2-MLE} constitute the MLE for multiple linear regression.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P78 | shortcut: mlr-mle | author: JoramSoch | date: 2020-03-11, 12:27.
\vspace{1em}



\subsection{Bayesian linear regression}

\subsubsection[\textbf{Conjugate prior distribution}]{Conjugate prior distribution} \label{sec:blr-prior}
\setcounter{equation}{0}

\textbf{Theorem:} Let

\begin{equation} \label{eq:blr-prior-GLM}
y = X \beta + \varepsilon, \; \varepsilon \sim \mathcal{N}(0, \sigma^2 V)
\end{equation}

be a linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}) with measured $n \times 1$ data vector $y$, known $n \times p$ design matrix $X$, known $n \times n$ covariance structure $V$ as well as unknown $p \times 1$ regression coefficients $\beta$ and unknown noise variance $\sigma^2$.

Then, the conjugate prior ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior-conj}) for this model is a normal-gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:ng})

\begin{equation} \label{eq:blr-prior-GLM-NG-prior}
p(\beta,\tau) = \mathcal{N}(\beta; \mu_0, (\tau \Lambda_0)^{-1}) \cdot \mathrm{Gam}(\tau; a_0, b_0)
\end{equation}

where $\tau = 1/\sigma^2$ is the inverse noise variance or noise precision.


\vspace{1em}
\textbf{Proof:} By definition, a conjugate prior ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior-conj}) is a prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) that, when combined with the likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}), leads to a posterior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) that belongs to the same family of probability distributions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist}). This is fulfilled when the prior density and the likelihood function are proportional to the model parameters in the same way, i.e. the model parameters appear in the same functional form in both.

Equation \eqref{eq:blr-prior-GLM} implies the following likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf})

\begin{equation} \label{eq:blr-prior-GLM-LF-class}
p(y|\beta,\sigma^2) = \mathcal{N}(y; X \beta, \sigma^2 V) = \sqrt{\frac{1}{(2 \pi)^n |\sigma^2 V|}} \, \exp\left[ -\frac{1}{2 \sigma^2} (y-X\beta)^\mathrm{T} V^{-1} (y-X\beta) \right]
\end{equation}

which, for mathematical convenience, can also be parametrized as

\begin{equation} \label{eq:blr-prior-GLM-LF-Bayes}
p(y|\beta,\tau) = \mathcal{N}(y; X \beta, (\tau P)^{-1}) = \sqrt{\frac{|\tau P|}{(2 \pi)^n}} \, \exp\left[ -\frac{\tau}{2} (y-X\beta)^\mathrm{T} P (y-X\beta) \right]
\end{equation}

using the noise precision $\tau = 1/\sigma^2$ and the $n \times n$ precision matrix $P = V^{-1}$.

\vspace{1em}
Seperating constant and variable terms, we have:

\begin{equation} \label{eq:blr-prior-GLM-LF-s1}
p(y|\beta,\tau) = \sqrt{\frac{|P|}{(2 \pi)^n}} \cdot \tau^{n/2} \cdot \exp\left[ -\frac{\tau}{2} (y-X\beta)^\mathrm{T} P (y-X\beta) \right] \; .
\end{equation}

Expanding the product in the exponent, we have:

\begin{equation} \label{eq:blr-prior-GLM-LF-s2}
p(y|\beta,\tau) = \sqrt{\frac{|P|}{(2 \pi)^n}} \cdot \tau^{n/2} \cdot \exp\left[ -\frac{\tau}{2} \left( y^\mathrm{T} P y - y^\mathrm{T} P X \beta - \beta^\mathrm{T} X^\mathrm{T} P y + \beta^\mathrm{T} X^\mathrm{T} P X \beta \right) \right] \; .
\end{equation}

Completing the square over $\beta$, finally gives

\begin{equation} \label{eq:blr-prior-GLM-LF-s3}
p(y|\beta,\tau) = \sqrt{\frac{|P|}{(2 \pi)^n}} \cdot \tau^{n/2} \cdot \exp\left[ -\frac{\tau}{2} \left( (\beta - \tilde{X}y)^\mathrm{T} X^\mathrm{T} P X (\beta - \tilde{X}y) - y^\mathrm{T} Q y + y^\mathrm{T} P y \right) \right]
\end{equation}

where $\tilde{X} = \left( X^\mathrm{T} P X \right)^{-1} X^\mathrm{T} P$ and $Q = \tilde{X}^\mathrm{T} \left( X^\mathrm{T} P X \right) \tilde{X}$.

\vspace{1em}
In other words, the likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) is proportional to a power of $\tau$, times an exponential of $\tau$ and an exponential of a squared form of $\beta$, weighted by $\tau$:

\begin{equation} \label{eq:blr-prior-GLM-LF-s4}
p(y|\beta,\tau) \propto \tau^{n/2} \cdot \exp\left[ -\frac{\tau}{2} \left( y^\mathrm{T} P y - y^\mathrm{T} Q y \right) \right] \cdot \exp\left[ -\frac{\tau}{2} (\beta - \tilde{X}y)^\mathrm{T} X^\mathrm{T} P X (\beta - \tilde{X}y) \right] \; .
\end{equation}

The same is true for a normal-gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:ng}) over $\beta$ and $\tau$

\begin{equation} \label{eq:blr-prior-BLR-prior-s1}
p(\beta,\tau) = \mathcal{N}(\beta; \mu_0, (\tau \Lambda_0)^{-1}) \cdot \mathrm{Gam}(\tau; a_0, b_0)
\end{equation}

the probability density function of which ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:ng-pdf})

\begin{equation} \label{eq:blr-prior-BLR-prior-s2}
p(\beta,\tau) = \sqrt{\frac{|\tau \Lambda_0|}{(2 \pi)^p}} \exp\left[ -\frac{\tau}{2} (\beta-\mu_0)^\mathrm{T} \Lambda_0 (\beta-\mu_0) \right] \cdot \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \, \tau^{a_0-1} \exp[-b_0 \tau]
\end{equation}

exhibits the same proportionality

\begin{equation} \label{eq:blr-prior-BLR-prior-s3}
p(\beta,\tau) \propto \tau^{a_0+p/2-1} \cdot \exp[-\tau b_0] \cdot \exp\left[ -\frac{\tau}{2} (\beta-\mu_0)^\mathrm{T} \Lambda_0 (\beta-\mu_0) \right]
\end{equation}

and is therefore conjugate relative to the likelihood.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Bishop CM (2006): "Bayesian linear regression"; in: \textit{Pattern Recognition for Machine Learning}, pp. 152-161, ex. 3.12, eq. 3.112; URL: \url{https://www.springer.com/gp/book/9780387310732}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P9 | shortcut: blr-prior | author: JoramSoch | date: 2020-01-03, 15:26.
\vspace{1em}



\subsubsection[\textbf{Posterior distribution}]{Posterior distribution} \label{sec:blr-post}
\setcounter{equation}{0}

\textbf{Theorem:} Let

\begin{equation} \label{eq:blr-post-GLM}
y = X \beta + \varepsilon, \; \varepsilon \sim \mathcal{N}(0, \sigma^2 V)
\end{equation}

be a linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}) with measured $n \times 1$ data vector $y$, known $n \times p$ design matrix $X$, known $n \times n$ covariance structure $V$ as well as unknown $p \times 1$ regression coefficients $\beta$ and unknown noise variance $\sigma^2$. Moreover, assume a normal-gamma prior distribution ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:blr-prior}) over the model parameters $\beta$ and $\tau = 1/\sigma^2$:

\begin{equation} \label{eq:blr-post-GLM-NG-prior}
p(\beta,\tau) = \mathcal{N}(\beta; \mu_0, (\tau \Lambda_0)^{-1}) \cdot \mathrm{Gam}(\tau; a_0, b_0) \; .
\end{equation}

Then, the posterior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) is also a normal-gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:ng})

\begin{equation} \label{eq:blr-post-GLM-NG-post}
p(\beta,\tau|y) = \mathcal{N}(\beta; \mu_n, (\tau \Lambda_n)^{-1}) \cdot \mathrm{Gam}(\tau; a_n, b_n)
\end{equation}

and the posterior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) are given by

\begin{equation} \label{eq:blr-post-GLM-NG-post-par}
\begin{split}
\mu_n &= \Lambda_n^{-1} (X^\mathrm{T} P y + \Lambda_0 \mu_0) \\
\Lambda_n &= X^\mathrm{T} P X + \Lambda_0 \\
a_n &= a_0 + \frac{n}{2} \\
b_n &= b_0 + \frac{1}{2} (y^\mathrm{T} P y + \mu_0^\mathrm{T} \Lambda_0 \mu_0 - \mu_n^\mathrm{T} \Lambda_n \mu_n) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Proof:} According to Bayes' theorem ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:bayes-th}), the posterior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) is given by

\begin{equation} \label{eq:blr-post-GLM-NG-BT}
p(\beta,\tau|y) = \frac{p(y|\beta,\tau) \, p(\beta,\tau)}{p(y)} \; .
\end{equation}

Since $p(y)$ is just a normalization factor, the posterior is proportional ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:post-jl}) to the numerator:

\begin{equation} \label{eq:blr-post-GLM-NG-post-JL}
p(\beta,\tau|y) \propto p(y|\beta,\tau) \, p(\beta,\tau) = p(y,\beta,\tau) \; .
\end{equation}

Equation \eqref{eq:blr-post-GLM} implies the following likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf})

\begin{equation} \label{eq:blr-post-GLM-LF-class}
p(y|\beta,\sigma^2) = \mathcal{N}(y; X \beta, \sigma^2 V) = \sqrt{\frac{1}{(2 \pi)^n |\sigma^2 V|}} \, \exp\left[ -\frac{1}{2 \sigma^2} (y-X\beta)^\mathrm{T} V^{-1} (y-X\beta) \right]
\end{equation}

which, for mathematical convenience, can also be parametrized as

\begin{equation} \label{eq:blr-post-GLM-LF-Bayes}
p(y|\beta,\tau) = \mathcal{N}(y; X \beta, (\tau P)^{-1}) = \sqrt{\frac{|\tau P|}{(2 \pi)^n}} \, \exp\left[ -\frac{\tau}{2} (y-X\beta)^\mathrm{T} P (y-X\beta) \right]
\end{equation}

using the noise precision $\tau = 1/\sigma^2$ and the $n \times n$ precision matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:precmat}) $P = V^{-1}$.

\vspace{1em}
Combining the likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) \eqref{eq:blr-post-GLM-LF-Bayes} with the prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) \eqref{eq:blr-post-GLM-NG-prior}, the joint likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:jl}) of the model is given by

\begin{equation} \label{eq:blr-post-GLM-NG-JL-s1}
\begin{split}
p(y,\beta,\tau) = \; & p(y|\beta,\tau) \, p(\beta,\tau) \\
= \; & \sqrt{\frac{|\tau P|}{(2 \pi)^n}} \, \exp\left[ -\frac{\tau}{2} (y-X\beta)^\mathrm{T} P (y-X\beta) \right] \cdot \\
& \sqrt{\frac{|\tau \Lambda_0|}{(2 \pi)^p}} \, \exp\left[ -\frac{\tau}{2} (\beta-\mu_0)^\mathrm{T} \Lambda_0 (\beta-\mu_0) \right] \cdot \\
& \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \, \tau^{a_0-1} \exp[-b_0 \tau] \; .
\end{split}
\end{equation}

Collecting identical variables gives:

\begin{equation} \label{eq:blr-post-GLM-NG-JL-s2}
\begin{split}
p(y,\beta,\tau) = \; & \sqrt{\frac{\tau^{n+p}}{(2 \pi)^{n+p}} |P| |\Lambda_0|} \, \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \, \tau^{a_0-1} \exp[-b_0 \tau] \cdot \\
& \exp\left[ -\frac{\tau}{2} \left( (y-X\beta)^\mathrm{T} P (y-X\beta) + (\beta-\mu_0)^\mathrm{T} \Lambda_0 (\beta-\mu_0) \right) \right] \; .
\end{split}
\end{equation}

Expanding the products in the exponent gives:

\begin{equation} \label{eq:blr-post-GLM-NG-JL-s3}
\begin{split}
p(y,\beta,\tau) = \; & \sqrt{\frac{\tau^{n+p}}{(2 \pi)^{n+p}} |P| |\Lambda_0|} \, \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \, \tau^{a_0-1} \exp[-b_0 \tau] \cdot \\
& \exp\left[ -\frac{\tau}{2} \left( y^\mathrm{T} P y - y^\mathrm{T} P X \beta - \beta^\mathrm{T} X^\mathrm{T} P y + \beta^\mathrm{T} X^\mathrm{T} P X \beta + \right. \right. \\
& \hphantom{\exp \left[ -\frac{\tau}{2} \right.} \; \left. \left. \beta^\mathrm{T} \Lambda_0 \beta - \beta^\mathrm{T} \Lambda_0 \mu_0 - \mu_0^\mathrm{T} \Lambda_0 \beta + \mu_0^\mathrm{T} \Lambda_0 \mu_0 \right) \right] \; .
\end{split}
\end{equation}

Completing the square over $\beta$, we finally have

\begin{equation} \label{eq:blr-post-GLM-NG-JL-s4}
\begin{split}
p(y,\beta,\tau) = \; & \sqrt{\frac{\tau^{n+p}}{(2 \pi)^{n+p}} |P| |\Lambda_0|} \, \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \, \tau^{a_0-1} \exp[-b_0 \tau] \cdot \\
& \exp\left[ -\frac{\tau}{2} \left( (\beta-\mu_n)^\mathrm{T} \Lambda_n (\beta-\mu_n) + (y^\mathrm{T} P y + \mu_0^\mathrm{T} \Lambda_0 \mu_0 - \mu_n^\mathrm{T} \Lambda_n \mu_n) \right) \right]
\end{split}
\end{equation}

with the posterior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post})

\begin{equation} \label{eq:blr-post-GLM-NG-post-beta-par}
\begin{split}
\mu_n &= \Lambda_n^{-1} (X^\mathrm{T} P y + \Lambda_0 \mu_0) \\
\Lambda_n &= X^\mathrm{T} P X + \Lambda_0 \; .
\end{split}
\end{equation}

Ergo, the joint likelihood is proportional to

\begin{equation} \label{eq:blr-post-GLM-NG-JL-s5}
p(y,\beta,\tau) \propto \tau^{p/2} \cdot \exp\left[ -\frac{\tau}{2} (\beta-\mu_n)^\mathrm{T} \Lambda_n (\beta-\mu_n) \right] \cdot \tau^{a_n-1} \cdot \exp\left[ -b_n \tau \right]
\end{equation}

with the posterior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post})

\begin{equation} \label{eq:blr-post-GLM-NG-post-tau-par}
\begin{split}
a_n &= a_0 + \frac{n}{2} \\
b_n &= b_0 + \frac{1}{2} (y^\mathrm{T} P y + \mu_0^\mathrm{T} \Lambda_0 \mu_0 - \mu_n^\mathrm{T} \Lambda_n \mu_n) \; .
\end{split}
\end{equation}

From the term in \eqref{eq:blr-post-GLM-NG-JL-s5}, we can isolate the posterior distribution over $\beta$ given $\tau$:

\begin{equation} \label{eq:blr-post-GLM-NG-post-beta}
p(\beta|\tau,y) = \mathcal{N}(\beta; \mu_n, (\tau \Lambda_n)^{-1}) \; .
\end{equation}

From the remaining term, we can isolate the posterior distribution over $\tau$:

\begin{equation} \label{eq:blr-post-GLM-NG-post-tau}
p(\tau|y) = \mathrm{Gam}(\tau; a_n, b_n) \; .
\end{equation}

Together, \eqref{eq:blr-post-GLM-NG-post-beta} and \eqref{eq:blr-post-GLM-NG-post-tau} constitute the joint ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) posterior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) of $\beta$ and $\tau$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Bishop CM (2006): "Bayesian linear regression"; in: \textit{Pattern Recognition for Machine Learning}, pp. 152-161, ex. 3.12, eq. 3.113; URL: \url{https://www.springer.com/gp/book/9780387310732}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P10 | shortcut: blr-post | author: JoramSoch | date: 2020-01-03, 17:53.
\vspace{1em}



\subsubsection[\textbf{Log model evidence}]{Log model evidence} \label{sec:blr-lme}
\setcounter{equation}{0}

\textbf{Theorem:} Let

\begin{equation} \label{eq:blr-lme-GLM}
m: \; y = X \beta + \varepsilon, \; \varepsilon \sim \mathcal{N}(0, \sigma^2 V)
\end{equation}

be a linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}) with measured $n \times 1$ data vector $y$, known $n \times p$ design matrix $X$, known $n \times n$ covariance structure $V$ as well as unknown $p \times 1$ regression coefficients $\beta$ and unknown noise variance $\sigma^2$. Moreover, assume a normal-gamma prior distribution ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:blr-prior}) over the model parameters $\beta$ and $\tau = 1/\sigma^2$:

\begin{equation} \label{eq:blr-lme-GLM-NG-prior}
p(\beta,\tau) = \mathcal{N}(\beta; \mu_0, (\tau \Lambda_0)^{-1}) \cdot \mathrm{Gam}(\tau; a_0, b_0) \; .
\end{equation}

Then, the log model evidence ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme}) for this model is

\begin{equation} \label{eq:blr-lme-GLM-NG-LME}
\begin{split}
\log p(y|m) = \frac{1}{2} & \log |P| - \frac{n}{2} \log (2 \pi)  + \frac{1}{2} \log |\Lambda_0| - \frac{1}{2} \log |\Lambda_n| + \\
& \log \Gamma(a_n) - \log \Gamma(a_0) + a_0 \log b_0 - a_n \log b_n
\end{split}
\end{equation}

where the posterior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) are given by

\begin{equation} \label{eq:blr-lme-GLM-NG-post-par}
\begin{split}
\mu_n &= \Lambda_n^{-1} (X^\mathrm{T} P y + \Lambda_0 \mu_0) \\
\Lambda_n &= X^\mathrm{T} P X + \Lambda_0 \\
a_n &= a_0 + \frac{n}{2} \\
b_n &= b_0 + \frac{1}{2} (y^\mathrm{T} P y + \mu_0^\mathrm{T} \Lambda_0 \mu_0 - \mu_n^\mathrm{T} \Lambda_n \mu_n) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Proof:} According to the law of marginal probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}), the model evidence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ml}) for this model is:

\begin{equation} \label{eq:blr-lme-GLM-NG-ME-s1}
p(y|m) = \iint p(y|\beta,\tau) \, p(\beta,\tau) \, \mathrm{d}\beta \, \mathrm{d}\tau \; .
\end{equation}

According to the law of conditional probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-cond}), the integrand is equivalent to the joint likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:jl}):

\begin{equation} \label{eq:blr-lme-GLM-NG-ME-s2}
p(y|m) = \iint p(y,\beta,\tau) \, \mathrm{d}\beta \, \mathrm{d}\tau \; .
\end{equation}

Equation \eqref{eq:blr-lme-GLM} implies the following likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf})

\begin{equation} \label{eq:blr-lme-GLM-LF-class}
p(y|\beta,\sigma^2) = \mathcal{N}(y; X \beta, \sigma^2 V) = \sqrt{\frac{1}{(2 \pi)^n |\sigma^2 V|}} \, \exp\left[ -\frac{1}{2 \sigma^2} (y-X\beta)^\mathrm{T} V^{-1} (y-X\beta) \right]
\end{equation}

which, for mathematical convenience, can also be parametrized as

\begin{equation} \label{eq:blr-lme-GLM-LF-Bayes}
p(y|\beta,\tau) = \mathcal{N}(y; X \beta, (\tau P)^{-1}) = \sqrt{\frac{|\tau P|}{(2 \pi)^n}} \, \exp\left[ -\frac{\tau}{2} (y-X\beta)^\mathrm{T} P (y-X\beta) \right]
\end{equation}

using the noise precision $\tau = 1/\sigma^2$ and the $n \times n$ precision matrix $P = V^{-1}$.

\vspace{1em}
When deriving the posterior distribution ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:blr-post}) $p(\beta,\tau|y)$, the joint likelihood $p(y,\beta,\tau)$ is obtained as

\begin{equation} \label{eq:blr-lme-GLM-NG-LME-s1}
\begin{split}
p(y,\beta,\tau) = \; & \sqrt{\frac{\tau^n |P|}{(2 \pi)^n}} \, \sqrt{\frac{\tau^p |\Lambda_0|}{(2 \pi)^p}} \, \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \, \tau^{a_0-1} \exp[-b_0 \tau] \cdot \\
& \exp\left[ -\frac{\tau}{2} \left( (\beta-\mu_n)^T \Lambda_n (\beta-\mu_n) + (y^T P y + \mu_0^T \Lambda_0 \mu_0 - \mu_n^T \Lambda_n \mu_n) \right) \right] \; .
\end{split}
\end{equation}

Using the probability density function of the multivariate normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mvn-pdf}), we can rewrite this as

\begin{equation} \label{eq:blr-lme-GLM-NG-LME-s2}
\begin{split}
p(y,\beta,\tau) = \; & \sqrt{\frac{\tau^n |P|}{(2 \pi)^n}} \, \sqrt{\frac{\tau^p |\Lambda_0|}{(2 \pi)^p}} \, \sqrt{\frac{(2 \pi)^p}{\tau^p |\Lambda_n|}} \, \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \, \tau^{a_0-1} \exp[-b_0 \tau] \cdot \\
& \mathcal{N}(\beta; \mu_n, (\tau \Lambda_n)^{-1}) \, \exp\left[ -\frac{\tau}{2} (y^T P y + \mu_0^T \Lambda_0 \mu_0 - \mu_n^T \Lambda_n \mu_n) \right] \; .
\end{split}
\end{equation}

Now, $\beta$ can be integrated out easily:

\begin{equation} \label{eq:blr-lme-GLM-NG-LME-s3}
\begin{split}
\int p(y,\beta,\tau) \, \mathrm{d}\beta = \; & \sqrt{\frac{\tau^n |P|}{(2 \pi)^n}} \, \sqrt{\frac{|\Lambda_0|}{|\Lambda_n|}} \, \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \, \tau^{a_0-1} \exp[-b_0 \tau] \cdot \\
& \exp\left[ -\frac{\tau}{2} (y^T P y + \mu_0^T \Lambda_0 \mu_0 - \mu_n^T \Lambda_n \mu_n) \right] \; .
\end{split}
\end{equation}

Using the probability density function of the gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-pdf}), we can rewrite this as

\begin{equation} \label{eq:blr-lme-GLM-NG-LME-s4}
\int p(y,\beta,\tau) \, \mathrm{d}\beta = \sqrt{\frac{|P|}{(2 \pi)^n}} \, \sqrt{\frac{|\Lambda_0|}{|\Lambda_n|}} \, \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \, \frac{\Gamma(a_n)}{ {b_n}^{a_n}} \, \mathrm{Gam}(\tau; a_n, b_n) \; .
\end{equation}

Finally, $\tau$ can also be integrated out:

\begin{equation} \label{eq:blr-lme-GLM-NG-LME-s5}
\iint p(y,\beta,\tau) \, \mathrm{d}\beta \, \mathrm{d}\tau = \sqrt{\frac{|P|}{(2 \pi)^n}} \, \sqrt{\frac{|\Lambda_0|}{|\Lambda_n|}} \, \frac{\Gamma(a_n)}{\Gamma(a_0)} \, \frac{ {b_0}^{a_0}}{ {b_n}^{a_n}} = p(y|m) \; .
\end{equation}

Thus, the log model evidence ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme}) of this model is given by

\begin{equation} \label{eq:blr-lme-GLM-NG-LME-s6}
\begin{split}
\log p(y|m) = \frac{1}{2} & \log |P| - \frac{n}{2} \log (2 \pi)  + \frac{1}{2} \log |\Lambda_0| - \frac{1}{2} \log |\Lambda_n| + \\
& \log \Gamma(a_n) - \log \Gamma(a_0) + a_0 \log b_0 - a_n \log b_n \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Bishop CM (2006): "Bayesian linear regression"; in: \textit{Pattern Recognition for Machine Learning}, pp. 152-161, ex. 3.23, eq. 3.118; URL: \url{https://www.springer.com/gp/book/9780387310732}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P11 | shortcut: blr-lme | author: JoramSoch | date: 2020-01-03, 22:05.
\vspace{1em}



\subsubsection[\textbf{Posterior probability of alternative hypothesis}]{Posterior probability of alternative hypothesis} \label{sec:blr-pp}
\setcounter{equation}{0}

\textbf{Theorem:} Let there be a linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}) with normally distributed ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mvn}) errors:

\begin{equation} \label{eq:blr-pp-GLM}
y = X \beta + \varepsilon, \; \varepsilon \sim \mathcal{N}(0, \sigma^2 V)
\end{equation}

and assume a normal-gamma ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:ng}) prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) over the model parameters $\beta$ and $\tau = 1/\sigma^2$:

\begin{equation} \label{eq:blr-pp-GLM-NG-prior}
p(\beta,\tau) = \mathcal{N}(\beta; \mu_0, (\tau \Lambda_0)^{-1}) \cdot \mathrm{Gam}(\tau; a_0, b_0) \; .
\end{equation}

Then, the posterior ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob}) of the alternative hypothesis ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:h1})

\begin{equation} \label{eq:blr-pp-GLM-H1}
\mathrm{H}_1: \, c^\mathrm{T} \beta > 0
\end{equation}

is given by

\begin{equation} \label{eq:blr-pp-GLM-NG-PP}
\mathrm{Pr}\left( \mathrm{H}_1 | y \right) = 1 - \mathrm{T}\left( -\frac{c^\mathrm{T} \mu}{\sqrt{c^\mathrm{T} \Sigma c}}; \nu \right)
\end{equation}

where $c$ is a $p \times 1$ contrast vector ($\rightarrow$ Definition "con"), $\mathrm{T}(x; \nu)$ is the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) of the t-distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:t}) with $\nu$ degrees of freedom ($\rightarrow$ Definition "dof") and $\mu$, $\Sigma$ and $\nu$ can be obtained from the posterior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) of Bayesian linear regression.


\vspace{1em}
\textbf{Proof:} The posterior distribution for Bayesian linear regression ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:blr-post}) is given by a normal-gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:ng}) over $\beta$ and $\tau = 1/\sigma^2$

\begin{equation} \label{eq:blr-pp-GLM-NG-post}
p(\beta,\tau|y) = \mathcal{N}(\beta; \mu_n, (\tau \Lambda_n)^{-1}) \cdot \mathrm{Gam}(\tau; a_n, b_n)
\end{equation}

with the posterior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post})

\begin{equation} \label{eq:blr-pp-GLM-NG-post-par}
\begin{split}
\mu_n &= \Lambda_n^{-1} (X^\mathrm{T} P y + \Lambda_0 \mu_0) \\
\Lambda_n &= X^\mathrm{T} P X + \Lambda_0 \\
a_n &= a_0 + \frac{n}{2} \\
b_n &= b_0 + \frac{1}{2} (y^\mathrm{T} P y + \mu_0^\mathrm{T} \Lambda_0 \mu_0 - \mu_n^\mathrm{T} \Lambda_n \mu_n) \; .
\end{split}
\end{equation}

The marginal distribution of a normal-gamma distribution is a multivariate t-distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:ng-marg}), such that the marginal ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-marg}) posterior ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) distribution of $\beta$ is

\begin{equation} \label{eq:blr-pp-GLM-NG-post-beta}
p(\beta|y) = t(\beta; \mu, \Sigma, \nu)
\end{equation}

with the posterior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post})

\begin{equation} \label{eq:blr-pp-GLM-NG-post-par-beta}
\begin{split}
\mu &= \mu_n \\
\Sigma &= \left( \frac{a_n}{b_n} \Lambda_n \right)^{-1} \\
\nu &= 2 \, a_n \; .
\end{split}
\end{equation}

Define the quantity $\gamma = c^\mathrm{T} \beta$. According to the linear transformation theorem for the multivariate t-distribution ($\rightarrow$ Proof "mvt-ltt"), $\gamma$ also follows a multivariate t-distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mvt}):

\begin{equation} \label{eq:blr-pp-GLM-NG-post-gamma}
p(\gamma|y) = t(\gamma; c^\mathrm{T} \mu, c^\mathrm{T} \Sigma \, c, \nu) \; .
\end{equation}

Because $c^\mathrm{T}$ is a $1 \times p$ vector, $\gamma$ is a scalar and actually has a non-standardized t-distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:nst}). Therefore, the posterior probability of $H_1$ can be calculated using a one-dimensional integral:

\begin{equation} \label{eq:blr-pp-GLM-NG-post-prob-H0-s1}
\begin{split}
\mathrm{Pr}\left( \mathrm{H}_1 | y \right) &= p(\gamma > 0|y) \\
&= \int_{0}^{+\infty} p(\gamma|y) \, \mathrm{d}\gamma \\
&= 1 - \int_{-\infty}^{0} p(\gamma|y) \, \mathrm{d}\gamma \\
&= 1 - \mathrm{T}_\mathrm{nst}(0; c^\mathrm{T} \mu, c^\mathrm{T} \Sigma \, c, \nu) \; .
\end{split}
\end{equation}

Using the relation between non-standardized t-distribution and standard t-distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:nst-t}), we can finally write:

\begin{equation} \label{eq:blr-pp-GLM-NG-post-prob-H0-s2}
\begin{split}
\mathrm{Pr}\left( \mathrm{H}_1 | y \right) &= 1 - \mathrm{T}\left( \frac{(0 - c^\mathrm{T} \mu)}{\sqrt{c^\mathrm{T} \Sigma c}}; \nu \right) \\
&= 1 - \mathrm{T}\left( -\frac{c^\mathrm{T} \mu}{\sqrt{c^\mathrm{T} \Sigma c}}; \nu \right) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Koch, Karl-Rudolf (2007): "Multivariate t-distribution"; in: \textit{Introduction to Bayesian Statistics}, Springer, Berlin/Heidelberg, 2007, eqs. 2.235, 2.236, 2.213, 2.210, 2.188; URL: \url{https://www.springer.com/de/book/9783540727231}; DOI: 10.1007/978-3-540-72726-2.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P133 | shortcut: blr-pp | author: JoramSoch | date: 2020-07-17, 17:03.
\vspace{1em}



\subsubsection[\textbf{Posterior credibility region excluding null hypothesis}]{Posterior credibility region excluding null hypothesis} \label{sec:blr-pcr}
\setcounter{equation}{0}

\textbf{Theorem:} Let there be a linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}) with normally distributed ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mvn}) errors:

\begin{equation} \label{eq:blr-pcr-GLM}
y = X \beta + \varepsilon, \; \varepsilon \sim \mathcal{N}(0, \sigma^2 V)
\end{equation}

and assume a normal-gamma ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:ng}) prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) over the model parameters $\beta$ and $\tau = 1/\sigma^2$:

\begin{equation} \label{eq:blr-pcr-GLM-NG-prior}
p(\beta,\tau) = \mathcal{N}(\beta; \mu_0, (\tau \Lambda_0)^{-1}) \cdot \mathrm{Gam}(\tau; a_0, b_0) \; .
\end{equation}

Then, the largest posterior ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) credibility region ($\rightarrow$ Definition "cr") that does not contain the omnibus null hypothesis ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:h0})

\begin{equation} \label{eq:blr-pcr-GLM-H0}
\mathrm{H}_0: \, C^\mathrm{T} \beta = 0
\end{equation}

is given by the credibility level ($\rightarrow$ Definition "cr")

\begin{equation} \label{eq:blr-pcr-GLM-NG-PCR}
(1-\alpha) = \mathrm{F}\left( \left[ \mu^\mathrm{T} C (C^\mathrm{T} \Sigma \, C)^{-1} C^\mathrm{T} \mu \right]/q; q, \nu \right)
\end{equation}

where $C$ is a $p \times q$ contrast matrix ($\rightarrow$ Definition "con"), $\mathrm{F}(x; v, w)$ is the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) of the F-distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:f}) with $v$ numerator degrees of freedom ($\rightarrow$ Definition "dof"), $w$ denominator degrees of freedom ($\rightarrow$ Definition "dof") and $\mu$, $\Sigma$ and $\nu$ can be obtained from the posterior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) of Bayesian linear regression.


\vspace{1em}
\textbf{Proof:} The posterior distribution for Bayesian linear regression ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:blr-post}) is given by a normal-gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:ng}) over $\beta$ and $\tau = 1/\sigma^2$

\begin{equation} \label{eq:blr-pcr-GLM-NG-post}
p(\beta,\tau|y) = \mathcal{N}(\beta; \mu_n, (\tau \Lambda_n)^{-1}) \cdot \mathrm{Gam}(\tau; a_n, b_n)
\end{equation}

with the posterior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post})

\begin{equation} \label{eq:blr-pcr-GLM-NG-post-par}
\begin{split}
\mu_n &= \Lambda_n^{-1} (X^\mathrm{T} P y + \Lambda_0 \mu_0) \\
\Lambda_n &= X^\mathrm{T} P X + \Lambda_0 \\
a_n &= a_0 + \frac{n}{2} \\
b_n &= b_0 + \frac{1}{2} (y^\mathrm{T} P y + \mu_0^\mathrm{T} \Lambda_0 \mu_0 - \mu_n^\mathrm{T} \Lambda_n \mu_n) \; .
\end{split}
\end{equation}

The marginal distribution of a normal-gamma distribution is a multivariate t-distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:ng-marg}), such that the marginal ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-marg}) posterior ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) distribution of $\beta$ is

\begin{equation} \label{eq:blr-pcr-GLM-NG-post-beta}
p(\beta|y) = t(\beta; \mu, \Sigma, \nu)
\end{equation}

with the posterior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post})

\begin{equation} \label{eq:blr-pcr-GLM-NG-post-par-beta}
\begin{split}
\mu &= \mu_n \\
\Sigma &= \left( \frac{a_n}{b_n} \Lambda_n \right)^{-1} \\
\nu &= 2 \, a_n \; .
\end{split}
\end{equation}

Define the quantity $\gamma = C^\mathrm{T} \beta$. According to the linear transformation theorem for the multivariate t-distribution ($\rightarrow$ Proof "mvt-ltt"), $\gamma$ also follows a multivariate t-distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mvt}):

\begin{equation} \label{eq:blr-pcr-GLM-NG-post-gamma}
p(\gamma|y) = t(\gamma; C^\mathrm{T} \mu, C^\mathrm{T} \Sigma \, C, \nu) \; .
\end{equation}

Because $C^\mathrm{T}$ is a $q \times p$ matrix, $\gamma$ is a $q \times 1$ vector. The quadratic form of a multivariate t-distributed random variable has an F-distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mvt-f}), such that we can write:

\begin{equation} \label{eq:blr-pcr-GLM-NG-post-qf}
\mathrm{QF}(\gamma) = (\gamma - C^\mathrm{T} \mu)^\mathrm{T} (C^\mathrm{T} \Sigma \, C)^{-1} (\gamma - C^\mathrm{T} \mu) /q \, \sim \mathrm{F}(q,\nu) \; .
\end{equation}

Therefore, the largest posterior credibility region for $\gamma$ which does not contain $\gamma = 0_q$ (i.e. only touches this origin point) can be obtained by plugging $\mathrm{QF}(0)$ into the cumulative distribution function of the F-distribution:

\begin{equation} \label{eq:blr-pcr-GLM-NG-post-cred-reg-not-H0}
\begin{split}
(1-\alpha) &= \mathrm{F}\left( \mathrm{QF}(0); q, \nu \right) \\
&= \mathrm{F}\left( \left[ \mu^\mathrm{T} C (C^\mathrm{T} \Sigma \, C)^{-1} C^\mathrm{T} \mu \right]/q; q, \nu \right) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Koch, Karl-Rudolf (2007): "Multivariate t-distribution"; in: \textit{Introduction to Bayesian Statistics}, Springer, Berlin/Heidelberg, 2007, eqs. 2.235, 2.236, 2.213, 2.210, 2.211, 2.183; URL: \url{https://www.springer.com/de/book/9783540727231}; DOI: 10.1007/978-3-540-72726-2.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P134 | shortcut: blr-pcr | author: JoramSoch | date: 2020-07-17, 17:41.
\vspace{1em}



\pagebreak
\section{Multivariate normal data}

\subsection{General linear model}

\subsubsection[\textit{Definition}]{Definition} \label{sec:glm}
\setcounter{equation}{0}

\textbf{Definition:} Let $Y$ be an $n \times v$ matrix and let $X$ be an $n \times p$ matrix. Then, a statement asserting a linear mapping from $X$ to $Y$ with parameters $B$ and matrix-normally distributed ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:matn}) errors $E$

\begin{equation} \label{eq:glm-glm}
Y = X B + E, \; E \sim \mathcal{MN}(0, V, \Sigma)
\end{equation}

is called a multivariate linear regression model or simply, "general linear model".

\begin{itemize}

\item $Y$ is called "data matrix", "set of dependent variables" or "measurements";

\item $X$ is called "design matrix", "set of independent variables" or "predictors";

\item $B$ are called "regression coefficients" or "weights";

\item $E$ is called "noise matrix" or "error terms";

\item $V$ is called "covariance across rows";

\item $\Sigma$ is called "covariance across columns";

\item $n$ is the number of observations;

\item $v$ is the number of measurements;

\item $p$ is the number of predictors.

\end{itemize}

When rows of $Y$ correspond to units of time, e.g. subsequent measurements, $V$ is called "temporal covariance". When columns of $Y$ correspond to units of space, e.g. measurement channels, $\Sigma$ is called "spatial covariance".

When the covariance matrix $V$ is a scalar multiple of the $n \times n$ identity matrix, this is called a general linear model with independent and identically distributed (i.i.d.) observations:

\begin{equation} \label{eq:glm-glm-iid}
V = \lambda I_n \quad \Rightarrow \quad E \sim \mathcal{MN}(0, \lambda I_n, \Sigma) \quad \Rightarrow \quad \varepsilon_i \overset{\text{i.i.d.}}{\sim} \mathcal{N}(0, \lambda \Sigma) \; .
\end{equation}

Otherwise, it is called a general linear model with correlated observations.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "General linear model"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-03-21; URL: \url{https://en.wikipedia.org/wiki/General_linear_model}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D40 | shortcut: glm | author: JoramSoch | date: 2020-03-21, 22:24.
\vspace{1em}



\subsubsection[\textbf{Ordinary least squares}]{Ordinary least squares} \label{sec:glm-ols}
\setcounter{equation}{0}

\textbf{Theorem:} Given a general linear model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:glm}) with independent observations

\begin{equation} \label{eq:glm-ols-GLM}
Y = X B + E, \; E \sim \mathcal{MN}(0, \sigma^2 I_n, \Sigma) \; ,
\end{equation}

the ordinary least squares ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mlr-ols}) parameters estimates are given by

\begin{equation} \label{eq:glm-ols-OLS}
\hat{B} = (X^\mathrm{T} X)^{-1} X^\mathrm{T} Y \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} Let $\hat{B}$ be the ordinary least squares ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mlr-ols}) (OLS) solution and let $\hat{E} = Y - X\hat{B}$ be the resulting matrix of residuals. According to the exogeneity assumption of OLS, the errors have conditional mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) zero

\begin{equation} \label{eq:glm-ols-OLS-exo}
\mathrm{E}(E|X) = 0 \; ,
\end{equation}

a direct consequence of which is that the regressors are uncorrelated with the errors

\begin{equation} \label{eq:glm-ols-OLS-uncorr}
\mathrm{E}(X^\mathrm{T} E) = 0 \; ,
\end{equation}

which, in the finite sample, means that the residual matrix must be orthogonal to the design matrix:

\begin{equation} \label{eq:glm-ols-X-E-orth}
X^\mathrm{T} \hat{E} = 0 \; .
\end{equation}

From \eqref{eq:glm-ols-X-E-orth}, the OLS formula can be directly derived:

\begin{equation} \label{eq:glm-ols-OLS-qed}
\begin{split}
X^\mathrm{T} \hat{E} &= 0 \\
X^\mathrm{T} \left( Y - X\hat{B} \right) &= 0 \\
X^\mathrm{T} Y - X^\mathrm{T} X\hat{B} &= 0 \\
X^\mathrm{T} X\hat{B} &= X^\mathrm{T} Y \\
\hat{B} &= (X^\mathrm{T} X)^{-1} X^\mathrm{T} Y \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P106 | shortcut: glm-ols | author: JoramSoch | date: 2020-05-19, 06:02.
\vspace{1em}



\subsubsection[\textbf{Weighted least squares}]{Weighted least squares} \label{sec:glm-wls}
\setcounter{equation}{0}

\textbf{Theorem:} Given a general linear model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:glm}) with correlated observations

\begin{equation} \label{eq:glm-wls-GLM}
Y = X B + E, \; E \sim \mathcal{MN}(0, V, \Sigma) \; ,
\end{equation}

the weighted least sqaures ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mlr-wls}) parameter estimates are given by

\begin{equation} \label{eq:glm-wls-WLS}
\hat{B} = (X^\mathrm{T} V^{-1} X)^{-1} X^\mathrm{T} V^{-1} Y \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} Let there be an $n \times n$ square matrix $W$, such that

\begin{equation} \label{eq:glm-wls-W-def}
W V W^\mathrm{T} = I_n \; .
\end{equation}

Since $V$ is a covariance matrix and thus symmetric, $W$ is also symmetric and can be expressed as the matrix square root of the inverse of $V$:

\begin{equation} \label{eq:glm-wls-W-V}
W W = V^{-1} \quad \Leftrightarrow \quad W = V^{-1/2} \; .
\end{equation}

Left-multiplying the linear regression equation \eqref{eq:glm-wls-GLM} with $W$, the linear transformation theorem ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:matn-ltt}) implies that

\begin{equation} \label{eq:glm-wls-GLM-W}
WY = WXB + WE, \; WE \sim \mathcal{MN}(0, W V W^\mathrm{T}, \Sigma) \; .
\end{equation}

Applying \eqref{eq:glm-wls-W-def}, we see that \eqref{eq:glm-wls-GLM-W} is actually a general linear model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:glm}) with independent observations

\begin{equation} \label{eq:glm-wls-GLM-W-dev}
\tilde{Y} = \tilde{X}B + \tilde{E}, \; \tilde{E} \sim \mathcal{N}(0, I_n, \Sigma)
\end{equation}

where $\tilde{Y} = WY$, $\tilde{X} = WX$ and $\tilde{E} = WE$, such that we can apply the ordinary least squares solution ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:glm-ols}) giving

\begin{equation} \label{eq:glm-wls-WLS-qed}
\begin{split}
\hat{B} &= (\tilde{X}^\mathrm{T} \tilde{X})^{-1} \tilde{X}^\mathrm{T} \tilde{Y} \\
&= \left( (WX)^\mathrm{T} WX \right)^{-1} (WX)^\mathrm{T} WY \\
&= \left( X^\mathrm{T} W^\mathrm{T} W X \right)^{-1} X^\mathrm{T} W^\mathrm{T} W Y \\
&= \left( X^\mathrm{T} W W X \right)^{-1} X^\mathrm{T} W W Y \\
&\overset{\eqref{eq:glm-wls-W-V}}{=} \left( X^\mathrm{T} V^{-1} X \right)^{-1} X^\mathrm{T} V^{-1} Y
\end{split}
\end{equation}

which corresponds to the weighted least squares solution \eqref{eq:glm-wls-WLS}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P107 | shortcut: glm-wls | author: JoramSoch | date: 2020-05-19, 06:27.
\vspace{1em}



\subsubsection[\textbf{Maximum likelihood estimation}]{Maximum likelihood estimation} \label{sec:glm-mle}
\setcounter{equation}{0}

\textbf{Theorem:} Given a general linear model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:glm}) with matrix-normally distributed ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:matn}) errors

\begin{equation} \label{eq:glm-mle-GLM}
Y = X B + E, \; E \sim \mathcal{MN}(0, V, \Sigma) \; ,
\end{equation}

maximum likelihood estimates ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mle}) for the unknown parameters $B$ and $\Sigma$ are given by

\begin{equation} \label{eq:glm-mle-GLM-MLE}
\begin{split}
\hat{B} &= (X^\mathrm{T} V^{-1} X)^{-1} X^\mathrm{T} V^{-1} Y \\
\hat{\Sigma} &= \frac{1}{n} (Y - X\hat{B})^\mathrm{T} V^{-1} (Y - X\hat{B}) \; . \\
\end{split}
\end{equation}


\vspace{1em}
\textbf{Proof:} In \eqref{eq:glm-mle-GLM}, $Y$ is an $n \times v$ matrix of measurements ($n$ observations, $v$ dependent variables), $X$ is an $n \times p$ design matrix ($n$ observations, $p$ independent variables) and $V$ is an $n \times n$ covariance matrix across observations. This multivariate GLM implies the following likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf})

\begin{equation} \label{eq:glm-mle-GLM-LF}
\begin{split}
p(Y|B,\Sigma) &= \mathcal{MN}(Y; XB, V, \Sigma) \\
&= \sqrt{\frac{1}{(2\pi)^{nv} |\Sigma|^n |V|^v}} \cdot \exp\left[ -\frac{1}{2} \, \mathrm{tr}\left( \Sigma^{-1} (Y - XB)^\mathrm{T} V^{-1} (Y - XB) \right)  \right] \\
\end{split}
\end{equation}

and the log-likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:llf})

\begin{equation} \label{eq:glm-mle-GLM-LL1}
\begin{split}
\mathrm{LL}(B,\Sigma) = &\log p(Y|B,\Sigma) \\
= &- \frac{nv}{2} \log(2\pi) - \frac{n}{2} \log |\Sigma| - \frac{v}{2} \log |V| \\
&- \frac{1}{2} \, \mathrm{tr}\left[ \Sigma^{-1} (Y - XB)^\mathrm{T} V^{-1} (Y - XB) \right] \; .\\
\end{split}
\end{equation}

Substituting $V^{-1}$ by the precision matrix $P$ to ease notation, we have:

\begin{equation} \label{eq:glm-mle-GLM-LL2}
\begin{split}
\mathrm{LL}(B,\Sigma) = &- \frac{nv}{2} \log(2\pi) - \frac{n}{2} \log(|\Sigma|) - \frac{v}{2} \log(|V|) \\
&- \frac{1}{2} \, \mathrm{tr}\left[ \Sigma^{-1} \left( Y^\mathrm{T} P Y - Y^\mathrm{T} P X B - B^\mathrm{T} X^\mathrm{T} P Y + B^\mathrm{T} X^\mathrm{T} P X B \right) \right] \; .\\
\end{split}
\end{equation}

\vspace{1em}
The derivative of the log-likelihood function \eqref{eq:glm-mle-GLM-LL2} with respect to $B$ is

\begin{equation} \label{eq:glm-mle-dLL-dB}
\begin{split}
\frac{\mathrm{d}\mathrm{LL}(B,\Sigma)}{\mathrm{d}B} &= \frac{\mathrm{d}}{\mathrm{d}B} \left( - \frac{1}{2} \, \mathrm{tr}\left[ \Sigma^{-1} \left( Y^\mathrm{T} P Y - Y^\mathrm{T} P X B - B^\mathrm{T} X^\mathrm{T} P Y + B^\mathrm{T} X^\mathrm{T} P X B \right) \right] \right) \\
&= \frac{\mathrm{d}}{\mathrm{d}B} \left( -\frac{1}{2} \, \mathrm{tr}\left[ -2 \Sigma^{-1} Y^\mathrm{T} P X B \right] \right) + \frac{\mathrm{d}}{\mathrm{d}B} \left( -\frac{1}{2} \, \mathrm{tr}\left[ \Sigma^{-1} B^\mathrm{T} X^\mathrm{T} P X B \right] \right) \\
&= - \frac{1}{2} \left( -2 X^\mathrm{T} P Y \Sigma^{-1} \right) - \frac{1}{2} \left( X^\mathrm{T} P X B \Sigma^{-1} + (X^\mathrm{T} P X)^\mathrm{T} B (\Sigma^{-1})^\mathrm{T} \right) \\
&= X^\mathrm{T} P Y \Sigma^{-1} - X^\mathrm{T} P X B \Sigma^{-1} \\
\end{split}
\end{equation}

and setting this derivative to zero gives the MLE for $B$:

\begin{equation} \label{eq:glm-mle-B-MLE}
\begin{split}
\frac{\mathrm{d}\mathrm{LL}(\hat{B},\Sigma)}{\mathrm{d}B} &= 0 \\
0 &= X^\mathrm{T} P Y \Sigma^{-1} - X^\mathrm{T} P X \hat{B} \Sigma^{-1} \\
0 &= X^\mathrm{T} P Y - X^\mathrm{T} P X \hat{B} \\
X^\mathrm{T} P X \hat{B} &= X^\mathrm{T} P Y \\
\hat{B} &= \left( X^\mathrm{T} P X \right)^{-1} X^\mathrm{T} P Y \\
\end{split}
\end{equation}

\vspace{1em}
The derivative of the log-likelihood function \eqref{eq:glm-mle-GLM-LL1} at $\hat{B}$ with respect to $\Sigma$ is

\begin{equation} \label{eq:glm-mle-dLL-dS}
\begin{split}
\frac{\mathrm{d}\mathrm{LL}(\hat{B},\Sigma)}{\mathrm{d}\Sigma} &= \frac{\mathrm{d}}{\mathrm{d}\Sigma} \left( - \frac{n}{2} \log |\Sigma| - \frac{1}{2} \, \mathrm{tr}\left[ \Sigma^{-1} (Y - X\hat{B})^\mathrm{T} V^{-1} (Y - X\hat{B}) \right] \right) \\
&= - \frac{n}{2} \left( \Sigma^{-1} \right)^\mathrm{T} + \frac{1}{2} \left( \Sigma^{-1} (Y - X\hat{B})^\mathrm{T} V^{-1} (Y - X\hat{B}) \, \Sigma^{-1} \right)^\mathrm{T} \\
&= - \frac{n}{2} \, \Sigma^{-1} + \frac{1}{2} \, \Sigma^{-1} (Y - X\hat{B})^\mathrm{T} V^{-1} (Y - X\hat{B}) \, \Sigma^{-1} \\
\end{split}
\end{equation}

and setting this derivative to zero gives the MLE for $\Sigma$:

\begin{equation} \label{eq:glm-mle-S-MLE}
\begin{split}
\frac{\mathrm{d}\mathrm{LL}(\hat{B},\hat{\Sigma})}{\mathrm{d}\Sigma} &= 0 \\
0 &= - \frac{n}{2} \, \hat{\Sigma}^{-1} + \frac{1}{2} \, \hat{\Sigma}^{-1} (Y - X\hat{B})^\mathrm{T} V^{-1} (Y - X\hat{B}) \, \hat{\Sigma}^{-1} \\
\frac{n}{2} \, \hat{\Sigma}^{-1} &= \frac{1}{2} \, \hat{\Sigma}^{-1} (Y - X\hat{B})^\mathrm{T} V^{-1} (Y - X\hat{B}) \, \hat{\Sigma}^{-1} \\
\hat{\Sigma}^{-1} &= \frac{1}{n} \, \hat{\Sigma}^{-1} (Y - X\hat{B})^\mathrm{T} V^{-1} (Y - X\hat{B}) \, \hat{\Sigma}^{-1} \\
I_v &= \frac{1}{n} \, (Y - X\hat{B})^\mathrm{T} V^{-1} (Y - X\hat{B}) \, \hat{\Sigma}^{-1} \\
\hat{\Sigma} &= \frac{1}{n} \, (Y - X\hat{B})^\mathrm{T} V^{-1} (Y - X\hat{B}) \\
\end{split}
\end{equation}

\vspace{1em}
Together, \eqref{eq:glm-mle-B-MLE} and \eqref{eq:glm-mle-S-MLE} constitute the MLE for the GLM.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P7 | shortcut: glm-mle | author: JoramSoch | date: 2019-12-06, 10:40.
\vspace{1em}



\subsection{Transformed general linear model}

\subsubsection[\textit{Definition}]{Definition} \label{sec:tglm}
\setcounter{equation}{0}

\textbf{Definition:} Let there be two general linear models ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:glm}) of measured data $Y \in \mathbb{R}^{n \times v}$ using design matrices ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:glm}) $X \in \mathbb{R}^{n \times p}$ and $X_t \in \mathbb{R}^{n \times t}$

\begin{equation} \label{eq:tglm-glm1}
Y = X B + E, \; E \sim \mathcal{MN}(0, V, \Sigma)
\end{equation}

\begin{equation} \label{eq:tglm-glm2}
Y = X_t \Gamma + E_t, \; E_t \sim \mathcal{MN}(0, V, \Sigma_t)
\end{equation}

and assume that $X_t$ can be transformed into $X$ using a transformation matrix $T \in \mathbb{R}^{t \times p}$

\begin{equation} \label{eq:tglm-X-Xt-T}
X = X_t \, T
\end{equation}

where $p < t$ and $X$, $X_t$ and $T$ have full ranks $\mathrm{rk}(X) = p$, $\mathrm{rk}(X_t) = t$ and $\mathrm{rk}(T) = p$.

Then, a linear model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:glm}) of the parameter estimates from \eqref{eq:tglm-glm2}, under the assumption of \eqref{eq:tglm-glm1}, is called a transformed general linear model.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Soch J, Allefeld C, Haynes JD (2020): "Inverse transformed encoding models â€“ a solution to the problem of correlated trial-by-trial parameter estimates in fMRI decoding"; in: \textit{NeuroImage}, vol. 209, art. 116449, Appendix A; URL: \url{https://www.sciencedirect.com/science/article/pii/S1053811919310407}; DOI: 10.1016/j.neuroimage.2019.116449.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D160 | shortcut: tglm | author: JoramSoch | date: 2021-10-21, 14:43.
\vspace{1em}



\subsubsection[\textbf{Derivation of the distribution}]{Derivation of the distribution} \label{sec:tglm-dist}
\setcounter{equation}{0}

\textbf{Theorem:} Let there be two general linear models ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:glm}) of measured data $Y$

\begin{equation} \label{eq:tglm-dist-glm1}
Y = X B + E, \; E \sim \mathcal{MN}(0, V, \Sigma)
\end{equation}

\begin{equation} \label{eq:tglm-dist-glm2}
Y = X_t \Gamma + E_t, \; E_t \sim \mathcal{MN}(0, V, \Sigma_t)
\end{equation}

and a matrix $T$ transforming $X_t$ into $X$:

\begin{equation} \label{eq:tglm-dist-X-Xt-T}
X = X_t \, T \; .
\end{equation}

Then, the transformed general linear model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:tglm}) is given by

\begin{equation} \label{eq:tglm-dist-tglm}
\hat{\Gamma} = T B + H, \; H \sim \mathcal{MN}(0, U, \Sigma)
\end{equation}

where the covariance across rows ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:matn}) is $U = ( X_t^\mathrm{T} V^{-1} X_t )^{-1}$.


\vspace{1em}
\textbf{Proof:} The linear transformation theorem for the matrix-normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:matn-ltt}) states:

\begin{equation} \label{eq:tglm-dist-matn-ltt}
X \sim \mathcal{MN}(M, U, V) \quad \Rightarrow \quad Y = AXB + C \sim \mathcal{MN}(AMB+C, AUA^\mathrm{T}, B^\mathrm{T}VB) \; .
\end{equation}

The weighted least squares parameter estimates ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:glm-wls}) for \eqref{eq:tglm-dist-glm2} are given by

\begin{equation} \label{eq:tglm-dist-glm2-wls}
\hat{\Gamma} = ( X_t^\mathrm{T} V^{-1} X_t )^{-1} X_t^\mathrm{T} V^{-1} Y \; .
\end{equation}

Using \eqref{eq:tglm-dist-glm1} and \eqref{eq:tglm-dist-matn-ltt}, the distribution of $Y$ is

\begin{equation} \label{eq:tglm-dist-Y-dist}
Y \sim \mathcal{MN}(X B, V, \Sigma)
\end{equation}

Combining \eqref{eq:tglm-dist-glm2-wls} with \eqref{eq:tglm-dist-Y-dist}, the distribution of $\hat{\Gamma}$ is

\begin{equation} \label{eq:tglm-dist-G-dist}
\begin{split}
\hat{\Gamma} &\sim \mathcal{MN}\left( \left[ ( X_t^\mathrm{T} V^{-1} X_t )^{-1} X_t^\mathrm{T} V^{-1} \right] X B, \left[ ( X_t^\mathrm{T} V^{-1} X_t )^{-1} X_t^\mathrm{T} V^{-1} \right] V \left[ V^{-1} X_t ( X_t^\mathrm{T} V^{-1} X_t )^{-1} \right], \Sigma \right) \\
&\sim \mathcal{MN}\left( ( X_t^\mathrm{T} V^{-1} X_t )^{-1} X_t^\mathrm{T} V^{-1} X_t \, T B, ( X_t^\mathrm{T} V^{-1} X_t )^{-1} X_t^\mathrm{T} V^{-1} X_t ( X_t^\mathrm{T} V^{-1} X_t )^{-1}, \Sigma \right) \\
&\sim \mathcal{MN}\left( T B, ( X_t^\mathrm{T} V^{-1} X_t )^{-1}, \Sigma \right) \; .
\end{split}
\end{equation}

This can also be written as

\begin{equation} \label{eq:tglm-dist-tglm-qed}
\hat{\Gamma} = T B + H, \; H \sim \mathcal{MN}\left( 0, ( X_t^\mathrm{T} V^{-1} X_t )^{-1}, \Sigma \right)
\end{equation}

which is equivalent to \eqref{eq:tglm-dist-tglm}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Soch J, Allefeld C, Haynes JD (2020): "Inverse transformed encoding models â€“ a solution to the problem of correlated trial-by-trial parameter estimates in fMRI decoding"; in: \textit{NeuroImage}, vol. 209, art. 116449, Appendix A, Theorem 1; URL: \url{https://www.sciencedirect.com/science/article/pii/S1053811919310407}; DOI: 10.1016/j.neuroimage.2019.116449.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P265 | shortcut: tglm-dist | author: JoramSoch | date: 2021-10-21, 15:03.
\vspace{1em}



\subsubsection[\textbf{Equivalence of parameter estimates}]{Equivalence of parameter estimates} \label{sec:tglm-para}
\setcounter{equation}{0}

\textbf{Theorem:} Let there be a general linear model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:glm})

\begin{equation} \label{eq:tglm-para-glm1}
Y = X B + E, \; E \sim \mathcal{MN}(0, V, \Sigma)
\end{equation}

and the transformed general linear model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:tglm})

\begin{equation} \label{eq:tglm-para-tglm}
\hat{\Gamma} = T B + H, \; H \sim \mathcal{MN}(0, U, \Sigma)
\end{equation}

which are linked to each other ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:tglm-dist}) via

\begin{equation} \label{eq:tglm-para-glm2-wls}
\hat{\Gamma} = ( X_t^\mathrm{T} V^{-1} X_t )^{-1} X_t^\mathrm{T} V^{-1} Y
\end{equation}

and

\begin{equation} \label{eq:tglm-para-X-Xt-T}
X = X_t \, T \; .
\end{equation}

Then, the parameter estimates for $B$ from \eqref{eq:tglm-para-glm1} and \eqref{eq:tglm-para-tglm} are equivalent.


\vspace{1em}
\textbf{Proof:} The weighted least squares parameter estimates ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:glm-wls}) for \eqref{eq:tglm-para-glm1} are given by

\begin{equation} \label{eq:tglm-para-glm1-wls}
\hat{B} = (X^\mathrm{T} V^{-1} X)^{-1} X^\mathrm{T} V^{-1} Y
\end{equation}

and the weighted least squares parameter estimates ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:glm-wls}) for \eqref{eq:tglm-para-tglm} are given by

\begin{equation} \label{eq:tglm-para-tglm-wls}
\hat{B} = (T^\mathrm{T} U^{-1} T)^{-1} T^\mathrm{T} U^{-1} \hat{\Gamma} \; .
\end{equation}

The covariance across rows for the transformed general linear model ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:tglm-dist}) is equal to

\begin{equation} \label{eq:tglm-para-U}
U = ( X_t^\mathrm{T} V^{-1} X_t )^{-1} \; .
\end{equation}

Applying \eqref{eq:tglm-para-U}, \eqref{eq:tglm-para-X-Xt-T} and \eqref{eq:tglm-para-glm2-wls}, the estimates in \eqref{eq:tglm-para-tglm-wls} can be developed into

\begin{equation} \label{eq:tglm-para-tglm-wls-dev}
\begin{split}
\hat{B} \; &\overset{\eqref{eq:tglm-para-tglm-wls}}{=} ( T^\mathrm{T} \, U^{-1} \, T )^{-1} \, T^\mathrm{T} \, U^{-1} \, \hat{\Gamma} \\
&\overset{\eqref{eq:tglm-para-U}}{=} ( T^\mathrm{T} \left[ X_t^\mathrm{T} V^{-1} X_t \right] T )^{-1} \, T^\mathrm{T} \left[ X_t^\mathrm{T} V^{-1} X_t \right] \hat{\Gamma} \\
&\overset{\eqref{eq:tglm-para-X-Xt-T}}{=} ( X^\mathrm{T} V^{-1} X )^{-1} \, T^\mathrm{T} \, X_t^\mathrm{T} V^{-1} X_t \, \hat{\Gamma} \\
&\overset{\eqref{eq:tglm-para-glm2-wls}}{=} ( X^\mathrm{T} V^{-1} X )^{-1} \, T^\mathrm{T} \, X_t^\mathrm{T} V^{-1} X_t \left[ ( X_t^\mathrm{T} V^{-1} X_t )^{-1} X_t^\mathrm{T} V^{-1} Y \right] \\
&= ( X^\mathrm{T} V^{-1} X )^{-1} \, T^\mathrm{T} \, X_t^\mathrm{T} V^{-1} Y \\
&\overset{\eqref{eq:tglm-para-X-Xt-T}}{=} ( X^\mathrm{T} V^{-1} X )^{-1} X^\mathrm{T} V^{-1} Y
\end{split}
\end{equation}

which is equivalent to the estimates in \eqref{eq:tglm-para-glm1-wls}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Soch J, Allefeld C, Haynes JD (2020): "Inverse transformed encoding models â€“ a solution to the problem of correlated trial-by-trial parameter estimates in fMRI decoding"; in: \textit{NeuroImage}, vol. 209, art. 116449, Appendix A, Theorem 2; URL: \url{https://www.sciencedirect.com/science/article/pii/S1053811919310407}; DOI: 10.1016/j.neuroimage.2019.116449.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P266 | shortcut: tglm-para | author: JoramSoch | date: 2021-10-21, 15:25.
\vspace{1em}



\subsection{Inverse general linear model}

\subsubsection[\textit{Definition}]{Definition} \label{sec:iglm}
\setcounter{equation}{0}

\textbf{Definition:} Let there be a general linear model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:glm}) of measured data $Y \in \mathbb{R}^{n \times v}$ in terms of the design matrix ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:glm}) $X \in \mathbb{R}^{n \times p}$:

\begin{equation} \label{eq:iglm-glm}
Y = X B + E, \; E \sim \mathcal{MN}(0, V, \Sigma) \; .
\end{equation}

Then, a linear model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:glm}) of $X$ in terms of $Y$, under the assumption of \eqref{eq:iglm-glm}, is called an inverse general linear model.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Soch J, Allefeld C, Haynes JD (2020): "Inverse transformed encoding models â€“ a solution to the problem of correlated trial-by-trial parameter estimates in fMRI decoding"; in: \textit{NeuroImage}, vol. 209, art. 116449, Appendix C; URL: \url{https://www.sciencedirect.com/science/article/pii/S1053811919310407}; DOI: 10.1016/j.neuroimage.2019.116449.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D161 | shortcut: iglm | author: JoramSoch | date: 2021-10-21, 15:31.
\vspace{1em}



\subsubsection[\textbf{Derivation of the distribution}]{Derivation of the distribution} \label{sec:iglm-dist}
\setcounter{equation}{0}

\textbf{Theorem:} Let there be a general linear model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:glm}) of $Y \in \mathbb{R}^{n \times v}$

\begin{equation} \label{eq:iglm-dist-glm}
Y = X B + E, \; E \sim \mathcal{MN}(0, V, \Sigma) \; .
\end{equation}

Then, the inverse general linear model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:iglm}) of $X \in \mathbb{R}^{n \times p}$ is given by

\begin{equation} \label{eq:iglm-dist-iglm}
X = Y W + N, \; N \sim \mathcal{MN}(0, V, \Sigma_x)
\end{equation}

where $W \in \mathbb{R}^{v \times p}$ is a matrix, such that $B \, W = I_p$, and the covariance across columns ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:matn}) is $\Sigma_x = W^\mathrm{T} \Sigma W$.


\vspace{1em}
\textbf{Proof:} The linear transformation theorem for the matrix-normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:matn-ltt}) states:

\begin{equation} \label{eq:iglm-dist-matn-ltt}
X \sim \mathcal{MN}(M, U, V) \quad \Rightarrow \quad Y = AXB + C \sim \mathcal{MN}(AMB+C, AUA^\mathrm{T}, B^\mathrm{T}VB) \; .
\end{equation}

The matrix $W$ exists, if the rows of $B \in \mathbb{R}^{p \times v}$ are linearly independent, such that $\mathrm{rk}(B) = p$. Then, right-multiplying the model \eqref{eq:iglm-dist-glm} with $W$ and applying \eqref{eq:iglm-dist-matn-ltt} yields

\begin{equation} \label{eq:iglm-dist-iglm-s1}
Y W = X B W + E W, \; E W \sim \mathcal{MN}(0, V, W^\mathrm{T} \Sigma W) \; .
\end{equation}

Employing $B \, W = I_p$ and rearranging, we have

\begin{equation} \label{eq:iglm-dist-iglm-s2}
X = Y W - E W, \; E W \sim \mathcal{MN}(0, V, W^\mathrm{T} \Sigma W) \; .
\end{equation}

Substituting $N = - E W$, we get

\begin{equation} \label{eq:iglm-dist-iglm-s3}
X = Y W + N, \; N \sim \mathcal{MN}(0, V, W^\mathrm{T} \Sigma W)
\end{equation}

which is equivalent to \eqref{eq:iglm-dist-iglm}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Soch J, Allefeld C, Haynes JD (2020): "Inverse transformed encoding models â€“ a solution to the problem of correlated trial-by-trial parameter estimates in fMRI decoding"; in: \textit{NeuroImage}, vol. 209, art. 116449, Appendix C, Theorem 4; URL: \url{https://www.sciencedirect.com/science/article/pii/S1053811919310407}; DOI: 10.1016/j.neuroimage.2019.116449.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P267 | shortcut: iglm-dist | author: JoramSoch | date: 2021-10-21, 16:03.
\vspace{1em}



\subsubsection[\textbf{Best linear unbiased estimator}]{Best linear unbiased estimator} \label{sec:iglm-blue}
\setcounter{equation}{0}

\textbf{Theorem:} Let there be a general linear model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:glm}) of $Y \in \mathbb{R}^{n \times v}$

\begin{equation} \label{eq:iglm-blue-glm}
Y = X B + E, \; E \sim \mathcal{MN}(0, V, \Sigma)
\end{equation}

implying the inverse general linear model ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:iglm-dist}) of $X \in \mathbb{R}^{n \times p}$

\begin{equation} \label{eq:iglm-blue-iglm}
X = Y W + N, \; N \sim \mathcal{MN}(0, V, \Sigma_x) \; .
\end{equation}

where 

\begin{equation} \label{eq:iglm-blue-BW-Sx}
B \, W = I_p \quad \text{and} \quad \Sigma_x = W^\mathrm{T} \Sigma W \; .
\end{equation}

Then, the weighted least squares solution ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:glm-wls}) for $W$ is the best linear unbiased estimator ($\rightarrow$ Definition "blue") of $W$.


\vspace{1em}
\textbf{Proof:} The linear transformation theorem for the matrix-normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:matn-ltt}) states:

\begin{equation} \label{eq:iglm-blue-matn-ltt}
X \sim \mathcal{MN}(M, U, V) \quad \Rightarrow \quad Y = AXB + C \sim \mathcal{MN}(AMB+C, AUA^\mathrm{T}, B^\mathrm{T}VB) \; .
\end{equation}

The weighted least squares parameter estimates ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:glm-wls}) for \eqref{eq:iglm-blue-iglm} are given by

\begin{equation} \label{eq:iglm-blue-iglm-wls}
\hat{W} = (Y^\mathrm{T} V^{-1} Y)^{-1} Y^\mathrm{T} V^{-1} X \; .
\end{equation}

The best linear unbiased estimator ($\rightarrow$ Definition "blue") $\hat{\theta}$ of a certain quantity $\theta$ estimated from measured data ($\rightarrow$ Definition "data") $y$ is 1) an estimator resulting from a linear operation $f(y)$, 2) whose expected value is equal to $\theta$ and 3) which has, among those satisfying 1) and 2), the minimum variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}).

\vspace{1em}
1) First, $\hat{W}$ is a linear estimator, because it is of the form $\tilde{W} = M \hat{X}$ where $M$ is an arbitrary $v \times n$ matrix.

\vspace{1em}
2) Second, $\hat{W}$ is an unbiased estimator, if $\left\langle \hat{W} \right\rangle = W$. By applying \eqref{eq:iglm-blue-matn-ltt} to \eqref{eq:iglm-blue-iglm}, the distribution of $\tilde{W}$ is

\begin{equation} \label{eq:iglm-blue-W-hat-dist}
\tilde{W} = M X \sim \mathcal{MN}(M Y W, M V M^T, \Sigma_x) \;
\end{equation}

which requires ($\rightarrow$ Proof "matn-mean") that $M Y = I_v$. This is fulfilled by any matrix

\begin{equation} \label{eq:iglm-blue-M-D}
M = (Y^\mathrm{T} V^{-1} Y)^{-1} Y^\mathrm{T} V^{-1} + D
\end{equation}

where $D$ is a $v \times n$ matrix which satisfies $D Y = 0$.

\vspace{1em}
3) Third, the best linear unbiased estimator ($\rightarrow$ Definition "blue") is the one with minimum variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}), i.e. the one that minimizes the expected Frobenius norm

\begin{equation} \label{eq:iglm-blue-Var-W}
\mathrm{Var}\left( \tilde{W} \right) = \left\langle \mathrm{tr}\left[ (\tilde{W} - W)^\mathrm{T} (\tilde{W} - W) \right] \right\rangle \; .
\end{equation}

Using the matrix-normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:matn}) of $\tilde{W}$ from \eqref{eq:iglm-blue-W-hat-dist}

\begin{equation} \label{eq:iglm-blue-W-hat-W-dist}
\left( \tilde{W} - W \right) \sim \mathcal{MN}(0, M V M^\mathrm{T}, \Sigma_x)
\end{equation}

and the property of the Wishart distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:wish})

\begin{equation} \label{eq:iglm-blue-E-XX}
X \sim \mathcal{MN}(0, U, V) \quad \Rightarrow \quad \left\langle X X^\mathrm{T} \right\rangle = \mathrm{tr}(V) \, U \; ,
\end{equation}

this variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) can be evaluated as a function of $M$:

\begin{equation} \label{eq:iglm-blue-Var-M}
\begin{split}
\mathrm{Var}\left[ \tilde{W}(M) \right] &\overset{\eqref{eq:iglm-blue-Var-W}}{=} \left\langle \mathrm{tr}\left[ (\tilde{W} - W)^\mathrm{T} (\tilde{W} - W) \right] \right\rangle \\
&= \left\langle \mathrm{tr}\left[ (\tilde{W} - W) (\tilde{W} - W)^\mathrm{T} \right] \right\rangle \\
&= \mathrm{tr}\left[ \left\langle (\tilde{W} - W) (\tilde{W} - W)^\mathrm{T} \right\rangle \right] \\
&\overset{\eqref{eq:iglm-blue-E-XX}}{=} \mathrm{tr}\left[ \mathrm{tr}(\Sigma_x) \, M V M^\mathrm{T} \right] \\
&= \mathrm{tr}(\Sigma_x) \; \mathrm{tr}(M V M^\mathrm{T}) \; .
\end{split}
\end{equation}

As a function of $D$ and using $D Y = 0$, it becomes:

\begin{equation} \label{eq:iglm-blue-Var-D}
\begin{split}
\mathrm{Var}\left[ \tilde{W}(D) \right] &\overset{\eqref{eq:iglm-blue-M-D}}{=} \mathrm{tr}(\Sigma_x) \; \mathrm{tr}\!\left[ \left( (Y^\mathrm{T} V^{-1} Y)^{-1} Y^\mathrm{T} V^{-1} + D \right) V \left( (Y^\mathrm{T} V^{-1} Y)^{-1} Y^\mathrm{T} V^{-1} + D \right)^\mathrm{T} \right] \\
&= \mathrm{tr}(\Sigma_x) \; \mathrm{tr}\!\left[ (Y^\mathrm{T} V^{-1} Y)^{-1} \, Y^\mathrm{T} V^{-1} V V^{-1} Y \; (Y^\mathrm{T} V^{-1} Y)^{-1} + \right. \\
&\hphantom{=\mathrm{tr}(\Sigma_x) \; \mathrm{tr}\!\left[\right.} \left. \, (Y^\mathrm{T} V^{-1} Y)^{-1} Y^\mathrm{T} V^{-1} V D^\mathrm{T} + D V V^{-1} Y (Y^\mathrm{T} V^{-1} Y)^{-1} + D V D^\mathrm{T} \right] \\
&= \mathrm{tr}(\Sigma_x) \left[ \mathrm{tr}\!\left( (Y^\mathrm{T} V^{-1} Y)^{-1} \right) + \mathrm{tr}\!\left( D V D^\mathrm{T} \right) \right] \; .
\end{split}
\end{equation}

Since $D V D^\mathrm{T}$ is a positive-semidefinite matrix, all its eigenvalues are non-negative. Because the trace of a square matrix is the sum of its eigenvalues, the mimimum variance is achieved by $D = 0$, thus producing $\hat{W}$ as in \eqref{eq:iglm-blue-iglm-wls}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Soch J, Allefeld C, Haynes JD (2020): "Inverse transformed encoding models â€“ a solution to the problem of correlated trial-by-trial parameter estimates in fMRI decoding"; in: \textit{NeuroImage}, vol. 209, art. 116449, Appendix C, Theorem 5; URL: \url{https://www.sciencedirect.com/science/article/pii/S1053811919310407}; DOI: 10.1016/j.neuroimage.2019.116449.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P268 | shortcut: iglm-blue | author: JoramSoch | date: 2021-10-21, 16:46.
\vspace{1em}



\subsubsection[\textit{Corresponding forward model}]{Corresponding forward model} \label{sec:cfm}
\setcounter{equation}{0}

\textbf{Definition:} Let there be observations $Y \in \mathbb{R}^{n \times v}$ and $X \in \mathbb{R}^{n \times p}$ and consider a weight matrix $W = f(Y,X) \in \mathbb{R}^{v \times p}$ estimated from $Y$ and $X$, such that right-multiplying $Y$ with the weight matrix gives an estimate or prediction of $X$:

\begin{equation} \label{eq:cfm-bda}
\hat{X} = Y W \; .
\end{equation}

Given that the columns of $\hat{X}$ are linearly independent, then

\begin{equation} \label{eq:cfm-cfm}
Y = \hat{X} A^\mathrm{T} + E \quad \text{with} \quad \hat{X}^\mathrm{T} E = 0
\end{equation}

is called the corresponding forward model relative to the weight matrix $W$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Haufe S, Meinecke F, GÃ¶rgen K, DÃ¤hne S, Haynes JD, Blankertz B, BieÃŸmann F (2014): "On the interpretation of weight vectors of linear models in multivariate neuroimaging"; in: \textit{NeuroImage}, vol. 87, pp. 96â€“110, eq. 3; URL: \url{https://www.sciencedirect.com/science/article/pii/S1053811913010914}; DOI: 10.1016/j.neuroimage.2013.10.067.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D162 | shortcut: cfm | author: JoramSoch | date: 2021-10-21, 17:01.
\vspace{1em}



\subsubsection[\textbf{Derivation of parameters}]{Derivation of parameters} \label{sec:cfm-para}
\setcounter{equation}{0}

\textbf{Theorem:} Let there be observations $Y \in \mathbb{R}^{n \times v}$ and $X \in \mathbb{R}^{n \times p}$ and consider a weight matrix $W = f(Y,X) \in \mathbb{R}^{v \times p}$ predicting $X$ from $Y$:

\begin{equation} \label{eq:cfm-para-bda}
\hat{X} = Y W \; .
\end{equation}

Then, the parameter matrix of the corresponding forward model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:cfm}) is equal to

\begin{equation} \label{eq:cfm-para-cfm-para}
A = \Sigma_y W \Sigma_x^{-1}
\end{equation}

with the "sample covariances ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cov-samp})"

\begin{equation} \label{eq:cfm-para-Sx-Sy}
\begin{split}
\Sigma_x &= \hat{X}^\mathrm{T} \hat{X} \\
\Sigma_y &= Y^\mathrm{T} Y \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Proof:} The corresponding forward model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:cfm}) is given by

\begin{equation} \label{eq:cfm-para-cfm}
Y = \hat{X} A^\mathrm{T} + E \; ,
\end{equation}

subject to the constraint that predicted $X$ and errors $E$ are uncorrelated:

\begin{equation} \label{eq:cfm-para-cfm-con}
\hat{X}^\mathrm{T} E = 0 \; .
\end{equation}

With that, we can directly derive the parameter matrix $A$:

\begin{equation} \label{eq:cfm-para-cfm-para-qed}
\begin{split}
Y &\overset{\eqref{eq:cfm-para-cfm}}{=} \hat{X} A^\mathrm{T} + E \\
\hat{X} A^\mathrm{T} &= Y - E \\
\hat{X}^\mathrm{T} \hat{X} A^\mathrm{T} &= \hat{X}^\mathrm{T} (Y - E) \\
\hat{X}^\mathrm{T} \hat{X} A^\mathrm{T} &= \hat{X}^\mathrm{T} Y - \hat{X}^\mathrm{T} E \\
\hat{X}^\mathrm{T} \hat{X} A^\mathrm{T} &\overset{\eqref{eq:cfm-para-cfm-con}}{=} \hat{X}^\mathrm{T} Y \\
\hat{X}^\mathrm{T} \hat{X} A^\mathrm{T} &\overset{\eqref{eq:cfm-para-bda}}{=} W^\mathrm{T} Y^\mathrm{T} Y \\
\Sigma_x A^\mathrm{T} &\overset{\eqref{eq:cfm-para-Sx-Sy}}{=} W^\mathrm{T} \Sigma_y \\
A^\mathrm{T} &= \Sigma_x^{-1} W^\mathrm{T} \Sigma_y \\
A &= \Sigma_y W \Sigma_x^{-1} \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Haufe S, Meinecke F, GÃ¶rgen K, DÃ¤hne S, Haynes JD, Blankertz B, BieÃŸmann F (2014): "On the interpretation of weight vectors of linear models in multivariate neuroimaging"; in: \textit{NeuroImage}, vol. 87, pp. 96â€“110, Theorem 1; URL: \url{https://www.sciencedirect.com/science/article/pii/S1053811913010914}; DOI: 10.1016/j.neuroimage.2013.10.067.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P269 | shortcut: cfm-para | author: JoramSoch | date: 2021-10-21, 17:20.
\vspace{1em}



\subsubsection[\textbf{Proof of existence}]{Proof of existence} \label{sec:cfm-exist}
\setcounter{equation}{0}

\textbf{Theorem:} Let there be observations $Y \in \mathbb{R}^{n \times v}$ and $X \in \mathbb{R}^{n \times p}$ and consider a weight matrix $W = f(Y,X) \in \mathbb{R}^{v \times p}$ predicting $X$ from $Y$:

\begin{equation} \label{eq:cfm-exist-bda}
\hat{X} = Y W \; .
\end{equation}

Then, there exists a corresponding forward model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:cfm}).


\vspace{1em}
\textbf{Proof:} The corresponding forward model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:cfm}) is defined as

\begin{equation} \label{eq:cfm-exist-cfm}
Y = \hat{X} A^\mathrm{T} + E \quad \text{with} \quad \hat{X}^\mathrm{T} E = 0
\end{equation}

and the parameters of the corresponding forward model ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:cfm-para}) are equal to

\begin{equation} \label{eq:cfm-exist-cfm-para}
A = \Sigma_y W \Sigma_x^{-1} \quad \text{where} \quad \Sigma_x = \hat{X}^\mathrm{T} \hat{X} \quad \text{and} \quad \Sigma_y = Y^\mathrm{T} Y \; .
\end{equation}

\vspace{1em}
1) Because the columns of $\hat{X}$ are assumed to be linearly independent by definition of the corresponding forward model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:cfm}), the matrix $\Sigma_x = \hat{X}^\mathrm{T} \hat{X}$ is invertible, such that $A$ in \eqref{eq:cfm-exist-cfm-para} is well-defined.

\vspace{1em}
2) Moreover, the solution for the matrix $A$ satisfies the constraint of the corresponding forward model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:cfm}) for predicted $X$ and errors $E$ to be uncorrelated which can be shown as follows:

\begin{equation} \label{eq:cfm-exist-X-E-0}
\begin{split}
\hat{X}^\mathrm{T} E &\overset{\eqref{eq:cfm-exist-cfm}}{=} \hat{X}^\mathrm{T} \left( Y - \hat{X} A^\mathrm{T} \right) \\
&\overset{\eqref{eq:cfm-exist-cfm-para}}{=} \hat{X}^\mathrm{T} \left( Y - \hat{X} \, \Sigma_x^{-1} W^\mathrm{T} \Sigma_y \right) \\
&= \hat{X}^\mathrm{T} Y - \hat{X}^\mathrm{T} \hat{X} \, \Sigma_x^{-1} W^\mathrm{T} \Sigma_y \\
&\overset{\eqref{eq:cfm-exist-cfm-para}}{=} \hat{X}^\mathrm{T} Y - \hat{X}^\mathrm{T} \hat{X} \left( \hat{X}^\mathrm{T} \hat{X} \right)^{-1} W^\mathrm{T} \left( Y^\mathrm{T} Y \right) \\
% &= \hat{X}^\mathrm{T} Y - W^\mathrm{T} \left( Y^\mathrm{T} Y \right) \\
&\overset{\eqref{eq:cfm-exist-bda}}{=} (Y W)^\mathrm{T} Y - W^\mathrm{T} \left( Y^\mathrm{T} Y \right) \\
&= W^\mathrm{T} Y^\mathrm{T} Y - W^\mathrm{T} Y^\mathrm{T} Y \\
&= 0 \; .
\end{split}
\end{equation}

This completes the proof.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Haufe S, Meinecke F, GÃ¶rgen K, DÃ¤hne S, Haynes JD, Blankertz B, BieÃŸmann F (2014): "On the interpretation of weight vectors of linear models in multivariate neuroimaging"; in: \textit{NeuroImage}, vol. 87, pp. 96â€“110, Appendix B; URL: \url{https://www.sciencedirect.com/science/article/pii/S1053811913010914}; DOI: 10.1016/j.neuroimage.2013.10.067.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P270 | shortcut: cfm-exist | author: JoramSoch | date: 2021-10-21, 17:43.
\vspace{1em}



\subsection{Multivariate Bayesian linear regression}

\subsubsection[\textbf{Conjugate prior distribution}]{Conjugate prior distribution} \label{sec:mblr-prior}
\setcounter{equation}{0}

\textbf{Theorem:} Let

\begin{equation} \label{eq:mblr-prior-GLM}
Y = X B + E, \; E \sim \mathcal{MN}(0, V, \Sigma)
\end{equation}

be a general linear model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:glm}) with measured $n \times v$ data matrix $Y$, known $n \times p$ design matrix $X$, known $n \times n$ covariance structure ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:matn}) $V$ as well as unknown $p \times v$ regression coefficients $B$ and unknown $v \times v$ noise covariance ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:matn}) $\Sigma$.

Then, the conjugate prior ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior-conj}) for this model is a normal-Wishart distribution ($\rightarrow$ Definition "nw")

\begin{equation} \label{eq:mblr-prior-GLM-NW-prior}
p(B,T) = \mathcal{MN}(B; M_0, \Lambda_0^{-1}, T^{-1}) \cdot \mathcal{W}(T; \Omega_0^{-1}, \nu_0)
\end{equation}

where $T = \Sigma^{-1}$ is the inverse noise covariance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:covmat}) or noise precision matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:precmat}).


\vspace{1em}
\textbf{Proof:} By definition, a conjugate prior ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior-conj}) is a prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) that, when combined with the likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}), leads to a posterior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) that belongs to the same family of probability distributions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist}). This is fulfilled when the prior density and the likelihood function are proportional to the model parameters in the same way, i.e. the model parameters appear in the same functional form in both.

Equation \eqref{eq:mblr-prior-GLM} implies the following likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf})

\begin{equation} \label{eq:mblr-prior-GLM-LF-Class}
p(Y|B,\Sigma) = \mathcal{MN}(Y; X B, V, \Sigma) = \sqrt{\frac{1}{(2 \pi)^{nv} |\Sigma|^n |V|^v}} \, \exp\left[ -\frac{1}{2} \mathrm{tr}\left( \Sigma^{-1} (Y-XB)^\mathrm{T} V^{-1} (Y-XB) \right) \right]
\end{equation}

which, for mathematical convenience, can also be parametrized as

\begin{equation} \label{eq:mblr-prior-GLM-LF-Bayes}
p(Y|B,T) = \mathcal{MN}(Y; X B, P, T^{-1}) = \sqrt{\frac{|T|^n |P|^v}{(2 \pi)^{nv}}} \, \exp\left[ -\frac{1}{2} \mathrm{tr}\left( T (Y-XB)^\mathrm{T} P (Y-XB) \right) \right]
\end{equation}

using the $v \times v$ precision matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:precmat}) $T = \Sigma^{-1}$ and the $n \times n$ precision matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:precmat}) $P = V^{-1}$.

\vspace{1em}
Seperating constant and variable terms, we have:

\begin{equation} \label{eq:mblr-prior-GLM-LF-s1}
p(Y|B,T) = \sqrt{\frac{|P|^v}{(2 \pi)^{nv}}} \cdot |T|^{n/2} \cdot \exp\left[ -\frac{1}{2} \mathrm{tr}\left( T (Y-XB)^\mathrm{T} P (Y-XB) \right) \right] \; .
\end{equation}

Expanding the product in the exponent, we have:

\begin{equation} \label{eq:mblr-prior-GLM-LF-s2}
p(Y|B,T) = \sqrt{\frac{|P|^v}{(2 \pi)^{nv}}} \cdot |T|^{n/2} \cdot \exp\left[ -\frac{1}{2} \mathrm{tr}\left( T \left[ Y^\mathrm{T} P Y - Y^\mathrm{T} P X B - B^\mathrm{T} X^\mathrm{T} P Y + B^\mathrm{T} X^\mathrm{T} P X B \right] \right) \right] \; .
\end{equation}

Completing the square over $\beta$, finally gives

\begin{equation} \label{eq:mblr-prior-GLM-LF-s3}
p(Y|B,T) = \sqrt{\frac{|P|^v}{(2 \pi)^{nv}}} \cdot |T|^{n/2} \cdot \exp\left[ -\frac{1}{2} \mathrm{tr}\left( T \left[ (B - \tilde{X}Y)^\mathrm{T} X^\mathrm{T} P X (B - \tilde{X}Y) - Y^\mathrm{T} Q Y + Y^\mathrm{T} P Y \right] \right) \right]
\end{equation}

where $\tilde{X} = \left( X^\mathrm{T} P X \right)^{-1} X^\mathrm{T} P$ and $Q = \tilde{X}^\mathrm{T} \left( X^\mathrm{T} P X \right) \tilde{X}$.

\vspace{1em}
In other words, the likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) is proportional to a power of the determinant of $T$, times an exponential of the trace of $T$ and an exponential of the trace of a squared form of $B$, weighted by $T$:

\begin{equation} \label{eq:mblr-prior-GLM-LF-s4}
p(Y|B,T) \propto |T|^{n/2} \cdot \exp\left[ -\frac{1}{2} \mathrm{tr}\left( T \left[ Y^\mathrm{T} P Y - Y^\mathrm{T} Q Y \right] \right) \right] \cdot \exp\left[ -\frac{1}{2} \mathrm{tr}\left( T \left[ (B - \tilde{X}Y)^\mathrm{T} X^\mathrm{T} P X (B - \tilde{X}Y) \right] \right) \right] \; .
\end{equation}

The same is true for a normal-Wishart distribution ($\rightarrow$ Definition "nw") over $B$ and $T$

\begin{equation} \label{eq:mblr-prior-MBLR-prior-s1}
p(B,T) = \mathcal{MN}(B; M_0, \Lambda_0^{-1}, T^{-1}) \cdot \mathcal{W}(T; \Omega_0^{-1}, \nu_0)
\end{equation}

the probability density function of which ($\rightarrow$ Proof "nw-pdf")

\begin{equation} \label{eq:mblr-prior-MBLR-prior-s2}
p(B,T) = \sqrt{\frac{|T|^p |\Lambda_0|^v}{(2 \pi)^{pv}}} \, \exp\left[ -\frac{1}{2} \mathrm{tr}\left( T (B-M_0)^\mathrm{T} \Lambda_0 (B-M_0) \right) \right] \cdot \frac{1}{\Gamma_v \left( \frac{\nu_0}{2} \right)} \sqrt{\frac{|\Omega_0|^{\nu_0}}{2^{\nu_0 v}}} |T|^{(\nu_0-v-1)/2} \exp\left[ -\frac{1}{2} \mathrm{tr}\left( \Omega_0 T \right) \right]
\end{equation}

exhibits the same proportionality

\begin{equation} \label{eq:mblr-prior-MBLR-prior-s3}
p(B,T) \propto |T|^{(\nu_0+p-v-1)/2} \cdot \exp\left[ -\frac{1}{2} \mathrm{tr}\left( T \Omega_0 \right) \right] \cdot \exp\left[ -\frac{1}{2} \mathrm{tr}\left( T \left[ (B-M_0)^\mathrm{T} \Lambda_0 (B-M_0) \right] \right) \right]
\end{equation}

and is therefore conjugate relative to the likelihood.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Bayesian multivariate linear regression"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-09-03; URL: \url{https://en.wikipedia.org/wiki/Bayesian_multivariate_linear_regression#Conjugate_prior_distribution}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P159 | shortcut: mblr-prior | author: JoramSoch | date: 2020-09-03, 07:33.
\vspace{1em}



\subsubsection[\textbf{Posterior distribution}]{Posterior distribution} \label{sec:mblr-post}
\setcounter{equation}{0}

\textbf{Theorem:} Let

\begin{equation} \label{eq:mblr-post-GLM}
Y = X B + E, \; E \sim \mathcal{MN}(0, V, \Sigma)
\end{equation}

be a general linear model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:glm}) with measured $n \times v$ data matrix $Y$, known $n \times p$ design matrix $X$, known $n \times n$ covariance structure ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:matn}) $V$ as well as unknown $p \times v$ regression coefficients $B$ and unknown $v \times v$ noise covariance ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:matn}) $\Sigma$. Moreover, assume a normal-Wishart prior distribution ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mblr-prior}) over the model parameters $B$ and $T = \Sigma^{-1}$:

\begin{equation} \label{eq:mblr-post-GLM-NW-prior}
p(B,T) = \mathcal{MN}(B; M_0, \Lambda_0^{-1}, T^{-1}) \cdot \mathcal{W}(T; \Omega_0^{-1}, \nu_0) \; .
\end{equation}

Then, the posterior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) is also a normal-Wishart distribution ($\rightarrow$ Definition "nw")

\begin{equation} \label{eq:mblr-post-GLM-NW-post}
p(B,T|Y) = \mathcal{MN}(B; M_n, \Lambda_n^{-1}, T^{-1}) \cdot \mathcal{W}(T; \Omega_n^{-1}, \nu_n)
\end{equation}

and the posterior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) are given by

\begin{equation} \label{eq:mblr-post-GLM-NW-post-par}
\begin{split}
M_n &= \Lambda_n^{-1} (X^\mathrm{T} P Y + \Lambda_0 M_0) \\
\Lambda_n &= X^\mathrm{T} P X + \Lambda_0 \\
\Omega_n &= \Omega_0 + Y^\mathrm{T} P Y + M_0^\mathrm{T} \Lambda_0 M_0 - M_n^\mathrm{T} \Lambda_n M_n \\
\nu_n &= \nu_0 + n \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Proof:} According to Bayes' theorem ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:bayes-th}), the posterior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) is given by

\begin{equation} \label{eq:mblr-post-GLM-NG-BT}
p(B,T|Y) = \frac{p(Y|B,T) \, p(B,T)}{p(Y)} \; .
\end{equation}

Since $p(Y)$ is just a normalization factor, the posterior is proportional ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:post-jl}) to the numerator:

\begin{equation} \label{eq:mblr-post-GLM-NG-post-JL}
p(B,T|Y) \propto p(Y|B,T) \, p(B,T) = p(Y,B,T) \; .
\end{equation}

Equation \eqref{eq:mblr-post-GLM} implies the following likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf})

\begin{equation} \label{eq:mblr-post-GLM-LF-Class}
p(Y|B,\Sigma) = \mathcal{MN}(Y; X B, V, \Sigma) = \sqrt{\frac{1}{(2 \pi)^{nv} |\Sigma|^n |V|^v}} \, \exp\left[ -\frac{1}{2} \mathrm{tr}\left( \Sigma^{-1} (Y-XB)^\mathrm{T} V^{-1} (Y-XB) \right) \right]
\end{equation}

which, for mathematical convenience, can also be parametrized as

\begin{equation} \label{eq:mblr-post-GLM-LF-Bayes}
p(Y|B,T) = \mathcal{MN}(Y; X B, P, T^{-1}) = \sqrt{\frac{|T|^n |P|^v}{(2 \pi)^{nv}}} \, \exp\left[ -\frac{1}{2} \mathrm{tr}\left( T (Y-XB)^\mathrm{T} P (Y-XB) \right) \right]
\end{equation}

using the $v \times v$ precision matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:precmat}) $T = \Sigma^{-1}$ and the $n \times n$ precision matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:precmat}) $P = V^{-1}$.

\vspace{1em}
Combining the likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) \eqref{eq:mblr-post-GLM-LF-Bayes} with the prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) \eqref{eq:mblr-post-GLM-NW-prior}, the joint likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:jl}) of the model is given by

\begin{equation} \label{eq:mblr-post-GLM-NW-JL-s1}
\begin{split}
p(Y,B,T) = \; & p(Y|B,T) \, p(B,T) \\
= \; & \sqrt{\frac{|T|^n |P|^v}{(2 \pi)^{nv}}} \, \exp\left[ -\frac{1}{2} \mathrm{tr}\left( T (Y-XB)^\mathrm{T} P (Y-XB) \right) \right] \cdot \\
& \sqrt{\frac{|T|^p |\Lambda_0|^v}{(2 \pi)^{pv}}} \, \exp\left[ -\frac{1}{2} \mathrm{tr}\left( T (B-M_0)^\mathrm{T} \Lambda_0 (B-M_0) \right) \right] \cdot \\
& \frac{1}{\Gamma_v \left( \frac{\nu_0}{2} \right)} \sqrt{\frac{|\Omega_0|^{\nu_0}}{2^{\nu_0 v}}} |T|^{(\nu_0-v-1)/2} \exp\left[ -\frac{1}{2} \mathrm{tr}\left( \Omega_0 T \right) \right] \; .
\end{split}
\end{equation}

Collecting identical variables gives:

\begin{equation} \label{eq:mblr-post-GLM-NW-JL-s2}
\begin{split}
p(Y,B,T) = \; & \sqrt{\frac{|T|^n |P|^v}{(2 \pi)^{nv}}} \sqrt{\frac{|T|^p |\Lambda_0|^v}{(2 \pi)^{pv}}} \sqrt{\frac{|\Omega_0|^{\nu_0}}{2^{\nu_0 v}}} \frac{1}{\Gamma_v \left( \frac{\nu_0}{2} \right)} \cdot |T|^{(\nu_0-v-1)/2} \exp\left[ -\frac{1}{2} \mathrm{tr}\left( \Omega_0 T \right) \right] \cdot \\
& \exp\left[ -\frac{1}{2} \mathrm{tr}\left( T \left[ (Y-XB)^\mathrm{T} P (Y-XB) + (B-M_0)^\mathrm{T} \Lambda_0 (B-M_0) \right] \right) \right] \; .
\end{split}
\end{equation}

Expanding the products in the exponent gives:

\begin{equation} \label{eq:mblr-post-GLM-NW-JL-s3}
\begin{split}
p(Y,B,T) = \; & \sqrt{\frac{|T|^n |P|^v}{(2 \pi)^{nv}}} \sqrt{\frac{|T|^p |\Lambda_0|^v}{(2 \pi)^{pv}}} \sqrt{\frac{|\Omega_0|^{\nu_0}}{2^{\nu_0 v}}} \frac{1}{\Gamma_v \left( \frac{\nu_0}{2} \right)} \cdot |T|^{(\nu_0-v-1)/2} \exp\left[ -\frac{1}{2} \mathrm{tr}\left( \Omega_0 T \right) \right] \cdot \\
& \exp\left[ -\frac{1}{2} \mathrm{tr}\left( T \left[ Y^\mathrm{T} P Y - Y^\mathrm{T} P X B - B^\mathrm{T} X^\mathrm{T} P Y + B^\mathrm{T} X^\mathrm{T} P X B + \right. \right. \right. \\
& \hphantom{\exp\left[ -\frac{1}{2} \mathrm{tr}\left( T \left[ \right. \right. \right. \!\!\!} \; \left. \left. \left. B^\mathrm{T} \Lambda_0 B - B^\mathrm{T} \Lambda_0 M_0 - M_0^\mathrm{T} \Lambda_0 B + M_0^\mathrm{T} \Lambda_0 \mu_0 \right] \right) \right] \; .
\end{split}
\end{equation}

Completing the square over $B$, we finally have

\begin{equation} \label{eq:mblr-post-GLM-NW-JL-s4}
\begin{split}
p(Y,B,T) = \; & \sqrt{\frac{|T|^n |P|^v}{(2 \pi)^{nv}}} \sqrt{\frac{|T|^p |\Lambda_0|^v}{(2 \pi)^{pv}}} \sqrt{\frac{|\Omega_0|^{\nu_0}}{2^{\nu_0 v}}} \frac{1}{\Gamma_v \left( \frac{\nu_0}{2} \right)} \cdot |T|^{(\nu_0-v-1)/2} \exp\left[ -\frac{1}{2} \mathrm{tr}\left( \Omega_0 T \right) \right] \cdot \\
& \exp\left[ -\frac{1}{2} \mathrm{tr}\left( T \left[ (B-M_n)^\mathrm{T} \Lambda_n (B-M_n) + (Y^\mathrm{T} P Y + M_0^\mathrm{T} \Lambda_0 M_0 - M_n^\mathrm{T} \Lambda_n M_n) \right] \right) \right] \; .
\end{split}
\end{equation}

with the posterior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post})

\begin{equation} \label{eq:mblr-post-GLM-NW-post-B-par}
\begin{split}
M_n &= \Lambda_n^{-1} (X^\mathrm{T} P Y + \Lambda_0 M_0) \\
\Lambda_n &= X^\mathrm{T} P X + \Lambda_0 \; .
\end{split}
\end{equation}

Ergo, the joint likelihood is proportional to

\begin{equation} \label{eq:mblr-post-GLM-NW-JL-s5}
p(Y,B,T) \propto |T|^{p/2} \cdot \exp\left[ -\frac{1}{2} \mathrm{tr}\left( T \left[ (B-M_n)^\mathrm{T} \Lambda_n (B-M_n) \right] \right) \right] \cdot |T|^{(\nu_n-v-1)/2} \cdot \exp\left[ -\frac{1}{2} \mathrm{tr}\left( \Omega_n T \right) \right]
\end{equation}

with the posterior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post})

\begin{equation} \label{eq:mblr-post-GLM-NW-post-T-par}
\begin{split}
\Omega_n &= \Omega_0 + Y^\mathrm{T} P Y + M_0^\mathrm{T} \Lambda_0 M_0 - M_n^\mathrm{T} \Lambda_n M_n \\
\nu_n &= \nu_0 + n \; .
\end{split}
\end{equation}

From the term in \eqref{eq:mblr-post-GLM-NW-JL-s5}, we can isolate the posterior distribution over $B$ given $T$:

\begin{equation} \label{eq:mblr-post-GLM-NW-post-B}
p(B|T,Y) = \mathcal{MN}(B; M_n, \Lambda_n^{-1}, T^{-1}) \; .
\end{equation}

From the remaining term, we can isolate the posterior distribution over $T$:

\begin{equation} \label{eq:mblr-post-GLM-NW-post-T}
p(T|Y) = \mathcal{W}(T; \Omega_n^{-1}, \nu_n) \; .
\end{equation}

Together, \eqref{eq:mblr-post-GLM-NW-post-B} and \eqref{eq:mblr-post-GLM-NW-post-T} constitute the joint ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) posterior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) of $B$ and $T$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Bayesian multivariate linear regression"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-09-03; URL: \url{https://en.wikipedia.org/wiki/Bayesian_multivariate_linear_regression#Posterior_distribution}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P160 | shortcut: mblr-post | author: JoramSoch | date: 2020-09-03, 08:37.
\vspace{1em}



\subsubsection[\textbf{Log model evidence}]{Log model evidence} \label{sec:mblr-lme}
\setcounter{equation}{0}

\textbf{Theorem:} Let

\begin{equation} \label{eq:mblr-lme-GLM}
Y = X B + E, \; E \sim \mathcal{MN}(0, V, \Sigma)
\end{equation}

be a general linear model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:glm}) with measured $n \times v$ data matrix $Y$, known $n \times p$ design matrix $X$, known $n \times n$ covariance structure ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:matn}) $V$ as well as unknown $p \times v$ regression coefficients $B$ and unknown $v \times v$ noise covariance ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:matn}) $\Sigma$. Moreover, assume a normal-Wishart prior distribution ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mblr-prior}) over the model parameters $B$ and $T = \Sigma^{-1}$:

\begin{equation} \label{eq:mblr-lme-GLM-NW-prior}
p(B,T) = \mathcal{MN}(B; M_0, \Lambda_0^{-1}, T^{-1}) \cdot \mathcal{W}(T; \Omega_0^{-1}, \nu_0) \; .
\end{equation}

Then, the log model evidence ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme}) for this model is

\begin{equation} \label{eq:mblr-lme-GLM-NW-LME}
\begin{split}
\log p(y|m) = & \frac{v}{2} \log |P| - \frac{nv}{2} \log (2 \pi)  + \frac{v}{2} \log |\Lambda_0| - \frac{v}{2} \log |\Lambda_n| + \\
& \frac{\nu_0}{2} \log\left| \frac{1}{2} \Omega_0 \right| - \frac{\nu_n}{2} \log\left| \frac{1}{2} \Omega_n \right| + \log \Gamma_v \left( \frac{\nu_n}{2} \right) - \log \Gamma_v \left( \frac{\nu_0}{2} \right)
\end{split}
\end{equation}

where the posterior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) are given by

\begin{equation} \label{eq:mblr-lme-GLM-NW-post-par}
\begin{split}
M_n &= \Lambda_n^{-1} (X^\mathrm{T} P Y + \Lambda_0 M_0) \\
\Lambda_n &= X^\mathrm{T} P X + \Lambda_0 \\
\Omega_n &= \Omega_0 + Y^\mathrm{T} P Y + M_0^\mathrm{T} \Lambda_0 M_0 - M_n^\mathrm{T} \Lambda_n M_n \\
\nu_n &= \nu_0 + n \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Proof:} According to the law of marginal probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}), the model evidence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ml}) for this model is:

\begin{equation} \label{eq:mblr-lme-GLM-NW-ME-s1}
p(Y|m) = \iint p(Y|B,T) \, p(B,T) \, \mathrm{d}B \, \mathrm{d}T \; .
\end{equation}

According to the law of conditional probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-cond}), the integrand is equivalent to the joint likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:jl}):

\begin{equation} \label{eq:mblr-lme-GLM-NW-ME-s2}
p(Y|m) = \iint p(Y,B,T) \, \mathrm{d}B \, \mathrm{d}T \; .
\end{equation}

Equation \eqref{eq:mblr-lme-GLM} implies the following likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf})

\begin{equation} \label{eq:mblr-lme-GLM-LF-Class}
p(Y|B,\Sigma) = \mathcal{MN}(Y; X B, V, \Sigma) = \sqrt{\frac{1}{(2 \pi)^{nv} |\Sigma|^n |V|^v}} \, \exp\left[ -\frac{1}{2} \mathrm{tr}\left( \Sigma^{-1} (Y-XB)^\mathrm{T} V^{-1} (Y-XB) \right) \right]
\end{equation}

which, for mathematical convenience, can also be parametrized as

\begin{equation} \label{eq:mblr-lme-GLM-LF-Bayes}
p(Y|B,T) = \mathcal{MN}(Y; X B, P, T^{-1}) = \sqrt{\frac{|T|^n |P|^v}{(2 \pi)^{nv}}} \, \exp\left[ -\frac{1}{2} \mathrm{tr}\left( T (Y-XB)^\mathrm{T} P (Y-XB) \right) \right]
\end{equation}

using the $v \times v$ precision matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:precmat}) $T = \Sigma^{-1}$ and the $n \times n$ precision matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:precmat}) $P = V^{-1}$.

\vspace{1em}
When deriving the posterior distribution ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mblr-post}) $p(B,T|Y)$, the joint likelihood $p(Y,B,T)$ is obtained as

\begin{equation} \label{eq:mblr-lme-GLM-NW-LME-s1}
\begin{split}
p(Y,B,T) = \; & \sqrt{\frac{|T|^n |P|^v}{(2 \pi)^{nv}}} \sqrt{\frac{|T|^p |\Lambda_0|^v}{(2 \pi)^{pv}}} \sqrt{\frac{|\Omega_0|^{\nu_0}}{2^{\nu_0 v}}} \frac{1}{\Gamma_v \left( \frac{\nu_0}{2} \right)} \cdot |T|^{(\nu_0-v-1)/2} \exp\left[ -\frac{1}{2} \mathrm{tr}\left( \Omega_0 T \right) \right] \cdot \\
& \exp\left[ -\frac{1}{2} \mathrm{tr}\left( T \left[ (B-M_n)^\mathrm{T} \Lambda_n (B-M_n) + (Y^\mathrm{T} P Y + M_0^\mathrm{T} \Lambda_0 M_0 - M_n^\mathrm{T} \Lambda_n M_n) \right] \right) \right] \; .
\end{split}
\end{equation}

Using the probability density function of the matrix-normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:matn-pdf}), we can rewrite this as

\begin{equation} \label{eq:mblr-lme-GLM-NW-LME-s2}
\begin{split}
p(Y,B,T) = \; & \sqrt{\frac{|T|^n |P|^v}{(2 \pi)^{nv}}} \sqrt{\frac{|T|^p |\Lambda_0|^v}{(2 \pi)^{pv}}} \sqrt{\frac{(2 \pi)^{pv}}{|T|^p |\Lambda_n|^v}} \sqrt{\frac{|\Omega_0|^{\nu_0}}{2^{\nu_0 v}}} \frac{1}{\Gamma_v \left( \frac{\nu_0}{2} \right)} \cdot |T|^{(\nu_0-v-1)/2} \exp\left[ -\frac{1}{2} \mathrm{tr}\left( \Omega_0 T \right) \right] \cdot \\
& \mathcal{MN}(B; M_n, \Lambda_n^{-1}, T^{-1}) \cdot \exp\left[ -\frac{1}{2} \mathrm{tr}\left( T \left[ Y^\mathrm{T} P Y + M_0^\mathrm{T} \Lambda_0 M_0 - M_n^\mathrm{T} \Lambda_n M_n \right] \right) \right] \; .
\end{split}
\end{equation}

Now, $B$ can be integrated out easily:

\begin{equation} \label{eq:mblr-lme-GLM-NW-LME-s3}
\begin{split}
\int p(Y,B,T) \, \mathrm{d}B = \; & \sqrt{\frac{|T|^n |P|^v}{(2 \pi)^{nv}}} \sqrt{\frac{|\Lambda_0|^v}{|\Lambda_n|^v}} \sqrt{\frac{|\Omega_0|^{\nu_0}}{2^{\nu_0 v}}} \frac{1}{\Gamma_v \left( \frac{\nu_0}{2} \right)} \cdot |T|^{(\nu_0-v-1)/2} \cdot \\
& \exp\left[ -\frac{1}{2} \mathrm{tr}\left( T \left[ \Omega_0 + Y^\mathrm{T} P Y + M_0^\mathrm{T} \Lambda_0 M_0 - M_n^\mathrm{T} \Lambda_n M_n \right] \right) \right] \; .
\end{split}
\end{equation}

Using the probability density function of the Wishart distribution ($\rightarrow$ Proof "wish-pdf"), we can rewrite this as

\begin{equation} \label{eq:mblr-lme-GLM-NW-LME-s4}
\int p(Y,B,T) \, \mathrm{d}B = \sqrt{\frac{|P|^v}{(2 \pi)^{nv}}} \sqrt{\frac{|\Lambda_0|^v}{|\Lambda_n|^v}} \sqrt{\frac{|\Omega_0|^{\nu_0}}{2^{\nu_0 v}}} \sqrt{\frac{2^{\nu_n v}}{|\Omega_n|^{\nu_n}}} \, \frac{\Gamma_v \left( \frac{\nu_n}{2} \right)}{\Gamma_v \left( \frac{\nu_0}{2} \right)} \cdot \mathcal{W}(T; \Omega_n^{-1}, \nu_n) \; .
\end{equation}

Finally, $T$ can also be integrated out:

\begin{equation} \label{eq:mblr-lme-GLM-NW-LME-s5}
\iint p(Y,B,T) \, \mathrm{d}B \, \mathrm{d}T = \sqrt{\frac{|P|^v}{(2 \pi)^{nv}}} \sqrt{\frac{|\Lambda_0|^v}{|\Lambda_n|^v}} \sqrt{\frac{\left| \frac{1}{2} \Omega_0 \right|^{\nu_0}}{\left| \frac{1}{2} \Omega_n \right|^{\nu_n}}} \, \frac{\Gamma_v \left( \frac{\nu_n}{2} \right)}{\Gamma_v \left( \frac{\nu_0}{2} \right)} = p(y|m) \; .
\end{equation}

Thus, the log model evidence ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme}) of this model is given by

\begin{equation} \label{eq:mblr-lme-GLM-NW-LME-s6}
\begin{split}
\log p(y|m) = & \frac{v}{2} \log |P| - \frac{nv}{2} \log (2 \pi)  + \frac{v}{2} \log |\Lambda_0| - \frac{v}{2} \log |\Lambda_n| + \\
& \frac{\nu_0}{2} \log\left| \frac{1}{2} \Omega_0 \right| - \frac{\nu_n}{2} \log\left| \frac{1}{2} \Omega_n \right| + \log \Gamma_v \left( \frac{\nu_n}{2} \right) - \log \Gamma_v \left( \frac{\nu_0}{2} \right) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P161 | shortcut: mblr-lme | author: JoramSoch | date: 2020-09-03, 09:23.
\vspace{1em}



\pagebreak
\section{Poisson data}

\subsection{Poisson-distributed data}

\subsubsection[\textit{Definition}]{Definition} \label{sec:poiss-data}
\setcounter{equation}{0}

\textbf{Definition:} Poisson-distributed data are defined as a set of observed counts $y = \left\lbrace y_1, \ldots, y_n \right\rbrace$, independent and identically distributed according to a Poisson distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:poiss}) with rate $\lambda$:

\begin{equation} \label{eq:poiss-data-Poiss}
y_i \sim \mathrm{Poiss}(\lambda), \quad i = 1, \ldots, n \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Poisson distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-03-22; URL: \url{https://en.wikipedia.org/wiki/Poisson_distribution#Parameter_estimation}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D41 | shortcut: poiss-data | author: JoramSoch | date: 2020-03-22, 22:50.
\vspace{1em}



\subsubsection[\textbf{Maximum likelihood estimation}]{Maximum likelihood estimation} \label{sec:poiss-mle}
\setcounter{equation}{0}

\textbf{Theorem:} Let there be a Poisson-distributed data ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:poiss-data}) set $y = \left\lbrace y_1, \ldots, y_n \right\rbrace$:

\begin{equation} \label{eq:poiss-mle-Poiss}
y_i \sim \mathrm{Poiss}(\lambda), \quad i = 1, \ldots, n \; .
\end{equation}

Then, the maximum likelihood estimate ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mle}) for the rate parameter $\lambda$ is given by

\begin{equation} \label{eq:poiss-mle-Poiss-MLE}
\hat{\lambda} = \bar{y}
\end{equation}

where $\bar{y}$ is the sample mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean-samp})

\begin{equation} \label{eq:poiss-mle-y-mean}
\bar{y} = \frac{1}{n} \sum_{i=1}^n y_i \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) for each observation is given by the probability mass function of the Poisson distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:poiss-pmf})

\begin{equation} \label{eq:poiss-mle-Poiss-yi}
p(y_i|\lambda) = \mathrm{Poiss}(y_i; \lambda) = \frac{\lambda^{y_i} \cdot \exp(-\lambda)}{y_i !}
\end{equation}

and because observations are independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}), the likelihood function for all observations is the product of the individual ones:

\begin{equation} \label{eq:poiss-mle-Poiss-LF}
p(y|\lambda) = \prod_{i=1}^n p(y_i|\lambda) = \prod_{i=1}^n \frac{\lambda^{y_i} \cdot \exp(-\lambda)}{y_i !} \; .
\end{equation}

Thus, the log-likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:llf}) is

\begin{equation} \label{eq:poiss-mle-Poiss-LL}
\mathrm{LL}(\lambda) = \log p(y|\lambda) = \log \left[ \prod_{i=1}^n \frac{\lambda^{y_i} \cdot \exp(-\lambda)}{y_i !} \right]
\end{equation}

which can be developed into

\begin{equation} \label{eq:poiss-mle-Poiss-LL-der}
\begin{split}
\mathrm{LL}(\lambda) &= \sum_{i=1}^n \log \left[ \frac{\lambda^{y_i} \cdot \exp(-\lambda)}{y_i !} \right] \\
&= \sum_{i=1}^n \left[ y_i \cdot \log(\lambda) - \lambda - \log(y_i !) \right] \\
&= - \sum_{i=1}^n \lambda + \sum_{i=1}^n y_i \cdot \log(\lambda) - \sum_{i=1}^n \log(y_i !) \\
&= - n \lambda + \log(\lambda) \sum_{i=1}^n y_i - \sum_{i=1}^n \log(y_i !) \\
\end{split}
\end{equation}

The derivatives of the log-likelihood with respect to $\lambda$ are

\begin{equation} \label{eq:poiss-mle-Poiss-dLLdl-d2LLdl2}
\begin{split}
\frac{\mathrm{d}\mathrm{LL}(\lambda)}{\mathrm{d}\lambda} &= \frac{1}{\lambda} \sum_{i=1}^n y_i - n \\
\frac{\mathrm{d}^2\mathrm{LL}(\lambda)}{\mathrm{d}\lambda^2} &= -\frac{1}{\lambda^2} \sum_{i=1}^n y_i \; . \\
\end{split}
\end{equation}

Setting the first derivative to zero, we obtain:

\begin{equation} \label{eq:poiss-mle-Poiss-dLLdl}
\begin{split}
\frac{\mathrm{d}\mathrm{LL}(\hat{\lambda})}{\mathrm{d}\lambda} &= 0 \\
0 &= \frac{1}{\hat{\lambda}} \sum_{i=1}^n y_i - n \\
\hat{\lambda} &= \frac{1}{n} \sum_{i=1}^n y_i = \bar{y} \; .
\end{split}
\end{equation}

Plugging this value into the second derivative, we confirm:

\begin{equation} \label{eq:poiss-mle-Poiss-d2LLdl2}
\begin{split}
\frac{\mathrm{d}^2\mathrm{LL}(\hat{\lambda})}{\mathrm{d}\lambda^2} &= -\frac{1}{\bar{y}^2} \sum_{i=1}^n y_i \\
&= -\frac{n \cdot \bar{y}}{\bar{y}^2} \\
&= -\frac{n}{\bar{y}} < 0 \; .
\end{split}
\end{equation}

This demonstrates that the estimate $\hat{\lambda} = \bar{y}$ maximizes the likelihood $p(y \vert \lambda)$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P27 | shortcut: poiss-mle | author: JoramSoch | date: 2020-01-20, 21:53.
\vspace{1em}



\subsubsection[\textbf{Conjugate prior distribution}]{Conjugate prior distribution} \label{sec:poiss-prior}
\setcounter{equation}{0}

\textbf{Theorem:} Let there be a Poisson-distributed data ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:poiss-data}) set $y = \left\lbrace y_1, \ldots, y_n \right\rbrace$:

\begin{equation} \label{eq:poiss-prior-Poiss}
y_i \sim \mathrm{Poiss}(\lambda), \quad i = 1, \ldots, n \; .
\end{equation}

Then, the conjugate prior ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior-conj}) for the model parameter $\lambda$ is a gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:gam}):

\begin{equation} \label{eq:poiss-prior-Poiss-prior}
p(\lambda) = \mathrm{Gam}(\lambda; a_0, b_0) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} With the probability mass function of the Poisson distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:poiss-pmf}), the likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) for each observation implied by \eqref{eq:poiss-prior-Poiss} is given by

\begin{equation} \label{eq:poiss-prior-Poiss-LF-s1}
p(y_i|\lambda) = \mathrm{Poiss}(y_i; \lambda) = \frac{\lambda^{y_i} \cdot \exp\left[-\lambda\right]}{y_i !}
\end{equation}

and because observations are independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}), the likelihood function for all observations is the product of the individual ones:

\begin{equation} \label{eq:poiss-prior-Poiss-LF-s2}
p(y|\lambda) = \prod_{i=1}^n p(y_i|\lambda) = \prod_{i=1}^n \frac{\lambda^{y_i} \cdot \exp\left[-\lambda\right]}{y_i !} \; .
\end{equation}

Resolving the product in the likelihood function, we have

\begin{equation} \label{eq:poiss-prior-Poiss-LF-s3}
\begin{split}
p(y|\lambda) &= \prod_{i=1}^n \frac{1}{y_i !} \cdot \prod_{i=1}^n \lambda^{y_i} \cdot \prod_{i=1}^n \exp\left[-\lambda\right] \\
&= \prod_{i=1}^n \left(\frac{1}{y_i !}\right) \cdot \lambda^{n \bar{y}} \cdot \exp\left[-n \lambda\right]
\end{split}
\end{equation}

where $\bar{y}$ is the mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean-samp}) of $y$:

\begin{equation} \label{eq:poiss-prior-y-mean}
\bar{y} = \frac{1}{n} \sum_{i=1}^n y_i \; .
\end{equation}

In other words, the likelihood function is proportional to a power of $\lambda$ times an exponential of $\lambda$:

\begin{equation} \label{eq:poiss-prior-Poiss-LF-prop}
p(y|\lambda) \propto \lambda^{n \bar{y}} \cdot \exp\left[-n \lambda\right] \; .
\end{equation}

The same is true for a gamma distribution over $\lambda$

\begin{equation} \label{eq:poiss-prior-Poiss-prior-s1}
p(\lambda) = \mathrm{Gam}(\lambda; a_0, b_0)
\end{equation}

the probability density function of which ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-pdf})

\begin{equation} \label{eq:poiss-prior-Poiss-prior-s2}
p(\lambda) = \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \lambda^{a_0-1} \exp[-b_0 \lambda]
\end{equation}

exhibits the same proportionality

\begin{equation} \label{eq:poiss-prior-Poiss-prior-s3}
p(\lambda) \propto \lambda^{a_0-1} \cdot \exp[-b_0 \lambda]
\end{equation}

and is therefore conjugate relative to the likelihood.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Gelman A, Carlin JB, Stern HS, Dunson DB, Vehtari A, Rubin DB (2014): "Other standard single-parameter models"; in: \textit{Bayesian Data Analysis}, 3rd edition, ch. 2.6, p. 45, eq. 2.14ff.; URL: \url{http://www.stat.columbia.edu/~gelman/book/}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P225 | shortcut: poiss-prior | author: JoramSoch | date: 2020-04-21, 08:31.
\vspace{1em}



\subsubsection[\textbf{Posterior distribution}]{Posterior distribution} \label{sec:poiss-post}
\setcounter{equation}{0}

\textbf{Theorem:} Let there be a Poisson-distributed data ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:poiss-data}) set $y = \left\lbrace y_1, \ldots, y_n \right\rbrace$:

\begin{equation} \label{eq:poiss-post-Poiss}
y_i \sim \mathrm{Poiss}(\lambda), \quad i = 1, \ldots, n \; .
\end{equation}

Moreover, assume a gamma prior distribution ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:poiss-prior}) over the model parameter $\lambda$:

\begin{equation} \label{eq:poiss-post-Poiss-prior}
p(\lambda) = \mathrm{Gam}(\lambda; a_0, b_0) \; .
\end{equation}

Then, the posterior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) is also a gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:gam})

\begin{equation} \label{eq:poiss-post-Poiss-post}
p(\lambda|y) = \mathrm{Gam}(\lambda; a_n, b_n)
\end{equation}

and the posterior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) are given by

\begin{equation} \label{eq:poiss-post-Poiss-post-par}
\begin{split}
a_n &= a_0 + n \bar{y} \\
b_n &= b_0 + n \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Proof:} With the probability mass function of the Poisson distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:poiss-pmf}), the likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) for each observation implied by \eqref{eq:poiss-post-Poiss} is given by

\begin{equation} \label{eq:poiss-post-Poiss-LF-s1}
p(y_i|\lambda) = \mathrm{Poiss}(y_i; \lambda) = \frac{\lambda^{y_i} \cdot \exp\left[-\lambda\right]}{y_i !}
\end{equation}

and because observations are independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}), the likelihood function for all observations is the product of the individual ones:

\begin{equation} \label{eq:poiss-post-Poiss-LF-s2}
p(y|\lambda) = \prod_{i=1}^n p(y_i|\lambda) = \prod_{i=1}^n \frac{\lambda^{y_i} \cdot \exp\left[-\lambda\right]}{y_i !} \; .
\end{equation}

Combining the likelihood function \eqref{eq:poiss-post-Poiss-LF-s2} with the prior distribution \eqref{eq:poiss-post-Poiss-prior}, the joint likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:jl}) of the model is given by

\begin{equation} \label{eq:poiss-post-Poiss-JL-s1}
\begin{split}
p(y,\lambda) &= p(y|\lambda) \, p(\lambda) \\
&= \prod_{i=1}^n \frac{\lambda^{y_i} \cdot \exp\left[-\lambda\right]}{y_i !} \cdot \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \lambda^{a_0-1} \exp[-b_0 \lambda] \; .
\end{split}
\end{equation}

Resolving the product in the joint likelihood, we have

\begin{equation} \label{eq:poiss-post-Poiss-JL-s2}
\begin{split}
p(y,\lambda) &= \prod_{i=1}^n \frac{1}{y_i !} \prod_{i=1}^n \lambda^{y_i} \prod_{i=1}^n \exp\left[-\lambda\right] \cdot \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \lambda^{a_0-1} \exp[-b_0 \lambda] \\
&= \prod_{i=1}^n \left(\frac{1}{y_i !}\right) \lambda^{n \bar{y}} \exp\left[-n \lambda\right] \cdot \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \lambda^{a_0-1} \exp[-b_0 \lambda] \\
&= \prod_{i=1}^n \left(\frac{1}{y_i !}\right) \cdot \frac{ {b_0}^{a_0}}{\Gamma(a_0)}  \cdot \lambda^{a_0 + n \bar{y} - 1} \cdot \exp\left[-(b_0 + n \lambda)\right] \\
\end{split}
\end{equation}

where $\bar{y}$ is the mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean-samp}) of $y$:

\begin{equation} \label{eq:poiss-post-y-mean}
\bar{y} = \frac{1}{n} \sum_{i=1}^n y_i \; .
\end{equation}

Note that the posterior distribution is proportional to the joint likelihood ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:post-jl}):

\begin{equation} \label{eq:poiss-post-Poiss-post-s1}
p(\lambda|y) \propto p(y,\lambda) \; .
\end{equation}

Setting $a_n = a_0 + n \bar{y}$ and $b_n = b_0 + n$, the posterior distribution is therefore proportional to

\begin{equation} \label{eq:poiss-post-Poiss-post-s2}
p(\lambda|y) \propto \lambda^{a_n-1} \cdot \exp\left[-b_n \lambda\right]
\end{equation}

which, when normalized to one, results in the probability density function of the gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-pdf}):

\begin{equation} \label{eq:poiss-post-Poiss-post-s3}
p(\lambda|y) = \frac{ {b_n}^{a_n}}{\Gamma(a_0)} \lambda^{a_n-1} \exp\left[-b_n \lambda\right] = \mathrm{Gam}(\lambda; a_n, b_n) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Gelman A, Carlin JB, Stern HS, Dunson DB, Vehtari A, Rubin DB (2014): "Other standard single-parameter models"; in: \textit{Bayesian Data Analysis}, 3rd edition, ch. 2.6, p. 45, eq. 2.15; URL: \url{http://www.stat.columbia.edu/~gelman/book/}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P226 | shortcut: poiss-post | author: JoramSoch | date: 2020-04-21, 08:48.
\vspace{1em}



\subsubsection[\textbf{Log model evidence}]{Log model evidence} \label{sec:poiss-lme}
\setcounter{equation}{0}

\textbf{Theorem:} Let there be a Poisson-distributed data ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:poiss-data}) set $y = \left\lbrace y_1, \ldots, y_n \right\rbrace$:

\begin{equation} \label{eq:poiss-lme-Poiss}
y_i \sim \mathrm{Poiss}(\lambda), \quad i = 1, \ldots, n \; .
\end{equation}

Moreover, assume a gamma prior distribution ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:poiss-prior}) over the model parameter $\lambda$:

\begin{equation} \label{eq:poiss-lme-Poiss-prior}
p(\lambda) = \mathrm{Gam}(\lambda; a_0, b_0) \; .
\end{equation}

Then, the log model evidence ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme}) for this model is

\begin{equation} \label{eq:poiss-lme-Poiss-LME}
\log p(y|m) = - \sum_{i=1}^n \log y_i ! + \log \Gamma(a_n) - \log \Gamma(a_0) + a_0 \log b_0 - a_n \log b_n \; .
\end{equation}

and the posterior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) are given by

\begin{equation} \label{eq:poiss-lme-Poiss-post-par}
\begin{split}
a_n &= a_0 + n \bar{y} \\
b_n &= b_0 + n \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Proof:} With the probability mass function of the Poisson distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:poiss-pmf}), the likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) for each observation implied by \eqref{eq:poiss-lme-Poiss} is given by

\begin{equation} \label{eq:poiss-lme-Poiss-LF-s1}
p(y_i|\lambda) = \mathrm{Poiss}(y_i; \lambda) = \frac{\lambda^{y_i} \cdot \exp\left[-\lambda\right]}{y_i !}
\end{equation}

and because observations are independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}), the likelihood function for all observations is the product of the individual ones:

\begin{equation} \label{eq:poiss-lme-Poiss-LF-s2}
p(y|\lambda) = \prod_{i=1}^n p(y_i|\lambda) = \prod_{i=1}^n \frac{\lambda^{y_i} \cdot \exp\left[-\lambda\right]}{y_i !} \; .
\end{equation}

Combining the likelihood function \eqref{eq:poiss-lme-Poiss-LF-s2} with the prior distribution \eqref{eq:poiss-lme-Poiss-prior}, the joint likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:jl}) of the model is given by

\begin{equation} \label{eq:poiss-lme-Poiss-JL-s1}
\begin{split}
p(y,\lambda) &= p(y|\lambda) \, p(\lambda) \\
&= \prod_{i=1}^n \frac{\lambda^{y_i} \cdot \exp\left[-\lambda\right]}{y_i !} \cdot \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \lambda^{a_0-1} \exp[-b_0 \lambda] \; .
\end{split}
\end{equation}

Resolving the product in the joint likelihood, we have

\begin{equation} \label{eq:poiss-lme-Poiss-JL-s2}
\begin{split}
p(y,\lambda) &= \prod_{i=1}^n \frac{1}{y_i !} \prod_{i=1}^n \lambda^{y_i} \prod_{i=1}^n \exp\left[-\lambda\right] \cdot \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \lambda^{a_0-1} \exp[-b_0 \lambda] \\
&= \prod_{i=1}^n \left(\frac{1}{y_i !}\right) \lambda^{n \bar{y}} \exp\left[-n \lambda\right] \cdot \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \lambda^{a_0-1} \exp[-b_0 \lambda] \\
&= \prod_{i=1}^n \left(\frac{1}{y_i !}\right) \cdot \frac{ {b_0}^{a_0}}{\Gamma(a_0)}  \cdot \lambda^{a_0 + n \bar{y} - 1} \cdot \exp\left[-(b_0 + n \lambda)\right] \\
\end{split}
\end{equation}

where $\bar{y}$ is the mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean-samp}) of $y$:

\begin{equation} \label{eq:poiss-lme-y-mean}
\bar{y} = \frac{1}{n} \sum_{i=1}^n y_i \; .
\end{equation}

Note that the model evidence is the marginal density of the joint likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ml}):

\begin{equation} \label{eq:poiss-lme-Poiss-ME}
p(y) = \int p(y,\lambda) \, \mathrm{d}\lambda \; .
\end{equation}

Setting $a_n = a_0 + n \bar{y}$ and $b_n = b_0 + n$, the joint likelihood can also be written as

\begin{equation} \label{eq:poiss-lme-Poiss-JL-s3}
p(y,\lambda) = \prod_{i=1}^n \left(\frac{1}{y_i !}\right) \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \frac{\Gamma(a_n)}{ {b_n}^{a_n}} \cdot \frac{ {b_n}^{a_n}}{\Gamma(a_n)} \lambda^{a_n-1} \exp\left[-b_n \lambda\right] \; .
\end{equation}

Using the probability density function of the gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-pdf}), $\lambda$ can now be integrated out easily

\begin{equation} \label{eq:poiss-lme-Poiss-ME-qed}
\begin{split}
\mathrm{p}(y) &= \int \prod_{i=1}^n \left(\frac{1}{y_i !}\right) \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \frac{\Gamma(a_n)}{ {b_n}^{a_n}} \cdot \frac{ {b_n}^{a_n}}{\Gamma(a_n)} \lambda^{a_n-1} \exp\left[-b_n \lambda\right] \, \mathrm{d}\lambda \\
&= \prod_{i=1}^n \left(\frac{1}{y_i !}\right) \frac{\Gamma(a_n)}{\Gamma(a_0)} \frac{ {b_0}^{a_0}}{ {b_n}^{a_n}} \int \mathrm{Gam}(\lambda; a_n, b_n) \, \mathrm{d}\lambda \\
&= \prod_{i=1}^n \left(\frac{1}{y_i !}\right) \frac{\Gamma(a_n)}{\Gamma(a_0)} \frac{ {b_0}^{a_0}}{ {b_n}^{a_n}} \; ,
\end{split}
\end{equation}

such that the log model evidence ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme}) is shown to be

\begin{equation} \label{eq:poiss-lme-Poiss-LME-qed}
\log p(y|m) = - \sum_{i=1}^n \log y_i ! + \log \Gamma(a_n) - \log \Gamma(a_0) + a_0 \log b_0 - a_n \log b_n \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P227 | shortcut: poiss-lme | author: JoramSoch | date: 2020-04-21, 09:09.
\vspace{1em}



\subsection{Poisson distribution with exposure values}

\subsubsection[\textit{Definition}]{Definition} \label{sec:poissexp}
\setcounter{equation}{0}

\textbf{Definition:} A Poisson distribution with exposure values is defined as a set of observed counts $y = \left\lbrace y_1, \ldots, y_n \right\rbrace$, independently distributed according to a Poisson distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:poiss}) with common rate $\lambda$ and a set of concurrent exposures $x = \left\lbrace x_1, \ldots, x_n \right\rbrace$:

\begin{equation} \label{eq:poissexp-Poiss-exp}
y_i \sim \mathrm{Poiss}(\lambda x_i), \quad i = 1, \ldots, n \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Gelman A, Carlin JB, Stern HS, Dunson DB, Vehtari A, Rubin DB (2014): "Other standard single-parameter models"; in: \textit{Bayesian Data Analysis}, 3rd edition, ch. 2.6, p. 45, eq. 2.14; URL: \url{http://www.stat.columbia.edu/~gelman/book/}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D42 | shortcut: poissexp | author: JoramSoch | date: 2020-03-22, 22:57.
\vspace{1em}



\subsubsection[\textbf{Maximum likelihood estimation}]{Maximum likelihood estimation} \label{sec:poissexp-mle}
\setcounter{equation}{0}

\textbf{Theorem:} Consider data $y = \left\lbrace y_1, \ldots, y_n \right\rbrace$ following a Poisson distribution with exposure values ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:poissexp}):

\begin{equation} \label{eq:poissexp-mle-Poiss-exp}
y_i \sim \mathrm{Poiss}(\lambda x_i), \quad i = 1, \ldots, n \; .
\end{equation}

Then, the maximum likelihood estimate ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mle}) for the rate parameter $\lambda$ is given by

\begin{equation} \label{eq:poissexp-mle-Poiss-exp-MLE}
\hat{\lambda} = \frac{\bar{y}}{\bar{x}}
\end{equation}

where $\bar{y}$ and $\bar{x}$ are the sample means ($\rightarrow$ Definition "mean-sample")

\begin{equation} \label{eq:poissexp-mle-xy-mean}
\begin{split}
\bar{y} &= \frac{1}{n} \sum_{i=1}^n y_i \\
\bar{x} &= \frac{1}{n} \sum_{i=1}^n x_i \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Proof:} With the probability mass function of the Poisson distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:poiss-pmf}), the likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) for each observation implied by \eqref{eq:poissexp-mle-Poiss-exp} is given by

\begin{equation} \label{eq:poissexp-mle-Poiss-exp-LF-s1}
p(y_i|\lambda) = \mathrm{Poiss}(y_i; \lambda x_i) = \frac{(\lambda x_i)^{y_i} \cdot \exp[-\lambda x_i]}{y_i !}
\end{equation}

and because observations are independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}), the likelihood function for all observations is the product of the individual ones:

\begin{equation} \label{eq:poissexp-mle-Poiss-exp-LF-s2}
p(y|\lambda) = \prod_{i=1}^n p(y_i|\lambda) = \prod_{i=1}^n \frac{(\lambda x_i)^{y_i} \cdot \exp[-\lambda x_i]}{y_i !} \; .
\end{equation}

Thus, the log-likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:llf}) is

\begin{equation} \label{eq:poissexp-mle-Poiss-LL}
\mathrm{LL}(\lambda) = \log p(y|\lambda) = \log \left[ \prod_{i=1}^n \frac{(\lambda x_i)^{y_i} \cdot \exp[-\lambda x_i]}{y_i !} \right]
\end{equation}

which can be developed into

\begin{equation} \label{eq:poissexp-mle-Poiss-LL-der}
\begin{split}
\mathrm{LL}(\lambda) &= \sum_{i=1}^n \log \left[ \frac{(\lambda x_i)^{y_i} \cdot \exp[-\lambda x_i]}{y_i !} \right] \\
&= \sum_{i=1}^n \left[ y_i \cdot \log(\lambda x_i) - \lambda x_i - \log(y_i !) \right] \\
&= - \sum_{i=1}^n \lambda x_i + \sum_{i=1}^n y_i \cdot \left[ \log(\lambda) + \log(x_i) \right] - \sum_{i=1}^n \log(y_i !) \\
&= - \lambda \sum_{i=1}^n x_i + \log(\lambda) \sum_{i=1}^n y_i + \sum_{i=1}^n y_i \log(x_i) - \sum_{i=1}^n \log(y_i !) \\
&= - n \bar{x} \lambda + n \bar{y} \log(\lambda) + \sum_{i=1}^n y_i \log(x_i) - \sum_{i=1}^n \log(y_i !) \\
\end{split}
\end{equation}

where $\bar{x}$ and $\bar{y}$ are the sample means from equation \eqref{eq:poissexp-mle-xy-mean}.

\vspace{1em}
The derivatives of the log-likelihood with respect to $\lambda$ are

\begin{equation} \label{eq:poissexp-mle-Poiss-dLLdl-d2LLdl2}
\begin{split}
\frac{\mathrm{d}\mathrm{LL}(\lambda)}{\mathrm{d}\lambda} &= - n \bar{x} + \frac{n \bar{y}}{\lambda} \\
\frac{\mathrm{d}^2\mathrm{LL}(\lambda)}{\mathrm{d}\lambda^2} &= -\frac{n \bar{y}}{\lambda^2} \; . \\
\end{split}
\end{equation}

Setting the first derivative to zero, we obtain:

\begin{equation} \label{eq:poissexp-mle-Poiss-dLLdl}
\begin{split}
\frac{\mathrm{d}\mathrm{LL}(\hat{\lambda})}{\mathrm{d}\lambda} &= 0 \\
0 &= - n \bar{x} + \frac{n \bar{y}}{\hat{\lambda}} \\
\hat{\lambda} &= \frac{n \bar{y}}{n \bar{x}} = \frac{\bar{y}}{\bar{x}} \; .
\end{split}
\end{equation}

Plugging this value into the second derivative, we confirm:

\begin{equation} \label{eq:poissexp-mle-Poiss-d2LLdl2}
\begin{split}
\frac{\mathrm{d}^2\mathrm{LL}(\hat{\lambda})}{\mathrm{d}\lambda^2} &= -\frac{n \bar{y}}{\hat{\lambda}^2} \\
&= -\frac{n \cdot \bar{y}}{(\bar{y}/\bar{x})^2} \\
&= -\frac{n \cdot \bar{x}^2}{\bar{y}} < 0 \; .
\end{split}
\end{equation}

This demonstrates that the estimate $\hat{\lambda} = \bar{y}/\bar{x}$ maximizes the likelihood $p(y \vert \lambda)$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P224 | shortcut: poissexp-mle | author: JoramSoch | date: 2021-04-16, 11:42.
\vspace{1em}



\subsubsection[\textbf{Conjugate prior distribution}]{Conjugate prior distribution} \label{sec:poissexp-prior}
\setcounter{equation}{0}

\textbf{Theorem:} Consider data $y = \left\lbrace y_1, \ldots, y_n \right\rbrace$ following a Poisson distribution with exposure values ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:poissexp}):

\begin{equation} \label{eq:poissexp-prior-Poiss-exp}
y_i \sim \mathrm{Poiss}(\lambda x_i), \quad i = 1, \ldots, n \; .
\end{equation}

Then, the conjugate prior ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior-conj}) for the model parameter $\lambda$ is a gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:gam}):

\begin{equation} \label{eq:poissexp-prior-Poiss-exp-prior}
p(\lambda) = \mathrm{Gam}(\lambda; a_0, b_0) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} With the probability mass function of the Poisson distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:poiss-pmf}), the likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) for each observation implied by \eqref{eq:poissexp-prior-Poiss-exp} is given by

\begin{equation} \label{eq:poissexp-prior-Poiss-exp-LF-s1}
p(y_i|\lambda) = \mathrm{Poiss}(y_i; \lambda x_i) = \frac{(\lambda x_i)^{y_i} \cdot \exp\left[-\lambda x_i\right]}{y_i !}
\end{equation}

and because observations are independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}), the likelihood function for all observations is the product of the individual ones:

\begin{equation} \label{eq:poissexp-prior-Poiss-exp-LF-s2}
p(y|\lambda) = \prod_{i=1}^n p(y_i|\lambda) = \prod_{i=1}^n \frac{(\lambda x_i)^{y_i} \cdot \exp\left[-\lambda x_i\right]}{y_i !} \; .
\end{equation}

Resolving the product in the likelihood function, we have

\begin{equation} \label{eq:poissexp-prior-Poiss-exp-LF-s3}
\begin{split}
p(y|\lambda) &= \prod_{i=1}^n \frac{ {x_i}^{y_i}}{y_i !} \cdot \prod_{i=1}^n \lambda^{y_i} \cdot \prod_{i=1}^n \exp\left[-\lambda x_i\right] \\
&= \prod_{i=1}^n \left(\frac{ {x_i}^{y_i}}{y_i !}\right) \cdot \lambda^{\sum_{i=1}^n y_i} \cdot \exp\left[-\lambda \sum_{i=1}^n x_i\right] \\
&= \prod_{i=1}^n \left(\frac{ {x_i}^{y_i}}{y_i !}\right) \cdot \lambda^{n \bar{y}} \cdot \exp\left[-n \bar{x} \lambda\right]
\end{split}
\end{equation}

where $\bar{y}$ and $\bar{x}$ are the means ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean-samp}) of $y$ and $x$ respectively:

\begin{equation} \label{eq:poissexp-prior-xy-mean}
\begin{split}
\bar{y} &= \frac{1}{n} \sum_{i=1}^n y_i \\
\bar{x} &= \frac{1}{n} \sum_{i=1}^n x_i \; .
\end{split}
\end{equation}

In other words, the likelihood function is proportional to a power of $\lambda$ times an exponential of $\lambda$:

\begin{equation} \label{eq:poissexp-prior-Poiss-exp-LF-prop}
p(y|\lambda) \propto \lambda^{n \bar{y}} \cdot \exp\left[-n \bar{x} \lambda\right] \; .
\end{equation}

The same is true for a gamma distribution over $\lambda$

\begin{equation} \label{eq:poissexp-prior-Poiss-exp-prior-s1}
p(\lambda) = \mathrm{Gam}(\lambda; a_0, b_0)
\end{equation}

the probability density function of which ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-pdf})

\begin{equation} \label{eq:poissexp-prior-Poiss-exp-prior-s2}
p(\lambda) = \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \lambda^{a_0-1} \exp[-b_0 \lambda]
\end{equation}

exhibits the same proportionality

\begin{equation} \label{eq:poissexp-prior-Poiss-exp-prior-s3}
p(\lambda) \propto \lambda^{a_0-1} \cdot \exp[-b_0 \lambda]
\end{equation}

and is therefore conjugate relative to the likelihood.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Gelman A, Carlin JB, Stern HS, Dunson DB, Vehtari A, Rubin DB (2014): "Other standard single-parameter models"; in: \textit{Bayesian Data Analysis}, 3rd edition, ch. 2.6, p. 45, eq. 2.14ff.; URL: \url{http://www.stat.columbia.edu/~gelman/book/}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P41 | shortcut: poissexp-prior | author: JoramSoch | date: 2020-02-04, 14:11.
\vspace{1em}



\subsubsection[\textbf{Posterior distribution}]{Posterior distribution} \label{sec:poissexp-post}
\setcounter{equation}{0}

\textbf{Theorem:} Consider data $y = \left\lbrace y_1, \ldots, y_n \right\rbrace$ following a Poisson distribution with exposure values ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:poissexp}):

\begin{equation} \label{eq:poissexp-post-Poiss-exp}
y_i \sim \mathrm{Poiss}(\lambda x_i), \quad i = 1, \ldots, n \; .
\end{equation}

Moreover, assume a gamma prior distribution ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:poissexp-prior}) over the model parameter $\lambda$:

\begin{equation} \label{eq:poissexp-post-Poiss-exp-prior}
p(\lambda) = \mathrm{Gam}(\lambda; a_0, b_0) \; .
\end{equation}

Then, the posterior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) is also a gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:gam})

\begin{equation} \label{eq:poissexp-post-Poiss-exp-post}
p(\lambda|y) = \mathrm{Gam}(\lambda; a_n, b_n)
\end{equation}

and the posterior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) are given by

\begin{equation} \label{eq:poissexp-post-Poiss-exp-post-par}
\begin{split}
a_n &= a_0 + n \bar{y} \\
b_n &= b_0 + n \bar{x} \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Proof:} With the probability mass function of the Poisson distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:poiss-pmf}), the likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) for each observation implied by \eqref{eq:poissexp-post-Poiss-exp} is given by

\begin{equation} \label{eq:poissexp-post-Poiss-exp-LF-s1}
p(y_i|\lambda) = \mathrm{Poiss}(y_i; \lambda x_i) = \frac{(\lambda x_i)^{y_i} \cdot \exp\left[-\lambda x_i\right]}{y_i !}
\end{equation}

and because observations are independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}), the likelihood function for all observations is the product of the individual ones:

\begin{equation} \label{eq:poissexp-post-Poiss-exp-LF-s2}
p(y|\lambda) = \prod_{i=1}^n p(y_i|\lambda) = \prod_{i=1}^n \frac{(\lambda x_i)^{y_i} \cdot \exp\left[-\lambda x_i\right]}{y_i !} \; .
\end{equation}

Combining the likelihood function \eqref{eq:poissexp-post-Poiss-exp-LF-s2} with the prior distribution \eqref{eq:poissexp-post-Poiss-exp-prior}, the joint likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:jl}) of the model is given by

\begin{equation} \label{eq:poissexp-post-Poiss-exp-JL-s1}
\begin{split}
p(y,\lambda) &= p(y|\lambda) \, p(\lambda) \\
&= \prod_{i=1}^n \frac{(\lambda x_i)^{y_i} \cdot \exp\left[-\lambda x_i\right]}{y_i !} \cdot \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \lambda^{a_0-1} \exp[-b_0 \lambda] \; .
\end{split}
\end{equation}

Resolving the product in the joint likelihood, we have

\begin{equation} \label{eq:poissexp-post-Poiss-JL-s2}
\begin{split}
p(y,\lambda) &= \prod_{i=1}^n \frac{ {x_i}^{y_i}}{y_i !} \prod_{i=1}^n \lambda^{y_i} \prod_{i=1}^n \exp\left[-\lambda x_i\right] \cdot \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \lambda^{a_0-1} \exp[-b_0 \lambda] \\
&= \prod_{i=1}^n \left(\frac{ {x_i}^{y_i}}{y_i !}\right) \lambda^{\sum_{i=1}^n y_i} \exp\left[-\lambda \sum_{i=1}^n x_i\right] \cdot \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \lambda^{a_0-1} \exp[-b_0 \lambda] \\
&= \prod_{i=1}^n \left(\frac{ {x_i}^{y_i}}{y_i !}\right) \lambda^{n \bar{y}} \exp\left[-n \bar{x} \lambda\right] \cdot \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \lambda^{a_0-1} \exp[-b_0 \lambda] \\
&= \prod_{i=1}^n \left(\frac{ {x_i}^{y_i}}{y_i !}\right) \cdot \frac{ {b_0}^{a_0}}{\Gamma(a_0)}  \cdot \lambda^{a_0 + n \bar{y} - 1} \cdot \exp\left[-(b_0 + n \bar{x}) \lambda\right] \\
\end{split}
\end{equation}

where $\bar{y}$ and $\bar{x}$ are the means ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean-samp}) of $y$ and $x$ respectively:

\begin{equation} \label{eq:poissexp-post-xy-mean}
\begin{split}
\bar{y} &= \frac{1}{n} \sum_{i=1}^n y_i \\
\bar{x} &= \frac{1}{n} \sum_{i=1}^n x_i \; .
\end{split}
\end{equation}

Note that the posterior distribution is proportional to the joint likelihood ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:post-jl}):

\begin{equation} \label{eq:poissexp-post-Poiss-exp-post-s1}
p(\lambda|y) \propto p(y,\lambda) \; .
\end{equation}

Setting $a_n = a_0 + n \bar{y}$ and $b_n = b_0 + n \bar{x}$, the posterior distribution is therefore proportional to

\begin{equation} \label{eq:poissexp-post-Poiss-exp-post-s2}
p(\lambda|y) \propto \lambda^{a_n-1} \cdot \exp\left[-b_n \lambda\right]
\end{equation}

which, when normalized to one, results in the probability density function of the gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-pdf}):

\begin{equation} \label{eq:poissexp-post-Poiss-exp-post-s3}
p(\lambda|y) = \frac{ {b_n}^{a_n}}{\Gamma(a_0)} \lambda^{a_n-1} \exp\left[-b_n \lambda\right] = \mathrm{Gam}(\lambda; a_n, b_n) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Gelman A, Carlin JB, Stern HS, Dunson DB, Vehtari A, Rubin DB (2014): "Other standard single-parameter models"; in: \textit{Bayesian Data Analysis}, 3rd edition, ch. 2.6, p. 45, eq. 2.15; URL: \url{http://www.stat.columbia.edu/~gelman/book/}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P42 | shortcut: poissexp-post | author: JoramSoch | date: 2020-02-04, 14:42.
\vspace{1em}



\subsubsection[\textbf{Log model evidence}]{Log model evidence} \label{sec:poissexp-lme}
\setcounter{equation}{0}

\textbf{Theorem:} Consider data $y = \left\lbrace y_1, \ldots, y_n \right\rbrace$ following a Poisson distribution with exposure values ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:poissexp}):

\begin{equation} \label{eq:poissexp-lme-Poiss-exp}
y_i \sim \mathrm{Poiss}(\lambda x_i), \quad i = 1, \ldots, n \; .
\end{equation}

Moreover, assume a gamma prior distribution ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:poissexp-prior}) over the model parameter $\lambda$:

\begin{equation} \label{eq:poissexp-lme-Poiss-exp-prior}
p(\lambda) = \mathrm{Gam}(\lambda; a_0, b_0) \; .
\end{equation}

Then, the log model evidence ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme}) for this model is

\begin{equation} \label{eq:poissexp-lme-Poiss-exp-LME}
\begin{split}
\log p(y|m) = &\sum_{i=1}^n y_i \log(x_i) - \sum_{i=1}^n \log y_i ! + \\ 
&\log \Gamma(a_n) - \log \Gamma(a_0) + a_0 \log b_0 - a_n \log b_n \; .
\end{split}
\end{equation}

where the posterior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) are given by

\begin{equation} \label{eq:poissexp-lme-Poiss-exp-post-par}
\begin{split}
a_n &= a_0 + n \bar{y} \\
a_n &= a_0 + n \bar{x} \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Proof:} With the probability mass function of the Poisson distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:poiss-pmf}), the likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) for each observation implied by \eqref{eq:poissexp-lme-Poiss-exp} is given by

\begin{equation} \label{eq:poissexp-lme-Poiss-exp-LF-s1}
p(y_i|\lambda) = \mathrm{Poiss}(y_i; \lambda x_i) = \frac{(\lambda x_i)^{y_i} \cdot \exp\left[-\lambda x_i\right]}{y_i !}
\end{equation}

and because observations are independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}), the likelihood function for all observations is the product of the individual ones:

\begin{equation} \label{eq:poissexp-lme-Poiss-exp-LF-s2}
p(y|\lambda) = \prod_{i=1}^n p(y_i|\lambda) = \prod_{i=1}^n \frac{(\lambda x_i)^{y_i} \cdot \exp\left[-\lambda x_i\right]}{y_i !} \; .
\end{equation}

Combining the likelihood function \eqref{eq:poissexp-lme-Poiss-exp-LF-s2} with the prior distribution \eqref{eq:poissexp-lme-Poiss-exp-prior}, the joint likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:jl}) of the model is given by

\begin{equation} \label{eq:poissexp-lme-Poiss-exp-JL-s1}
\begin{split}
p(y,\lambda) &= p(y|\lambda) \, p(\lambda) \\
&= \prod_{i=1}^n \frac{(\lambda x_i)^{y_i} \cdot \exp\left[-\lambda x_i\right]}{y_i !} \cdot \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \lambda^{a_0-1} \exp[-b_0 \lambda] \; .
\end{split}
\end{equation}

Resolving the product in the joint likelihood, we have

\begin{equation} \label{eq:poissexp-lme-Poiss-exp-JL-s2}
\begin{split}
p(y,\lambda) &= \prod_{i=1}^n \frac{ {x_i}^{y_i}}{y_i !} \prod_{i=1}^n \lambda^{y_i} \prod_{i=1}^n \exp\left[-\lambda x_i\right] \cdot \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \lambda^{a_0-1} \exp[-b_0 \lambda] \\
&= \prod_{i=1}^n \left(\frac{ {x_i}^{y_i}}{y_i !}\right) \lambda^{\sum_{i=1}^n y_i} \exp\left[-\lambda \sum_{i=1}^n x_i\right] \cdot \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \lambda^{a_0-1} \exp[-b_0 \lambda] \\
&= \prod_{i=1}^n \left(\frac{ {x_i}^{y_i}}{y_i !}\right) \lambda^{n \bar{y}} \exp\left[-n \bar{x} \lambda\right] \cdot \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \lambda^{a_0-1} \exp[-b_0 \lambda] \\
&= \prod_{i=1}^n \left(\frac{ {x_i}^{y_i}}{y_i !}\right) \frac{ {b_0}^{a_0}}{\Gamma(a_0)}  \cdot \lambda^{a_0 + n \bar{y} - 1} \cdot \exp\left[-(b_0 + n \bar{x}) \lambda\right] \\
\end{split}
\end{equation}

where $\bar{y}$ and $\bar{x}$ are the means ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean-samp}) of $y$ and $x$ respectively:

\begin{equation} \label{eq:poissexp-lme-xy-mean}
\begin{split}
\bar{y} &= \frac{1}{n} \sum_{i=1}^n y_i \\
\bar{x} &= \frac{1}{n} \sum_{i=1}^n x_i \; .
\end{split}
\end{equation}

Note that the model evidence is the marginal density of the joint likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ml}):

\begin{equation} \label{eq:poissexp-lme-Poiss-exp-ME}
p(y) = \int p(y,\lambda) \, \mathrm{d}\lambda \; .
\end{equation}

Setting $a_n = a_0 + n \bar{y}$ and $b_n = b_0 + n \bar{x}$, the joint likelihood can also be written as

\begin{equation} \label{eq:poissexp-lme-Poiss-exp-JL-s3}
p(y,\lambda) = \prod_{i=1}^n \left(\frac{ {x_i}^{y_i}}{y_i !}\right) \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \frac{\Gamma(a_n)}{ {b_n}^{a_n}} \cdot \frac{ {b_n}^{a_n}}{\Gamma(a_n)} \lambda^{a_n-1} \exp\left[-b_n \lambda\right] \; .
\end{equation}

Using the probability density function of the gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-pdf}), $\lambda$ can now be integrated out easily

\begin{equation} \label{eq:poissexp-lme-Poiss-exp-ME-qed}
\begin{split}
\mathrm{p}(y) &= \int \prod_{i=1}^n \left(\frac{ {x_i}^{y_i}}{y_i !}\right) \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \frac{\Gamma(a_n)}{ {b_n}^{a_n}} \cdot \frac{ {b_n}^{a_n}}{\Gamma(a_n)} \lambda^{a_n-1} \exp\left[-b_n \lambda\right] \, \mathrm{d}\lambda \\
&= \prod_{i=1}^n \left(\frac{ {x_i}^{y_i}}{y_i !}\right) \frac{\Gamma(a_n)}{\Gamma(a_0)} \frac{ {b_0}^{a_0}}{ {b_n}^{a_n}} \int \mathrm{Gam}(\lambda; a_n, b_n) \, \mathrm{d}\lambda \\
&= \prod_{i=1}^n \left(\frac{ {x_i}^{y_i}}{y_i !}\right) \frac{\Gamma(a_n)}{\Gamma(a_0)} \frac{ {b_0}^{a_0}}{ {b_n}^{a_n}} \; ,
\end{split}
\end{equation}

such that the log model evidence ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme}) is shown to be

\begin{equation} \label{eq:poissexp-lme-Poiss-exp-LME-qed}
\begin{split}
\log p(y|m) = &\sum_{i=1}^n y_i \log(x_i) - \sum_{i=1}^n \log y_i ! + \\ 
&\log \Gamma(a_n) - \log \Gamma(a_0) + a_0 \log b_0 - a_n \log b_n \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P43 | shortcut: poissexp-lme | author: JoramSoch | date: 2020-02-04, 15:12.
\vspace{1em}



\pagebreak
\section{Probability data}

\subsection{Beta-distributed data}

\subsubsection[\textit{Definition}]{Definition} \label{sec:beta-data}
\setcounter{equation}{0}

\textbf{Definition:} Beta-distributed data are defined as a set of proportions $y = \left\lbrace y_1, \ldots, y_n \right\rbrace$ with $y_i \in [0,1], \; i = 1,\ldots,n$, independent and identically distributed according to a Beta distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:beta}) with shapes $\alpha$ and $\beta$:

\begin{equation} \label{eq:beta-data-beta-data}
y_i \sim \mathrm{Bet}(\alpha,\beta), \quad i = 1, \ldots, n \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D77 | shortcut: beta-data | author: JoramSoch | date: 2020-06-28, 21:16.
\vspace{1em}



\subsubsection[\textbf{Method of moments}]{Method of moments} \label{sec:beta-mome}
\setcounter{equation}{0}

\textbf{Theorem:} Let $y = \left\lbrace y_1, \ldots, y_n \right\rbrace$ be a set of observed counts independent and identically distributed ($\rightarrow$ Definition "iid") according to a beta distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:beta}) with shapes $\alpha$ and $\beta$:

\begin{equation} \label{eq:beta-mome-Beta}
y_i \sim \mathrm{Bet}(\alpha,\beta), \quad i = 1, \ldots, n \; .
\end{equation}

Then, the method-of-moments estimates ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mome}) for the shape parameters $\alpha$ and $\beta$ are given by

\begin{equation} \label{eq:beta-mome-Beta-MoM}
\begin{split}
\hat{\alpha} &= \bar{y} \left( \frac{\bar{y} (1-\bar{y})}{\bar{v}} - 1  \right) \\
\hat{\beta} &= (1-\bar{y}) \left( \frac{\bar{y} (1-\bar{y})}{\bar{v}} - 1  \right)
\end{split}
\end{equation}

where $\bar{y}$ is the sample mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean-samp}) and $\bar{v}$ is the unbiased sample variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var-samp}):

\begin{equation} \label{eq:beta-mome-y-mean-var}
\begin{split}
\bar{y} &= \frac{1}{n} \sum_{i=1}^n y_i \\
\bar{v} &= \frac{1}{n-1} \sum_{i=1}^n (y_i - \bar{y})^2 \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Proof:} Mean ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:beta-mean}) and variance ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:beta-var}) of the beta distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:beta}) in terms of the parameters $\alpha$ and $\beta$ are given by

\begin{equation} \label{eq:beta-mome-Beta-E-Var}
\begin{split}
\mathrm{E}(X) &= \frac{\alpha}{\alpha+\beta} \\
\mathrm{Var}(X) &= \frac{\alpha\beta}{(\alpha+\beta)^2 (\alpha+\beta+1)} \; .
\end{split}
\end{equation}

Thus, matching the moments ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mome}) requires us to solve the following equation system for $\alpha$ and $\beta$:

\begin{equation} \label{eq:beta-mome-Beta-mean-var}
\begin{split}
\bar{y} &= \frac{\alpha}{\alpha+\beta} \\
\bar{v} &= \frac{\alpha\beta}{(\alpha+\beta)^2 (\alpha+\beta+1)} \; .
\end{split}
\end{equation}

From the first equation, we can deduce:

\begin{equation} \label{eq:beta-mome-beta-as-alpha}
\begin{split}
\bar{y}(\alpha+\beta) &= \alpha \\
\alpha \bar{y} + \beta \bar{y} &= \alpha \\
\beta \bar{y} &= \alpha - \alpha \bar{y} \\
\beta &= \frac{\alpha}{\bar{y}} - \alpha \\
\beta &= \alpha \left( \frac{1}{\bar{y}} - 1 \right) \; .
\end{split}
\end{equation}

If we define $q = 1/\bar{y} - 1$ and plug \eqref{eq:beta-mome-beta-as-alpha} into the second equation, we have:

\begin{equation} \label{eq:beta-mome-alpha-as-q}
\begin{split}
\bar{v} &= \frac{\alpha \cdot \alpha q}{(\alpha + \alpha q)^2 (\alpha + \alpha q + 1)} \\
&= \frac{\alpha^2 q}{(\alpha (1+q))^2 (\alpha (1+q) + 1)} \\
&= \frac{q}{(1+q)^2 (\alpha (1+q) + 1)} \\
&= \frac{q}{\alpha (1+q)^3 + (1+q)^2} \\
q &= \bar{v} \left[ \alpha (1+q)^3 + (1+q)^2 \right] \; .
\end{split}
\end{equation}

Noting that $1+q = 1/\bar{y}$ and $q = (1-\bar{y})/\bar{y}$, one obtains for $\alpha$:

\begin{equation} \label{eq:beta-mome-Beta-MoM-alpha}
\begin{split}
\frac{1-\bar{y}}{\bar{y}} &= \bar{v} \left[ \frac{\alpha}{\bar{y}^3} + \frac{1}{\bar{y}^2} \right] \\
\frac{1-\bar{y}}{\bar{y} \, \bar{v}} &= \frac{\alpha}{\bar{y}^3} + \frac{1}{\bar{y}^2} \\
\frac{\bar{y}^3(1-\bar{y})}{\bar{y} \, \bar{v}} &= \alpha + \bar{y} \\
\alpha &= \frac{\bar{y}^2(1-\bar{y})}{\bar{v}} - \bar{y} \\
&= \bar{y} \left( \frac{\bar{y} (1-\bar{y})}{\bar{v}} - 1 \right) \; .
\end{split}
\end{equation}

Plugging this into equation \eqref{eq:beta-mome-beta-as-alpha}, one obtains for $\beta$:

\begin{equation} \label{eq:beta-mome-Beta-MoM-beta}
\begin{split}
\beta &= \bar{y} \left( \frac{\bar{y} (1-\bar{y})}{\bar{v}} - 1 \right) \cdot \left( \frac{1-\bar{y}}{\bar{y}} \right) \\
&= (1-\bar{y}) \left( \frac{\bar{y} (1-\bar{y})}{\bar{v}} - 1 \right) \; .
\end{split}
\end{equation}

Together, \eqref{eq:beta-mome-Beta-MoM-alpha} and \eqref{eq:beta-mome-Beta-MoM-beta} constitute the method-of-moment estimates of $\alpha$ and $\beta$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Beta distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-01-20; URL: \url{https://en.wikipedia.org/wiki/Beta_distribution#Method_of_moments}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P28 | shortcut: beta-mome | author: JoramSoch | date: 2020-01-22, 02:53.
\vspace{1em}



\subsection{Dirichlet-distributed data}

\subsubsection[\textit{Definition}]{Definition} \label{sec:dir-data}
\setcounter{equation}{0}

\textbf{Definition:} Dirichlet-distributed data are defined as a set of vectors of proportions $y = \left\lbrace y_1, \ldots, y_n \right\rbrace$ where

\begin{equation} \label{eq:dir-data-dir-def}
\begin{split}
y_i &= [y_{i1}, \ldots, y_{ik}], \\
y_{ij} &\in [0,1] \quad \text{and} \\
\sum_{j=1}^k y_{ij} &= 1
\end{split}
\end{equation}

for all $i = 1,\ldots,n$ (and $j = 1,\ldots,k$) and each $y_i$ is independent and identically distributed according to a Dirichlet distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:dir}) with concentration parameters $\alpha = [\alpha_1, \ldots, \alpha_k]$:

\begin{equation} \label{eq:dir-data-dir-data}
y_i \sim \mathrm{Dir}(\alpha), \quad i = 1, \ldots, n \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D104 | shortcut: dir-data | author: JoramSoch | date: 2020-10-22, 05:06.
\vspace{1em}



\subsubsection[\textbf{Maximum likelihood estimation}]{Maximum likelihood estimation} \label{sec:dir-mle}
\setcounter{equation}{0}

\textbf{Theorem:} Let there be a Dirichlet-distributed data ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:dir-data}) set $y = \left\lbrace y_1, \ldots, y_n \right\rbrace$:

\begin{equation} \label{eq:dir-mle-Dir}
y_i \sim \mathrm{Dir}(\alpha), \quad i = 1, \ldots, n \; .
\end{equation}

Then, the maximum likelihood estimate ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mle}) for the concentration parameters $\alpha$ can be obtained by iteratively computing

\begin{equation} \label{eq:dir-mle-Dir-MLE}
\alpha_j^{\text{(new)}} = \psi^{-1}\left[ \psi\left( \sum_{j=1}^k \alpha_j^{\text{(old)}} \right) + \log \bar{y}_j \right]
\end{equation}

where $\psi(x)$ is the digamma function and $\log \bar{y}_j$ is given by:

\begin{equation} \label{eq:dir-mle-log-pi}
\log \bar{y}_j = \frac{1}{n} \sum_{i=1}^n \log y_{ij} \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) for each observation is given by the probability density function of the Dirichlet distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:dir-pdf})

\begin{equation} \label{eq:dir-mle-Dir-yi}
p(y_i|\alpha) = \frac{\Gamma\left( \sum_{j=1}^k \alpha_j \right)}{\prod_{j=1}^k \Gamma(\alpha_j)} \, \prod_{j=1}^k {y_{ij}}^{\alpha_j-1}
\end{equation}

and because observations are independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}), the likelihood function for all observations is the product of the individual ones:

\begin{equation} \label{eq:dir-mle-Dir-LF}
p(y|\alpha) = \prod_{i=1}^n p(y_i|\alpha) = \prod_{i=1}^n \left[ \frac{\Gamma\left( \sum_{j=1}^k \alpha_j \right)}{\prod_{j=1}^k \Gamma(\alpha_j)} \, \prod_{j=1}^k {y_{ij}}^{\alpha_j-1} \right] \; .
\end{equation}

Thus, the log-likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:llf}) is

\begin{equation} \label{eq:dir-mle-Dir-LL}
\mathrm{LL}(\alpha) = \log p(y|\alpha) = \log \prod_{i=1}^n \left[ \frac{\Gamma\left( \sum_{j=1}^k \alpha_j \right)}{\prod_{j=1}^k \Gamma(\alpha_j)} \, \prod_{j=1}^k {y_{ij}}^{\alpha_j-1} \right]
\end{equation}

which can be developed into

\begin{equation} \label{eq:dir-mle-Dir-LL-der}
\begin{split}
\mathrm{LL}(\alpha) &= \sum_{i=1}^n \log \Gamma\left( \sum_{j=1}^k \alpha_j \right) - \sum_{i=1}^n \sum_{j=1}^k \log \Gamma(\alpha_j) + \sum_{i=1}^n \sum_{j=1}^k (\alpha_j-1) \log y_{ij} \\
&= n \log \Gamma\left( \sum_{j=1}^k \alpha_j \right) - n \sum_{j=1}^k \log \Gamma(\alpha_j) + n \sum_{j=1}^k (\alpha_j-1) \, \frac{1}{n} \sum_{i=1}^n \log y_{ij} \\
&= n \log \Gamma\left( \sum_{j=1}^k \alpha_j \right) - n \sum_{j=1}^k \log \Gamma(\alpha_j) + n \sum_{j=1}^k (\alpha_j-1) \, \log \bar{y}_j
\end{split}
\end{equation}

where we have specified

\begin{equation} \label{eq:dir-mle-log-pi-reit}
\log \bar{y}_j = \frac{1}{n} \sum_{i=1}^n \log y_{ij} \; .
\end{equation}

The derivative of the log-likelihood with respect to a particular parameter $\alpha_j$ is

\begin{equation} \label{eq:dir-mle-Dir-dLLdaj}
\begin{split}
\frac{\mathrm{d}\mathrm{LL}(\alpha)}{\mathrm{d}\alpha_j} &= \frac{\mathrm{d}}{\mathrm{d}\alpha_j} \left[ n \log \Gamma\left( \sum_{j=1}^k \alpha_j \right) - n \sum_{j=1}^k \log \Gamma(\alpha_j) + n \sum_{j=1}^k (\alpha_j-1) \, \log \bar{y}_j \right] \\
&= \frac{\mathrm{d}}{\mathrm{d}\alpha_j} \left[ n \log \Gamma\left( \sum_{j=1}^k \alpha_j \right) \right] - \frac{\mathrm{d}}{\mathrm{d}\alpha_j} \left[ n \log \Gamma(\alpha_j) \right] + \frac{\mathrm{d}}{\mathrm{d}\alpha_j} \left[ n (\alpha_j-1) \, \log \bar{y}_j \right] \\
&= n \psi\left( \sum_{j=1}^k \alpha_j \right) - n \psi(\alpha_j) + n \log \bar{y}_j
\end{split}
\end{equation}

where we have used the digamma function

\begin{equation} \label{eq:dir-mle-digamma-fct}
\psi(x) = \frac{\mathrm{d}\log \Gamma(x)}{\mathrm{d}x} \; .
\end{equation}

Setting this derivative to zero, we obtain:

\begin{equation} \label{eq:dir-mle-Dir-dLLdaj-0}
\begin{split}
\frac{\mathrm{d}\mathrm{LL}(\alpha)}{\mathrm{d}\alpha_j} &= 0 \\
0 &= n \psi\left( \sum_{j=1}^k \alpha_j \right) - n \psi(\alpha_j) + n \log \bar{y}_j \\
0 &= \psi\left( \sum_{j=1}^k \alpha_j \right) - \psi(\alpha_j) + \log \bar{y}_j \\
\psi(\alpha_j) &= \psi\left( \sum_{j=1}^k \alpha_j \right) + \log \bar{y}_j \\
\alpha_j &= \psi^{-1} \left[ \psi\left( \sum_{j=1}^k \alpha_j \right) + \log \bar{y}_j \right] \; .
\end{split}
\end{equation}

In the following, we will use a fixed-point iteration to maximize $\mathrm{LL}(\alpha)$. Given an initial guess for $\alpha$, we construct a lower bound on the likelihood function \eqref{eq:dir-mle-Dir-LL-der} which is tight at $\alpha$. The maximum of this bound is computed and it becomes the new guess. Because the Dirichlet distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:dir}) belongs to the exponential family ($\rightarrow$ Definition "dist-expfam"), the log-likelihood function is convex in $\alpha$ Ã¡nd the maximum is the only stationary point, such that the procedure is guaranteed to converge to the maximum.

In our case, we use a bound on the gamma function

\begin{equation} \label{eq:dir-mle-gamma-fct-bound}
\begin{split}
\Gamma(x) &\geq \Gamma(\hat{x}) \cdot \mathrm{exp}\left[(x-\hat{x}) \, \psi(\hat{x}) \right] \\
\log \Gamma(x) &\geq \log \Gamma(\hat{x}) + (x-\hat{x}) \, \psi(\hat{x})
\end{split}
\end{equation}

and apply it to $\Gamma\left( \sum_{j=1}^k \alpha_j \right)$ in \eqref{eq:dir-mle-Dir-LL-der} to yield

\begin{equation} \label{eq:dir-mle-Dir-LL-bound}
\begin{split}
\frac{1}{n} \mathrm{LL}(\alpha) &= \log \Gamma\left( \sum_{j=1}^k \alpha_j \right) - \sum_{j=1}^k \log \Gamma(\alpha_j) + \sum_{j=1}^k (\alpha_j-1) \, \log \bar{y}_j \\
\frac{1}{n} \mathrm{LL}(\alpha) &\geq \log \Gamma\left(\sum_{j=1}^k \hat{\alpha}_j\right) + \left(\sum_{j=1}^k \alpha_j - \sum_{j=1}^k \hat{\alpha}_j\right) \psi\left(\sum_{j=1}^k \hat{\alpha}_j\right) - \sum_{j=1}^k \log \Gamma(\alpha_j) + \sum_{j=1}^k (\alpha_j-1) \, \log \bar{y}_j \\
\frac{1}{n} \mathrm{LL}(\alpha) &\geq \left(\sum_{j=1}^k \alpha_j\right) \psi\left(\sum_{j=1}^k \hat{\alpha}_j\right) - \sum_{j=1}^k \log \Gamma(\alpha_j) + \sum_{j=1}^k (\alpha_j-1) \, \log \bar{y}_j + \mathrm{const.}
\end{split}
\end{equation}

which leads to the following fixed-point iteration using \eqref{eq:dir-mle-Dir-dLLdaj-0}:

\begin{equation} \label{eq:dir-mle-Dir-MLE-qed}
\alpha_j^{\text{(new)}} = \psi^{-1}\left[ \psi\left( \sum_{j=1}^k \alpha_j^{\text{(old)}} \right) + \log \bar{y}_j \right] \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Minka TP (2012): "Estimating a Dirichlet distribution"; in: \textit{Papers by Tom Minka}, retrieved on 2020-10-22; URL: \url{https://tminka.github.io/papers/dirichlet/minka-dirichlet.pdf}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P182 | shortcut: dir-mle | author: JoramSoch | date: 2020-10-22, 09:31.
\vspace{1em}



\pagebreak
\section{Categorical data}

\subsection{Binomial observations}

\subsubsection[\textit{Definition}]{Definition} \label{sec:bin-data}
\setcounter{equation}{0}

\textbf{Definition:} An ordered pair $(n,y)$ with $n \in \mathbb{N}$ and $y \in \mathbb{N}_0$, where $y$ is the number of successes in $n$ trials, consititutes a set of binomial observations.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D78 | shortcut: bin-data | author: JoramSoch | date: 2020-07-07, 07:04.
\vspace{1em}



\subsubsection[\textbf{Conjugate prior distribution}]{Conjugate prior distribution} \label{sec:bin-prior}
\setcounter{equation}{0}

\textbf{Theorem:} Let $y$ be the number of successes resulting from $n$ independent trials with unknown success probability $p$, such that $y$ follows a binomial distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:bin}):

\begin{equation} \label{eq:bin-prior-Bin}
y \sim \mathrm{Bin}(n,p) \; .
\end{equation}

Then, the conjugate prior ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior-conj}) for the model parameter $p$ is a beta distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:beta}):

\begin{equation} \label{eq:bin-prior-Beta}
\mathrm{p}(p) = \mathrm{Bet}(p; \alpha_0, \beta_0) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} With the probability mass function of the binomial distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:bin-pmf}), the likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) implied by \eqref{eq:bin-prior-Bin} is given by

\begin{equation} \label{eq:bin-prior-Bin-LF}
\mathrm{p}(y|p) = {n \choose y} \, p^y \, (1-p)^{n-y} \; .
\end{equation}

In other words, the likelihood function is proportional to a power of $p$ times a power of $(1-p)$:

\begin{equation} \label{eq:bin-prior-Bin-LF-prop}
\mathrm{p}(y|p) \propto p^y \, (1-p)^{n-y} \; .
\end{equation}

The same is true for a beta distribution over $p$

\begin{equation} \label{eq:bin-prior-Bin-prior-s1}
\mathrm{p}(p) = \mathrm{Bet}(p; \alpha_0, \beta_0)
\end{equation}

the probability density function of which ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:beta-pdf})

\begin{equation} \label{eq:bin-prior-Bin-prior-s2}
\mathrm{p}(p) = \frac{1}{B(\alpha_0,\beta_0)} \, p^{\alpha_0-1} \, (1-p)^{\beta_0-1}
\end{equation}

exhibits the same proportionality

\begin{equation} \label{eq:bin-prior-Bin-prior-s3}
\mathrm{p}(p) \propto p^{\alpha_0-1} \, (1-p)^{\beta_0-1}
\end{equation}

and is therefore conjugate relative to the likelihood.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Binomial distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-01-23; URL: \url{https://en.wikipedia.org/wiki/Binomial_distribution#Estimation_of_parameters}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P29 | shortcut: bin-prior | author: JoramSoch | date: 2020-01-23, 23:38.
\vspace{1em}



\subsubsection[\textbf{Posterior distribution}]{Posterior distribution} \label{sec:bin-post}
\setcounter{equation}{0}

\textbf{Theorem:} Let $y$ be the number of successes resulting from $n$ independent trials with unknown success probability $p$, such that $y$ follows a binomial distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:bin}):

\begin{equation} \label{eq:bin-post-Bin}
y \sim \mathrm{Bin}(n,p) \; .
\end{equation}

Moreover, assume a beta prior distribution ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:bin-prior}) over the model parameter $p$:

\begin{equation} \label{eq:bin-post-Bin-prior}
\mathrm{p}(p) = \mathrm{Bet}(p; \alpha_0, \beta_0) \; .
\end{equation}

Then, the posterior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) is also a beta distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:beta})

\begin{equation} \label{eq:bin-post-Bin-post}
\mathrm{p}(p|y) = \mathrm{Bet}(p; \alpha_n, \beta_n) \; .
\end{equation}

and the posterior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) are given by

\begin{equation} \label{eq:bin-post-Bin-post-par}
\begin{split}
\alpha_n &= \alpha_0 + y \\
\beta_n &= \beta_0 + (n-y) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Proof:} With the probability mass function of the binomial distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:bin-pmf}), the likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) implied by \eqref{eq:bin-post-Bin} is given by

\begin{equation} \label{eq:bin-post-Bin-LF}
\mathrm{p}(y|p) = {n \choose y} \, p^y \, (1-p)^{n-y} \; .
\end{equation}

Combining the likelihood function \eqref{eq:bin-post-Bin-LF} with the prior distribution \eqref{eq:bin-post-Bin-prior}, the joint likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:jl}) of the model is given by

\begin{equation} \label{eq:bin-post-Bin-JL}
\begin{split}
\mathrm{p}(y,p) &= \mathrm{p}(y|p) \, \mathrm{p}(p) \\
&= {n \choose y} \, p^y \, (1-p)^{n-y} \cdot frac{1}{B(\alpha_0,\beta_0)} \, p^{\alpha_0-1} \, (1-p)^{\beta_0-1} \\
&= \frac{1}{B(\alpha_0,\beta_0)} {n \choose y} \, p^{\alpha_0+y-1} \, (1-p)^{\beta_0+(n-y)-1} \; .
\end{split}
\end{equation}

Note that the posterior distribution is proportional to the joint likelihood ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:post-jl}):

\begin{equation} \label{eq:bin-post-Bin-post-s1}
\mathrm{p}(p|y) \propto \mathrm{p}(y,p) \; .
\end{equation}

Setting $\alpha_n = \alpha_0 + y$ and $\beta_n = \beta_0 + (n-y)$, the posterior distribution is therefore proportional to

\begin{equation} \label{eq:bin-post-Bin-post-s2}
\mathrm{p}(p|y) \propto p^{\alpha_n-1} \, (1-p)^{\beta_n-1}
\end{equation}

which, when normalized to one, results in the probability density function of the beta distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:beta-pdf}):

\begin{equation} \label{eq:bin-post-Bin-post-qed}
\mathrm{p}(p|y) = \frac{1}{B(\alpha_n,\beta_n)} \, p^{\alpha_n-1} \, (1-p)^{\beta_n-1} = \mathrm{Bet}(p; \alpha_n, \beta_n) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Binomial distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-01-23; URL: \url{https://en.wikipedia.org/wiki/Binomial_distribution#Estimation_of_parameters}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P30 | shortcut: bin-post | author: JoramSoch | date: 2020-01-24, 00:20.
\vspace{1em}



\subsubsection[\textbf{Log model evidence}]{Log model evidence} \label{sec:bin-lme}
\setcounter{equation}{0}

\textbf{Theorem:} Let $y$ be the number of successes resulting from $n$ independent trials with unknown success probability $p$, such that $y$ follows a binomial distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:bin}):

\begin{equation} \label{eq:bin-lme-Bin}
y \sim \mathrm{Bin}(n,p) \; .
\end{equation}

Moreover, assume a beta prior distribution ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:bin-prior}) over the model parameter $p$:

\begin{equation} \label{eq:bin-lme-Bin-prior}
\mathrm{p}(p) = \mathrm{Bet}(p; \alpha_0, \beta_0) \; .
\end{equation}

Then, the log model evidence ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme}) for this model is

\begin{equation} \label{eq:bin-lme-Bin-LME}
\begin{split}
\log \mathrm{p}(y|m) = \log \Gamma(n+1) &- \log \Gamma(k+1) - \log \Gamma(n-k+1) \\
&+ \log B(\alpha_n,\beta_n) - \log B(\alpha_0,\beta_0) \; .
\end{split}
\end{equation}

where the posterior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) are given by

\begin{equation} \label{eq:bin-lme-Bin-post-par}
\begin{split}
\alpha_n &= \alpha_0 + y \\
\beta_n &= \beta_0 + (n-y) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Proof:} With the probability mass function of the binomial distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:bin-pmf}), the likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) implied by \eqref{eq:bin-lme-Bin} is given by

\begin{equation} \label{eq:bin-lme-Bin-LF}
\mathrm{p}(y|p) = {n \choose y} \, p^y \, (1-p)^{n-y} \; .
\end{equation}

Combining the likelihood function \eqref{eq:bin-lme-Bin-LF} with the prior distribution \eqref{eq:bin-lme-Bin-prior}, the joint likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:jl}) of the model is given by

\begin{equation} \label{eq:bin-lme-Bin-JL-s1}
\begin{split}
\mathrm{p}(y,p) &= \mathrm{p}(y|p) \, \mathrm{p}(p) \\
&= {n \choose y} \, p^y \, (1-p)^{n-y} \cdot frac{1}{B(\alpha_0,\beta_0)} \, p^{\alpha_0-1} \, (1-p)^{\beta_0-1} \\
&= {n \choose y} \, \frac{1}{B(\alpha_0,\beta_0)} \, p^{\alpha_0+y-1} \, (1-p)^{\beta_0+(n-y)-1} \; .
\end{split}
\end{equation}

Note that the model evidence is the marginal density of the joint likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ml}):

\begin{equation} \label{eq:bin-lme-Bin-ME-s1}
\mathrm{p}(y) = \int \mathrm{p}(y,p) \, \mathrm{d}p \; .
\end{equation}

Setting $\alpha_n = \alpha_0 + y$ and $\beta_n = \beta_0 + (n-y)$, the joint likelihood can also be written as

\begin{equation} \label{eq:bin-lme-Bin-JL-s2}
\mathrm{p}(y,p) = {n \choose y} \, \frac{1}{B(\alpha_0,\beta_0)} \, \frac{B(\alpha_n,\beta_n)}{1} \, \frac{1}{B(\alpha_n,\beta_n)} \, p^{\alpha_n-1} \, (1-p)^{\beta_n-1} \; .
\end{equation}

Using the probability density function of the beta distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:beta-pdf}), $p$ can now be integrated out easily

\begin{equation} \label{eq:bin-lme-Bin-ME-s2}
\begin{split}
\mathrm{p}(y) &= \int {n \choose y} \, \frac{1}{B(\alpha_0,\beta_0)} \, \frac{B(\alpha_n,\beta_n)}{1} \, \frac{1}{B(\alpha_n,\beta_n)} \, p^{\alpha_n-1} \, (1-p)^{\beta_n-1} \, \mathrm{d}p \\
&= {n \choose y} \, \frac{B(\alpha_n,\beta_n)}{B(\alpha_0,\beta_0)} \int \mathrm{Bet}(p; \alpha_n, \beta_n) \, \mathrm{d}p \\
&= {n \choose y} \, \frac{B(\alpha_n,\beta_n)}{B(\alpha_0,\beta_0)} \; ,
\end{split}
\end{equation}

such that the log model evidence ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme}) (LME) is shown to be

\begin{equation} \label{eq:bin-lme-Bin-LME-s1}
\log \mathrm{p}(y|m) = \log {n \choose y} + \log B(\alpha_n,\beta_n) - \log B(\alpha_0,\beta_0) \; .
\end{equation}

With the definition of the binomial coefficient

\begin{equation} \label{eq:bin-lme-bin-coeff}
{n \choose k} = \frac{n!}{k! \, (n-k)!}
\end{equation}

and the definition of the gamma function

\begin{equation} \label{eq:bin-lme-gam-fct}
\Gamma(n) = (n-1)! \; ,
\end{equation}

the LME finally becomes

\begin{equation} \label{eq:bin-lme-Bin-LME-s2}
\begin{split}
\log \mathrm{p}(y|m) = \log \Gamma(n+1) &- \log \Gamma(k+1) - \log \Gamma(n-k+1) \\
&+ \log B(\alpha_n,\beta_n) - \log B(\alpha_0,\beta_0) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Beta-binomial distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-01-24; URL: \url{https://en.wikipedia.org/wiki/Beta-binomial_distribution#Motivation_and_derivation}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P31 | shortcut: bin-lme | author: JoramSoch | date: 2020-01-24, 00:44.
\vspace{1em}



\subsection{Multinomial observations}

\subsubsection[\textit{Definition}]{Definition} \label{sec:mult-data}
\setcounter{equation}{0}

\textbf{Definition:} An ordered pair $(n,y)$ with $n \in \mathbb{N}$ and $y = \left[ y_1, \ldots, y_k \right] \in \mathbb{N}_0^{1 \times k}$, where $y_i$ is the number of observations for the $i$-th out of $k$ categories obtained in $n$ trials, $i = 1, \ldots, k$, consititutes a set of multinomial observations.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D79 | shortcut: mult-data | author: JoramSoch | date: 2020-07-07, 07:12.
\vspace{1em}



\subsubsection[\textbf{Conjugate prior distribution}]{Conjugate prior distribution} \label{sec:mult-prior}
\setcounter{equation}{0}

\textbf{Theorem:} Let $y = [y_1, \ldots, y_k]$ be the number of observations in $k$ categories resulting from $n$ independent trials with unknown category probabilities $p = [p_1, \ldots, p_k]$, such that $y$ follows a multinomial distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mult}):

\begin{equation} \label{eq:mult-prior-Mult}
y \sim \mathrm{Mult}(n,p) \; .
\end{equation}

Then, the conjugate prior ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior-conj}) for the model parameter $p$ is a Dirichlet distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:dir}):

\begin{equation} \label{eq:mult-prior-Dir}
\mathrm{p}(p) = \mathrm{Dir}(p; \alpha_0) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} With the probability mass function of the multinomial distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mult-pmf}), the likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) implied by \eqref{eq:mult-prior-Mult} is given by

\begin{equation} \label{eq:mult-prior-Mult-LF}
\mathrm{p}(y|p) = {n \choose {y_1, \ldots, y_k}} \prod_{j=1}^{k} {p_j}^{y_j} \; .
\end{equation}

In other words, the likelihood function is proportional to a product of powers of the entries of the vector $p$:

\begin{equation} \label{eq:mult-prior-Mult-LF-prop}
\mathrm{p}(y|p) \propto \prod_{j=1}^{k} {p_j}^{y_j} \; .
\end{equation}

The same is true for a Dirichlet distribution over $p$

\begin{equation} \label{eq:mult-prior-Mult-prior-s1}
\mathrm{p}(p) = \mathrm{Dir}(p; \alpha_0)
\end{equation}

the probability density function of which ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:dir-pdf})

\begin{equation} \label{eq:mult-prior-Mult-prior-s2}
\mathrm{p}(p) = \frac{\Gamma \left( \sum_{j=1}^{k} \alpha_{0j} \right)}{\prod_{j=1}^k \Gamma(\alpha_{0j})} \prod_{j=1}^{k} {p_j}^{\alpha_{0j}-1}
\end{equation}

exhibits the same proportionality

\begin{equation} \label{eq:mult-prior-Mult-prior-s3}
\mathrm{p}(p) \propto \prod_{j=1}^{k} {p_j}^{\alpha_{0j}-1}
\end{equation}

and is therefore conjugate relative to the likelihood.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Dirichlet distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-03-11; URL: \url{https://en.wikipedia.org/wiki/Dirichlet_distribution#Conjugate_to_categorical/multinomial}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P79 | shortcut: mult-prior | author: JoramSoch | date: 2020-03-11, 14:15.
\vspace{1em}



\subsubsection[\textbf{Posterior distribution}]{Posterior distribution} \label{sec:mult-post}
\setcounter{equation}{0}

\textbf{Theorem:} Let $y = [y_1, \ldots, y_k]$ be the number of observations in $k$ categories resulting from $n$ independent trials with unknown category probabilities $p = [p_1, \ldots, p_k]$, such that $y$ follows a multinomial distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mult}):

\begin{equation} \label{eq:mult-post-Mult}
y \sim \mathrm{Mult}(n,p) \; .
\end{equation}

Moreover, assume a Dirichlet prior distribution ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mult-prior}) over the model parameter $p$:

\begin{equation} \label{eq:mult-post-Mult-prior}
\mathrm{p}(p) = \mathrm{Dir}(p; \alpha_0) \; .
\end{equation}

Then, the posterior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) is also a Dirichlet distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:dir})

\begin{equation} \label{eq:mult-post-Mult-post}
\mathrm{p}(p|y) = \mathrm{Dir}(p; \alpha_n) \; .
\end{equation}

and the posterior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) are given by

\begin{equation} \label{eq:mult-post-Mult-post-par}
\alpha_{nj} = \alpha_{0j} + y_j, \; j = 1,\ldots,k \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} With the probability mass function of the multinomial distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mult-pmf}), the likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) implied by \eqref{eq:mult-post-Mult} is given by

\begin{equation} \label{eq:mult-post-Mult-LF}
\mathrm{p}(y|p) = {n \choose {y_1, \ldots, y_k}} \prod_{j=1}^{k} {p_j}^{y_j} \; .
\end{equation}

Combining the likelihood function \eqref{eq:mult-post-Mult-LF} with the prior distribution \eqref{eq:mult-post-Mult-prior}, the joint likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:jl}) of the model is given by

\begin{equation} \label{eq:mult-post-Mult-JL}
\begin{split}
\mathrm{p}(y,p) &= \mathrm{p}(y|p) \, \mathrm{p}(p) \\
&= {n \choose {y_1, \ldots, y_k}} \prod_{j=1}^{k} {p_j}^{y_j} \cdot \frac{\Gamma \left( \sum_{j=1}^{k} \alpha_{0j} \right)}{\prod_{j=1}^k \Gamma(\alpha_{0j})} \prod_{j=1}^{k} {p_j}^{\alpha_{0j}-1} \\
&= \frac{\Gamma \left( \sum_{j=1}^{k} \alpha_{0j} \right)}{\prod_{j=1}^k \Gamma(\alpha_{0j})} {n \choose {y_1, \ldots, y_k}} \prod_{j=1}^{k} {p_j}^{\alpha_{0j}+y_j-1} \; .
\end{split}
\end{equation}

Note that the posterior distribution is proportional to the joint likelihood ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:post-jl}):

\begin{equation} \label{eq:mult-post-Mult-post-s1}
\mathrm{p}(p|y) \propto \mathrm{p}(y,p) \; .
\end{equation}

Setting $\alpha_{nj} = \alpha_{0j} + y_j$, the posterior distribution is therefore proportional to

\begin{equation} \label{eq:mult-post-Mult-post-s2}
\mathrm{p}(p|y) \propto \prod_{j=1}^{k} {p_j}^{\alpha_{nj}-1}
\end{equation}

which, when normalized to one, results in the probability density function of the Dirichlet distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:dir-pdf}):

\begin{equation} \label{eq:mult-post-Mult-post-qed}
\mathrm{p}(p|y) = \frac{\Gamma \left( \sum_{j=1}^{k} \alpha_{nj} \right)}{\prod_{j=1}^k \Gamma(\alpha_{nj})} \prod_{j=1}^{k} {p_j}^{\alpha_{nj}-1} = \mathrm{Dir}(p; \alpha_n) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Dirichlet distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-03-11; URL: \url{https://en.wikipedia.org/wiki/Dirichlet_distribution#Conjugate_to_categorical/multinomial}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P80 | shortcut: mult-post | author: JoramSoch | date: 2020-03-11, 14:40.
\vspace{1em}



\subsubsection[\textbf{Log model evidence}]{Log model evidence} \label{sec:mult-lme}
\setcounter{equation}{0}

\textbf{Theorem:} Let $y = [y_1, \ldots, y_k]$ be the number of observations in $k$ categories resulting from $n$ independent trials with unknown category probabilities $p = [p_1, \ldots, p_k]$, such that $y$ follows a multinomial distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mult}):

\begin{equation} \label{eq:mult-lme-Mult}
y \sim \mathrm{Mult}(n,p) \; .
\end{equation}

Moreover, assume a Dirichlet prior distribution ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mult-prior}) over the model parameter $p$:

\begin{equation} \label{eq:mult-lme-Mult-prior}
\mathrm{p}(p) = \mathrm{Dir}(p; \alpha_0) \; .
\end{equation}

Then, the log model evidence ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme}) for this model is

\begin{equation} \label{eq:mult-lme-Mult-LME}
\begin{split}
\log \mathrm{p}(y|m) &= \log \Gamma(n+1) - \sum_{j=1}^{k} \log \Gamma(k_j+1) \\
&+ \log \Gamma \left( \sum_{j=1}^{k} \alpha_{0j} \right) - \log \Gamma \left( \sum_{j=1}^{k} \alpha_{nj} \right) \\
&+ \sum_{j=1}^k \log \Gamma(\alpha_{nj}) - \sum_{j=1}^k \log \Gamma(\alpha_{0j}) \; .
\end{split}
\end{equation}

and the posterior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) are given by

\begin{equation} \label{eq:mult-lme-Mult-post-par}
\alpha_{nj} = \alpha_{0j} + y_j, \; j = 1,\ldots,k \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} With the probability mass function of the multinomial distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mult-pmf}), the likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) implied by \eqref{eq:mult-lme-Mult} is given by

\begin{equation} \label{eq:mult-lme-Mult-LF}
\mathrm{p}(y|p) = {n \choose {y_1, \ldots, y_k}} \prod_{j=1}^{k} {p_j}^{y_j} \; .
\end{equation}

Combining the likelihood function \eqref{eq:mult-lme-Mult-LF} with the prior distribution \eqref{eq:mult-lme-Mult-prior}, the joint likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:jl}) of the model is given by

\begin{equation} \label{eq:mult-lme-Mult-JL}
\begin{split}
\mathrm{p}(y,p) &= \mathrm{p}(y|p) \, \mathrm{p}(p) \\
&= {n \choose {y_1, \ldots, y_k}} \prod_{j=1}^{k} {p_j}^{y_j} \cdot \frac{\Gamma \left( \sum_{j=1}^{k} \alpha_{0j} \right)}{\prod_{j=1}^k \Gamma(\alpha_{0j})} \prod_{j=1}^{k} {p_j}^{\alpha_{0j}-1} \\
&= {n \choose {y_1, \ldots, y_k}} \frac{\Gamma \left( \sum_{j=1}^{k} \alpha_{0j} \right)}{\prod_{j=1}^k \Gamma(\alpha_{0j})} \prod_{j=1}^{k} {p_j}^{\alpha_{0j}+y_j-1} \; .
\end{split}
\end{equation}

Note that the model evidence is the marginal density of the joint likelihood:

\begin{equation} \label{eq:mult-lme-Mult-ME-s1}
\mathrm{p}(y) = \int \mathrm{p}(y,p) \, \mathrm{d}p \; .
\end{equation}

Setting $\alpha_{nj} = \alpha_{0j} + y_j$, the joint likelihood can also be written as

\begin{equation} \label{eq:mult-lme-Mult-JL-s2}
\mathrm{p}(y,p) = {n \choose {y_1, \ldots, y_k}} \frac{\Gamma \left( \sum_{j=1}^{k} \alpha_{0j} \right)}{\prod_{j=1}^k \Gamma(\alpha_{0j})} \, \frac{\prod_{j=1}^k \Gamma(\alpha_{nj})} {\Gamma \left( \sum_{j=1}^{k} \alpha_{nj} \right)} \, \frac{\Gamma \left( \sum_{j=1}^{k} \alpha_{nj} \right)}{\prod_{j=1}^k \Gamma(\alpha_{nj})} \prod_{j=1}^{k} {p_j}^{\alpha_{nj}-1} \; .
\end{equation}

Using the probability density function of the Dirichlet distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:dir-pdf}), $p$ can now be integrated out easily

\begin{equation} \label{eq:mult-lme-Mult-ME-s2}
\begin{split}
\mathrm{p}(y) &= \int {n \choose {y_1, \ldots, y_k}} \frac{\Gamma \left( \sum_{j=1}^{k} \alpha_{0j} \right)}{\prod_{j=1}^k \Gamma(\alpha_{0j})} \, \frac{\prod_{j=1}^k \Gamma(\alpha_{nj})}{\Gamma \left( \sum_{j=1}^{k} \alpha_{nj} \right)} \, \frac{\Gamma \left( \sum_{j=1}^{k} \alpha_{nj} \right)}{\prod_{j=1}^k \Gamma(\alpha_{nj})} \prod_{j=1}^{k} {p_j}^{\alpha_{nj}-1} \, \mathrm{d}p \\
&= {n \choose {y_1, \ldots, y_k}} \frac{\Gamma \left( \sum_{j=1}^{k} \alpha_{0j} \right)}{\prod_{j=1}^k \Gamma(\alpha_{0j})} \, \frac{\prod_{j=1}^k \Gamma(\alpha_{nj})}{\Gamma \left( \sum_{j=1}^{k} \alpha_{nj} \right)} \int \mathrm{Dir}(p; \alpha_n) \, \mathrm{d}p \\
&= {n \choose {y_1, \ldots, y_k}} \frac{\Gamma \left( \sum_{j=1}^{k} \alpha_{0j} \right)}{\Gamma \left( \sum_{j=1}^{k} \alpha_{nj} \right)} \, \frac{\prod_{j=1}^k \Gamma(\alpha_{nj})}{\prod_{j=1}^k \Gamma(\alpha_{0j})} \; ,
\end{split}
\end{equation}

such that the log model evidence ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme}) (LME) is shown to be

\begin{equation} \label{eq:mult-lme-Mult-LME-s1}
\begin{split}
\log \mathrm{p}(y|m) = \log {n \choose {y_1, \ldots, y_k}} &+ \log \Gamma \left( \sum_{j=1}^{k} \alpha_{0j} \right) - \log \Gamma \left( \sum_{j=1}^{k} \alpha_{nj} \right) \\
&+ \sum_{j=1}^k \log \Gamma(\alpha_{nj}) - \sum_{j=1}^k \log \Gamma(\alpha_{0j}) \; .
\end{split}
\end{equation}

With the definition of the multinomial coefficient

\begin{equation} \label{eq:mult-lme-mult-coeff}
{n \choose {k_1, \ldots, k_m}} = \frac{n!}{k_1! \cdot \ldots \cdot k_m!}
\end{equation}

and the definition of the gamma function

\begin{equation} \label{eq:mult-lme-gam-fct}
\Gamma(n) = (n-1)! \; ,
\end{equation}

the LME finally becomes

\begin{equation} \label{eq:mult-lme-Mult-LME-s2}
\begin{split}
\log \mathrm{p}(y|m) &= \log \Gamma(n+1) - \sum_{j=1}^{k} \log \Gamma(k_j+1) \\
&+ \log \Gamma \left( \sum_{j=1}^{k} \alpha_{0j} \right) - \log \Gamma \left( \sum_{j=1}^{k} \alpha_{nj} \right) \\
&+ \sum_{j=1}^k \log \Gamma(\alpha_{nj}) - \sum_{j=1}^k \log \Gamma(\alpha_{0j}) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P81 | shortcut: mult-lme | author: JoramSoch | date: 2020-03-11, 15:17.
\vspace{1em}



\subsection{Logistic regression}

\subsubsection[\textit{Definition}]{Definition} \label{sec:logreg}
\setcounter{equation}{0}

\textbf{Definition:} A logistic regression model is given by a set of binary observations $y_i \in \left\lbrace 0, 1 \right\rbrace, i = 1,\ldots,n$, a set of predictors $x_j \in \mathbb{R}^n, j = 1,\ldots,p$, a base $b$ and the assumption that the log-odds are a linear combination of the predictors:

\begin{equation} \label{eq:logreg-logreg}
l_i = x_i \beta + \varepsilon_i, \; i = 1,\ldots,n
\end{equation}

where $l_i$ are the log-odds that $y_i = 1$

\begin{equation} \label{eq:logreg-logodds}
l_i = \log_b \frac{\mathrm{Pr}(y_i = 1)}{\mathrm{Pr}(y_i = 0)}
\end{equation}

and $x_i$ is the $i$-th row of the $n \times p$ matrix

\begin{equation} \label{eq:logreg-X}
X = \left[ x_1, \ldots, x_p \right] \; .
\end{equation}

Within this model,

\begin{itemize}

\item $y$ are called "categorical observations" or "dependent variable";

\item $X$ is called "design matrix" or "set of independent variables";

\item $\beta$ are called "regression coefficients" or "weights";

\item $\varepsilon_i$ is called "noise" or "error term";

\item $n$ is the number of observations;

\item $p$ is the number of predictors.

\end{itemize}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Logistic regression"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-06-28; URL: \url{https://en.wikipedia.org/wiki/Logistic_regression#Logistic_model}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D76 | shortcut: logreg | author: JoramSoch | date: 2020-06-28, 20:51.
\vspace{1em}



\subsubsection[\textbf{Probability and log-odds}]{Probability and log-odds} \label{sec:logreg-pnlo}
\setcounter{equation}{0}

\textbf{Theorem:} Assume a logistic regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:logreg})

\begin{equation} \label{eq:logreg-pnlo-logreg}
l_i = x_i \beta + \varepsilon_i, \; i = 1,\ldots,n
\end{equation}

where $x_i$ are the predictors corresponding to the $i$-th observation $y_i$ and $l_i$ are the log-odds that $y_i = 1$.

Then, the log-odds in favor of $y_i = 1$ against $y_i = 0$ can also be expressed as

\begin{equation} \label{eq:logreg-pnlo-lodds}
l_i = \log_b \frac{p(x_i|y_i=1) \, p(y_i=1)}{p(x_i|y_i=0) \, p(y_i=0)}
\end{equation}

where $p(x_i \vert y_i)$ is a likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) consistent with \eqref{eq:logreg-pnlo-logreg}, $p(y_i)$ are prior probabilities ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) for $y_i = 1$ and $y_i = 0$ and where $b$ is the base used to form the log-odds $l_i$.


\vspace{1em}
\textbf{Proof:} Using Bayes' theorem ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:bayes-th}) and the law of marginal probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}), the posterior probabilities ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) for $y_i = 1$ and $y_i = 0$ are given by

\begin{equation} \label{eq:logreg-pnlo-prob}
\begin{split}
p(y_i=1|x_i) &= \frac{p(x_i|y_i=1) \, p(y_i=1)}{p(x_i|y_i=1) \, p(y_i=1) + p(x_i|y_i=0) \, p(y_i=0)} \\
p(y_i=0|x_i) &= \frac{p(x_i|y_i=0) \, p(y_i=0)}{p(x_i|y_i=1) \, p(y_i=1) + p(x_i|y_i=0) \, p(y_i=0)} \; .
\end{split}
\end{equation}

Calculating the log-odds from the posterior probabilties, we have

\begin{equation} \label{eq:logreg-pnlo-lodds-qed}
\begin{split}
l_i &= \log_b \frac{p(y_i=1|x_i)}{p(y_i=0|x_i)} \\
&= \log_b \frac{p(x_i|y_i=1) \, p(y_i=1)}{p(x_i|y_i=0) \, p(y_i=0)} \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Bishop, Christopher M. (2006): "Linear Models for Classification"; in: \textit{Pattern Recognition for Machine Learning}, ch. 4, p. 197, eq. 4.58; URL: \url{http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P105 | shortcut: logreg-pnlo | author: JoramSoch | date: 2020-05-19, 05:08.
\vspace{1em}



\subsubsection[\textbf{Log-odds and probability}]{Log-odds and probability} \label{sec:logreg-lonp}
\setcounter{equation}{0}

\textbf{Theorem:} Assume a logistic regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:logreg})

\begin{equation} \label{eq:logreg-lonp-logreg}
l_i = x_i \beta + \varepsilon_i, \; i = 1,\ldots,n
\end{equation}

where $x_i$ are the predictors corresponding to the $i$-th observation $y_i$ and $l_i$ are the log-odds that $y_i = 1$.

Then, the probability that $y_i = 1$ is given by

\begin{equation} \label{eq:logreg-lonp-prob}
\mathrm{Pr}(y_i = 1) = \frac{1}{1 + b^{-(x_i \beta + \varepsilon_i)}}
\end{equation}

where $b$ is the base used to form the log-odds $l_i$.


\vspace{1em}
\textbf{Proof:} Let us denote $\mathrm{Pr}(y_i = 1)$ as $p_i$. Then, the log-odds are

\begin{equation} \label{eq:logreg-lonp-lodds}
l_i = \log_b \frac{p_i}{1-p_i}
\end{equation}

and using \eqref{eq:logreg-lonp-logreg}, we have

\begin{equation} \label{eq:logreg-lonp-prob-qed}
\begin{split}
\log_b \frac{p_i}{1-p_i} &= x_i \beta + \varepsilon_i \\
\frac{p_i}{1-p_i} &= b^{x_i \beta + \varepsilon_i} \\
p_i &= \left( b^{x_i \beta + \varepsilon_i} \right) (1-p_i) \\
p_i \left( 1 + b^{x_i \beta + \varepsilon_i} \right) &= b^{x_i \beta + \varepsilon_i} \\
p_i &= \frac{b^{x_i \beta + \varepsilon_i}}{1 + b^{x_i \beta + \varepsilon_i}} \\
p_i &= \frac{b^{x_i \beta + \varepsilon_i}}{b^{x_i \beta + \varepsilon_i} \left( 1 + b^{-(x_i \beta + \varepsilon_i)} \right)} \\
p_i &= \frac{1}{1 + b^{-(x_i \beta + \varepsilon_i)}}
\end{split}
\end{equation}

which proves the identity given by \eqref{eq:logreg-lonp-prob}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Logistic regression"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-03-03; URL: \url{https://en.wikipedia.org/wiki/Logistic_regression#Logistic_model}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P72 | shortcut: logreg-lonp | author: JoramSoch | date: 2020-03-03, 12:01.
\vspace{1em}





% Chapter 4 %
\chapter{Model Selection} \label{sec:Model Selection} \newpage

\pagebreak
\section{Goodness-of-fit measures}

\subsection{Residual variance}

\subsubsection[\textit{Definition}]{Definition} \label{sec:resvar}
\setcounter{equation}{0}

\textbf{Definition:} Let there be a linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr})

\begin{equation} \label{eq:resvar-mlr}
y = X\beta + \varepsilon, \; \varepsilon \sim \mathcal{N}(0, \sigma^2 V)
\end{equation}

with measured data $y$, known design matrix $X$ and covariance structure $V$ as well as unknown regression coefficients $\beta$ and noise variance $\sigma^2$.

Then, an estimate of the noise variance $\sigma^2$ is called the "residual variance" $\hat{\sigma}^2$, e.g. obtained via maximum likelihood estimation ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mle}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D20 | shortcut: resvar | author: JoramSoch | date: 2020-02-25, 11:21.
\vspace{1em}



\subsubsection[\textbf{Maximum likelihood estimator is biased}]{Maximum likelihood estimator is biased} \label{sec:resvar-bias}
\setcounter{equation}{0}

\textbf{Theorem:} Let $x = \left\lbrace x_1, \ldots, x_n \right\rbrace$ be a set of independent normally distributed ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}) observations with unknown mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) $\mu$ and variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) $\sigma^2$:

\begin{equation} \label{eq:resvar-bias-ug}
x_i \overset{\text{i.i.d.}}{\sim} \mathcal{N}(\mu, \sigma^2), \quad i = 1,\ldots,n \; .
\end{equation}

Then,

1) the maximum likelihood estimator ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mle}) of $\sigma^2$ is

\begin{equation} \label{eq:resvar-bias-resvar-mle}
\hat{\sigma}^2 = \frac{1}{n} \sum_{i=1}^{n} \left( x_i - \bar{x} \right)^2
\end{equation}

where

\begin{equation} \label{eq:resvar-bias-mean-mle}
\bar{x} = \frac{1}{n} \sum_{i=1}^{n} x_i
\end{equation}

2) and $\hat{\sigma}^2$ is a biased estimator ($\rightarrow$ Definition "est-unb") of $\sigma^2$

\begin{equation} \label{eq:resvar-bias-resvar-var}
\mathbb{E}\left[ \hat{\sigma}^2 \right] \neq \sigma^2 \; ,
\end{equation}

more precisely:

\begin{equation} \label{eq:resvar-bias-resvar-bias}
\mathbb{E}\left[ \hat{\sigma}^2 \right] = \frac{n-1}{n} \sigma^2 \; .
\end{equation}


\vspace{1em}
\textbf{Proof:}

1) This is equivalent to the maximum likelihood estimator for the univariate Gaussian with unknown variance ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:ug-mle}) and a special case of the maximum likelihood estimator for multiple linear regression ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mlr-mle}) in which $y = x$, $X = 1_n$ and $\hat{\beta} = \bar{x}$:

\begin{equation} \label{eq:resvar-bias-resvar-mle-qed}
\begin{split}
\hat{\sigma}^2 &= \frac{1}{n} (y-X\hat{\beta})^\mathrm{T} (y-X\hat{\beta}) \\
&= \frac{1}{n} (x - 1_n \bar{x})^\mathrm{T} (x - 1_n \bar{x}) \\
&= \frac{1}{n} \sum_{i=1}^{n} \left( x_i - \bar{x} \right)^2 \; .
\end{split}
\end{equation}

2) The expectation ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of the maximum likelihood estimator ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mle}) can be developed as follows:

\begin{equation} \label{eq:resvar-bias-E-resvar-mle-s1}
\begin{split}
\mathbb{E}\left[ \hat{\sigma}^2 \right] &= \mathbb{E}\left[ \frac{1}{n} \sum_{i=1}^{n} \left( x_i - \bar{x} \right)^2 \right] \\
&= \frac{1}{n} \mathbb{E}\left[ \sum_{i=1}^{n} \left( x_i - \bar{x} \right)^2 \right] \\
&= \frac{1}{n} \mathbb{E}\left[ \sum_{i=1}^{n} \left( x_i^2 - 2 x_i \bar{x} + \bar{x}^2 \right) \right] \\
&= \frac{1}{n} \mathbb{E}\left[ \sum_{i=1}^{n} x_i^2 - 2 \sum_{i=1}^{n} x_i \bar{x} + \sum_{i=1}^{n} \bar{x}^2 \right] \\
&= \frac{1}{n} \mathbb{E}\left[ \sum_{i=1}^{n} x_i^2 - 2 n \bar{x}^2 + n \bar{x}^2 \right] \\
&= \frac{1}{n} \mathbb{E}\left[ \sum_{i=1}^{n} x_i^2 - n \bar{x}^2 \right] \\
&= \frac{1}{n} \left( \sum_{i=1}^{n} \mathbb{E} \left[ x_i^2 \right] - n \mathbb{E}\left[ \bar{x}^2 \right] \right) \\
&= \frac{1}{n} \sum_{i=1}^{n} \mathbb{E} \left[ x_i^2 \right] - \mathbb{E}\left[ \bar{x}^2 \right] \\
\end{split}
\end{equation}

Due to the partition of variance into expected values ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:var-mean})

\begin{equation} \label{eq:resvar-bias-var-mean}
\mathrm{Var}(X) = \mathbb{E}(X^2) - \mathbb{E}(X)^2 \; ,
\end{equation}

we have

\begin{equation} \label{eq:resvar-bias-Var-xi-xb}
\begin{split}
\mathrm{Var}(x_i) &= \mathbb{E}(x_i^2) - \mathbb{E}(x_i)^2 \\
\mathrm{Var}(\bar{x}) &= \mathbb{E}(\bar{x}^2) - \mathbb{E}(\bar{x})^2 \; ,
\end{split}
\end{equation}

such that \eqref{eq:resvar-bias-E-resvar-mle-s1} becomes

\begin{equation} \label{eq:resvar-bias-E-resvar-mle-s2}
\mathbb{E}\left[ \hat{\sigma}^2 \right] = \frac{1}{n} \sum_{i=1}^{n} \left( \mathrm{Var}(x_i) + \mathbb{E}(x_i)^2 \right) - \left( \mathrm{Var}(\bar{x}) + \mathbb{E}(\bar{x})^2 \right) \; .
\end{equation}

From \eqref{eq:resvar-bias-ug}, it follows that

\begin{equation} \label{eq:resvar-bias-E-Var-xi}
\mathbb{E}(x_i) = \mu \quad \text{and} \quad \mathrm{Var}(x_i) = \sigma^2 \; .
\end{equation}

The expectation ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of $\bar{x}$ given by \eqref{eq:resvar-bias-mean-mle} is

\begin{equation} \label{eq:resvar-bias-E-mean-mle}
\begin{split}
\mathbb{E}\left[ \bar{x} \right] &= \mathbb{E}\left[ \frac{1}{n} \sum_{i=1}^{n} x_i \right] = \frac{1}{n} \sum_{i=1}^{n} \mathbb{E}\left[ x_i \right] \\
&\overset{\eqref{eq:resvar-bias-E-Var-xi}}{=} \frac{1}{n} \sum_{i=1}^{n} \mu = \frac{1}{n} \cdot n \cdot \mu \\
&= \mu \; .
\end{split}
\end{equation}

The variance of $\bar{x}$ given by \eqref{eq:resvar-bias-mean-mle} is

\begin{equation} \label{eq:resvar-bias-Var-mean-mle}
\begin{split}
\mathrm{Var}\left[ \bar{x} \right] &= \mathrm{Var}\left[ \frac{1}{n} \sum_{i=1}^{n} x_i \right] = \frac{1}{n^2} \sum_{i=1}^{n} \mathrm{Var}\left[ x_i \right] \\
&\overset{\eqref{eq:resvar-bias-E-Var-xi}}{=} \frac{1}{n^2} \sum_{i=1}^{n} \sigma^2 = \frac{1}{n^2} \cdot n \cdot \sigma^2 \\
&= \frac{1}{n} \sigma^2 \; .
\end{split}
\end{equation}

Plugging \eqref{eq:resvar-bias-E-Var-xi}, \eqref{eq:resvar-bias-E-mean-mle} and \eqref{eq:resvar-bias-Var-mean-mle} into \eqref{eq:resvar-bias-E-resvar-mle-s2}, we have

\begin{equation} \label{eq:resvar-bias-E-resvar-mle-s3}
\begin{split}
\mathbb{E}\left[ \hat{\sigma}^2 \right] &= \frac{1}{n} \sum_{i=1}^{n} \left( \sigma^2 + \mu^2 \right) - \left( \frac{1}{n} \sigma^2 + \mu^2 \right) \\
\mathbb{E}\left[ \hat{\sigma}^2 \right] &= \frac{1}{n} \cdot n \cdot \left( \sigma^2 + \mu^2 \right) - \left( \frac{1}{n} \sigma^2 + \mu^2 \right) \\
\mathbb{E}\left[ \hat{\sigma}^2 \right] &= \sigma^2 + \mu^2 - \frac{1}{n} \sigma^2 - \mu^2 \\
\mathbb{E}\left[ \hat{\sigma}^2 \right] &= \frac{n-1}{n} \sigma^2
\end{split}
\end{equation}

which proves the bias ($\rightarrow$ Definition "est-unb") given by \eqref{eq:resvar-bias-resvar-bias}.



\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Liang, Dawen (????): "Maximum Likelihood Estimator for Variance is Biased: Proof", retrieved on 2020-02-24; URL: \url{https://dawenl.github.io/files/mle_biased.pdf}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P61 | shortcut: resvar-bias | author: JoramSoch | date: 2020-02-24, 23:44.
\vspace{1em}



\subsubsection[\textbf{Construction of unbiased estimator}]{Construction of unbiased estimator} \label{sec:resvar-unb}
\setcounter{equation}{0}

\textbf{Theorem:} Let $x = \left\lbrace x_1, \ldots, x_n \right\rbrace$ be a set of independent normally distributed ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}) observations with unknown mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) $\mu$ and variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) $\sigma^2$:

\begin{equation} \label{eq:resvar-unb-ug}
x_i \overset{\text{i.i.d.}}{\sim} \mathcal{N}(\mu, \sigma^2), \quad i = 1,\ldots,n \; .
\end{equation}

An unbiased estimator ($\rightarrow$ Definition "est-unb") of $\sigma^2$ is given by

\begin{equation} \label{eq:resvar-unb-resvar-unb}
\hat{\sigma}^2_{\mathrm{unb}} = \frac{1}{n-1} \sum_{i=1}^{n} \left( x_i - \bar{x} \right)^2 \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} It can be shown that ($\rightarrow$ Proof \ref{sec:Model Selection}/\ref{sec:resvar-bias}) the maximum likelihood estimator ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mle}) of $\sigma^2$

\begin{equation} \label{eq:resvar-unb-resvar-mle}
\hat{\sigma}^2_{\mathrm{MLE}} = \frac{1}{n} \sum_{i=1}^{n} \left( x_i - \bar{x} \right)^2
\end{equation}

is a biased estimator ($\rightarrow$ Definition "est-unb") in the sense that

\begin{equation} \label{eq:resvar-unb-resvar-bias}
\mathbb{E}\left[ \hat{\sigma}^2_{\mathrm{MLE}} \right] = \frac{n-1}{n} \sigma^2 \; .
\end{equation}

From \eqref{eq:resvar-unb-resvar-bias}, it follows that

\begin{equation} \label{eq:resvar-unb-resvar-bias-adj}
\begin{split}
\mathbb{E}\left[ \frac{n}{n-1} \hat{\sigma}^2_{\mathrm{MLE}} \right] &= \frac{n}{n-1} \mathbb{E}\left[ \hat{\sigma}^2_{\mathrm{MLE}} \right] \\
&\overset{\eqref{eq:resvar-unb-resvar-bias}}{=} \frac{n}{n-1} \cdot \frac{n-1}{n} \sigma^2 \\
&= \sigma^2 \; ,
\end{split}
\end{equation}

such that an unbiased estimator ($\rightarrow$ Definition "est-unb") can be constructed as

\begin{equation} \label{eq:resvar-unb-resvar-unb-qed}
\begin{split}
\hat{\sigma}^2_{\mathrm{unb}} &= \frac{n}{n-1} \hat{\sigma}^2_{\mathrm{MLE}} \\
&\overset{\eqref{eq:resvar-unb-resvar-mle}}{=} \frac{n}{n-1} \cdot \frac{1}{n} \sum_{i=1}^{n} \left( x_i - \bar{x} \right)^2 \\
&= \frac{1}{n-1} \sum_{i=1}^{n} \left( x_i - \bar{x} \right)^2 \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Liang, Dawen (????): "Maximum Likelihood Estimator for Variance is Biased: Proof", retrieved on 2020-02-25; URL: \url{https://dawenl.github.io/files/mle_biased.pdf}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P62 | shortcut: resvar-unb | author: JoramSoch | date: 2020-02-25, 15:38.
\vspace{1em}



\subsection{R-squared}

\subsubsection[\textit{Definition}]{Definition} \label{sec:rsq}
\setcounter{equation}{0}

\textbf{Definition:} Let there be a linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}) with independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}) observations

\begin{equation} \label{eq:rsq-mlr}
y = X\beta + \varepsilon, \; \varepsilon_i \overset{\mathrm{i.i.d.}}{\sim} \mathcal{N}(0, \sigma^2)
\end{equation}

with measured data $y$, known design matrix $X$ as well as unknown regression coefficients $\beta$ and noise variance $\sigma^2$.

Then, the proportion of the variance of the dependent variable $y$ ("total variance ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:tss})") that can be predicted from the independent variables $X$ ("explained variance ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:ess})") is called "coefficient of determination", "R-squared" or $R^2$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Coefficient of determination"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-02-25; URL: \url{https://en.wikipedia.org/wiki/Mean_squared_error#Proof_of_variance_and_bias_relationship}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D21 | shortcut: rsq | author: JoramSoch | date: 2020-02-25, 11:41.
\vspace{1em}



\subsubsection[\textbf{Derivation of RÂ² and adjusted RÂ²}]{Derivation of RÂ² and adjusted RÂ²} \label{sec:rsq-der}
\setcounter{equation}{0}

\textbf{Theorem:} Given a linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr})

\begin{equation} \label{eq:rsq-der-rsq-mlr}
y = X\beta + \varepsilon, \; \varepsilon_i \overset{\mathrm{i.i.d.}}{\sim} \mathcal{N}(0, \sigma^2)
\end{equation}

with $n$ independent observations and $p$ independent variables,

1) the coefficient of determination ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:rsq}) is given by

\begin{equation} \label{eq:rsq-der-R2}
R^2 = 1 - \frac{\mathrm{RSS}}{\mathrm{TSS}}
\end{equation}

2) the adjusted coefficient of determination is

\begin{equation} \label{eq:rsq-der-R2-adj}
R^2_{\mathrm{adj}} = 1 - \frac{\mathrm{RSS}/(n-p)}{\mathrm{TSS}/(n-1)}
\end{equation}

where the residual ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:rss}) and total sum of squares ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:tss}) are

\begin{equation} \label{eq:rsq-der-SS}
\begin{split}
\mathrm{RSS} &= \sum_{i=1}^{n} (y_i - \hat{y}_i)^2, \quad \hat{y} = X\hat{\beta} \\
\mathrm{TSS} &= \sum_{i=1}^{n} (y_i - \bar{y})^2\;, \quad \bar{y} = \frac{1}{n} \sum_{i=1}^n y_i \\
\end{split}
\end{equation}

where $X$ is the $n \times p$ design matrix and $\hat{\beta}$ are the ordinary least squares ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mlr-ols}) estimates.


\vspace{1em}
\textbf{Proof:} The coefficient of determination $R^2$ is defined as ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:rsq}) the proportion of the variance explained by the independent variables, relative to the total variance in the data.

\vspace{1em}
1) If we define the explained sum of squares ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:ess}) as

\begin{equation} \label{eq:rsq-der-ESS}
\mathrm{ESS} = \sum_{i=1}^{n} (\hat{y}_i - \bar{y})^2 \; ,
\end{equation}

then $R^2$ is given by

\begin{equation} \label{eq:rsq-der-R2-s1}
R^2 = \frac{\mathrm{ESS}}{\mathrm{TSS}} \; .
\end{equation}

which is equal to

\begin{equation} \label{eq:rsq-der-R2-s2}
R^2 = \frac{\mathrm{TSS}-\mathrm{RSS}}{\mathrm{TSS}} = 1 - \frac{\mathrm{RSS}}{\mathrm{TSS}} \; ,
\end{equation}

because ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mlr-pss}) $\mathrm{TSS} = \mathrm{ESS} + \mathrm{RSS}$.

\vspace{1em}
2) Using \eqref{eq:rsq-der-SS}, the coefficient of determination can be also written as:

\begin{equation} \label{eq:rsq-der-R2'}
R^2 = 1 - \frac{\sum_{i=1}^{n} (y_i - \hat{y}_i)^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2} = 1 - \frac{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}{\frac{1}{n} \sum_{i=1}^{n} (y_i - \bar{y})^2} \; .
\end{equation}

If we replace the variance estimates by their unbiased estimators ($\rightarrow$ Proof \ref{sec:Model Selection}/\ref{sec:resvar-unb}), we obtain

\begin{equation} \label{eq:rsq-der-R2-adj'}
R^2_{\mathrm{adj}} = 1 - \frac{\frac{1}{n-p} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}{\frac{1}{n-1} \sum_{i=1}^{n} (y_i - \bar{y})^2} = 1 - \frac{\mathrm{RSS}/\mathrm{df}_r}{\mathrm{TSS}/\mathrm{df}_t}
\end{equation}

where $\mathrm{df}_r = n-p$ and $\mathrm{df}_t = n-1$ are the residual and total degrees of freedom ($\rightarrow$ Definition "dof").

\vspace{1em}
This gives the adjusted $R^2$ which adjusts $R^2$ for the number of explanatory variables.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2019): "Coefficient of determination"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2019-12-06; URL: \url{https://en.wikipedia.org/wiki/Coefficient_of_determination#Adjusted_R2}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P8 | shortcut: rsq-der | author: JoramSoch | date: 2019-12-06, 11:19.
\vspace{1em}



\subsubsection[\textbf{Relationship to maximum log-likelihood}]{Relationship to maximum log-likelihood} \label{sec:rsq-mll}
\setcounter{equation}{0}

\textbf{Theorem:} Given a linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}) with independent observations

\begin{equation} \label{eq:rsq-mll-MLR}
y = X\beta + \varepsilon, \; \varepsilon_i \overset{\mathrm{i.i.d.}}{\sim} \mathcal{N}(0, \sigma^2) \; ,
\end{equation}

the coefficient of determination ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:rsq}) can be expressed in terms of the maximum log-likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mll}) as

\begin{equation} \label{eq:rsq-mll-R2-MLL}
R^2 = 1 - \left( \exp[\Delta\mathrm{MLL}] \right)^{-2/n}
\end{equation}

where $n$ is the number of observations and $\Delta\mathrm{MLL}$ is the difference in maximum log-likelihood between the model given by \eqref{eq:rsq-mll-MLR} and a linear regression model with only a constant regressor.


\vspace{1em}
\textbf{Proof:} First, we express the maximum log-likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mll}) (MLL) of a linear regression model in terms of its residual sum of squares ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:rss}) (RSS). The model in \eqref{eq:rsq-mll-MLR} implies the following log-likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:llf})

\begin{equation} \label{eq:rsq-mll-MLR-LL}
\mathrm{LL}(\beta,\sigma^2) = \log p(y|\beta,\sigma^2) = - \frac{n}{2} \log(2\pi\sigma^2) - \frac{1}{2\sigma^2} (y - X\beta)^\mathrm{T} (y - X\beta) \; ,
\end{equation}

such that maximum likelihood estimates are ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mlr-mle})

\begin{equation} \label{eq:rsq-mll-MLR-MLE-beta}
\hat{\beta} = (X^\mathrm{T} X)^{-1} X^\mathrm{T} y
\end{equation}

\begin{equation} \label{eq:rsq-mll-MLR-MLE-sigma2}
\hat{\sigma}^2 = \frac{1}{n} (y - X\hat{\beta})^\mathrm{T} (y - X\hat{\beta})
\end{equation}

and the residual sum of squares ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:rss}) is

\begin{equation} \label{eq:rsq-mll-RSS}
\mathrm{RSS} = \sum_{i=1}^n \hat{\varepsilon}_i = \hat{\varepsilon}^\mathrm{T} \hat{\varepsilon} = (y - X\hat{\beta})^\mathrm{T} (y - X\hat{\beta}) = n \cdot \hat{\sigma}^2 \; .
\end{equation}

Since $\hat{\beta}$ and $\hat{\sigma}^2$ are maximum likelihood estimates ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mle}), plugging them into the log-likelihood function gives the maximum log-likelihood:

\begin{equation} \label{eq:rsq-mll-MLR-MLL}
\mathrm{MLL} = \mathrm{LL}(\hat{\beta},\hat{\sigma}^2) = - \frac{n}{2} \log(2\pi\hat{\sigma}^2) - \frac{1}{2\hat{\sigma}^2} (y - X\hat{\beta})^\mathrm{T} (y - X\hat{\beta}) \; .
\end{equation}

With \eqref{eq:rsq-mll-RSS} for the first $\hat{\sigma}^2$ and \eqref{eq:rsq-mll-MLR-MLE-sigma2} for the second $\hat{\sigma}^2$, the MLL becomes

\begin{equation} \label{eq:rsq-mll-MLR-MLL-RSS}
\mathrm{MLL} = - \frac{n}{2} \log(\mathrm{RSS}) - \frac{n}{2} \log \left( \frac{2\pi}{n} \right) - \frac{n}{2} \; .
\end{equation}

Second, we establish the relationship between maximum log-likelihood (MLL) and coefficient of determination (RÂ²). Consider the two models

\begin{equation} \label{eq:rsq-mll-m0-m1}
\begin{split}
m_0: \; X_0 &= 1_n \\
m_1: \; X_1 &= X
\end{split}
\end{equation}

For $m_1$, the residual sum of squares is given by \eqref{eq:rsq-mll-RSS}; and for $m_0$, the residual sum of squares is equal to the total sum of squares ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:tss}):

\begin{equation} \label{eq:rsq-mll-TSS}
\mathrm{TSS} = \sum_{i=1}^n (y_i - \bar{y})^2 \; .
\end{equation}

Using \eqref{eq:rsq-mll-MLR-MLL-RSS}, we can therefore write

\begin{equation} \label{eq:rsq-mll-MLR-DMLL}
\Delta\mathrm{MLL} = \mathrm{MLL}(m_1) - \mathrm{MLL}(m_0) = - \frac{n}{2} \log(\mathrm{RSS}) + \frac{n}{2} \log(\mathrm{TSS}) \; .
\end{equation}

Exponentiating both sides of the equation, we have:

\begin{equation} \label{eq:rsq-mll-MLR-DMLL-RTSS}
\begin{split}
\exp[\Delta\mathrm{MLL}] &= \exp\left[ - \frac{n}{2} \log(\mathrm{RSS}) + \frac{n}{2} \log(\mathrm{TSS}) \right] \\
&= \left( \exp\left[ \log(\mathrm{RSS}) - \log(\mathrm{TSS}) \right] \right)^{-n/2} \\
&= \left( \frac{\exp[\log(\mathrm{RSS})]}{\exp[\log(\mathrm{TSS})]} \right)^{-n/2} \\
&= \left( \frac{\mathrm{RSS}}{\mathrm{TSS}} \right)^{-n/2} \; .
\end{split}
\end{equation}

Taking both sides to the power of $-2/n$ and subtracting from 1, we have

\begin{equation} \label{eq:rsq-mll-MLR-DMLL-R2}
\begin{split}
\left( \exp[\Delta\mathrm{MLL}] \right)^{-2/n} &= \frac{\mathrm{RSS}}{\mathrm{TSS}} \\
1 - \left( \exp[\Delta\mathrm{MLL}] \right)^{-2/n} &= 1 - \frac{\mathrm{RSS}}{\mathrm{TSS}} = R^2
\end{split}
\end{equation}

which proves the identity given above.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P14 | shortcut: rsq-mll | author: JoramSoch | date: 2020-01-08, 04:46.
\vspace{1em}



\subsection{Signal-to-noise ratio}

\subsubsection[\textit{Definition}]{Definition} \label{sec:snr}
\setcounter{equation}{0}

\textbf{Definition:} Let there be a linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}) with independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}) observations

\begin{equation} \label{eq:snr-mlr}
y = X\beta + \varepsilon, \; \varepsilon_i \overset{\mathrm{i.i.d.}}{\sim} \mathcal{N}(0, \sigma^2)
\end{equation}

with measured data $y$, known design matrix $X$ as well as unknown regression coefficients $\beta$ and noise variance $\sigma^2$.

Given estimated regression coefficients ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mlr-mle}) $\hat{\beta}$ and residual variance ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:resvar}) $\hat{\sigma}^2$, the signal-to-noise ratio (SNR) is defined as the ratio of estimated signal variance to estimated noise variance:

\begin{equation} \label{eq:snr-SNR}
\mathrm{SNR} = \frac{\mathrm{Var}(X\hat{\beta})}{\hat{\sigma}^2} \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Soch J, Allefeld C (2018): "MACS â€“ a new SPM toolbox for model assessment, comparison and selection"; in: \textit{Journal of Neuroscience Methods}, vol. 306, pp. 19-31, eq. 6; URL: \url{https://www.sciencedirect.com/science/article/pii/S0165027018301468}; DOI: 10.1016/j.jneumeth.2018.05.017.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D22 | shortcut: snr | author: JoramSoch | date: 2020-02-25, 12:01.
\vspace{1em}



\subsubsection[\textbf{Relationship with RÂ²}]{Relationship with RÂ²} \label{sec:snr-rsq}
\setcounter{equation}{0}

\textbf{Theorem:} Let there be a linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}) with independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}) observations

\begin{equation} \label{eq:snr-rsq-mlr}
y = X\beta + \varepsilon, \; \varepsilon_i \overset{\mathrm{i.i.d.}}{\sim} \mathcal{N}(0, \sigma^2)
\end{equation}

and parameter estimates ($\rightarrow$ Definition "est") obtained with ordinary least squares ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mlr-ols})

\begin{equation} \label{eq:snr-rsq-OLS}
\hat{\beta} = (X^\mathrm{T} X)^{-1} X^\mathrm{T} y \; .
\end{equation}

Then, the signal-to noise ratio ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:snr}) can be expressed in terms of the coefficient of determination ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:rsq})

\begin{equation} \label{eq:snr-rsq-SNR-R2}
\mathrm{SNR} = \frac{R^2}{\mathrm{1-R^2}}
\end{equation}

and vice versa

\begin{equation} \label{eq:snr-rsq-R2-SNR}
R^2 = \frac{\mathrm{SNR}}{\mathrm{1+\mathrm{SNR}}} \; ,
\end{equation}

if the predicted signal mean is equal to the actual signal mean.


\vspace{1em}
\textbf{Proof:} The signal-to-noise ratio (SNR) is defined as ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:snr})

\begin{equation} \label{eq:snr-rsq-SNR}
\mathrm{SNR} = \frac{\mathrm{Var}(X\hat{\beta})}{\hat{\sigma}^2} = \frac{\mathrm{Var}(\hat{y})}{\hat{\sigma}^2} \; .
\end{equation}

Writing out the variances, we have

\begin{equation} \label{eq:snr-rsq-SNR-s1}
\mathrm{SNR} = \frac{\frac{1}{n} \sum_{i=1}^{n} (\hat{y}_i - \bar{\hat{y}})^2}{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2} = \frac{\sum_{i=1}^{n} (\hat{y}_i - \bar{\hat{y}})^2}{\sum_{i=1}^{n} (y_i - \hat{y}_i)^2} \; .
\end{equation}

Note that it is irrelevant whether we use the biased estimator of the variance ($\rightarrow$ Proof \ref{sec:Model Selection}/\ref{sec:resvar-bias}) (dividing by $n$) or the unbiased estimator fo the variance ($\rightarrow$ Proof \ref{sec:Model Selection}/\ref{sec:resvar-unb}) (dividing by $n-1$), because the relevant terms cancel out.

If the predicted signal mean is equal to the actual signal mean -- which is the case when variable regressors in $X$ have mean zero, such that they are orthogonal to a constant regressor in $X$ --, this means that $\bar{\hat{y}} = \bar{y}$, such that

\begin{equation} \label{eq:snr-rsq-SNR-s2}
\mathrm{SNR} = \frac{\sum_{i=1}^{n} (\hat{y}_i - \bar{y})^2}{\sum_{i=1}^{n} (y_i - \hat{y}_i)^2} \; .
\end{equation}

Then, the SNR can be written in terms of the explained ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:ess}), residual ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:rss}) and total sum of squares ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:tss}):

\begin{equation} \label{eq:snr-rsq-SNR-s3}
\mathrm{SNR} = \frac{\mathrm{ESS}}{\mathrm{RSS}} = \frac{\mathrm{ESS}/\mathrm{TSS}}{\mathrm{RSS}/\mathrm{TSS}} \; .
\end{equation}

With the derivation of the coefficient of determination ($\rightarrow$ Proof \ref{sec:Model Selection}/\ref{sec:rsq-der}), this becomes

\begin{equation} \label{eq:snr-rsq-SNR-R2-qed}
\mathrm{SNR} = \frac{R^2}{1-R^2} \; .
\end{equation}

Rearranging this equation for the coefficient of determination ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:rsq}), we have

\begin{equation} \label{eq:snr-rsq-R2-SNR-qed}
R^2 = \frac{\mathrm{SNR}}{\mathrm{1+\mathrm{SNR}}} \; ,
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P63 | shortcut: snr-rsq | author: JoramSoch | date: 2020-02-26, 10:37.
\vspace{1em}



\pagebreak
\section{Classical information criteria}

\subsection{Akaike information criterion}

\subsubsection[\textit{Definition}]{Definition} \label{sec:aic}
\setcounter{equation}{0}

\textbf{Definition:} Let $m$ be a generative model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) with likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) $p(y \vert \theta, m)$ and maximum likelihood estimates ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mle})

\begin{equation} \label{eq:aic-MLE}
\hat{\theta} = \operatorname*{arg\,max}_\theta \log p(y | \theta, m) \; .
\end{equation}

Then, the Akaike information criterion (AIC) of this model is defined as

\begin{equation} \label{eq:aic-AIC}
\mathrm{AIC}(m) = -2 \log p(y | \hat{\theta}, m) + 2 \, p
\end{equation}

where $p$ is the number of free parameters estimated via \eqref{eq:aic-MLE}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Akaike H (1974): "A New Look at the Statistical Model Identification"; in: \textit{IEEE Transactions on Automatic Control}, vol. AC-19, no. 6, pp. 716-723; URL: \url{https://ieeexplore.ieee.org/document/1100705}; DOI: 10.1109/TAC.1974.1100705.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D23 | shortcut: aic | author: JoramSoch | date: 2020-02-25, 12:31.
\vspace{1em}



\subsection{Bayesian information criterion}

\subsubsection[\textit{Definition}]{Definition} \label{sec:bic}
\setcounter{equation}{0}

\textbf{Definition:} Let $m$ be a generative model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) with likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) $p(y \vert \theta, m)$ and maximum likelihood estimates ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mle})

\begin{equation} \label{eq:bic-MLE}
\hat{\theta} = \operatorname*{arg\,max}_\theta \log p(y | \theta, m) \; .
\end{equation}

Then, the Bayesian information criterion (BIC) of this model is defined as

\begin{equation} \label{eq:bic-BIC}
\mathrm{BIC}(m) = -2 \log p(y | \hat{\theta}, m) + p \log n
\end{equation}

where $n$ is the number of data points and $p$ is the number of free parameters estimated via \eqref{eq:bic-MLE}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Schwarz G (1978): "Estimating the Dimension of a Model"; in: \textit{The Annals of Statistics}, vol. 6, no. 2, pp. 461-464; URL: \url{https://www.jstor.org/stable/2958889}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D24 | shortcut: bic | author: JoramSoch | date: 2020-02-25, 12:21.
\vspace{1em}



\subsubsection[\textbf{Derivation}]{Derivation} \label{sec:bic-der}
\setcounter{equation}{0}

\textbf{Theorem:} Let $p(y \vert \theta, m)$ be the likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) of a generative model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) $m \in \mathcal{M}$ with model parameters $\theta \in \Theta$ describing measured data $y \in \mathbb{R}^n$. Let $p(\theta \vert m)$ be a prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) on the model parameters. Assume that likelihood function and prior density are twice differentiable.

Then, as the number of data points goes to infinity, an approximation to the log-marginal likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ml}) $\log p(y \vert m)$, up to constant terms not depending on the model, is given by the Bayesian information criterion ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:bic}) (BIC) as

\begin{equation} \label{eq:bic-der-BIC}
-2 \log p(y|m) \approx \mathrm{BIC}(m) = -2 \log p(y|\hat{\theta}, m) + p \log n
\end{equation}

where $\hat{\theta}$ is the maximum likelihood estimator ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mle}) (MLE) of $\theta$, $n$ is the number of data points and $p$ is the number of model parameters.


\vspace{1em}
\textbf{Proof:} Let $\mathrm{LL}(\theta)$ be the log-likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:llf})

\begin{equation} \label{eq:bic-der-LL}
\mathrm{LL}(\theta) = \log p(y|\theta,m)
\end{equation}

and define the functions $g$ and $h$ as follows:

\begin{equation} \label{eq:bic-der-gh}
\begin{split}
g(\theta) &= p(\theta|m) \\
h(\theta) &= \frac{1}{n} \, \mathrm{LL}(\theta) \; .
\end{split}
\end{equation}

Then, the marginal likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ml}) can be written as follows:

\begin{equation} \label{eq:bic-der-ML}
\begin{split}
p(y|m) &= \int_{\Theta} p(y|\theta,m) \, p(\theta|m) \, \mathrm{d}\theta \\
&= \int_{\Theta} \exp\left[n \, h(\theta)\right] \, g(\theta) \, \mathrm{d}\theta \; .
\end{split}
\end{equation}

This is an integral suitable for Laplace approximation which states that

\begin{equation} \label{eq:bic-der-LA}
\int_{\Theta} \exp\left[n \, h(\theta)\right] \, g(\theta) \, \mathrm{d}\theta = \left( \sqrt{\frac{2 \pi}{n}} \right)^p \exp\left[n \, h(\theta_0)\right] \left( g(\theta_0) \left| J(\theta_0) \right|^{-1/2} + O(1/n) \right)
\end{equation}

where $\theta_0$ is the value that maximizes $h(\theta)$ and $J(\theta_0)$ is the Hessian matrix evaluated at $\theta_0$. In our case, we have $h(\theta) = 1/n \, \mathrm{LL}(\theta)$ such that $\theta_0$ is the maximum likelihood estimator $\hat{\theta}$:

\begin{equation} \label{eq:bic-der-MLE}
\hat{\theta} = \operatorname*{arg\,max}_\theta \mathrm{LL}(\theta) \; .
\end{equation}

With this, \eqref{eq:bic-der-LA} can be applied to \eqref{eq:bic-der-ML} using \eqref{eq:bic-der-gh} to give:

\begin{equation} \label{eq:bic-der-ML-approx}
p(y|m) \approx \left( \sqrt{\frac{2 \pi}{n}} \right)^p p(y|\hat{\theta},m) \, p(\hat{\theta}|m) \, \left| J(\hat{\theta}) \right|^{-1/2} \; .
\end{equation}

Logarithmizing and multiplying with $-2$, we have:

\begin{equation} \label{eq:bic-der-LME-approx}
-2 \log p(y|m) \approx -2 \, \mathrm{LL}(\hat{\theta}) + p \log n - p \log(2 \pi) - 2 \log p(\hat{\theta}|m) + \log \left| J(\hat{\theta}) \right| \; .
\end{equation}

As $n \to \infty$, the last three terms are $O_p(1)$ and can therefore be ignored when comparing between models $\mathcal{M} = \left\lbrace m_1, \ldots, m_M \right\rbrace$ and using $p(y \vert m_j)$ to compute posterior model probabilies ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:pmp}) $p(m_j \vert y)$. With that, the BIC is given as

\begin{equation} \label{eq:bic-der-BIC-qed}
\mathrm{BIC}(m) = -2 \log p(y|\hat{\theta}, m) + p \log n \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Claeskens G, Hjort NL (2008): "The Bayesian information criterion"; in: \textit{Model Selection and Model Averaging}, ch. 3.2, pp. 78-81; URL: \url{https://www.cambridge.org/core/books/model-selection-and-model-averaging/E6F1EC77279D1223423BB64FC3A12C37}; DOI: 10.1017/CBO9780511790485.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P32 | shortcut: bic-der | author: JoramSoch | date: 2020-01-26, 23:36.
\vspace{1em}



\subsection{Deviance information criterion}

\subsubsection[\textit{Definition}]{Definition} \label{sec:dic}
\setcounter{equation}{0}

\textbf{Definition:} Let $m$ be a generative model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) with likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) $p(y \vert \theta, m)$ and prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) $p(\theta \vert m)$. Together, likelihood function and prior distribution imply a posterior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) $p(\theta \vert y, m)$.

Define the posterior expected log-likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:llf}) (PLL)

\begin{equation} \label{eq:dic-PLL}
\mathrm{PLL}(m) = \left\langle \log p(y|\theta,m) \right\rangle_{\theta|y}
\end{equation}

and the log-likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:llf}) at the posterior expectation (LLP)

\begin{equation} \label{eq:dic-LLP}
\mathrm{LLP}(m) = \log p(y|\left\langle \theta \right\rangle_{\theta|y},m)
\end{equation}

where $\left\langle \cdot \right\rangle_{\theta \vert y}$ denotes an expectation across the posterior distribution.

Then, the deviance information criterion (DIC) of the model is defined as

\begin{equation} \label{eq:dic-DIC}
\mathrm{DIC}(m) = -2 \, \mathrm{LLP}(m) + 2 \, p_D \quad \text{or} \quad \mathrm{DIC}(m) = -2 \, \mathrm{PLL}(m) + p_D
\end{equation}

where the "effective number of parameters" $p_D$ is given by

\begin{equation} \label{eq:dic-DIC-pD}
p_D = -2 \, \mathrm{PLL}(m) +2 \, \mathrm{LLP}(m) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Spiegelhalter DJ, Best NG, Carlin BP, Van Der Linde A (2002): "Bayesian measures of model complexity and fit"; in: \textit{Journal of the Royal Statistical Society, Series B: Statistical Methodology}, vol. 64, iss. 4, pp. 583-639; URL: \url{https://rss.onlinelibrary.wiley.com/doi/10.1111/1467-9868.00353}; DOI: 10.1111/1467-9868.00353.
\item Soch J, Allefeld C (2018): "MACS â€“ a new SPM toolbox for model assessment, comparison and selection"; in: \textit{Journal of Neuroscience Methods}, vol. 306, pp. 19-31, eqs. 10-12; URL: \url{https://www.sciencedirect.com/science/article/pii/S0165027018301468}; DOI: 10.1016/j.jneumeth.2018.05.017.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D25 | shortcut: dic | author: JoramSoch | date: 2020-02-25, 12:46.
\vspace{1em}



\pagebreak
\section{Bayesian model selection}

\subsection{Log model evidence}

\subsubsection[\textit{Definition}]{Definition} \label{sec:lme}
\setcounter{equation}{0}

\textbf{Definition:} Let $m$ be a generative model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) with likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) $p(y \vert \theta, m)$ and prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) $p(\theta \vert m)$. Then, the log model evidence (LME) of this model is defined as the logarithm of the marginal likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ml}):

\begin{equation} \label{eq:lme-LME}
\mathrm{LME}(m) = \log p(y|m) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Soch J, Allefeld C (2018): "MACS â€“ a new SPM toolbox for model assessment, comparison and selection"; in: \textit{Journal of Neuroscience Methods}, vol. 306, pp. 19-31, eq. 13; URL: \url{https://www.sciencedirect.com/science/article/pii/S0165027018301468}; DOI: 10.1016/j.jneumeth.2018.05.017.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D26 | shortcut: lme | author: JoramSoch | date: 2020-02-25, 12:56.
\vspace{1em}



\subsubsection[\textbf{Derivation}]{Derivation} \label{sec:lme-der}
\setcounter{equation}{0}

\textbf{Theorem:} Let $p(y \vert \theta,m)$ be a likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) of a generative model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) $m$ for making inferences on model parameters $\theta$ given measured data $y$. Moreover, let $p(\theta \vert m)$ be a prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) on model parameters $\theta$. Then, the log model evidence ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme}) (LME), also called marginal log-likelihood,

\begin{equation} \label{eq:lme-der-LME-term}
\mathrm{LME}(m) = \log p(y|m) \; ,
\end{equation}

can be expressed

1) as

\begin{equation} \label{eq:lme-der-LME-marg}
\mathrm{LME}(m) = \log \int p(y|\theta,m) \, p(\theta|m) \, \mathrm{d}\theta
\end{equation}

2) or

\begin{equation} \label{eq:lme-der-LME-bayes}
\mathrm{LME}(m) = \log p(y|\theta,m) + \log p(\theta|m) - \log p(\theta|y,m) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:}

1) The first expression is a simple consequence of the law of marginal probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}) for continuous variables according to which

\begin{equation} \label{eq:lme-der-ME}
p(y|m) = \int p(y|\theta,m) \, p(\theta|m) \, \mathrm{d}\theta
\end{equation}

which, when logarithmized, gives

\begin{equation} \label{eq:lme-der-LME-marg-qed}
\mathrm{LME}(m) = \log p(y|m) = \log \int p(y|\theta,m) \, p(\theta|m) \, \mathrm{d}\theta \; .
\end{equation}

2) The second expression can be derived from Bayes' theorem ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:bayes-th}) which makes a statement about the posterior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}):

\begin{equation} \label{eq:lme-der-BT}
p(\theta|y,m) = \frac{p(y|\theta,m) \, p(\theta|m)}{p(y|m)} \; .
\end{equation}

Rearranging for $p(y \vert m)$ and logarithmizing, we have:

\begin{equation} \label{eq:lme-der-LME-bayes-qed}
\begin{split}
\mathrm{LME}(m) = \log p(y|m) & = \log \frac{p(y|\theta,m) \, p(\theta|m)}{p(\theta|y,m)} \\
&= \log p(y|\theta,m) + \log p(\theta|m) - \log p(\theta|y,m) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P13 | shortcut: lme-der | author: JoramSoch | date: 2020-01-06, 21:27.
\vspace{1em}



\subsubsection[\textbf{Partition into accuracy and complexity}]{Partition into accuracy and complexity} \label{sec:lme-anc}
\setcounter{equation}{0}

\textbf{Theorem:} The log model evidence ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme}) can be partitioned into accuracy and complexity

\begin{equation} \label{eq:lme-anc-LME}
\mathrm{LME}(m) = \mathrm{Acc}(m) - \mathrm{Com}(m)
\end{equation}

where the accuracy term is the posterior ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) expectation ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-lotus}) of the log-likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:llf})

\begin{equation} \label{eq:lme-anc-Acc}
\mathrm{Acc}(m) = \left\langle \log p(y|\theta,m) \right\rangle_{p(\theta|y,m)}
\end{equation}

and the complexity penalty is the Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) of posterior ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) from prior ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior})

\begin{equation} \label{eq:lme-anc-Com}
\mathrm{Com}(m) = \mathrm{KL} \left[ p(\theta|y,m) \, || \, p(\theta|m) \right] \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} We consider Bayesian inference on data ($\rightarrow$ Definition "data") $y$ using model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) $m$ with parameters $\theta$. Then, Bayes' theorem ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:bayes-th}) makes a statement about the posterior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}), i.e. the probability of parameters, given the data and the model:

\begin{equation} \label{eq:lme-anc-AnC-s1}
p(\theta|y,m) = \frac{p(y|\theta,m) \, p(\theta|m)}{p(y|m)} \; .
\end{equation}

Rearranging this for the model evidence ($\rightarrow$ Proof \ref{sec:Model Selection}/\ref{sec:lme-der}), we have:

\begin{equation} \label{eq:lme-anc-AnC-s2}
p(y|m) = \frac{p(y|\theta,m) \, p(\theta|m)}{p(\theta|y,m)} \; .
\end{equation}

Logarthmizing both sides of the equation, we obtain:

\begin{equation} \label{eq:lme-anc-AnC-s3}
\log p(y|m) = \log p(y|\theta,m) - \log \frac{p(\theta|y,m)}{p(\theta|m)} \; .
\end{equation}

Now taking the expectation over the posterior distribution yields:

\begin{equation} \label{eq:lme-anc-AnC-s4}
\log p(y|m) = \int p(\theta|y,m) \log p(y|\theta,m) \, \mathrm{d}\theta - \int p(\theta|y,m) \log \frac{p(\theta|y,m)}{p(\theta|m)} \, \mathrm{d}\theta \; .
\end{equation}

By definition, the left-hand side is the log model evidence and the terms on the right-hand side correspond to the posterior expectation of the log-likelihood function and the Kullback-Leibler divergence of posterior from prior

\begin{equation} \label{eq:lme-anc-LME-AnC}
\mathrm{LME}(m) = \left\langle \log p(y|\theta,m) \right\rangle_{p(\theta|y,m)} - \mathrm{KL} \left[ p(\theta|y,m) \, || \, p(\theta|m) \right]
\end{equation}

which proofs the partition given by \eqref{eq:lme-anc-LME}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Penny et al. (2007): "Bayesian Comparison of Spatially Regularised General Linear Models"; in: \textit{Human Brain Mapping}, vol. 28, pp. 275â€“293; URL: \url{https://onlinelibrary.wiley.com/doi/full/10.1002/hbm.20327}; DOI: 10.1002/hbm.20327.
\item Soch et al. (2016): "How to avoid mismodelling in GLM-based fMRI data analysis: cross-validated Bayesian model selection"; in: \textit{NeuroImage}, vol. 141, pp. 469â€“489; URL: \url{https://www.sciencedirect.com/science/article/pii/S1053811916303615}; DOI: 10.1016/j.neuroimage.2016.07.047.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P3 | shortcut: lme-anc | author: JoramSoch | date: 2019-09-27, 16:13.
\vspace{1em}



\subsubsection[\textit{Uniform-prior log model evidence}]{Uniform-prior log model evidence} \label{sec:uplme}
\setcounter{equation}{0}

\textbf{Definition:} Assume a generative model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) $m$ with likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) $p(y \vert \theta, m)$ and a uniform ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior-uni}) prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) $p_{\mathrm{uni}}(\theta \vert m)$. Then, the log model evidence ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme}) of this model is called "log model evidence with uniform prior" or "uniform-prior log model evidence" (upLME):

\begin{equation} \label{eq:uplme-upLME}
\mathrm{upLME}(m) = \log \int p(y \vert \theta, m) \, p_{\mathrm{uni}}(\theta \vert m) \, \mathrm{d}\theta \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Lindley's paradox"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-11-25; URL: \url{https://en.wikipedia.org/wiki/Lindley%27s_paradox#Bayesian_approach}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D113 | shortcut: uplme | author: JoramSoch | date: 2020-11-25, 07:28.
\vspace{1em}



\subsubsection[\textit{Cross-validated log model evidence}]{Cross-validated log model evidence} \label{sec:cvlme}
\setcounter{equation}{0}

\textbf{Definition:} Let there be a data set ($\rightarrow$ Definition "data") $y$ with mutually exclusive and collectively exhaustive subsets $y_1, \ldots, y_S$. Assume a generative model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) $m$ with model parameters $\theta$ implying a likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) $p(y \vert \theta, m)$ and a non-informative ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior-inf}) prior density ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) $p_{\mathrm{ni}}(\theta \vert m)$.

Then, the cross-validated log model evidence of $m$ is given by

\begin{equation} \label{eq:cvlme-cvLME}
\mathrm{cvLME}(m) = \sum_{i=1}^{S} \log \int p( y_i \vert \theta, m ) \, p( \theta \vert y_{\neg i}, m ) \, \mathrm{d}\theta
\end{equation}

where $y_{\neg i} = \bigcup_{j \neq i} y_j$ is the union of all data subsets except $y_i$ and $p( \theta \vert y_{\neg i}, m )$ is the posterior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) obtained from $y_{\neg i}$ when using the prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) $p_{\mathrm{ni}}(\theta \vert m)$:

\begin{equation} \label{eq:cvlme-post}
p( \theta \vert y_{\neg i}, m ) = \frac{p( y_{\neg i} \vert \theta, m ) \, p_{\mathrm{ni}}(\theta \vert m)}{p( y_{\neg i} \vert m )} \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Soch J, Allefeld C, Haynes JD (2016): "How to avoid mismodelling in GLM-based fMRI data analysis: cross-validated Bayesian model selection"; in: \textit{NeuroImage}, vol. 141, pp. 469-489, eqs. 13-15; URL: \url{https://www.sciencedirect.com/science/article/pii/S1053811916303615}; DOI: 10.1016/j.neuroimage.2016.07.047.
\item Soch J, Meyer AP, Allefeld C, Haynes JD (2017): "How to improve parameter estimates in GLM-based fMRI data analysis: cross-validated Bayesian model averaging"; in: \textit{NeuroImage}, vol. 158, pp. 186-195, eq. 6; URL: \url{https://www.sciencedirect.com/science/article/pii/S105381191730527X}; DOI: 10.1016/j.neuroimage.2017.06.056.
\item Soch J, Allefeld C (2018): "MACS â€“ a new SPM toolbox for model assessment, comparison and selection"; in: \textit{Journal of Neuroscience Methods}, vol. 306, pp. 19-31, eqs. 14-15; URL: \url{https://www.sciencedirect.com/science/article/pii/S0165027018301468}; DOI: 10.1016/j.jneumeth.2018.05.017.
\item Soch J (2018): "cvBMS and cvBMA: filling in the gaps"; in: \textit{arXiv stat.ME}, arXiv:1807.01585; URL: \url{https://arxiv.org/abs/1807.01585}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D111 | shortcut: cvlme | author: JoramSoch | date: 2020-11-19, 04:55.
\vspace{1em}



\subsubsection[\textit{Empirical Bayesian log model evidence}]{Empirical Bayesian log model evidence} \label{sec:eblme}
\setcounter{equation}{0}

\textbf{Definition:} Let $m$ be a generative model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) with model parameters $\theta$ and hyper-parameters $\lambda$ implying the likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) $p(y \vert \theta, \lambda, m)$ and prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) $p(\theta \vert \lambda, m)$. Then, the Empirical Bayesian ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:eb}) log model evidence ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme}) is the logarithm of the marginal likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ml}), maximized with respect to the hyper-parameters:

\begin{equation} \label{eq:eblme-ebLME}
\mathrm{ebLME}(m) = \log p(y \vert \hat{\lambda}, m)
\end{equation}

where

\begin{equation} \label{eq:eblme-ML}
p(y \vert \lambda, m) = \int p(y \vert \theta, \lambda, m) \, (\theta \vert \lambda, m) \, \mathrm{d}\theta
\end{equation}

and ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior-eb})

\begin{equation} \label{eq:eblme-EB}
\hat{\lambda} = \operatorname*{arg\,max}_{\lambda} \log p(y \vert \lambda, m) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Empirical Bayes method"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-11-25; URL: \url{https://en.wikipedia.org/wiki/Empirical_Bayes_method#Introduction}.
\item Penny, W.D. and Ridgway, G.R. (2013): "Efficient Posterior Probability Mapping Using Savage-Dickey Ratios"; in: \textit{PLoS ONE}, vol. 8, iss. 3, art. e59655, eqs. 7/11; URL: \url{https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0059655}; DOI: 10.1371/journal.pone.0059655.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D114 | shortcut: eblme | author: JoramSoch | date: 2020-11-25, 07:43.
\vspace{1em}



\subsubsection[\textit{Variational Bayesian log model evidence}]{Variational Bayesian log model evidence} \label{sec:vblme}
\setcounter{equation}{0}

\textbf{Definition:} Let $m$ be a generative model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) with model parameters $\theta$ implying the likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) $p(y \vert \theta, m)$ and prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) $p(\theta \vert m)$. Moreover, assume an approximate ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:vb}) posterior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) $q(\theta)$. Then, the Variational Bayesian ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:vb}) log model evidence ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme}), also referred to as the "negative free energy", is the expectation of the log-likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:llf}) with respect to the approximate posterior, minus the Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) between approximate posterior and the prior distribution:

\begin{equation} \label{eq:vblme-vbLME}
\mathrm{vbLME}(m) = \left\langle \log p(y \vert \theta, m) \right\rangle_{q(\theta)} - \mathrm{KL}\left[q(\theta) || p(\theta \vert m)\right]
\end{equation}

where

\begin{equation} \label{eq:vblme-ELL}
\left\langle \log p(y \vert \theta, m) \right\rangle_{q(\theta)} = \int q(\theta) \log p(y \vert \theta, m) \, \mathrm{d}\theta
\end{equation}

and

\begin{equation} \label{eq:vblme-KL}
\mathrm{KL}\left[q(\theta) || p(\theta \vert m)\right] = \int q(\theta) \log \frac{q(\theta)}{p(\theta \vert m)} \, \mathrm{d}\theta  \; .
\end{equation}



\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Variational Bayesian methods"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-11-25; URL: \url{https://en.wikipedia.org/wiki/Variational_Bayesian_methods#Evidence_lower_bound}.
\item Penny W, Flandin G, Trujillo-Barreto N (2007): "Bayesian Comparison of Spatially Regularised General Linear Models"; in: \textit{Human Brain Mapping}, vol. 28, pp. 275â€“293, eqs. 2-9; URL: \url{https://onlinelibrary.wiley.com/doi/full/10.1002/hbm.20327}; DOI: 10.1002/hbm.20327.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D115 | shortcut: vblme | author: JoramSoch | date: 2020-11-25, 08:10.
\vspace{1em}



\subsection{Log family evidence}

\subsubsection[\textit{Definition}]{Definition} \label{sec:lfe}
\setcounter{equation}{0}

\textbf{Definition:} Let $f$ be a family of $M$ generative models ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) $m_1, \ldots, m_M$, such that the following statement holds true:

\begin{equation} \label{eq:lfe-fam}
f \Leftrightarrow m_1 \vee \ldots \vee m_M \; .
\end{equation}

Then, the family evidence of $f$ is the weighted average of the model evidences ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ml}) of $m_1, \ldots, m_M$ where the weights are the within-family prior model probabilities ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior})

\begin{equation} \label{eq:lfe-fe}
p(y|f) = \sum_{i=1}^M p(y|m_i) \, p(m_i|f) \; .
\end{equation}

The log family evidence is given by the logarithm of the family evidence:

\begin{equation} \label{eq:lfe-lfe}
\mathrm{LFE}(f) = \log p(y|f) = \log \sum_{i=1}^M p(y|m_i) \, p(m_i|f) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Soch J, Allefeld C (2018): "MACS â€“ a new SPM toolbox for model assessment, comparison and selection"; in: \textit{Journal of Neuroscience Methods}, vol. 306, pp. 19-31, eq. 16; URL: \url{https://www.sciencedirect.com/science/article/pii/S0165027018301468}; DOI: 10.1016/j.jneumeth.2018.05.017.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D80 | shortcut: lfe | author: JoramSoch | date: 2020-07-13, 22:31.
\vspace{1em}



\subsubsection[\textbf{Derivation}]{Derivation} \label{sec:lfe-der}
\setcounter{equation}{0}

\textbf{Theorem:} Let $f$ be a family of $M$ generative models ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) $m_1, \ldots, m_M$ with model evidences ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ml}) $p(y \vert m_1), \ldots, p(y \vert m_M)$. Then, the log family evidence ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lfe})

\begin{equation} \label{eq:lfe-der-LFE-term}
\mathrm{LFE}(f) = \log p(y|f)
\end{equation}

can be expressed as

\begin{equation} \label{eq:lfe-der-LFE-marg}
\mathrm{LFE}(f) = \log \sum_{i=1}^M p(y|m_i) \, p(m_i|f)
\end{equation}

where $p(m_i \vert f)$ are the within-family ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lfe}) prior ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) probabilities ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob}).


\vspace{1em}
\textbf{Proof:} We will assume "prior addivivity"

\begin{equation} \label{eq:lfe-der-fam-prior}
p(f) = \sum_{i=1}^M p(m_i)
\end{equation}

and "posterior additivity" for family probabilities:

\begin{equation} \label{eq:lfe-der-fam-post}
p(f|y) = \sum_{i=1}^M p(m_i|y)
\end{equation}

Bayes' theorem ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:bayes-th}) for the family evidence ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lfe}) gives

\begin{equation} \label{eq:lfe-der-fe-bayes-th}
p(y|f) = \frac{p(f|y) \, p(y)}{p(f)} \; .
\end{equation}

Applying \eqref{eq:lfe-der-fam-prior} and \eqref{eq:lfe-der-fam-post}, we have

\begin{equation} \label{eq:lfe-der-fe-me}
p(y|f) = \frac{\sum_{i=1}^M p(m_i|y) \, p(y)}{\sum_{i=1}^M p(m_i)} \; .
\end{equation}

Bayes' theorem ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:bayes-th}) for the model evidence ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lfe}) gives

\begin{equation} \label{eq:lfe-der-me-bayes-th}
p(y|m_i) = \frac{p(m_i|y) \, p(y)}{p(m_i)}
\end{equation}

which can be rearranged into

\begin{equation} \label{eq:lfe-der-me-bayes-th-dev}
p(m_i|y) \, p(y) = p(y|m_i) \, p(m_i) \; .
\end{equation}

Plugging \eqref{eq:lfe-der-me-bayes-th-dev} into \eqref{eq:lfe-der-fe-me}, we have

\begin{equation} \label{eq:lfe-der-fe-marg-qed}
\begin{split}
p(y|f) &= \frac{\sum_{i=1}^M p(y|m_i) \, p(m_i)}{\sum_{i=1}^M p(m_i)} \\
&= \sum_{i=1}^M p(y|m_i) \cdot \frac{p(m_i)}{\sum_{i=1}^M p(m_i)} \\
&= \sum_{i=1}^M p(y|m_i) \cdot \frac{p(m_i,f)}{p(f)} \\
&= \sum_{i=1}^M p(y|m_i) \cdot p(m_i|f) \; .
\end{split}
\end{equation}

Equation \eqref{eq:lfe-der-LFE-marg} follows by logarithmizing both sides of \eqref{eq:lfe-der-fe-marg-qed}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P132 | shortcut: lfe-der | author: JoramSoch | date: 2020-07-13, 22:58.
\vspace{1em}



\subsubsection[\textbf{Calculation from log model evidences}]{Calculation from log model evidences} \label{sec:lfe-lme}
\setcounter{equation}{0}

\textbf{Theorem:} Let $m_1, \ldots, m_M$ be $M$ statistical models with log model evidences ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme}) $\mathrm{LME}(m_1), \ldots, \mathrm{LME}(m_M)$ and belonging to $F$ mutually exclusive model families $f_1, \ldots, f_F$. Then, the log family evidences ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lfe}) are given by:

\begin{equation} \label{eq:lfe-lme-LFE-LME}
\mathrm{LFE}(f_j) = \log \sum_{m_i \in f_j} \left[ \exp[\mathrm{LME}(m_i)] \cdot p(m_i|f_j) \right], \quad j = 1, \ldots, F,
\end{equation}

where $p(m_i \vert f_j)$ are within-family ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lfe}) prior ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) probabilities ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob}).


\vspace{1em}
\textbf{Proof:} Let us consider the (unlogarithmized) family evidence $p(y \vert f_j)$. According to the law of marginal probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}), this conditional probability is given by

\begin{equation} \label{eq:lfe-lme-FE-ME-s1}
p(y|f_j) = \sum_{m_i \in f_j} \left[ p(y|m_i,f_j) \cdot p(m_i|f_j) \right] \; .
\end{equation}

Because model families are mutually exclusive, it holds that $p(y \vert m_i,f_j) = p(y \vert m_i)$, such that

\begin{equation} \label{eq:lfe-lme-FE-ME-s2}
p(y|f_j) = \sum_{m_i \in f_j} \left[ p(y|m_i) \cdot p(m_i|f_j) \right] \; .
\end{equation}

Logarithmizing transforms the family evidence $p(y \vert f_j)$ into the log family evidence $\mathrm{LFE}(f_j)$:

\begin{equation} \label{eq:lfe-lme-LFE-LME-s1}
\mathrm{LFE}(f_j) = \log \sum_{m_i \in f_j} \left[ p(y|m_i) \cdot p(m_i|f_j) \right] \; .
\end{equation}

The definition of the log model evidence ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme})

\begin{equation} \label{eq:lfe-lme-LME}
\mathrm{LME}(m) = \log p(y|m)
\end{equation}

can be exponentiated to then read

\begin{equation} \label{eq:lfe-lme-ME}
\exp\left[ \mathrm{LME}(m) \right] = p(y|m)
\end{equation}

and applying \eqref{eq:lfe-lme-ME} to \eqref{eq:lfe-lme-LFE-LME-s1}, we finally have:

\begin{equation} \label{eq:lfe-lme-LFE-LME-s2}
\mathrm{LFE}(f_j) = \log \sum_{m_i \in f_j} \left[ \exp[\mathrm{LME}(m_i)] \cdot p(m_i|f_j) \right] \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Soch J, Allefeld C (2018): "MACS â€“ a new SPM toolbox for model assessment, comparison and selection"; in: \textit{Journal of Neuroscience Methods}, vol. 306, pp. 19-31, eq. 16; URL: \url{https://www.sciencedirect.com/science/article/pii/S0165027018301468}; DOI: 10.1016/j.jneumeth.2018.05.017.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P65 | shortcut: lfe-lme | author: JoramSoch | date: 2020-02-27, 21:16.
\vspace{1em}



\subsection{Log Bayes factor}

\subsubsection[\textit{Definition}]{Definition} \label{sec:lbf}
\setcounter{equation}{0}

\textbf{Definition:} Let there be two generative models ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) $m_1$ and $m_2$ which are mutually exclusive, but not necessarily collectively exhaustive:

\begin{equation} \label{eq:lbf-m12}
\neg (m_1 \land m_2)
\end{equation}

Then, the Bayes factor in favor of $m_1$ and against $m_2$ is the ratio of the model evidences ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ml}) of $m_1$ and $m_2$:

\begin{equation} \label{eq:lbf-bf}
\mathrm{BF}_{12} = \frac{p(y|m_1)}{p(y|m_2)} \; .
\end{equation}

The log Bayes factor is given by the logarithm of the Bayes factor:

\begin{equation} \label{eq:lbf-lbf}
\mathrm{LBF}_{12} = \log \mathrm{BF}_{12} = \log \frac{p(y|m_1)}{p(y|m_2)} \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Soch J, Allefeld C (2018): "MACS â€“ a new SPM toolbox for model assessment, comparison and selection"; in: \textit{Journal of Neuroscience Methods}, vol. 306, pp. 19-31, eq. 18; URL: \url{https://www.sciencedirect.com/science/article/pii/S0165027018301468}; DOI: 10.1016/j.jneumeth.2018.05.017.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D84 | shortcut: lbf | author: JoramSoch | date: 2020-07-22, 07:02.
\vspace{1em}



\subsubsection[\textbf{Derivation}]{Derivation} \label{sec:lbf-der}
\setcounter{equation}{0}

\textbf{Theorem:} Let there be two generative models ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) $m_1$ and $m_2$ with model evidences ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ml}) $p(y \vert m_1)$ and $p(y \vert m_2)$. Then, the log Bayes factor ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lbf})

\begin{equation} \label{eq:lbf-der-LBF-term}
\mathrm{LBF}_{12} = \log \mathrm{BF}_{12}
\end{equation}

can be expressed as

\begin{equation} \label{eq:lbf-der-LBF-ratio}
\mathrm{LBF}_{12} = \log \frac{p(y|m_1)}{p(y|m_2)} \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The Bayes factor ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:bf}) is defined as the posterior ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) odds ratio ($\rightarrow$ Definition "odds") when both models ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) are equally likely apriori ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}):

\begin{equation} \label{eq:lbf-der-BF-s1}
\mathrm{BF}_{12} = \frac{p(m_1|y)}{p(m_2|y)}
\end{equation}

Plugging in the posterior odds ratio according to Bayes' rule ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:bayes-rule}), we have

\begin{equation} \label{eq:lbf-der-BF-s2}
\mathrm{BF}_{12} = \frac{p(y|m_1)}{p(y|m_2)} \cdot \frac{p(m_1)}{p(m_2)} \; .
\end{equation}

When both models are equally likely apriori, the prior ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) odds ratio ($\rightarrow$ Definition "odds") is one, such that

\begin{equation} \label{eq:lbf-der-BF-s3}
\mathrm{BF}_{12} = \frac{p(y|m_1)}{p(y|m_2)} \; .
\end{equation}

Equation \eqref{eq:lbf-der-LBF-ratio} follows by logarithmizing both sides of \eqref{eq:lbf-der-BF-s3}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P137 | shortcut: lbf-der | author: JoramSoch | date: 2020-07-22, 07:27.
\vspace{1em}



\subsubsection[\textbf{Calculation from log model evidences}]{Calculation from log model evidences} \label{sec:lbf-lme}
\setcounter{equation}{0}

\textbf{Theorem:} Let $m_1$ and $m_2$ be two statistical models with log model evidences ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme}) $\mathrm{LME}(m_1)$ and $\mathrm{LME}(m_2)$. Then, the log Bayes factor ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lbf}) in favor of model $m_1$ and against model $m_2$ is the difference of the log model evidences:

\begin{equation} \label{eq:lbf-lme-LBF-LME}
\mathrm{LBF}_{12} = \mathrm{LME}(m_1) - \mathrm{LME}(m_2) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The Bayes factor ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:bf}) is defined as the ratio of the model evidences ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ml}) of $m_1$ and $m_2$

\begin{equation} \label{eq:lbf-lme-BF}
\mathrm{BF}_{12} = \frac{p(y|m_1)}{p(y|m_2)}
\end{equation}

and the log Bayes factor ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lbf}) is defined as the logarithm of the Bayes factor

\begin{equation} \label{eq:lbf-lme-LBF}
\mathrm{LBF}_{12} = \log \mathrm{BF}_{12} = \log \frac{p(y|m_1)}{p(y|m_2)} \; .
\end{equation}

With the definition of the log model evidence ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme})

\begin{equation} \label{eq:lbf-lme-LME}
\mathrm{LME}(m) = \log p(y|m)
\end{equation}

the log Bayes factor can be expressed as:

Resolving the logarithm and applying the definition of the log model evidence ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme}), we finally have:

\begin{equation} \label{eq:lbf-lme-LBF-LME-qed}
\begin{split}
\mathrm{LBF}_{12} &= \log p(y|m_1) - \log p(y|m_2) \\
&= \mathrm{LME}(m_1) - \mathrm{LME}(m_2) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Soch J, Allefeld C (2018): "MACS â€“ a new SPM toolbox for model assessment, comparison and selection"; in: \textit{Journal of Neuroscience Methods}, vol. 306, pp. 19-31, eq. 18; URL: \url{https://www.sciencedirect.com/science/article/pii/S0165027018301468}; DOI: 10.1016/j.jneumeth.2018.05.017.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P64 | shortcut: lbf-lme | author: JoramSoch | date: 2020-02-27, 20:51.
\vspace{1em}



\subsection{Bayes factor}

\subsubsection[\textit{Definition}]{Definition} \label{sec:bf}
\setcounter{equation}{0}

\textbf{Definition:} Consider two competing generative models ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) $m_1$ and $m_2$ for observed data $y$. Then the Bayes factor in favor $m_1$ over $m_2$ is the ratio of marginal likelihoods ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ml}) of $m_1$ and $m_2$:

\begin{equation} \label{eq:bf-BF}
\text{BF}_{12} = \frac{p(y\mid m_1)}{p(y\mid m_2)}.
\end{equation}

Note that by Bayes' theorem ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:bayes-th}), the ratio of posterior model probabilities ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:pmp}) (i.e., the posterior model odds) can be written as

\begin{equation} \label{eq:bf-odds}
\frac{p(m_1 \mid y)}{p(m_2 \mid y)} = \frac{p(m_1)}{p(m_2)} \cdot \frac{p(y\mid m_1)}{p(y\mid m_2)},
\end{equation}

or equivalently by \eqref{eq:bf-BF},

\begin{equation} \label{eq:bf-odds2}
\frac{p(m_1 \mid y)}{p(m_2 \mid y)} = \frac{p(m_1)}{p(m_2)} \cdot \text{BF}_{12}.
\end{equation}

In other words, the Bayes factor can be viewed as the factor by which the prior model odds are updated (after observing data $y$) to posterior model odds â€“ which is also expressed by Bayes' rule ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:bayes-rule}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Kass, Robert E. and Raftery, Adrian E. (1995): "Bayes Factors"; in: \textit{Journal of the American Statistical Association}, vol. 90, no. 430, pp. 773-795; URL: \url{https://dx.doi.org/10.1080/01621459.1995.10476572}; DOI: 10.1080/01621459.1995.10476572.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D92 | shortcut: bf | author: tomfaulkenberry | date: 2020-08-26, 12:00.
\vspace{1em}



\subsubsection[\textbf{Transitivity}]{Transitivity} \label{sec:bf-trans}
\setcounter{equation}{0}

\textbf{Theorem:} Consider three competing models ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) $m_1$, $m_2$, and $m3$ for observed data $y$. Then the Bayes factor ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:bf}) for $m_1$ over $m_3$ can be written as:

\begin{equation} \label{eq:bf-trans-bf-trans}
\text{BF}_{13} = \text{BF}_{12}\cdot \text{BF}_{23}.
\end{equation}

\vspace{1em}
\textbf{Proof:} By definition ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:bf}), the Bayes factor $\text{BF}_{13}$ is the ratio of marginal likelihoods of data $y$ over $m_1$ and $m_3$, respectively. That is,

\begin{equation} \label{eq:bf-trans-bf}
\text{BF}_{13}=\frac{p(y \mid m_1)}{p(y \mid m_3)}.
\end{equation}

We can equivalently write 

\begin{equation}
\begin{split}
  \text{BF}_{13} &\overset{\eqref{eq:bf-trans-bf}}{=} \frac{p(y \mid m_1)}{p(y \mid m_3)}\\
  &= \frac{p(y \mid m_1)}{p(y \mid m_3)} \cdot \frac{p(y \mid m_2)}{p(y \mid m_2)}\\
  &=\frac{p(y \mid m_1)}{p(y \mid m_2)} \cdot \frac{p(y \mid m_2)}{p(y \mid m_3)}\\
  &\overset{\eqref{eq:bf-trans-bf}}{=}\text{BF}_{12} \cdot \text{BF}_{23},
\end{split}
\end{equation}

which completes the proof of \eqref{eq:bf-trans-bf-trans}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P163 | shortcut: bf-trans | author: tomfaulkenberry | date: 2020-09-07, 12:00.
\vspace{1em}



\subsubsection[\textbf{Computation using Savage-Dickey Density Ratio}]{Computation using Savage-Dickey Density Ratio} \label{sec:bf-sddr}
\setcounter{equation}{0}

\textbf{Theorem:} Consider two competing models ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) on data $y$ containing parameters $\delta$ and $\varphi$, namely $m_0:\delta=\delta_0,\varphi$ and $m_1:\delta,\varphi$. In this context, we say that $\delta$ is a parameter of interest, $\varphi$ is a nuisance parameter (i.e., common to both models), and $m_0$ is a sharp point hypothesis nested within $m_1$. Suppose further that the prior for the nuisance parameter $\varphi$ in $m_0$ is equal to the prior for $\varphi$ in $m_1$ after conditioning on the restriction -- that is, $p(\varphi\mid m_0) = p(\varphi\mid \delta=\delta_0,m_1)$. Then the Bayes factor ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:bf}) for $m_0$ over $m_1$ can be computed as:

\begin{equation} \label{eq:bf-sddr-sd}
\text{BF}_{01} = \frac{p(\delta=\delta_0\mid y,m_1)}{p(\delta=\delta_0\mid m_1)}.
\end{equation}

\vspace{1em}
\textbf{Proof:} By definition ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:bf}), the Bayes factor $\text{BF}_{01}$ is the ratio of marginal likelihoods of data $y$ over $m_0$ and $m_1$, respectively. That is,

\begin{equation} \label{eq:bf-sddr-bf}
\text{BF}_{01}=\frac{p(y \mid m_0)}{p(y \mid m_1)}.
\end{equation}

The key idea in the proof is that we can use a "change of variables" technique to express $\text{BF}_{01}$ entirely in terms of the "encompassing" model $m_1$. This proceeds by first unpacking the marginal likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ml}) for $m_0$ over the nuisance parameter $\varphi$ and then using the fact that $m_0$ is a sharp hypothesis nested within $m_1$ to rewrite everything in terms of $m_1$. Specifically,

\begin{equation} \label{eq:bf-sddr-ml-m0}
\begin{split}
 p(y \mid m_0) &= \int p(y \mid \varphi,m_0) \, p(\varphi\mid m_0) \, \mathrm{d} \varphi \\
  &= \int p(y \mid \varphi,\delta=\delta_0,m_1) \, p(\varphi\mid \delta=\delta_0,m_1) \, \mathrm{d} \varphi \\
  &= p(y \mid \delta=\delta_0,m_1).\\
\end{split}
\end{equation}

By Bayes' theorem ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:bayes-th}), we can rewrite this last line as

\begin{equation} \label{eq:bf-sddr-ml-m0-bt}
p(y \mid \delta=\delta_0,m_1) = \frac{p(\delta=\delta_0\mid y,m_1) \, p(y \mid m_1)}{p(\delta=\delta_0\mid m_1)}.
\end{equation}

Thus we have

\begin{equation} 
\begin{split}
  \text{BF}_{01} &\overset{\eqref{eq:bf-sddr-bf}}{=} \frac{p(y \mid m_0)}{p(y \mid m_1)}\\
  &= p(y \mid m_0) \cdot \frac{1}{p(y \mid m_1)}\\
  &\overset{\eqref{eq:bf-sddr-ml-m0}}{=} p(y \mid \delta=\delta_0,m_1) \cdot \frac{1}{p(y \mid m_1)}\\
  &\overset{\eqref{eq:bf-sddr-ml-m0-bt}}{=} \frac{p(\delta=\delta_0\mid y,m_1) \, p(y \mid m_1)}{p(\delta=\delta_0\mid m_1)} \cdot \frac{1}{p(y \mid m_1)}\\
  &= \frac{p(\delta=\delta_0 \mid y,m_1)}{p(\delta=\delta_0\mid m_1)},
\end{split}
\end{equation}

which completes the proof of \eqref{eq:bf-sddr-sd}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Faulkenberry, Thomas J. (2019): "A tutorial on generalizing the default Bayesian t-test via posterior sampling and encompassing priors"; in: \textit{Communications for Statistical Applications and Methods}, vol. 26, no. 2, pp. 217-238; URL: \url{https://dx.doi.org/10.29220/CSAM.2019.26.2.217}; DOI: 10.29220/CSAM.2019.26.2.217.
\item Penny, W.D. and Ridgway, G.R. (2013): "Efficient Posterior Probability Mapping Using Savage-Dickey Ratios"; in: \textit{PLoS ONE}, vol. 8, iss. 3, art. e59655, eq. 16; URL: \url{https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0059655}; DOI: 10.1371/journal.pone.0059655.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P156 | shortcut: bf-sddr | author: tomfaulkenberry | date: 2020-08-26, 12:00.
\vspace{1em}



\subsubsection[\textbf{Computation using Encompassing Prior Method}]{Computation using Encompassing Prior Method} \label{sec:bf-ep}
\setcounter{equation}{0}

\textbf{Theorem:} Consider two models $m_1$ and $m_e$, where $m_1$ is nested within an encompassing model ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:encm}) $m_e$ via an inequality constraint on some parameter $\theta$, and $\theta$ is unconstrained under $m_e$. Then, the Bayes factor ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:bf}) is

\begin{equation} \label{eq:bf-ep-bf-ep}
  \text{BF}_{1e} = \frac{c}{d} = \frac{1/d}{1/c}
\end{equation}

where $1/d$ and $1/c$ represent the proportions of the posterior and prior of the encompassing model, respectively, that are in agreement with the inequality constraint imposed by the nested model $m_1$.

\vspace{1em}
\textbf{Proof:} Consider first that for any model $m_1$ on data $y$ with parameter $\theta$, Bayes' theorem ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:bayes-th}) implies

\begin{equation} \label{eq:bf-ep-bayesth}
  p(\theta \mid y,m_1) = \frac{p(y \mid \theta,m_1) \cdot p(\theta \mid m_1)}{p(y \mid m_1)}.
\end{equation}

Rearranging equation \eqref{eq:bf-ep-bayesth} allows us to write the marginal likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ml}) for $y$ under $m_1$ as

\begin{equation} \label{eq:bf-ep-marginal}
  p(y \mid m_1) = \frac{p(y \mid \theta,m_1) \cdot p(\theta \mid m_1)}{p(\theta \mid y,m_1)}.
\end{equation}

Taking the ratio of the marginal likelihoods for $m_1$ and the encompassing model ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:encm}) $m_e$ yields the following Bayes factor ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:bf}):

\begin{equation} \label{eq:bf-ep-bayesfactor}
  \text{BF}_{1e} = \frac{p(y \mid \theta,m_1) \cdot p(\theta \mid m_1) / p(\theta \mid y,m_1)}{p(y \mid \theta,m_e) \cdot p(\theta \mid m_e) / p(\theta \mid y,m_e)}.
\end{equation}

Now, both the constrained model $m_1$ and the encompassing model ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:encm}) $m_e$ contain the same parameter vector $\theta$. Choose a specific value of $\theta$, say $\theta'$, that exists in the support of both models $m_1$ and $m_e$ (we can do this, because $m_1$ is nested within $m_e$). Then, for this parameter value $\theta'$, we have $p(y \mid \theta',m_1)=p(y \mid \theta',m_e)$, so the expression for the Bayes factor in equation \eqref{eq:bf-ep-bayesfactor} reduces to an expression involving only the priors and posteriors for $\theta'$ under $m_1$ and $m_e$:

\begin{equation} \label{eq:bf-ep-bayesfactor2}
  \text{BF}_{1e} = \frac{p(\theta' \mid m_1) / p(\theta' \mid y,m_1)}{p(\theta' \mid m_e) / p(\theta' \mid y,m_e)}.
\end{equation}

Because $m_1$ is nested within $m_e$ via an inequality constraint, the prior $p(\theta' \mid m_1)$ is simply a truncation of the encompassing prior $p(\theta' \mid m_e)$. Thus, we can express $p(\theta' \mid m_1)$ in terms of the encompassing prior $p(\theta' \mid m_e)$ by multiplying the encompassing prior by an indicator function over $m_1$ and then normalizing the resulting product.  That is,

\begin{equation} \label{eq:bf-ep-normalize}
\begin{split}
  p(\theta' \mid m_1) & = \frac{p(\theta' \mid m_e) \cdot I_{\theta' \in m_1}}{\int p(\theta' \mid m_e) \cdot I_{\theta' \in m_1} \, \mathrm{d}\theta'}\\
                      & = \Biggl(\frac{I_{\theta' \in m_1}}{\int p(\theta' \mid m_e) \cdot I_{\theta' \in m_1} \, \mathrm{d}\theta'}\Biggr) \cdot p(\theta' \mid m_e),
\end{split}
\end{equation}

where $I_{\theta' \in m_1}$ is an indicator function. For parameters $\theta' \in m_1$, this indicator function is identically equal to 1, so the expression in parentheses reduces to a constant, say $c$, allowing us to write the prior as

\begin{equation} \label{eq:bf-ep-prior}
  p(\theta' \mid m_1) = c \cdot p(\theta' \mid m_e).
\end{equation}

By similar reasoning, we can write the posterior as

\begin{equation} \label{eq:bf-ep-posterior}
  p(\theta' \mid y,m_1) = \Biggl(\frac{I_{\theta' \in m_1}}{\int p(\theta' \mid y,m_e) \cdot I_{\theta' \in m_1} \, \mathrm{d}\theta'}\Biggr)\cdot p(\theta' \mid y,m_e) = d \cdot p(\theta' \mid y,m_e).
\end{equation}

Plugging \eqref{eq:bf-ep-prior} and \eqref{eq:bf-ep-posterior} into \eqref{eq:bf-ep-bayesfactor2}, this gives us

\begin{equation} \label{eq:bf-ep-bayesfactor3}
  \text{BF}_{1e} = \frac{c \cdot p(\theta' \mid m_e) / d \cdot p(\theta' \mid y,m_e)}{p(\theta' \mid m_e) / p(\theta' \mid y,m_e)} = \frac{c}{d} = \frac{1/d}{1/c},
\end{equation}

which completes the proof. Note that by definition, $1/d$ represents the proportion of the posterior distribution for $\theta$ under the encompassing model ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:encm}) $m_e$ that agrees with the constraints imposed by $m_1$.  Similarly, $1/c$ represents the proportion of the prior distribution for $\theta$ under the encompassing model ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:encm}) $m_e$ that agrees with the constraints imposed by $m_1$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Klugkist, I., Kato, B., and Hoijtink, H. (2005): "Bayesian model selection using encompassing priors"; in: \textit{Statistica Neerlandica}, vol. 59, no. 1., pp. 57-69; URL: \url{https://dx.doi.org/10.1111/j.1467-9574.2005.00279.x}; DOI: 10.1111/j.1467-9574.2005.00279.x.
\item Faulkenberry, Thomas J. (2019): "A tutorial on generalizing the default Bayesian t-test via posterior sampling and encompassing priors"; in: \textit{Communications for Statistical Applications and Methods}, vol. 26, no. 2, pp. 217-238; URL: \url{https://dx.doi.org/10.29220/CSAM.2019.26.2.217}; DOI: 10.29220/CSAM.2019.26.2.217.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P157 | shortcut: bf-ep | author: tomfaulkenberry | date: 2020-09-02, 12:00.
\vspace{1em}



\subsubsection[\textit{Encompassing model}]{Encompassing model} \label{sec:encm}
\setcounter{equation}{0}

\textbf{Definition:} Consider a family $f$ of generative models ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) $m$ on data $y$, where each $m \in f$ is defined by placing an inequality constraint on model parameter(s) $\theta$ (e.g., $m:\theta>0$). Then the encompassing model $m_e$ is constructed such that each $m$ is nested within $m_e$ and all inequality constraints on the parameter(s) $\theta$ are removed.



\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Klugkist, I., Kato, B., and Hoijtink, H. (2005): "Bayesian model selection using encompassing priors"; in: \textit{Statistica Neerlandica}, vol. 59, no. 1, pp. 57-69; URL: \url{https://dx.doi.org/10.1111/j.1467-9574.2005.00279.x}; DOI: 10.1111/j.1467-9574.2005.00279.x.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D93 | shortcut: encm | author: tomfaulkenberry | date: 2020-09-02, 12:00.
\vspace{1em}



\subsection{Posterior model probability}

\subsubsection[\textit{Definition}]{Definition} \label{sec:pmp}
\setcounter{equation}{0}

\textbf{Definition:} Let $m_1, \ldots, m_M$ be $M$ statistical models ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:fpm}) with model evidences ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ml}) $p(y \vert m_1), \ldots, p(y \vert m_M)$ and prior probabilities ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior})  $p(m_1), \ldots, p(m_M)$. Then, the conditional probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-cond}) of model $m_i$, given the data $y$, is called the posterior probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) of model $m_i$:

\begin{equation} \label{eq:pmp-PMP}
\mathrm{PP}(m_i) = p(m_i|y) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Soch J, Allefeld C (2018): "MACS â€“ a new SPM toolbox for model assessment, comparison and selection"; in: \textit{Journal of Neuroscience Methods}, vol. 306, pp. 19-31, eq. 23; URL: \url{https://www.sciencedirect.com/science/article/pii/S0165027018301468}; DOI: 10.1016/j.jneumeth.2018.05.017.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D87 | shortcut: pmp | author: JoramSoch | date: 2020-07-28, 03:30.
\vspace{1em}



\subsubsection[\textbf{Derivation}]{Derivation} \label{sec:pmp-der}
\setcounter{equation}{0}

\textbf{Theorem:} Let there be a set of generative models ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) $m_1, \ldots, m_M$ with model evidences ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ml}) $p(y \vert m_1), \ldots, p(y \vert m_M)$ and prior probabilities ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior})  $p(m_1), \ldots, p(m_M)$. Then, the posterior probability ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:pmp}) of model $m_i$ is given by

\begin{equation} \label{eq:pmp-der-PMP}
p(m_i|y) = \frac{p(y|m_i) \, p(m_i)}{\sum_{j=1}^{M} p(y|m_j) \, p(m_j)}, \; i = 1, \ldots, M \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} From Bayes' theorem ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:bayes-th}), the posterior model probability ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:pmp}) of the $i$-th model can be derived as

\begin{equation} \label{eq:pmp-der-PMP-s1}
p(m_i|y) = \frac{p(y|m_i) \, p(m_i)}{p(y)} \; .
\end{equation}

Using the law of marginal probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}), the denominator can be rewritten, such that

\begin{equation} \label{eq:pmp-der-PMP-s2}
p(m_i|y) = \frac{p(y|m_i) \, p(m_i)}{\sum_{j=1}^{M} p(y,m_j)} \; .
\end{equation}

Finally, using the law of conditional probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-cond}), we have

\begin{equation} \label{eq:pmp-der-PMP-s3}
p(m_i|y) = \frac{p(y|m_i) \, p(m_i)}{\sum_{j=1}^{M} p(y|m_j) \, p(m_j)} \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P139 | shortcut: pmp-der | author: JoramSoch | date: 2020-07-28, 03:58.
\vspace{1em}



\subsubsection[\textbf{Calculation from Bayes factors}]{Calculation from Bayes factors} \label{sec:pmp-bf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $m_0, m_1, \ldots, m_M$ be $M+1$ statistical models with model evidences ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme}) $p(y \vert m_0), p(y \vert m_1), \ldots, p(y \vert m_M)$. Then, the posterior model probabilities ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:pmp}) of the models $m_1, \ldots, m_M$ are given by

\begin{equation} \label{eq:pmp-bf-PMP-BF}
p(m_i|y) = \frac{\mathrm{BF}_{i,0} \cdot \alpha_i}{\sum_{j=1}^{M} \mathrm{BF}_{j,0} \cdot \alpha_j}, \quad i = 1,\ldots,M \; ,
\end{equation}

where $\mathrm{BF}_{i,0}$ is the Bayes factor ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:bf}) comparing model $m_i$ with $m_0$ and $\alpha_i$ is the prior ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) odds ratio ($\rightarrow$ Definition "odds") of model $m_i$ against $m_0$.


\vspace{1em}
\textbf{Proof:} Define the Bayes factor ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:bf}) for $m_i$

\begin{equation} \label{eq:pmp-bf-BF-i0}
\mathrm{BF}_{i,0} = \frac{p(y|m_i)}{p(y|m_0)}
\end{equation}

and prior odds ratio of $m_i$ against $m_0$

\begin{equation} \label{eq:pmp-bf-prior-i0}
\alpha_i = \frac{p(m_i)}{p(m_0)} \; .
\end{equation}

The posterior model probability ($\rightarrow$ Proof \ref{sec:Model Selection}/\ref{sec:pmp-der}) of $m_i$ is given by

\begin{equation} \label{eq:pmp-bf-PMP-s1}
p(m_i|y) = \frac{p(y|m_i) \cdot p(m_i)}{\sum_{j=1}^{M} p(y|m_j) \cdot p(m_j)} \; .
\end{equation}

Now applying \eqref{eq:pmp-bf-BF-i0} and \eqref{eq:pmp-bf-prior-i0} to \eqref{eq:pmp-bf-PMP-s1}, we have

\begin{equation} \label{eq:pmp-bf-PMP-s2}
\begin{split}
p(m_i|y) &= \frac{ \mathrm{BF}_{i,0} \, p(y|m_0) \cdot \alpha_i \, p(m_0)}{\sum_{j=1}^{M} \mathrm{BF}_{j,0} \, p(y|m_0) \cdot \alpha_j \, p(m_0)} \\
&= \frac{\left[ p(y|m_0) \, p(m_0) \right] \mathrm{BF}_{i,0} \cdot \alpha_i}{\left[ p(y|m_0) \, p(m_0) \right] \sum_{j=1}^{M} \mathrm{BF}_{j,0} \cdot \alpha_j} \; ,
\end{split}
\end{equation}

such that

\begin{equation} \label{eq:pmp-bf-PMP-BF-qed}
p(m_i|y)= \frac{\mathrm{BF}_{i,0} \cdot \alpha_i}{\sum_{j=1}^{M} \mathrm{BF}_{j,0} \cdot \alpha_j} \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Hoeting JA, Madigan D, Raftery AE, Volinsky CT (1999): "Bayesian Model Averaging: A Tutorial"; in: \textit{Statistical Science}, vol. 14, no. 4, pp. 382â€“417, eq. 9; URL: \url{https://projecteuclid.org/euclid.ss/1009212519}; DOI: 10.1214/ss/1009212519.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P74 | shortcut: pmp-bf | author: JoramSoch | date: 2020-03-03, 13:13.
\vspace{1em}



\subsubsection[\textbf{Calculation from log Bayes factor}]{Calculation from log Bayes factor} \label{sec:pmp-lbf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $m_1$ and $m_2$ be two statistical models with the log Bayes factor ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lbf}) $\mathrm{LBF}_{12}$ in favor of model $m_1$ and against model $m_2$. Then, if both models are equally likely apriori ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}), the posterior model probability ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:pmp}) of $m_1$ is

\begin{equation} \label{eq:pmp-lbf-PMP-LBF}
p(m_1|y) = \frac{\exp(\mathrm{LBF}_{12})}{\exp(\mathrm{LBF}_{12}) + 1} \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} From Bayes' rule ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:bayes-rule}), the posterior odds ratio ($\rightarrow$ Definition "odds") is

\begin{equation} \label{eq:pmp-lbf-post-odds-s1}
\frac{p(m_1|y)}{p(m_2|y)} = \frac{p(y|m_1)}{p(y|m_2)} \cdot \frac{p(m_1)}{p(m_2)} \; .
\end{equation}

When both models are equally likely apriori ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}), the prior odds ratio ($\rightarrow$ Definition "odds") is one, such that

\begin{equation} \label{eq:pmp-lbf-post-odds-s2}
\frac{p(m_1|y)}{p(m_2|y)} = \frac{p(y|m_1)}{p(y|m_2)} \; .
\end{equation}

Now the right-hand side corresponds to the Bayes factor ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:bf}), therefore

\begin{equation} \label{eq:pmp-lbf-post-odds-s4}
\frac{p(m_1|y)}{p(m_2|y)} = \mathrm{BF}_{12} \; .
\end{equation}

Because the two posterior model probabilities ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:pmp}) add up to 1, we have

\begin{equation} \label{eq:pmp-lbf-post-odds-s3}
\frac{p(m_1|y)}{1-p(m_1|y)} = \mathrm{BF}_{12} \; .
\end{equation}

Now rearranging for the posterior probability ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:pmp}), this gives

\begin{equation} \label{eq:pmp-lbf-post-s1}
p(m_1|y) = \frac{\mathrm{BF}_{12}}{\mathrm{BF}_{12} + 1} \; .
\end{equation}

Because the log Bayes factor is the logarithm of the Bayes factor ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lbf}), we finally have

\begin{equation} \label{eq:pmp-lbf-post-s2}
p(m_1|y) = \frac{\exp(\mathrm{LBF}_{12})}{\exp(\mathrm{LBF}_{12}) + 1} \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Soch J, Allefeld C (2018): "MACS â€“ a new SPM toolbox for model assessment, comparison and selection"; in: \textit{Journal of Neuroscience Methods}, vol. 306, pp. 19-31, eq. 21; URL: \url{https://www.sciencedirect.com/science/article/pii/S0165027018301468}; DOI: 10.1016/j.jneumeth.2018.05.017.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P73 | shortcut: pmp-lbf | author: JoramSoch | date: 2020-03-03, 12:27.
\vspace{1em}



\subsubsection[\textbf{Calculation from log model evidences}]{Calculation from log model evidences} \label{sec:pmp-lme}
\setcounter{equation}{0}

\textbf{Theorem:} Let $m_1, \ldots, m_M$ be $M$ statistical models with log model evidences ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme}) $\mathrm{LME}(m_1), \ldots, \mathrm{LME}(m_M)$. Then, the posterior model probabilities ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:pmp}) are given by:

\begin{equation} \label{eq:pmp-lme-PMP-LME}
p(m_i|y) = \frac{\exp[\mathrm{LME}(m_i)] \, p(m_i)}{\sum_{j=1}^{M} \exp[\mathrm{LME}(m_j)] \, p(m_j)}, \quad i = 1,\ldots,M \; ,
\end{equation}

where $p(m_i)$ are prior ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) model probabilities.


\vspace{1em}
\textbf{Proof:} The posterior model probability ($\rightarrow$ Proof \ref{sec:Model Selection}/\ref{sec:pmp-der}) can be derived as

\begin{equation} \label{eq:pmp-lme-PMP-s1}
p(m_i|y) = \frac{p(y|m_i) \, p(m_i)}{\sum_{j=1}^{M} p(y|m_j) \, p(m_j)} \; .
\end{equation}

The definition of the log model evidence ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme})

\begin{equation} \label{eq:pmp-lme-LME}
\mathrm{LME}(m) = \log p(y|m)
\end{equation}

can be exponentiated to then read

\begin{equation} \label{eq:pmp-lme-ME}
\exp\left[ \mathrm{LME}(m) \right] = p(y|m)
\end{equation}

and applying \eqref{eq:pmp-lme-ME} to \eqref{eq:pmp-lme-PMP-s1}, we finally have:

\begin{equation} \label{eq:pmp-lme-PMP-s2}
p(m_i|y) = \frac{\exp[\mathrm{LME}(m_i)] \, p(m_i)}{\sum_{j=1}^{M} \exp[\mathrm{LME}(m_j)] \, p(m_j)} \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Soch J, Allefeld C (2018): "MACS â€“ a new SPM toolbox for model assessment, comparison and selection"; in: \textit{Journal of Neuroscience Methods}, vol. 306, pp. 19-31, eq. 23; URL: \url{https://www.sciencedirect.com/science/article/pii/S0165027018301468}; DOI: 10.1016/j.jneumeth.2018.05.017.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P66 | shortcut: pmp-lme | author: JoramSoch | date: 2020-02-27, 21:33.
\vspace{1em}



\subsection{Bayesian model averaging}

\subsubsection[\textit{Definition}]{Definition} \label{sec:bma}
\setcounter{equation}{0}

\textbf{Definition:} Let $m_1, \ldots, m_M$ be $M$ statistical models ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:fpm}) with posterior model probabilities ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:pmp}) $p(m_1 \vert y), \ldots, p(m_M \vert y)$ and posterior distributions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) $p(\theta \vert y, m_1), \ldots, p(\theta \vert y, m_M)$. Then, Bayesian model averaging (BMA) consists in finding the marginal ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-marg}) posterior ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) density ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}), conditional ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-cond}) on the measured data $y$, but unconditional ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}) on the modelling approach $m$:

\begin{equation} \label{eq:bma-BMA}
p(\theta|y) = \sum_{i=1}^{M} p(\theta|y,m_i) \cdot p(m_i|y) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Hoeting JA, Madigan D, Raftery AE, Volinsky CT (1999): "Bayesian Model Averaging: A Tutorial"; in: \textit{Statistical Science}, vol. 14, no. 4, pp. 382â€“417, eq. 1; URL: \url{https://projecteuclid.org/euclid.ss/1009212519}; DOI: 10.1214/ss/1009212519.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D89 | shortcut: bma | author: JoramSoch | date: 2020-08-03, 21:34.
\vspace{1em}



\subsubsection[\textbf{Derivation}]{Derivation} \label{sec:bma-der}
\setcounter{equation}{0}

\textbf{Theorem:} Let $m_1, \ldots, m_M$ be $M$ statistical models ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:fpm}) with posterior model probabilities ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:pmp}) $p(m_1 \vert y), \ldots, p(m_M \vert y)$ and posterior distributions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) $p(\theta \vert y, m_1), \ldots, p(\theta \vert y, m_M)$. Then, the marginal ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-marg}) posterior ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) density ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}), conditional ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-cond}) on the measured data $y$, but unconditional ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}) on the modelling approach $m$, is given by:

\begin{equation} \label{eq:bma-der-BMA}
p(\theta|y) = \sum_{i=1}^{M} p(\theta|y,m_i) \cdot p(m_i|y) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} Using the law of marginal probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}), the probability distribution of the shared parameters $\theta$ conditional ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-cond}) on the measured data $y$ can be obtained by marginalizing ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}) over the discrete random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) model $m$:

\begin{equation} \label{eq:bma-der-BMA-s1}
p(\theta|y) = \sum_{i=1}^{M} p(\theta,m_i|y) \; .
\end{equation}

Using the law of the conditional probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-cond}), the summand can be expanded to give

\begin{equation} \label{eq:bma-der-BMA-s2}
p(\theta|y) = \sum_{i=1}^{M} p(\theta|y,m_i) \cdot p(m_i|y)
\end{equation}

where $p(\theta \vert y,m_i)$ is the posterior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) of the $i$-th model and $p(m_i \vert y)$ happens to be the posterior probability ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:pmp}) of the $i$-th model.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P143 | shortcut: bma-der | author: JoramSoch | date: 2020-08-03, 22:05.
\vspace{1em}



\subsubsection[\textbf{Calculation from log model evidences}]{Calculation from log model evidences} \label{sec:bma-lme}
\setcounter{equation}{0}

\textbf{Theorem:} Let $m_1, \ldots, m_M$ be $M$ statistical models ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:fpm}) describing the same measured data $y$ with log model evidences ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme}) $\mathrm{LME}(m_1), \ldots, \mathrm{LME}(m_M)$ and shared model parameters $\theta$. Then, Bayesian model averaging ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:bma}) determines the following posterior distribution over $\theta$:

\begin{equation} \label{eq:bma-lme-BMA-LME}
p(\theta|y) = \sum_{i=1}^{M} p(\theta|m_i,y) \cdot \frac{\exp[\mathrm{LME}(m_i)] \, p(m_i)}{\sum_{j=1}^{M} \exp[\mathrm{LME}(m_j)] \, p(m_j)} \; ,
\end{equation}

where $p(\theta \vert m_i,y)$ is the posterior distributions over $\theta$ obtained using $m_i$.


\vspace{1em}
\textbf{Proof:} According to the law of marginal probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}), the probability of the shared parameters $\theta$ conditional on the measured data $y$ can be obtained ($\rightarrow$ Proof \ref{sec:Model Selection}/\ref{sec:bma-der}) by marginalizing over the discrete variable model $m$:

\begin{equation} \label{eq:bma-lme-BMA-PMP}
p(\theta|y) = \sum_{i=1}^{M} p(\theta|m_i,y) \cdot p(m_i|y) \; ,
\end{equation}

where $p(m_i \vert y)$ is the posterior probability ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:pmp}) of the $i$-th model. One can express posterior model probabilities in terms of log model evidences ($\rightarrow$ Proof \ref{sec:Model Selection}/\ref{sec:pmp-lme}) as

\begin{equation} \label{eq:bma-lme-PMP-LME}
p(m_i|y) = \frac{\exp[\mathrm{LME}(m_i)] \, p(m_i)}{\sum_{j=1}^{M} \exp[\mathrm{LME}(m_j)] \, p(m_j)}
\end{equation}

and by plugging \eqref{eq:bma-lme-PMP-LME} into \eqref{eq:bma-lme-BMA-PMP}, one arrives at \eqref{eq:bma-lme-BMA-LME}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Soch J, Allefeld C (2018): "MACS â€“ a new SPM toolbox for model assessment, comparison and selection"; in: \textit{Journal of Neuroscience Methods}, vol. 306, pp. 19-31, eq. 25; URL: \url{https://www.sciencedirect.com/science/article/pii/S0165027018301468}; DOI: 10.1016/j.jneumeth.2018.05.017.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P67 | shortcut: bma-lme | author: JoramSoch | date: 2020-02-27, 21:58.
\vspace{1em}



% Appendix %
\chapter{Appendix} \label{sec:Appendix} \newpage

\pagebreak
\section{Proof by Number}

\begin{longtable}{|p{1cm}|p{2cm}|p{6.5cm}|p{3cm}|p{2cm}|c|}
\hline
\textbf{ID} & \textbf{Shortcut} & \textbf{Theorem} & \textbf{Author} & \textbf{Date} & \textbf{Page} \\ \hline
P1 & mvn-ltt & Linear transformation theorem for the multivariate normal distribution & JoramSoch & 2019-08-27 & \pageref{sec:mvn-ltt} \\ \hline
P2 & mlr-ols & Ordinary least squares for multiple linear regression & JoramSoch & 2019-09-27 & \pageref{sec:mlr-ols} \\ \hline
P3 & lme-anc & Partition of the log model evidence into accuracy and complexity & JoramSoch & 2019-09-27 & \pageref{sec:lme-anc} \\ \hline
P4 & bayes-th & Bayes' theorem & JoramSoch & 2019-09-27 & \pageref{sec:bayes-th} \\ \hline
P5 & mse-bnv & Partition of the mean squared error into bias and variance & JoramSoch & 2019-11-27 & \pageref{sec:mse-bnv} \\ \hline
P6 & ng-kl & Kullback-Leibler divergence for the normal-gamma distribution & JoramSoch & 2019-12-06 & \pageref{sec:ng-kl} \\ \hline
P7 & glm-mle & Maximum likelihood estimation for the general linear model & JoramSoch & 2019-12-06 & \pageref{sec:glm-mle} \\ \hline
P8 & rsq-der & Derivation of RÂ² and adjusted RÂ² & JoramSoch & 2019-12-06 & \pageref{sec:rsq-der} \\ \hline
P9 & blr-prior & Conjugate prior distribution for Bayesian linear regression & JoramSoch & 2020-01-03 & \pageref{sec:blr-prior} \\ \hline
P10 & blr-post & Posterior distribution for Bayesian linear regression & JoramSoch & 2020-01-03 & \pageref{sec:blr-post} \\ \hline
P11 & blr-lme & Log model evidence for Bayesian linear regression & JoramSoch & 2020-01-03 & \pageref{sec:blr-lme} \\ \hline
P12 & bayes-rule & Bayes' rule & JoramSoch & 2020-01-06 & \pageref{sec:bayes-rule} \\ \hline
P13 & lme-der & Derivation of the log model evidence & JoramSoch & 2020-01-06 & \pageref{sec:lme-der} \\ \hline
P14 & rsq-mll & Relationship between RÂ² and maximum log-likelihood & JoramSoch & 2020-01-08 & \pageref{sec:rsq-mll} \\ \hline
P15 & norm-mean & Mean of the normal distribution & JoramSoch & 2020-01-09 & \pageref{sec:norm-mean} \\ \hline
P16 & norm-med & Median of the normal distribution & JoramSoch & 2020-01-09 & \pageref{sec:norm-med} \\ \hline
P17 & norm-mode & Mode of the normal distribution & JoramSoch & 2020-01-09 & \pageref{sec:norm-mode} \\ \hline
P18 & norm-var & Variance of the normal distribution & JoramSoch & 2020-01-09 & \pageref{sec:norm-var} \\ \hline
P19 & dmi-mce & Relation of mutual information to marginal and conditional entropy & JoramSoch & 2020-01-13 & \pageref{sec:dmi-mce} \\ \hline
P20 & dmi-mje & Relation of mutual information to marginal and joint entropy & JoramSoch & 2020-01-13 & \pageref{sec:dmi-mje} \\ \hline
P21 & dmi-jce & Relation of mutual information to joint and conditional entropy & JoramSoch & 2020-01-13 & \pageref{sec:dmi-jce} \\ \hline
P22 & bern-mean & Mean of the Bernoulli distribution & JoramSoch & 2020-01-16 & \pageref{sec:bern-mean} \\ \hline
P23 & bin-mean & Mean of the binomial distribution & JoramSoch & 2020-01-16 & \pageref{sec:bin-mean} \\ \hline
P24 & cat-mean & Mean of the categorical distribution & JoramSoch & 2020-01-16 & \pageref{sec:cat-mean} \\ \hline
P25 & mult-mean & Mean of the multinomial distribution & JoramSoch & 2020-01-16 & \pageref{sec:mult-mean} \\ \hline
P26 & matn-mvn & Equivalence of matrix-normal distribution and multivariate normal distribution & JoramSoch & 2020-01-20 & \pageref{sec:matn-mvn} \\ \hline
P27 & poiss-mle & Maximum likelihood estimation for Poisson-distributed data & JoramSoch & 2020-01-20 & \pageref{sec:poiss-mle} \\ \hline
P28 & beta-mome & Method of moments for beta-distributed data & JoramSoch & 2020-01-22 & \pageref{sec:beta-mome} \\ \hline
P29 & bin-prior & Conjugate prior distribution for binomial observations & JoramSoch & 2020-01-23 & \pageref{sec:bin-prior} \\ \hline
P30 & bin-post & Posterior distribution for binomial observations & JoramSoch & 2020-01-24 & \pageref{sec:bin-post} \\ \hline
P31 & bin-lme & Log model evidence for binomial observations & JoramSoch & 2020-01-24 & \pageref{sec:bin-lme} \\ \hline
P32 & bic-der & Derivation of the Bayesian information criterion & JoramSoch & 2020-01-26 & \pageref{sec:bic-der} \\ \hline
P33 & norm-pdf & Probability density function of the normal distribution & JoramSoch & 2020-01-27 & \pageref{sec:norm-pdf} \\ \hline
P34 & mvn-pdf & Probability density function of the multivariate normal distribution & JoramSoch & 2020-01-27 & \pageref{sec:mvn-pdf} \\ \hline
P35 & mvn-marg & Marginal distributions of the multivariate normal distribution & JoramSoch & 2020-01-29 & \pageref{sec:mvn-marg} \\ \hline
P36 & ng-marg & Marginal distributions of the normal-gamma distribution & JoramSoch & 2020-01-29 & \pageref{sec:ng-marg} \\ \hline
P37 & cuni-pdf & Probability density function of the continuous uniform distribution & JoramSoch & 2020-01-31 & \pageref{sec:cuni-pdf} \\ \hline
P38 & cuni-cdf & Cumulative distribution function of the continuous uniform distribution & JoramSoch & 2020-01-02 & \pageref{sec:cuni-cdf} \\ \hline
P39 & cuni-qf & Quantile function of the continuous uniform distribution & JoramSoch & 2020-01-02 & \pageref{sec:cuni-qf} \\ \hline
P40 & mlr-ols2 & Ordinary least squares for multiple linear regression & JoramSoch & 2020-02-03 & \pageref{sec:mlr-ols2} \\ \hline
P41 & poissexp-prior & Conjugate prior distribution for the Poisson distribution with exposure values & JoramSoch & 2020-02-04 & \pageref{sec:poissexp-prior} \\ \hline
P42 & poissexp-post & Posterior distribution for the Poisson distribution with exposure values & JoramSoch & 2020-02-04 & \pageref{sec:poissexp-post} \\ \hline
P43 & poissexp-lme & Log model evidence for the Poisson distribution with exposure values & JoramSoch & 2020-02-04 & \pageref{sec:poissexp-lme} \\ \hline
P44 & ng-pdf & Probability density function of the normal-gamma distribution & JoramSoch & 2020-02-07 & \pageref{sec:ng-pdf} \\ \hline
P45 & gam-pdf & Probability density function of the gamma distribution & JoramSoch & 2020-02-08 & \pageref{sec:gam-pdf} \\ \hline
P46 & exp-pdf & Probability density function of the exponential distribution & JoramSoch & 2020-02-08 & \pageref{sec:exp-pdf} \\ \hline
P47 & exp-mean & Mean of the exponential distribution & JoramSoch & 2020-02-10 & \pageref{sec:exp-mean} \\ \hline
P48 & exp-cdf & Cumulative distribution function of the exponential distribution & JoramSoch & 2020-02-11 & \pageref{sec:exp-cdf} \\ \hline
P49 & exp-med & Median of the exponential distribution & JoramSoch & 2020-02-11 & \pageref{sec:exp-med} \\ \hline
P50 & exp-qf & Quantile function of the exponential distribution & JoramSoch & 2020-02-12 & \pageref{sec:exp-qf} \\ \hline
P51 & exp-mode & Mode of the exponential distribution & JoramSoch & 2020-02-12 & \pageref{sec:exp-mode} \\ \hline
P52 & mean-nonneg & Non-negativity of the expected value & JoramSoch & 2020-02-13 & \pageref{sec:mean-nonneg} \\ \hline
P53 & mean-lin & Linearity of the expected value & JoramSoch & 2020-02-13 & \pageref{sec:mean-lin} \\ \hline
P54 & mean-mono & Monotonicity of the expected value & JoramSoch & 2020-02-17 & \pageref{sec:mean-mono} \\ \hline
P55 & mean-mult & (Non-)Multiplicativity of the expected value & JoramSoch & 2020-02-17 & \pageref{sec:mean-mult} \\ \hline
P56 & ci-wilks & Construction of confidence intervals using Wilks' theorem & JoramSoch & 2020-02-19 & \pageref{sec:ci-wilks} \\ \hline
P57 & ent-nonneg & Non-negativity of the Shannon entropy & JoramSoch & 2020-02-19 & \pageref{sec:ent-nonneg} \\ \hline
P58 & cmi-mcde & Relation of continuous mutual information to marginal and conditional differential entropy & JoramSoch & 2020-02-21 & \pageref{sec:cmi-mcde} \\ \hline
P59 & cmi-mjde & Relation of continuous mutual information to marginal and joint differential entropy & JoramSoch & 2020-02-21 & \pageref{sec:cmi-mjde} \\ \hline
P60 & cmi-jcde & Relation of continuous mutual information to joint and conditional differential entropy & JoramSoch & 2020-02-21 & \pageref{sec:cmi-jcde} \\ \hline
P61 & resvar-bias & Maximum likelihood estimator of variance is biased & JoramSoch & 2020-02-24 & \pageref{sec:resvar-bias} \\ \hline
P62 & resvar-unb & Construction of unbiased estimator for variance & JoramSoch & 2020-02-25 & \pageref{sec:resvar-unb} \\ \hline
P63 & snr-rsq & Relationship between signal-to-noise ratio and RÂ² & JoramSoch & 2020-02-26 & \pageref{sec:snr-rsq} \\ \hline
P64 & lbf-lme & Log Bayes factor in terms of log model evidences & JoramSoch & 2020-02-27 & \pageref{sec:lbf-lme} \\ \hline
P65 & lfe-lme & Log family evidences in terms of log model evidences & JoramSoch & 2020-02-27 & \pageref{sec:lfe-lme} \\ \hline
P66 & pmp-lme & Posterior model probabilities in terms of log model evidences & JoramSoch & 2020-02-27 & \pageref{sec:pmp-lme} \\ \hline
P67 & bma-lme & Bayesian model averaging in terms of log model evidences & JoramSoch & 2020-02-27 & \pageref{sec:bma-lme} \\ \hline
P68 & dent-neg & Differential entropy can be negative & JoramSoch & 2020-03-02 & \pageref{sec:dent-neg} \\ \hline
P69 & exp-gam & Exponential distribution is a special case of gamma distribution & JoramSoch & 2020-03-02 & \pageref{sec:exp-gam} \\ \hline
P70 & matn-pdf & Probability density function of the matrix-normal distribution & JoramSoch & 2020-03-02 & \pageref{sec:matn-pdf} \\ \hline
P71 & norm-mgf & Moment-generating function of the normal distribution & JoramSoch & 2020-03-03 & \pageref{sec:norm-mgf} \\ \hline
P72 & logreg-lonp & Log-odds and probability in logistic regression & JoramSoch & 2020-03-03 & \pageref{sec:logreg-lonp} \\ \hline
P73 & pmp-lbf & Posterior model probability in terms of log Bayes factor & JoramSoch & 2020-03-03 & \pageref{sec:pmp-lbf} \\ \hline
P74 & pmp-bf & Posterior model probabilities in terms of Bayes factors & JoramSoch & 2020-03-03 & \pageref{sec:pmp-bf} \\ \hline
P75 & mlr-mat & Transformation matrices for ordinary least squares & JoramSoch & 2020-03-09 & \pageref{sec:mlr-mat} \\ \hline
P76 & mlr-pss & Partition of sums of squares in ordinary least squares & JoramSoch & 2020-03-09 & \pageref{sec:mlr-pss} \\ \hline
P77 & mlr-wls & Weighted least squares for multiple linear regression & JoramSoch & 2020-03-11 & \pageref{sec:mlr-wls} \\ \hline
P78 & mlr-mle & Maximum likelihood estimation for multiple linear regression & JoramSoch & 2020-03-11 & \pageref{sec:mlr-mle} \\ \hline
P79 & mult-prior & Conjugate prior distribution for multinomial observations & JoramSoch & 2020-03-11 & \pageref{sec:mult-prior} \\ \hline
P80 & mult-post & Posterior distribution for multinomial observations & JoramSoch & 2020-03-11 & \pageref{sec:mult-post} \\ \hline
P81 & mult-lme & Log model evidence for multinomial observations & JoramSoch & 2020-03-11 & \pageref{sec:mult-lme} \\ \hline
P82 & cuni-mean & Mean of the continuous uniform distribution & JoramSoch & 2020-03-16 & \pageref{sec:cuni-mean} \\ \hline
P83 & cuni-med & Median of the continuous uniform distribution & JoramSoch & 2020-03-16 & \pageref{sec:cuni-med} \\ \hline
P84 & cuni-med & Mode of the continuous uniform distribution & JoramSoch & 2020-03-16 & \pageref{sec:cuni-med} \\ \hline
P85 & norm-cdf & Cumulative distribution function of the normal distribution & JoramSoch & 2020-03-20 & \pageref{sec:norm-cdf} \\ \hline
P86 & norm-cdfwerf & Expression of the cumulative distribution function of the normal distribution without the error function & JoramSoch & 2020-03-20 & \pageref{sec:norm-cdfwerf} \\ \hline
P87 & norm-qf & Quantile function of the normal distribution & JoramSoch & 2020-03-20 & \pageref{sec:norm-qf} \\ \hline
P88 & mvn-cond & Conditional distributions of the multivariate normal distribution & JoramSoch & 2020-03-20 & \pageref{sec:mvn-cond} \\ \hline
P89 & jl-lfnprior & Joint likelihood is the product of likelihood function and prior density & JoramSoch & 2020-05-05 & \pageref{sec:jl-lfnprior} \\ \hline
P90 & post-jl & Posterior density is proportional to joint likelihood & JoramSoch & 2020-05-05 & \pageref{sec:post-jl} \\ \hline
P91 & ml-jl & Marginal likelihood is a definite integral of joint likelihood & JoramSoch & 2020-05-05 & \pageref{sec:ml-jl} \\ \hline
P92 & mvn-kl & Kullback-Leibler divergence for the multivariate normal distribution & JoramSoch & 2020-05-05 & \pageref{sec:mvn-kl} \\ \hline
P93 & gam-kl & Kullback-Leibler divergence for the gamma distribution & JoramSoch & 2020-05-05 & \pageref{sec:gam-kl} \\ \hline
P94 & beta-pdf & Probability density function of the beta distribution & JoramSoch & 2020-05-05 & \pageref{sec:beta-pdf} \\ \hline
P95 & dir-pdf & Probability density function of the Dirichlet distribution & JoramSoch & 2020-05-05 & \pageref{sec:dir-pdf} \\ \hline
P96 & bern-pmf & Probability mass function of the Bernoulli distribution & JoramSoch & 2020-05-11 & \pageref{sec:bern-pmf} \\ \hline
P97 & bin-pmf & Probability mass function of the binomial distribution & JoramSoch & 2020-05-11 & \pageref{sec:bin-pmf} \\ \hline
P98 & cat-pmf & Probability mass function of the categorical distribution & JoramSoch & 2020-05-11 & \pageref{sec:cat-pmf} \\ \hline
P99 & mult-pmf & Probability mass function of the multinomial distribution & JoramSoch & 2020-05-11 & \pageref{sec:mult-pmf} \\ \hline
P100 & mvn-dent & Differential entropy of the multivariate normal distribution & JoramSoch & 2020-05-14 & \pageref{sec:mvn-dent} \\ \hline
P101 & norm-dent & Differential entropy of the normal distribution & JoramSoch & 2020-05-14 & \pageref{sec:norm-dent} \\ \hline
P102 & poiss-pmf & Probability mass function of the Poisson distribution & JoramSoch & 2020-05-14 & \pageref{sec:poiss-pmf} \\ \hline
P103 & mean-nnrvar & Expected value of a non-negative random variable & JoramSoch & 2020-05-18 & \pageref{sec:mean-nnrvar} \\ \hline
P104 & var-mean & Partition of variance into expected values & JoramSoch & 2020-05-19 & \pageref{sec:var-mean} \\ \hline
P105 & logreg-pnlo & Probability and log-odds in logistic regression & JoramSoch & 2020-05-19 & \pageref{sec:logreg-pnlo} \\ \hline
P106 & glm-ols & Ordinary least squares for the general linear model & JoramSoch & 2020-05-19 & \pageref{sec:glm-ols} \\ \hline
P107 & glm-wls & Weighted least squares for the general linear model & JoramSoch & 2020-05-19 & \pageref{sec:glm-wls} \\ \hline
P108 & gam-mean & Mean of the gamma distribution & JoramSoch & 2020-05-19 & \pageref{sec:gam-mean} \\ \hline
P109 & gam-var & Variance of the gamma distribution & JoramSoch & 2020-05-19 & \pageref{sec:gam-var} \\ \hline
P110 & gam-logmean & Logarithmic expectation of the gamma distribution & JoramSoch & 2020-05-25 & \pageref{sec:gam-logmean} \\ \hline
P111 & norm-snorm & Relationship between normal distribution and standard normal distribution & JoramSoch & 2020-05-26 & \pageref{sec:norm-snorm} \\ \hline
P112 & gam-sgam & Relationship between gamma distribution and standard gamma distribution & JoramSoch & 2020-05-26 & \pageref{sec:gam-sgam} \\ \hline
P113 & kl-ent & Relation of Kullback-Leibler divergence to entropy & JoramSoch & 2020-05-27 & \pageref{sec:kl-ent} \\ \hline
P114 & kl-dent & Relation of continuous Kullback-Leibler divergence to differential entropy & JoramSoch & 2020-05-27 & \pageref{sec:kl-dent} \\ \hline
P115 & kl-inv & Invariance of the Kullback-Leibler divergence under parameter transformation & JoramSoch & 2020-05-28 & \pageref{sec:kl-inv} \\ \hline
P116 & kl-add & Additivity of the Kullback-Leibler divergence for independent distributions & JoramSoch & 2020-05-31 & \pageref{sec:kl-add} \\ \hline
P117 & kl-nonneg & Non-negativity of the Kullback-Leibler divergence & JoramSoch & 2020-05-31 & \pageref{sec:kl-nonneg} \\ \hline
P118 & cov-mean & Partition of covariance into expected values & JoramSoch & 2020-06-02 & \pageref{sec:cov-mean} \\ \hline
P119 & cov-corr & Relationship between covariance and correlation & JoramSoch & 2020-06-02 & \pageref{sec:cov-corr} \\ \hline
P120 & covmat-mean & Partition of a covariance matrix into expected values & JoramSoch & 2020-06-06 & \pageref{sec:covmat-mean} \\ \hline
P121 & covmat-corrmat & Relationship between covariance matrix and correlation matrix & JoramSoch & 2020-06-06 & \pageref{sec:covmat-corrmat} \\ \hline
P122 & precmat-corrmat & Relationship between precision matrix and correlation matrix & JoramSoch & 2020-06-06 & \pageref{sec:precmat-corrmat} \\ \hline
P123 & var-nonneg & Non-negativity of the variance & JoramSoch & 2020-06-06 & \pageref{sec:var-nonneg} \\ \hline
P124 & var-const & Variance of constant is zero & JoramSoch & 2020-06-27 & \pageref{sec:var-const} \\ \hline
P126 & var-inv & Invariance of the variance under addition of a constant & JoramSoch & 2020-07-07 & \pageref{sec:var-inv} \\ \hline
P127 & var-scal & Scaling of the variance upon multiplication with a constant & JoramSoch & 2020-07-07 & \pageref{sec:var-scal} \\ \hline
P128 & var-sum & Variance of the sum of two random variables & JoramSoch & 2020-07-07 & \pageref{sec:var-sum} \\ \hline
P129 & var-lincomb & Variance of the linear combination of two random variables & JoramSoch & 2020-07-07 & \pageref{sec:var-lincomb} \\ \hline
P130 & var-add & Additivity of the variance for independent random variables & JoramSoch & 2020-07-07 & \pageref{sec:var-add} \\ \hline
P131 & mean-qf & Expectation of a quadratic form & JoramSoch & 2020-07-13 & \pageref{sec:mean-qf} \\ \hline
P132 & lfe-der & Derivation of the log family evidence & JoramSoch & 2020-07-13 & \pageref{sec:lfe-der} \\ \hline
P133 & blr-pp & Posterior probability of the alternative hypothesis for Bayesian linear regression & JoramSoch & 2020-07-17 & \pageref{sec:blr-pp} \\ \hline
P134 & blr-pcr & Posterior credibility region against the omnibus null hypothesis for Bayesian linear regression & JoramSoch & 2020-07-17 & \pageref{sec:blr-pcr} \\ \hline
P135 & mlr-idem & Projection matrix and residual-forming matrix are idempotent & JoramSoch & 2020-07-22 & \pageref{sec:mlr-idem} \\ \hline
P136 & mlr-wls2 & Weighted least squares for multiple linear regression & JoramSoch & 2020-07-22 & \pageref{sec:mlr-wls2} \\ \hline
P137 & lbf-der & Derivation of the log Bayes factor & JoramSoch & 2020-07-22 & \pageref{sec:lbf-der} \\ \hline
P138 & mean-lotus & Law of the unconscious statistician & JoramSoch & 2020-07-22 & \pageref{sec:mean-lotus} \\ \hline
P139 & pmp-der & Derivation of the posterior model probability & JoramSoch & 2020-07-28 & \pageref{sec:pmp-der} \\ \hline
P140 & duni-pmf & Probability mass function of the discrete uniform distribution & JoramSoch & 2020-07-28 & \pageref{sec:duni-pmf} \\ \hline
P141 & duni-cdf & Cumulative distribution function of the discrete uniform distribution & JoramSoch & 2020-07-28 & \pageref{sec:duni-cdf} \\ \hline
P142 & duni-qf & Quantile function of the discrete uniform distribution & JoramSoch & 2020-07-28 & \pageref{sec:duni-qf} \\ \hline
P143 & bma-der & Derivation of Bayesian model averaging & JoramSoch & 2020-08-03 & \pageref{sec:bma-der} \\ \hline
P144 & matn-trans & Transposition of a matrix-normal random variable & JoramSoch & 2020-08-03 & \pageref{sec:matn-trans} \\ \hline
P145 & matn-ltt & Linear transformation theorem for the matrix-normal distribution & JoramSoch & 2020-08-03 & \pageref{sec:matn-ltt} \\ \hline
P146 & ng-cond & Conditional distributions of the normal-gamma distribution & JoramSoch & 2020-08-05 & \pageref{sec:ng-cond} \\ \hline
P147 & kl-nonsymm & Non-symmetry of the Kullback-Leibler divergence & JoramSoch & 2020-08-11 & \pageref{sec:kl-nonsymm} \\ \hline
P148 & kl-conv & Convexity of the Kullback-Leibler divergence & JoramSoch & 2020-08-11 & \pageref{sec:kl-conv} \\ \hline
P149 & ent-conc & Concavity of the Shannon entropy & JoramSoch & 2020-08-11 & \pageref{sec:ent-conc} \\ \hline
P150 & entcross-conv & Convexity of the cross-entropy & JoramSoch & 2020-08-11 & \pageref{sec:entcross-conv} \\ \hline
P151 & poiss-mean & Mean of the Poisson distribution & JoramSoch & 2020-08-19 & \pageref{sec:poiss-mean} \\ \hline
P152 & norm-fwhm & Full width at half maximum for the normal distribution & JoramSoch & 2020-08-19 & \pageref{sec:norm-fwhm} \\ \hline
P153 & mom-mgf & Moment in terms of moment-generating function & JoramSoch & 2020-08-19 & \pageref{sec:mom-mgf} \\ \hline
P154 & mgf-ltt & Linear transformation theorem for the moment-generating function & JoramSoch & 2020-08-19 & \pageref{sec:mgf-ltt} \\ \hline
P155 & mgf-lincomb & Moment-generating function of linear combination of independent random variables & JoramSoch & 2020-08-19 & \pageref{sec:mgf-lincomb} \\ \hline
P156 & bf-sddr & Savage-Dickey Density Ratio for computing Bayes Factors & tomfaulkenberry & 2020-08-26 & \pageref{sec:bf-sddr} \\ \hline
P157 & bf-ep & Encompassing Prior Method for computing Bayes Factors & tomfaulkenberry & 2020-09-02 & \pageref{sec:bf-ep} \\ \hline
P158 & cov-ind & Covariance of independent random variables & JoramSoch & 2020-09-03 & \pageref{sec:cov-ind} \\ \hline
P159 & mblr-prior & Conjugate prior distribution for multivariate Bayesian linear regression & JoramSoch & 2020-09-03 & \pageref{sec:mblr-prior} \\ \hline
P160 & mblr-post & Posterior distribution for multivariate Bayesian linear regression & JoramSoch & 2020-09-03 & \pageref{sec:mblr-post} \\ \hline
P161 & mblr-lme & Log model evidence for multivariate Bayesian linear regression & JoramSoch & 2020-09-03 & \pageref{sec:mblr-lme} \\ \hline
P162 & wald-pdf & Probability density function of the Wald distribution & tomfaulkenberry & 2020-09-04 & \pageref{sec:wald-pdf} \\ \hline
P163 & bf-trans & Transitivity of Bayes Factors & tomfaulkenberry & 2020-09-07 & \pageref{sec:bf-trans} \\ \hline
P164 & gibbs-ineq & Gibbs' inequality & JoramSoch & 2020-09-09 & \pageref{sec:gibbs-ineq} \\ \hline
P165 & logsum-ineq & Log sum inequality & JoramSoch & 2020-09-09 & \pageref{sec:logsum-ineq} \\ \hline
P166 & kl-nonneg2 & Non-negativity of the Kullback-Leibler divergence & JoramSoch & 2020-09-09 & \pageref{sec:kl-nonneg2} \\ \hline
P167 & momcent-1st & First central moment is zero & JoramSoch & 2020-09-09 & \pageref{sec:momcent-1st} \\ \hline
P168 & wald-mgf & Moment-generating function of the Wald distribution & tomfaulkenberry & 2020-09-13 & \pageref{sec:wald-mgf} \\ \hline
P169 & wald-mean & Mean of the Wald distribution & tomfaulkenberry & 2020-09-13 & \pageref{sec:wald-mean} \\ \hline
P170 & wald-var & Variance of the Wald distribution & tomfaulkenberry & 2020-09-13 & \pageref{sec:wald-var} \\ \hline
P171 & momraw-1st & First raw moment is mean & JoramSoch & 2020-10-08 & \pageref{sec:momraw-1st} \\ \hline
P172 & momraw-2nd & Relationship between second raw moment, variance and mean & JoramSoch & 2020-10-08 & \pageref{sec:momraw-2nd} \\ \hline
P173 & momcent-2nd & Second central moment is variance & JoramSoch & 2020-10-08 & \pageref{sec:momcent-2nd} \\ \hline
P174 & chi2-gam & Chi-squared distribution is a special case of gamma distribution & kjpetrykowski & 2020-10-12 & \pageref{sec:chi2-gam} \\ \hline
P175 & chi2-mom & Moments of the chi-squared distribution & kjpetrykowski & 2020-10-13 & \pageref{sec:chi2-mom} \\ \hline
P176 & norm-snorm2 & Relationship between normal distribution and standard normal distribution & JoramSoch & 2020-10-15 & \pageref{sec:norm-snorm2} \\ \hline
P177 & gam-sgam2 & Relationship between gamma distribution and standard gamma distribution & JoramSoch & 2020-10-15 & \pageref{sec:gam-sgam2} \\ \hline
P178 & gam-cdf & Cumulative distribution function of the gamma distribution & JoramSoch & 2020-10-15 & \pageref{sec:gam-cdf} \\ \hline
P179 & gam-xlogx & Expected value of x times ln(x) for a gamma distribution & JoramSoch & 2020-10-15 & \pageref{sec:gam-xlogx} \\ \hline
P180 & norm-snorm3 & Relationship between normal distribution and standard normal distribution & JoramSoch & 2020-10-22 & \pageref{sec:norm-snorm3} \\ \hline
P181 & dir-ep & Exceedance probabilities for the Dirichlet distribution & JoramSoch & 2020-10-22 & \pageref{sec:dir-ep} \\ \hline
P182 & dir-mle & Maximum likelihood estimation for Dirichlet-distributed data & JoramSoch & 2020-10-22 & \pageref{sec:dir-mle} \\ \hline
P183 & cdf-sifct & Cumulative distribution function of a strictly increasing function of a random variable & JoramSoch & 2020-10-29 & \pageref{sec:cdf-sifct} \\ \hline
P184 & pmf-sifct & Probability mass function of a strictly increasing function of a discrete random variable & JoramSoch & 2020-10-29 & \pageref{sec:pmf-sifct} \\ \hline
P185 & pdf-sifct & Probability density function of a strictly increasing function of a continuous random variable & JoramSoch & 2020-10-29 & \pageref{sec:pdf-sifct} \\ \hline
P186 & cdf-sdfct & Cumulative distribution function of a strictly decreasing function of a random variable & JoramSoch & 2020-11-06 & \pageref{sec:cdf-sdfct} \\ \hline
P187 & pmf-sdfct & Probability mass function of a strictly decreasing function of a discrete random variable & JoramSoch & 2020-11-06 & \pageref{sec:pmf-sdfct} \\ \hline
P188 & pdf-sdfct & Probability density function of a strictly decreasing function of a continuous random variable & JoramSoch & 2020-11-06 & \pageref{sec:pdf-sdfct} \\ \hline
P189 & cdf-pmf & Cumulative distribution function in terms of probability mass function of a discrete random variable & JoramSoch & 2020-11-12 & \pageref{sec:cdf-pmf} \\ \hline
P190 & cdf-pdf & Cumulative distribution function in terms of probability density function of a continuous random variable & JoramSoch & 2020-11-12 & \pageref{sec:cdf-pdf} \\ \hline
P191 & pdf-cdf & Probability density function is first derivative of cumulative distribution function & JoramSoch & 2020-11-12 & \pageref{sec:pdf-cdf} \\ \hline
P192 & qf-cdf & Quantile function is inverse of strictly monotonically increasing cumulative distribution function & JoramSoch & 2020-11-12 & \pageref{sec:qf-cdf} \\ \hline
P193 & norm-kl & Kullback-Leibler divergence for the normal distribution & JoramSoch & 2020-11-19 & \pageref{sec:norm-kl} \\ \hline
P194 & gam-qf & Quantile function of the gamma distribution & JoramSoch & 2020-11-19 & \pageref{sec:gam-qf} \\ \hline
P195 & beta-cdf & Cumulative distribution function of the beta distribution & JoramSoch & 2020-11-19 & \pageref{sec:beta-cdf} \\ \hline
P196 & norm-gi & Gaussian integral & JoramSoch & 2020-11-25 & \pageref{sec:norm-gi} \\ \hline
P197 & chi2-pdf & Probability density function of the chi-squared distribution & JoramSoch & 2020-11-25 & \pageref{sec:chi2-pdf} \\ \hline
P198 & beta-mgf & Moment-generating function of the beta distribution & JoramSoch & 2020-11-25 & \pageref{sec:beta-mgf} \\ \hline
P199 & dent-inv & Invariance of the differential entropy under addition of a constant & JoramSoch & 2020-12-02 & \pageref{sec:dent-inv} \\ \hline
P200 & dent-add & Addition of the differential entropy upon multiplication with a constant & JoramSoch & 2020-12-02 & \pageref{sec:dent-add} \\ \hline
P201 & ug-prior & Conjugate prior distribution for the univariate Gaussian & JoramSoch & 2021-03-03 & \pageref{sec:ug-prior} \\ \hline
P202 & ug-post & Posterior distribution for the univariate Gaussian & JoramSoch & 2021-03-03 & \pageref{sec:ug-post} \\ \hline
P203 & ug-lme & Log model evidence for the univariate Gaussian & JoramSoch & 2021-03-03 & \pageref{sec:ug-lme} \\ \hline
P204 & ug-ttest1 & One-sample t-test for independent observations & JoramSoch & 2021-03-12 & \pageref{sec:ug-ttest1} \\ \hline
P205 & ug-ttest2 & Two-sample t-test for independent observations & JoramSoch & 2021-03-12 & \pageref{sec:ug-ttest2} \\ \hline
P206 & ug-ttestp & Paired t-test for dependent observations & JoramSoch & 2021-03-12 & \pageref{sec:ug-ttestp} \\ \hline
P207 & ugkv-mle & Maximum likelihood estimation for the univariate Gaussian with known variance & JoramSoch & 2021-03-24 & \pageref{sec:ugkv-mle} \\ \hline
P208 & ugkv-ztest1 & One-sample z-test for independent observations & JoramSoch & 2021-03-24 & \pageref{sec:ugkv-ztest1} \\ \hline
P209 & ugkv-ztest2 & Two-sample z-test for independent observations & JoramSoch & 2021-03-24 & \pageref{sec:ugkv-ztest2} \\ \hline
P210 & ugkv-ztestp & Paired z-test for dependent observations & JoramSoch & 2021-03-24 & \pageref{sec:ugkv-ztestp} \\ \hline
P211 & ugkv-prior & Conjugate prior distribution for the univariate Gaussian with known variance & JoramSoch & 2021-03-24 & \pageref{sec:ugkv-prior} \\ \hline
P212 & ugkv-post & Posterior distribution for the univariate Gaussian with known variance & JoramSoch & 2021-03-24 & \pageref{sec:ugkv-post} \\ \hline
P213 & ugkv-lme & Log model evidence for the univariate Gaussian with known variance & JoramSoch & 2021-03-24 & \pageref{sec:ugkv-lme} \\ \hline
P214 & ugkv-anc & Accuracy and complexity for the univariate Gaussian with known variance & JoramSoch & 2021-03-24 & \pageref{sec:ugkv-anc} \\ \hline
P215 & ugkv-lbf & Log Bayes factor for the univariate Gaussian with known variance & JoramSoch & 2021-03-24 & \pageref{sec:ugkv-lbf} \\ \hline
P216 & ugkv-lbfmean & Expectation of the log Bayes factor for the univariate Gaussian with known variance & JoramSoch & 2021-03-24 & \pageref{sec:ugkv-lbfmean} \\ \hline
P217 & ugkv-cvlme & Cross-validated log model evidence for the univariate Gaussian with known variance & JoramSoch & 2021-03-24 & \pageref{sec:ugkv-cvlme} \\ \hline
P218 & ugkv-cvlbf & Cross-validated log Bayes factor for the univariate Gaussian with known variance & JoramSoch & 2021-03-24 & \pageref{sec:ugkv-cvlbf} \\ \hline
P219 & ugkv-cvlbfmean & Expectation of the cross-validated log Bayes factor for the univariate Gaussian with known variance & JoramSoch & 2021-03-24 & \pageref{sec:ugkv-cvlbfmean} \\ \hline
P220 & cdf-pit & Probability integral transform using cumulative distribution function & JoramSoch & 2021-04-07 & \pageref{sec:cdf-pit} \\ \hline
P221 & cdf-itm & Inverse transformation method using cumulative distribution function & JoramSoch & 2021-04-07 & \pageref{sec:cdf-itm} \\ \hline
P222 & cdf-dt & Distributional transformation using cumulative distribution function & JoramSoch & 2021-04-07 & \pageref{sec:cdf-dt} \\ \hline
P223 & ug-mle & Maximum likelihood estimation for the univariate Gaussian & JoramSoch & 2021-04-16 & \pageref{sec:ug-mle} \\ \hline
P224 & poissexp-mle & Maximum likelihood estimation for the Poisson distribution with exposure values & JoramSoch & 2021-04-16 & \pageref{sec:poissexp-mle} \\ \hline
P225 & poiss-prior & Conjugate prior distribution for Poisson-distributed data & JoramSoch & 2020-04-21 & \pageref{sec:poiss-prior} \\ \hline
P226 & poiss-post & Posterior distribution for Poisson-distributed data & JoramSoch & 2020-04-21 & \pageref{sec:poiss-post} \\ \hline
P227 & poiss-lme & Log model evidence for Poisson-distributed data & JoramSoch & 2020-04-21 & \pageref{sec:poiss-lme} \\ \hline
P228 & beta-mean & Mean of the beta distribution & JoramSoch & 2021-04-29 & \pageref{sec:beta-mean} \\ \hline
P229 & beta-var & Variance of the beta distribution & JoramSoch & 2021-04-29 & \pageref{sec:beta-var} \\ \hline
P230 & poiss-var & Variance of the Poisson distribution & JoramSoch & 2021-04-29 & \pageref{sec:poiss-var} \\ \hline
P231 & mvt-f & Relationship between multivariate t-distribution and F-distribution & JoramSoch & 2021-05-04 & \pageref{sec:mvt-f} \\ \hline
P232 & nst-t & Relationship between non-standardized t-distribution and t-distribution & JoramSoch & 2021-05-11 & \pageref{sec:nst-t} \\ \hline
P233 & norm-chi2 & Relationship between normal distribution and chi-squared distribution & JoramSoch & 2021-05-20 & \pageref{sec:norm-chi2} \\ \hline
P234 & norm-t & Relationship between normal distribution and t-distribution & JoramSoch & 2021-05-27 & \pageref{sec:norm-t} \\ \hline
P235 & norm-lincomb & Linear combination of independent normal random variables & JoramSoch & 2021-06-02 & \pageref{sec:norm-lincomb} \\ \hline
P236 & mvn-ind & Necessary and sufficient condition for independence of multivariate normal random variables & JoramSoch & 2021-06-02 & \pageref{sec:mvn-ind} \\ \hline
P237 & ng-mean & Mean of the normal-gamma distribution & JoramSoch & 2021-07-08 & \pageref{sec:ng-mean} \\ \hline
P238 & ng-dent & Differential entropy of the normal-gamma distribution & JoramSoch & 2021-07-08 & \pageref{sec:ng-dent} \\ \hline
P239 & gam-dent & Differential entropy of the gamma distribution & JoramSoch & 2021-07-14 & \pageref{sec:gam-dent} \\ \hline
P240 & ug-anc & Accuracy and complexity for the univariate Gaussian & JoramSoch & 2021-07-14 & \pageref{sec:ug-anc} \\ \hline
P241 & prob-ind & Probability under statistical independence & JoramSoch & 2021-07-23 & \pageref{sec:prob-ind} \\ \hline
P242 & prob-exc & Probability under mutual exclusivity & JoramSoch & 2021-07-23 & \pageref{sec:prob-exc} \\ \hline
P243 & prob-mon & Monotonicity of probability & JoramSoch & 2021-07-30 & \pageref{sec:prob-mon} \\ \hline
P244 & prob-emp & Probability of the empty set & JoramSoch & 2021-07-30 & \pageref{sec:prob-emp} \\ \hline
P245 & prob-comp & Probability of the complement & JoramSoch & 2021-07-30 & \pageref{sec:prob-comp} \\ \hline
P246 & prob-range & Range of probability & JoramSoch & 2021-07-30 & \pageref{sec:prob-range} \\ \hline
P247 & prob-add & Addition law of probability & JoramSoch & 2021-07-30 & \pageref{sec:prob-add} \\ \hline
P248 & prob-tot & Law of total probability & JoramSoch & 2021-08-08 & \pageref{sec:prob-tot} \\ \hline
P249 & prob-exh & Probability of exhaustive events & JoramSoch & 2021-08-08 & \pageref{sec:prob-exh} \\ \hline
P250 & norm-maxent & Normal distribution maximizes differential entropy for fixed variance & JoramSoch & 2020-08-25 & \pageref{sec:norm-maxent} \\ \hline
P251 & norm-extr & Extreme points of the probability density function of the normal distribution & JoramSoch & 2020-08-25 & \pageref{sec:norm-extr} \\ \hline
P252 & norm-infl & Inflection points of the probability density function of the normal distribution & JoramSoch & 2020-08-26 & \pageref{sec:norm-infl} \\ \hline
P253 & pmf-invfct & Probability mass function of an invertible function of a random vector & JoramSoch & 2021-08-30 & \pageref{sec:pmf-invfct} \\ \hline
P254 & pdf-invfct & Probability density function of an invertible function of a continuous random vector & JoramSoch & 2021-08-30 & \pageref{sec:pdf-invfct} \\ \hline
P255 & pdf-linfct & Probability density function of a linear function of a continuous random vector & JoramSoch & 2021-08-30 & \pageref{sec:pdf-linfct} \\ \hline
P256 & cdf-sumind & Cumulative distribution function of a sum of independent random variables & JoramSoch & 2021-08-30 & \pageref{sec:cdf-sumind} \\ \hline
P257 & pmf-sumind & Probability mass function of a sum of independent discrete random variables & JoramSoch & 2021-08-30 & \pageref{sec:pmf-sumind} \\ \hline
P258 & pdf-sumind & Probability density function of a sum of independent discrete random variables & JoramSoch & 2021-08-30 & \pageref{sec:pdf-sumind} \\ \hline
P259 & cf-fct & Characteristic function of a function of a random variable & JoramSoch & 2021-09-22 & \pageref{sec:cf-fct} \\ \hline
P260 & mgf-fct & Moment-generating function of a function of a random variable & JoramSoch & 2021-09-22 & \pageref{sec:mgf-fct} \\ \hline
P261 & dent-addvec & Addition of the differential entropy upon multiplication with invertible matrix & JoramSoch & 2021-10-07 & \pageref{sec:dent-addvec} \\ \hline
P262 & dent-noninv & Non-invariance of the differential entropy under change of variables & JoramSoch & 2021-10-07 & \pageref{sec:dent-noninv} \\ \hline
P263 & t-pdf & Probability density function of the t-distribution & JoramSoch & 2021-10-12 & \pageref{sec:t-pdf} \\ \hline
P264 & f-pdf & Probability density function of the F-distribution & JoramSoch & 2021-10-12 & \pageref{sec:f-pdf} \\ \hline
P265 & tglm-dist & Distribution of the transformed general linear model & JoramSoch & 2021-10-21 & \pageref{sec:tglm-dist} \\ \hline
P266 & tglm-para & Equivalence of parameter estimates from the transformed general linear model & JoramSoch & 2021-10-21 & \pageref{sec:tglm-para} \\ \hline
P267 & iglm-dist & Distribution of the inverse general linear model & JoramSoch & 2021-10-21 & \pageref{sec:iglm-dist} \\ \hline
P268 & iglm-blue & Best linear unbiased estimator for the inverse general linear model & JoramSoch & 2021-10-21 & \pageref{sec:iglm-blue} \\ \hline
P269 & cfm-para & Parameters of the corresponding forward model & JoramSoch & 2021-10-21 & \pageref{sec:cfm-para} \\ \hline
P270 & cfm-exist & Existence of a corresponding forward model & JoramSoch & 2021-10-21 & \pageref{sec:cfm-exist} \\ \hline
P271 & slr-ols & Ordinary least squares for simple linear regression & JoramSoch & 2021-10-27 & \pageref{sec:slr-ols} \\ \hline
P272 & slr-olsmean & Expectation of parameter estimates for simple linear regression & JoramSoch & 2021-10-27 & \pageref{sec:slr-olsmean} \\ \hline
P273 & slr-olsvar & Variance of parameter estimates for simple linear regression & JoramSoch & 2021-10-27 & \pageref{sec:slr-olsvar} \\ \hline
P274 & slr-meancent & Effects of mean-centering on parameter estimates for simple linear regression & JoramSoch & 2021-10-27 & \pageref{sec:slr-meancent} \\ \hline
P275 & slr-comp & The regression line goes through the center of mass point & JoramSoch & 2021-10-27 & \pageref{sec:slr-comp} \\ \hline
P276 & slr-ressum & The sum of residuals is zero in simple linear regression & JoramSoch & 2021-10-27 & \pageref{sec:slr-ressum} \\ \hline
P277 & slr-rescorr & The residuals and the covariate are uncorrelated in simple linear regression & JoramSoch & 2021-10-27 & \pageref{sec:slr-rescorr} \\ \hline
P278 & slr-resvar & Relationship between residual variance and sample variance in simple linear regression & JoramSoch & 2021-10-27 & \pageref{sec:slr-resvar} \\ \hline
P279 & slr-corr & Relationship between correlation coefficient and slope estimate in simple linear regression & JoramSoch & 2021-10-27 & \pageref{sec:slr-corr} \\ \hline
P280 & slr-rsq & Relationship between coefficient of determination and correlation coefficient in simple linear regression & JoramSoch & 2021-10-27 & \pageref{sec:slr-rsq} \\ \hline
P281 & slr-mlr & Simple linear regression is a special case of multiple linear regression & JoramSoch & 2021-11-09 & \pageref{sec:slr-mlr} \\ \hline
P282 & slr-olsdist & Distribution of parameter estimates for simple linear regression & JoramSoch & 2021-11-09 & \pageref{sec:slr-olsdist} \\ \hline
P283 & slr-proj & Projection of a data point to the regression line & JoramSoch & 2021-11-09 & \pageref{sec:slr-proj} \\ \hline
P284 & slr-sss & Sums of squares for simple linear regression & JoramSoch & 2021-11-09 & \pageref{sec:slr-sss} \\ \hline
P285 & slr-mat & Transformation matrices for simple linear regression & JoramSoch & 2021-11-09 & \pageref{sec:slr-mat} \\ \hline
P286 & slr-wls & Weighted least squares for simple linear regression & JoramSoch & 2021-11-16 & \pageref{sec:slr-wls} \\ \hline
P287 & slr-mle & Maximum likelihood estimation for simple linear regression & JoramSoch & 2021-11-16 & \pageref{sec:slr-mle} \\ \hline
P288 & slr-ols2 & Ordinary least squares for simple linear regression & JoramSoch & 2021-11-16 & \pageref{sec:slr-ols2} \\ \hline
P289 & slr-wls2 & Weighted least squares for simple linear regression & JoramSoch & 2021-11-16 & \pageref{sec:slr-wls2} \\ \hline
P290 & slr-mle2 & Maximum likelihood estimation for simple linear regression & JoramSoch & 2021-11-16 & \pageref{sec:slr-mle2} \\ \hline
P291 & mean-tot & Law of total expectation & JoramSoch & 2021-11-26 & \pageref{sec:mean-tot} \\ \hline
P292 & var-tot & Law of total variance & JoramSoch & 2021-11-26 & \pageref{sec:var-tot} \\ \hline
P293 & cov-tot & Law of total covariance & JoramSoch & 2021-11-26 & \pageref{sec:cov-tot} \\ \hline
P294 & dir-kl & Kullback-Leibler divergence for the Dirichlet distribution & JoramSoch & 2021-12-02 & \pageref{sec:dir-kl} \\ \hline
P295 & wish-kl & Kullback-Leibler divergence for the Wishart distribution & JoramSoch & 2021-12-02 & \pageref{sec:wish-kl} \\ \hline
P296 & matn-kl & Kullback-Leibler divergence for the matrix-normal distribution & JoramSoch & 2021-12-02 & \pageref{sec:matn-kl} \\ \hline
P297 & matn-samp & Sampling from the matrix-normal distribution & JoramSoch & 2021-12-07 & \pageref{sec:matn-samp} \\ \hline
P298 & mean-tr & Expected value of the trace of a matrix & JoramSoch & 2021-12-07 & \pageref{sec:mean-tr} \\ \hline
P299 & corr-z & Correlation coefficient in terms of standard scores & JoramSoch & 2021-12-14 & \pageref{sec:corr-z} \\ \hline
P300 & corr-range & Correlation always falls between -1 and +1 & JoramSoch & 2021-12-14 & \pageref{sec:corr-range} \\ \hline
\end{longtable}



\pagebreak
\section{Definition by Number}

\begin{longtable}{|p{1cm}|p{2cm}|p{6.5cm}|p{3cm}|p{2cm}|c|}
\hline
\textbf{ID} & \textbf{Shortcut} & \textbf{Definition} & \textbf{Author} & \textbf{Date} & \textbf{Page} \\ \hline
D1 & mvn & Multivariate normal distribution & JoramSoch & 2020-01-22 & \pageref{sec:mvn} \\ \hline
D2 & mgf & Moment-generating function & JoramSoch & 2020-01-22 & \pageref{sec:mgf} \\ \hline
D3 & cuni & Continuous uniform distribution & JoramSoch & 2020-01-27 & \pageref{sec:cuni} \\ \hline
D4 & norm & Normal distribution & JoramSoch & 2020-01-27 & \pageref{sec:norm} \\ \hline
D5 & ng & Normal-gamma distribution & JoramSoch & 2020-01-27 & \pageref{sec:ng} \\ \hline
D6 & matn & Matrix-normal distribution & JoramSoch & 2020-01-27 & \pageref{sec:matn} \\ \hline
D7 & gam & Gamma distribution & JoramSoch & 2020-02-08 & \pageref{sec:gam} \\ \hline
D8 & exp & Exponential distribution & JoramSoch & 2020-02-08 & \pageref{sec:exp} \\ \hline
D9 & pmf & Probability mass function & JoramSoch & 2020-02-13 & \pageref{sec:pmf} \\ \hline
D10 & pdf & Probability density function & JoramSoch & 2020-02-13 & \pageref{sec:pdf} \\ \hline
D11 & mean & Expected value & JoramSoch & 2020-02-13 & \pageref{sec:mean} \\ \hline
D12 & var & Variance & JoramSoch & 2020-02-13 & \pageref{sec:var} \\ \hline
D13 & cdf & Cumulative distribution function & JoramSoch & 2020-02-17 & \pageref{sec:cdf} \\ \hline
D14 & qf & Quantile function & JoramSoch & 2020-02-17 & \pageref{sec:qf} \\ \hline
D15 & ent & Shannon entropy & JoramSoch & 2020-02-19 & \pageref{sec:ent} \\ \hline
D16 & dent & Differential entropy & JoramSoch & 2020-02-19 & \pageref{sec:dent} \\ \hline
D17 & ent-cond & Conditional entropy & JoramSoch & 2020-02-19 & \pageref{sec:ent-cond} \\ \hline
D18 & ent-joint & Joint entropy & JoramSoch & 2020-02-19 & \pageref{sec:ent-joint} \\ \hline
D19 & mi & Mutual information & JoramSoch & 2020-02-19 & \pageref{sec:mi} \\ \hline
D19 & mi & Mutual information & JoramSoch & 2020-02-19 & \pageref{sec:mi} \\ \hline
D20 & resvar & Residual variance & JoramSoch & 2020-02-25 & \pageref{sec:resvar} \\ \hline
D21 & rsq & Coefficient of determination & JoramSoch & 2020-02-25 & \pageref{sec:rsq} \\ \hline
D22 & snr & Signal-to-noise ratio & JoramSoch & 2020-02-25 & \pageref{sec:snr} \\ \hline
D23 & aic & Akaike information criterion & JoramSoch & 2020-02-25 & \pageref{sec:aic} \\ \hline
D24 & bic & Bayesian information criterion & JoramSoch & 2020-02-25 & \pageref{sec:bic} \\ \hline
D25 & dic & Deviance information criterion & JoramSoch & 2020-02-25 & \pageref{sec:dic} \\ \hline
D26 & lme & Log model evidence & JoramSoch & 2020-02-25 & \pageref{sec:lme} \\ \hline
D27 & gm & Generative model & JoramSoch & 2020-03-03 & \pageref{sec:gm} \\ \hline
D28 & lf & Likelihood function & JoramSoch & 2020-03-03 & \pageref{sec:lf} \\ \hline
D28 & lf & Likelihood function & JoramSoch & 2020-03-03 & \pageref{sec:lf} \\ \hline
D29 & prior & Prior distribution & JoramSoch & 2020-03-03 & \pageref{sec:prior} \\ \hline
D30 & fpm & Full probability model & JoramSoch & 2020-03-03 & \pageref{sec:fpm} \\ \hline
D31 & jl & Joint likelihood & JoramSoch & 2020-03-03 & \pageref{sec:jl} \\ \hline
D32 & post & Posterior distribution & JoramSoch & 2020-03-03 & \pageref{sec:post} \\ \hline
D33 & ml & Marginal likelihood & JoramSoch & 2020-03-03 & \pageref{sec:ml} \\ \hline
D34 & dent-cond & Conditional differential entropy & JoramSoch & 2020-03-21 & \pageref{sec:dent-cond} \\ \hline
D35 & dent-joint & Joint differential entropy & JoramSoch & 2020-03-21 & \pageref{sec:dent-joint} \\ \hline
D36 & mlr & Multiple linear regression & JoramSoch & 2020-03-21 & \pageref{sec:mlr} \\ \hline
D37 & tss & Total sum of squares & JoramSoch & 2020-03-21 & \pageref{sec:tss} \\ \hline
D38 & ess & Explained sum of squares & JoramSoch & 2020-03-21 & \pageref{sec:ess} \\ \hline
D39 & rss & Residual sum of squares & JoramSoch & 2020-03-21 & \pageref{sec:rss} \\ \hline
D40 & glm & General linear model & JoramSoch & 2020-03-21 & \pageref{sec:glm} \\ \hline
D41 & poiss-data & Poisson-distributed data & JoramSoch & 2020-03-22 & \pageref{sec:poiss-data} \\ \hline
D42 & poissexp & Poisson distribution with exposure values & JoramSoch & 2020-03-22 & \pageref{sec:poissexp} \\ \hline
D43 & wish & Wishart distribution & JoramSoch & 2020-03-22 & \pageref{sec:wish} \\ \hline
D44 & bern & Bernoulli distribution & JoramSoch & 2020-03-22 & \pageref{sec:bern} \\ \hline
D45 & bin & Binomial distribution & JoramSoch & 2020-03-22 & \pageref{sec:bin} \\ \hline
D46 & cat & Categorical distribution & JoramSoch & 2020-03-22 & \pageref{sec:cat} \\ \hline
D47 & mult & Multinomial distribution & JoramSoch & 2020-03-22 & \pageref{sec:mult} \\ \hline
D48 & prob & Probability & JoramSoch & 2020-05-10 & \pageref{sec:prob} \\ \hline
D49 & prob-joint & Joint probability & JoramSoch & 2020-05-10 & \pageref{sec:prob-joint} \\ \hline
D50 & prob-marg & Law of marginal probability & JoramSoch & 2020-05-10 & \pageref{sec:prob-marg} \\ \hline
D51 & prob-cond & Law of conditional probability & JoramSoch & 2020-05-10 & \pageref{sec:prob-cond} \\ \hline
D52 & kl & Kullback-Leibler divergence & JoramSoch & 2020-05-10 & \pageref{sec:kl} \\ \hline
D53 & beta & Beta distribution & JoramSoch & 2020-05-10 & \pageref{sec:beta} \\ \hline
D54 & dir & Dirichlet distribution & JoramSoch & 2020-05-10 & \pageref{sec:dir} \\ \hline
D55 & dist & Probability distribution & JoramSoch & 2020-05-17 & \pageref{sec:dist} \\ \hline
D56 & dist-joint & Joint probability distribution & JoramSoch & 2020-05-17 & \pageref{sec:dist-joint} \\ \hline
D57 & dist-marg & Marginal probability distribution & JoramSoch & 2020-05-17 & \pageref{sec:dist-marg} \\ \hline
D58 & dist-cond & Conditional probability distribution & JoramSoch & 2020-05-17 & \pageref{sec:dist-cond} \\ \hline
D59 & llf & Log-likelihood function & JoramSoch & 2020-05-17 & \pageref{sec:llf} \\ \hline
D60 & mle & Maximum likelihood estimation & JoramSoch & 2020-05-15 & \pageref{sec:mle} \\ \hline
D61 & mll & Maximum log-likelihood & JoramSoch & 2020-05-15 & \pageref{sec:mll} \\ \hline
D62 & poiss & Poisson distribution & JoramSoch & 2020-05-25 & \pageref{sec:poiss} \\ \hline
D63 & snorm & Standard normal distribution & JoramSoch & 2020-05-26 & \pageref{sec:snorm} \\ \hline
D64 & sgam & Standard gamma distribution & JoramSoch & 2020-05-26 & \pageref{sec:sgam} \\ \hline
D65 & rvar & Random variable & JoramSoch & 2020-05-27 & \pageref{sec:rvar} \\ \hline
D66 & rvec & Random vector & JoramSoch & 2020-05-27 & \pageref{sec:rvec} \\ \hline
D67 & rmat & Random matrix & JoramSoch & 2020-05-27 & \pageref{sec:rmat} \\ \hline
D68 & cgf & Cumulant-generating function & JoramSoch & 2020-05-31 & \pageref{sec:cgf} \\ \hline
D69 & pgf & Probability-generating function & JoramSoch & 2020-05-31 & \pageref{sec:pgf} \\ \hline
D70 & cov & Covariance & JoramSoch & 2020-06-02 & \pageref{sec:cov} \\ \hline
D71 & corr & Correlation & JoramSoch & 2020-06-02 & \pageref{sec:corr} \\ \hline
D72 & covmat & Covariance matrix & JoramSoch & 2020-06-06 & \pageref{sec:covmat} \\ \hline
D73 & corrmat & Correlation matrix & JoramSoch & 2020-06-06 & \pageref{sec:corrmat} \\ \hline
D74 & precmat & Precision matrix & JoramSoch & 2020-06-06 & \pageref{sec:precmat} \\ \hline
D75 & ind & Statistical independence & JoramSoch & 2020-06-06 & \pageref{sec:ind} \\ \hline
D76 & logreg & Logistic regression & JoramSoch & 2020-06-28 & \pageref{sec:logreg} \\ \hline
D77 & beta-data & Beta-distributed data & JoramSoch & 2020-06-28 & \pageref{sec:beta-data} \\ \hline
D78 & bin-data & Binomial observations & JoramSoch & 2020-07-07 & \pageref{sec:bin-data} \\ \hline
D79 & mult-data & Multinomial observations & JoramSoch & 2020-07-07 & \pageref{sec:mult-data} \\ \hline
D80 & lfe & Log family evidence & JoramSoch & 2020-07-13 & \pageref{sec:lfe} \\ \hline
D81 & emat & Estimation matrix & JoramSoch & 2020-07-22 & \pageref{sec:emat} \\ \hline
D82 & pmat & Projection matrix & JoramSoch & 2020-07-22 & \pageref{sec:pmat} \\ \hline
D83 & rfmat & Residual-forming matrix & JoramSoch & 2020-07-22 & \pageref{sec:rfmat} \\ \hline
D84 & lbf & Log Bayes factor & JoramSoch & 2020-07-22 & \pageref{sec:lbf} \\ \hline
D85 & ent-cross & Cross-entropy & JoramSoch & 2020-07-28 & \pageref{sec:ent-cross} \\ \hline
D86 & dent-cross & Differential cross-entropy & JoramSoch & 2020-07-28 & \pageref{sec:dent-cross} \\ \hline
D87 & pmp & Posterior model probability & JoramSoch & 2020-07-28 & \pageref{sec:pmp} \\ \hline
D88 & duni & Discrete uniform distribution & JoramSoch & 2020-07-28 & \pageref{sec:duni} \\ \hline
D89 & bma & Bayesian model averaging & JoramSoch & 2020-08-03 & \pageref{sec:bma} \\ \hline
D90 & mom & Moment & JoramSoch & 2020-08-19 & \pageref{sec:mom} \\ \hline
D91 & fwhm & Full width at half maximum & JoramSoch & 2020-08-19 & \pageref{sec:fwhm} \\ \hline
D92 & bf & Bayes factor & tomfaulkenberry & 2020-08-26 & \pageref{sec:bf} \\ \hline
D93 & encm & Encompassing model & tomfaulkenberry & 2020-09-02 & \pageref{sec:encm} \\ \hline
D94 & std & Standard deviation & JoramSoch & 2020-09-03 & \pageref{sec:std} \\ \hline
D95 & wald & Wald distribution & tomfaulkenberry & 2020-09-04 & \pageref{sec:wald} \\ \hline
D96 & const & Constant & JoramSoch & 2020-09-09 & \pageref{sec:const} \\ \hline
D97 & mom-raw & Raw moment & JoramSoch & 2020-10-08 & \pageref{sec:mom-raw} \\ \hline
D98 & mom-cent & Central moment & JoramSoch & 2020-10-08 & \pageref{sec:mom-cent} \\ \hline
D99 & mom-stand & Standardized moment & JoramSoch & 2020-10-08 & \pageref{sec:mom-stand} \\ \hline
D100 & chi2 & Chi-squared distribution & kjpetrykowski & 2020-10-13 & \pageref{sec:chi2} \\ \hline
D101 & med & Median & JoramSoch & 2020-10-15 & \pageref{sec:med} \\ \hline
D102 & mode & Mode & JoramSoch & 2020-10-15 & \pageref{sec:mode} \\ \hline
D103 & prob-exc & Exceedance probability & JoramSoch & 2020-10-22 & \pageref{sec:prob-exc} \\ \hline
D104 & dir-data & Dirichlet-distributed data & JoramSoch & 2020-10-22 & \pageref{sec:dir-data} \\ \hline
D105 & rvar-disc & Discrete and continuous random variable & JoramSoch & 2020-10-29 & \pageref{sec:rvar-disc} \\ \hline
D106 & rvar-uni & Univariate and multivariate random variable & JoramSoch & 2020-11-06 & \pageref{sec:rvar-uni} \\ \hline
D107 & min & Minimum & JoramSoch & 2020-11-12 & \pageref{sec:min} \\ \hline
D108 & max & Maximum & JoramSoch & 2020-11-12 & \pageref{sec:max} \\ \hline
D109 & rexp & Random experiment & JoramSoch & 2020-11-19 & \pageref{sec:rexp} \\ \hline
D110 & reve & Random event & JoramSoch & 2020-11-19 & \pageref{sec:reve} \\ \hline
D111 & cvlme & Cross-validated log model evidence & JoramSoch & 2020-11-19 & \pageref{sec:cvlme} \\ \hline
D112 & ind-cond & Conditional independence & JoramSoch & 2020-11-19 & \pageref{sec:ind-cond} \\ \hline
D113 & uplme & Uniform-prior log model evidence & JoramSoch & 2020-11-25 & \pageref{sec:uplme} \\ \hline
D114 & eblme & Empirical Bayesian log model evidence & JoramSoch & 2020-11-25 & \pageref{sec:eblme} \\ \hline
D115 & vblme & Variational Bayesian log model evidence & JoramSoch & 2020-11-25 & \pageref{sec:vblme} \\ \hline
D116 & prior-flat & Flat, hard and soft prior distribution & JoramSoch & 2020-12-02 & \pageref{sec:prior-flat} \\ \hline
D117 & prior-uni & Uniform and non-uniform prior distribution & JoramSoch & 2020-12-02 & \pageref{sec:prior-uni} \\ \hline
D118 & prior-inf & Informative and non-informative prior distribution & JoramSoch & 2020-12-02 & \pageref{sec:prior-inf} \\ \hline
D119 & prior-emp & Empirical and theoretical prior distribution & JoramSoch & 2020-12-02 & \pageref{sec:prior-emp} \\ \hline
D120 & prior-conj & Conjugate and non-conjugate prior distribution & JoramSoch & 2020-12-02 & \pageref{sec:prior-conj} \\ \hline
D121 & prior-maxent & Maximum entropy prior distribution & JoramSoch & 2020-12-02 & \pageref{sec:prior-maxent} \\ \hline
D122 & prior-eb & Empirical Bayes prior distribution & JoramSoch & 2020-12-02 & \pageref{sec:prior-eb} \\ \hline
D123 & prior-ref & Reference prior distribution & JoramSoch & 2020-12-02 & \pageref{sec:prior-ref} \\ \hline
D124 & ug & Univariate Gaussian & JoramSoch & 2021-03-03 & \pageref{sec:ug} \\ \hline
D125 & h0 & Null hypothesis & JoramSoch & 2021-03-12 & \pageref{sec:h0} \\ \hline
D126 & h1 & Alternative hypothesis & JoramSoch & 2021-03-12 & \pageref{sec:h1} \\ \hline
D127 & hyp & Statistical hypothesis & JoramSoch & 2021-03-19 & \pageref{sec:hyp} \\ \hline
D128 & hyp-simp & Simple and composite hypothesis & JoramSoch & 2021-03-19 & \pageref{sec:hyp-simp} \\ \hline
D129 & hyp-point & Point and set hypothesis & JoramSoch & 2021-03-19 & \pageref{sec:hyp-point} \\ \hline
D130 & test & Statistical hypothesis test & JoramSoch & 2021-03-19 & \pageref{sec:test} \\ \hline
D131 & tstat & Test statistic & JoramSoch & 2021-03-19 & \pageref{sec:tstat} \\ \hline
D132 & size & Size of a statistical test & JoramSoch & 2021-03-19 & \pageref{sec:size} \\ \hline
D133 & alpha & Significance level & JoramSoch & 2021-03-19 & \pageref{sec:alpha} \\ \hline
D134 & cval & Critical value & JoramSoch & 2021-03-19 & \pageref{sec:cval} \\ \hline
D135 & pval & p-value & JoramSoch & 2021-03-19 & \pageref{sec:pval} \\ \hline
D136 & ugkv & Univariate Gaussian with known variance & JoramSoch & 2021-03-23 & \pageref{sec:ugkv} \\ \hline
D137 & power & Power of a statistical test & JoramSoch & 2021-03-31 & \pageref{sec:power} \\ \hline
D138 & hyp-tail & One-tailed and two-tailed hypothesis & JoramSoch & 2021-03-31 & \pageref{sec:hyp-tail} \\ \hline
D139 & test-tail & One-tailed and two-tailed test & JoramSoch & 2021-03-31 & \pageref{sec:test-tail} \\ \hline
D140 & dist-samp & Sampling distribution & JoramSoch & 2021-03-31 & \pageref{sec:dist-samp} \\ \hline
D141 & cdf-joint & Joint cumulative distribution function & JoramSoch & 2020-04-07 & \pageref{sec:cdf-joint} \\ \hline
D142 & mean-samp & Sample mean & JoramSoch & 2021-04-16 & \pageref{sec:mean-samp} \\ \hline
D143 & var-samp & Sample variance & JoramSoch & 2021-04-16 & \pageref{sec:var-samp} \\ \hline
D144 & cov-samp & Sample covariance & ciaranmci & 2021-04-21 & \pageref{sec:cov-samp} \\ \hline
D145 & prec & Precision & JoramSoch & 2020-04-21 & \pageref{sec:prec} \\ \hline
D146 & f & F-distribution & JoramSoch & 2020-04-21 & \pageref{sec:f} \\ \hline
D147 & t & t-distribution & JoramSoch & 2021-04-21 & \pageref{sec:t} \\ \hline
D148 & mvt & Multivariate t-distribution & JoramSoch & 2020-04-21 & \pageref{sec:mvt} \\ \hline
D149 & eb & Empirical Bayes & JoramSoch & 2021-04-29 & \pageref{sec:eb} \\ \hline
D150 & vb & Variational Bayes & JoramSoch & 2021-04-29 & \pageref{sec:vb} \\ \hline
D151 & mome & Method-of-moments estimation & JoramSoch & 2021-04-29 & \pageref{sec:mome} \\ \hline
D152 & nst & Non-standardized t-distribution & JoramSoch & 2021-05-20 & \pageref{sec:nst} \\ \hline
D153 & covmat-samp & Sample covariance matrix & JoramSoch & 2021-05-20 & \pageref{sec:covmat-samp} \\ \hline
D154 & mean-rvec & Expected value of a random vector & JoramSoch & 2021-07-08 & \pageref{sec:mean-rvec} \\ \hline
D155 & mean-rmat & Expected value of a random matrix & JoramSoch & 2021-07-08 & \pageref{sec:mean-rmat} \\ \hline
D156 & exc & Mutual exclusivity & JoramSoch & 2021-07-23 & \pageref{sec:exc} \\ \hline
D157 & suni & Standard uniform distribution & JoramSoch & 2021-07-23 & \pageref{sec:suni} \\ \hline
D158 & prob-ax & Kolmogorov axioms of probability & JoramSoch & 2021-07-30 & \pageref{sec:prob-ax} \\ \hline
D159 & cf & Characteristic function & JoramSoch & 2021-09-22 & \pageref{sec:cf} \\ \hline
D160 & tglm & Transformed general linear model & JoramSoch & 2021-10-21 & \pageref{sec:tglm} \\ \hline
D161 & iglm & Inverse general linear model & JoramSoch & 2021-10-21 & \pageref{sec:iglm} \\ \hline
D162 & cfm & Corresponding forward model & JoramSoch & 2021-10-21 & \pageref{sec:cfm} \\ \hline
D163 & slr & Simple linear regression & JoramSoch & 2021-10-27 & \pageref{sec:slr} \\ \hline
D164 & regline & Regression line & JoramSoch & 2021-10-27 & \pageref{sec:regline} \\ \hline
D165 & samp-spc & Sample space & JoramSoch & 2021-11-26 & \pageref{sec:samp-spc} \\ \hline
D166 & eve-spc & Event space & JoramSoch & 2021-11-26 & \pageref{sec:eve-spc} \\ \hline
D167 & prob-spc & Probability space & JoramSoch & 2021-11-26 & \pageref{sec:prob-spc} \\ \hline
D168 & corr-samp & Sample correlation coefficient & JoramSoch & 2021-12-14 & \pageref{sec:corr-samp} \\ \hline
D169 & corrmat-samp & Sample correlation matrix & JoramSoch & 2021-12-14 & \pageref{sec:corrmat-samp} \\ \hline
\end{longtable}



\pagebreak
\section{Proof by Topic}

\textbf{A}

$\bullet$ Accuracy and complexity for the univariate Gaussian, \pageref{sec:ug-anc}

$\bullet$ Accuracy and complexity for the univariate Gaussian with known variance, \pageref{sec:ugkv-anc}

$\bullet$ Addition law of probability, \pageref{sec:prob-add}

$\bullet$ Addition of the differential entropy upon multiplication with a constant, \pageref{sec:dent-add}

$\bullet$ Addition of the differential entropy upon multiplication with invertible matrix, \pageref{sec:dent-addvec}

$\bullet$ Additivity of the Kullback-Leibler divergence for independent distributions, \pageref{sec:kl-add}

$\bullet$ Additivity of the variance for independent random variables, \pageref{sec:var-add}


\vspace{1em}
\textbf{B}

$\bullet$ Bayes' rule, \pageref{sec:bayes-rule}

$\bullet$ Bayes' theorem, \pageref{sec:bayes-th}

$\bullet$ Bayesian model averaging in terms of log model evidences, \pageref{sec:bma-lme}

$\bullet$ Best linear unbiased estimator for the inverse general linear model, \pageref{sec:iglm-blue}


\vspace{1em}
\textbf{C}

$\bullet$ Characteristic function of a function of a random variable, \pageref{sec:cf-fct}

$\bullet$ Chi-squared distribution is a special case of gamma distribution, \pageref{sec:chi2-gam}

$\bullet$ Concavity of the Shannon entropy, \pageref{sec:ent-conc}

$\bullet$ Conditional distributions of the multivariate normal distribution, \pageref{sec:mvn-cond}

$\bullet$ Conditional distributions of the normal-gamma distribution, \pageref{sec:ng-cond}

$\bullet$ Conjugate prior distribution for Bayesian linear regression, \pageref{sec:blr-prior}

$\bullet$ Conjugate prior distribution for binomial observations, \pageref{sec:bin-prior}

$\bullet$ Conjugate prior distribution for multinomial observations, \pageref{sec:mult-prior}

$\bullet$ Conjugate prior distribution for multivariate Bayesian linear regression, \pageref{sec:mblr-prior}

$\bullet$ Conjugate prior distribution for Poisson-distributed data, \pageref{sec:poiss-prior}

$\bullet$ Conjugate prior distribution for the Poisson distribution with exposure values, \pageref{sec:poissexp-prior}

$\bullet$ Conjugate prior distribution for the univariate Gaussian, \pageref{sec:ug-prior}

$\bullet$ Conjugate prior distribution for the univariate Gaussian with known variance, \pageref{sec:ugkv-prior}

$\bullet$ Construction of confidence intervals using Wilks' theorem, \pageref{sec:ci-wilks}

$\bullet$ Construction of unbiased estimator for variance, \pageref{sec:resvar-unb}

$\bullet$ Convexity of the cross-entropy, \pageref{sec:entcross-conv}

$\bullet$ Convexity of the Kullback-Leibler divergence, \pageref{sec:kl-conv}

$\bullet$ Correlation always falls between -1 and +1, \pageref{sec:corr-range}

$\bullet$ Correlation coefficient in terms of standard scores, \pageref{sec:corr-z}

$\bullet$ Covariance of independent random variables, \pageref{sec:cov-ind}

$\bullet$ Cross-validated log Bayes factor for the univariate Gaussian with known variance, \pageref{sec:ugkv-cvlbf}

$\bullet$ Cross-validated log model evidence for the univariate Gaussian with known variance, \pageref{sec:ugkv-cvlme}

$\bullet$ Cumulative distribution function in terms of probability density function of a continuous random variable, \pageref{sec:cdf-pdf}

$\bullet$ Cumulative distribution function in terms of probability mass function of a discrete random variable, \pageref{sec:cdf-pmf}

$\bullet$ Cumulative distribution function of a strictly decreasing function of a random variable, \pageref{sec:cdf-sdfct}

$\bullet$ Cumulative distribution function of a strictly increasing function of a random variable, \pageref{sec:cdf-sifct}

$\bullet$ Cumulative distribution function of a sum of independent random variables, \pageref{sec:cdf-sumind}

$\bullet$ Cumulative distribution function of the beta distribution, \pageref{sec:beta-cdf}

$\bullet$ Cumulative distribution function of the continuous uniform distribution, \pageref{sec:cuni-cdf}

$\bullet$ Cumulative distribution function of the discrete uniform distribution, \pageref{sec:duni-cdf}

$\bullet$ Cumulative distribution function of the exponential distribution, \pageref{sec:exp-cdf}

$\bullet$ Cumulative distribution function of the gamma distribution, \pageref{sec:gam-cdf}

$\bullet$ Cumulative distribution function of the normal distribution, \pageref{sec:norm-cdf}


\vspace{1em}
\textbf{D}

$\bullet$ Derivation of Bayesian model averaging, \pageref{sec:bma-der}

$\bullet$ Derivation of RÂ² and adjusted RÂ², \pageref{sec:rsq-der}

$\bullet$ Derivation of the Bayesian information criterion, \pageref{sec:bic-der}

$\bullet$ Derivation of the log Bayes factor, \pageref{sec:lbf-der}

$\bullet$ Derivation of the log family evidence, \pageref{sec:lfe-der}

$\bullet$ Derivation of the log model evidence, \pageref{sec:lme-der}

$\bullet$ Derivation of the posterior model probability, \pageref{sec:pmp-der}

$\bullet$ Differential entropy can be negative, \pageref{sec:dent-neg}

$\bullet$ Differential entropy of the gamma distribution, \pageref{sec:gam-dent}

$\bullet$ Differential entropy of the multivariate normal distribution, \pageref{sec:mvn-dent}

$\bullet$ Differential entropy of the normal distribution, \pageref{sec:norm-dent}

$\bullet$ Differential entropy of the normal-gamma distribution, \pageref{sec:ng-dent}

$\bullet$ Distribution of parameter estimates for simple linear regression, \pageref{sec:slr-olsdist}

$\bullet$ Distribution of the inverse general linear model, \pageref{sec:iglm-dist}

$\bullet$ Distribution of the transformed general linear model, \pageref{sec:tglm-dist}

$\bullet$ Distributional transformation using cumulative distribution function, \pageref{sec:cdf-dt}


\vspace{1em}
\textbf{E}

$\bullet$ Effects of mean-centering on parameter estimates for simple linear regression, \pageref{sec:slr-meancent}

$\bullet$ Encompassing Prior Method for computing Bayes Factors, \pageref{sec:bf-ep}

$\bullet$ Equivalence of matrix-normal distribution and multivariate normal distribution, \pageref{sec:matn-mvn}

$\bullet$ Equivalence of parameter estimates from the transformed general linear model, \pageref{sec:tglm-para}

$\bullet$ Exceedance probabilities for the Dirichlet distribution, \pageref{sec:dir-ep}

$\bullet$ Existence of a corresponding forward model, \pageref{sec:cfm-exist}

$\bullet$ Expectation of a quadratic form, \pageref{sec:mean-qf}

$\bullet$ Expectation of parameter estimates for simple linear regression, \pageref{sec:slr-olsmean}

$\bullet$ Expectation of the cross-validated log Bayes factor for the univariate Gaussian with known variance, \pageref{sec:ugkv-cvlbfmean}

$\bullet$ Expectation of the log Bayes factor for the univariate Gaussian with known variance, \pageref{sec:ugkv-lbfmean}

$\bullet$ Expected value of a non-negative random variable, \pageref{sec:mean-nnrvar}

$\bullet$ Expected value of the trace of a matrix, \pageref{sec:mean-tr}

$\bullet$ Expected value of x times ln(x) for a gamma distribution, \pageref{sec:gam-xlogx}

$\bullet$ Exponential distribution is a special case of gamma distribution, \pageref{sec:exp-gam}

$\bullet$ Expression of the cumulative distribution function of the normal distribution without the error function, \pageref{sec:norm-cdfwerf}

$\bullet$ Extreme points of the probability density function of the normal distribution, \pageref{sec:norm-extr}


\vspace{1em}
\textbf{F}

$\bullet$ First central moment is zero, \pageref{sec:momcent-1st}

$\bullet$ First raw moment is mean, \pageref{sec:momraw-1st}

$\bullet$ Full width at half maximum for the normal distribution, \pageref{sec:norm-fwhm}


\vspace{1em}
\textbf{G}

$\bullet$ Gaussian integral, \pageref{sec:norm-gi}

$\bullet$ Gibbs' inequality, \pageref{sec:gibbs-ineq}


\vspace{1em}
\textbf{I}

$\bullet$ Inflection points of the probability density function of the normal distribution, \pageref{sec:norm-infl}

$\bullet$ Invariance of the differential entropy under addition of a constant, \pageref{sec:dent-inv}

$\bullet$ Invariance of the Kullback-Leibler divergence under parameter transformation, \pageref{sec:kl-inv}

$\bullet$ Invariance of the variance under addition of a constant, \pageref{sec:var-inv}

$\bullet$ Inverse transformation method using cumulative distribution function, \pageref{sec:cdf-itm}


\vspace{1em}
\textbf{J}

$\bullet$ Joint likelihood is the product of likelihood function and prior density, \pageref{sec:jl-lfnprior}


\vspace{1em}
\textbf{K}

$\bullet$ Kullback-Leibler divergence for the Dirichlet distribution, \pageref{sec:dir-kl}

$\bullet$ Kullback-Leibler divergence for the gamma distribution, \pageref{sec:gam-kl}

$\bullet$ Kullback-Leibler divergence for the matrix-normal distribution, \pageref{sec:matn-kl}

$\bullet$ Kullback-Leibler divergence for the multivariate normal distribution, \pageref{sec:mvn-kl}

$\bullet$ Kullback-Leibler divergence for the normal distribution, \pageref{sec:norm-kl}

$\bullet$ Kullback-Leibler divergence for the normal-gamma distribution, \pageref{sec:ng-kl}

$\bullet$ Kullback-Leibler divergence for the Wishart distribution, \pageref{sec:wish-kl}


\vspace{1em}
\textbf{L}

$\bullet$ Law of the unconscious statistician, \pageref{sec:mean-lotus}

$\bullet$ Law of total covariance, \pageref{sec:cov-tot}

$\bullet$ Law of total expectation, \pageref{sec:mean-tot}

$\bullet$ Law of total probability, \pageref{sec:prob-tot}

$\bullet$ Law of total variance, \pageref{sec:var-tot}

$\bullet$ Linear combination of independent normal random variables, \pageref{sec:norm-lincomb}

$\bullet$ Linear transformation theorem for the matrix-normal distribution, \pageref{sec:matn-ltt}

$\bullet$ Linear transformation theorem for the moment-generating function, \pageref{sec:mgf-ltt}

$\bullet$ Linear transformation theorem for the multivariate normal distribution, \pageref{sec:mvn-ltt}

$\bullet$ Linearity of the expected value, \pageref{sec:mean-lin}

$\bullet$ Log Bayes factor for the univariate Gaussian with known variance, \pageref{sec:ugkv-lbf}

$\bullet$ Log Bayes factor in terms of log model evidences, \pageref{sec:lbf-lme}

$\bullet$ Log family evidences in terms of log model evidences, \pageref{sec:lfe-lme}

$\bullet$ Log model evidence for Bayesian linear regression, \pageref{sec:blr-lme}

$\bullet$ Log model evidence for binomial observations, \pageref{sec:bin-lme}

$\bullet$ Log model evidence for multinomial observations, \pageref{sec:mult-lme}

$\bullet$ Log model evidence for multivariate Bayesian linear regression, \pageref{sec:mblr-lme}

$\bullet$ Log model evidence for Poisson-distributed data, \pageref{sec:poiss-lme}

$\bullet$ Log model evidence for the Poisson distribution with exposure values, \pageref{sec:poissexp-lme}

$\bullet$ Log model evidence for the univariate Gaussian, \pageref{sec:ug-lme}

$\bullet$ Log model evidence for the univariate Gaussian with known variance, \pageref{sec:ugkv-lme}

$\bullet$ Log sum inequality, \pageref{sec:logsum-ineq}

$\bullet$ Log-odds and probability in logistic regression, \pageref{sec:logreg-lonp}

$\bullet$ Logarithmic expectation of the gamma distribution, \pageref{sec:gam-logmean}


\vspace{1em}
\textbf{M}

$\bullet$ Marginal distributions of the multivariate normal distribution, \pageref{sec:mvn-marg}

$\bullet$ Marginal distributions of the normal-gamma distribution, \pageref{sec:ng-marg}

$\bullet$ Marginal likelihood is a definite integral of joint likelihood, \pageref{sec:ml-jl}

$\bullet$ Maximum likelihood estimation for Dirichlet-distributed data, \pageref{sec:dir-mle}

$\bullet$ Maximum likelihood estimation for multiple linear regression, \pageref{sec:mlr-mle}

$\bullet$ Maximum likelihood estimation for Poisson-distributed data, \pageref{sec:poiss-mle}

$\bullet$ Maximum likelihood estimation for simple linear regression, \pageref{sec:slr-mle}

$\bullet$ Maximum likelihood estimation for simple linear regression, \pageref{sec:slr-mle2}

$\bullet$ Maximum likelihood estimation for the general linear model, \pageref{sec:glm-mle}

$\bullet$ Maximum likelihood estimation for the Poisson distribution with exposure values, \pageref{sec:poissexp-mle}

$\bullet$ Maximum likelihood estimation for the univariate Gaussian, \pageref{sec:ug-mle}

$\bullet$ Maximum likelihood estimation for the univariate Gaussian with known variance, \pageref{sec:ugkv-mle}

$\bullet$ Maximum likelihood estimator of variance is biased, \pageref{sec:resvar-bias}

$\bullet$ Mean of the Bernoulli distribution, \pageref{sec:bern-mean}

$\bullet$ Mean of the beta distribution, \pageref{sec:beta-mean}

$\bullet$ Mean of the binomial distribution, \pageref{sec:bin-mean}

$\bullet$ Mean of the categorical distribution, \pageref{sec:cat-mean}

$\bullet$ Mean of the continuous uniform distribution, \pageref{sec:cuni-mean}

$\bullet$ Mean of the exponential distribution, \pageref{sec:exp-mean}

$\bullet$ Mean of the gamma distribution, \pageref{sec:gam-mean}

$\bullet$ Mean of the multinomial distribution, \pageref{sec:mult-mean}

$\bullet$ Mean of the normal distribution, \pageref{sec:norm-mean}

$\bullet$ Mean of the normal-gamma distribution, \pageref{sec:ng-mean}

$\bullet$ Mean of the Poisson distribution, \pageref{sec:poiss-mean}

$\bullet$ Mean of the Wald distribution, \pageref{sec:wald-mean}

$\bullet$ Median of the continuous uniform distribution, \pageref{sec:cuni-med}

$\bullet$ Median of the exponential distribution, \pageref{sec:exp-med}

$\bullet$ Median of the normal distribution, \pageref{sec:norm-med}

$\bullet$ Method of moments for beta-distributed data, \pageref{sec:beta-mome}

$\bullet$ Mode of the continuous uniform distribution, \pageref{sec:cuni-med}

$\bullet$ Mode of the exponential distribution, \pageref{sec:exp-mode}

$\bullet$ Mode of the normal distribution, \pageref{sec:norm-mode}

$\bullet$ Moment in terms of moment-generating function, \pageref{sec:mom-mgf}

$\bullet$ Moment-generating function of a function of a random variable, \pageref{sec:mgf-fct}

$\bullet$ Moment-generating function of linear combination of independent random variables, \pageref{sec:mgf-lincomb}

$\bullet$ Moment-generating function of the beta distribution, \pageref{sec:beta-mgf}

$\bullet$ Moment-generating function of the normal distribution, \pageref{sec:norm-mgf}

$\bullet$ Moment-generating function of the Wald distribution, \pageref{sec:wald-mgf}

$\bullet$ Moments of the chi-squared distribution, \pageref{sec:chi2-mom}

$\bullet$ Monotonicity of probability, \pageref{sec:prob-mon}

$\bullet$ Monotonicity of the expected value, \pageref{sec:mean-mono}


\vspace{1em}
\textbf{N}

$\bullet$ Necessary and sufficient condition for independence of multivariate normal random variables, \pageref{sec:mvn-ind}

$\bullet$ Non-invariance of the differential entropy under change of variables, \pageref{sec:dent-noninv}

$\bullet$ (Non-)Multiplicativity of the expected value, \pageref{sec:mean-mult}

$\bullet$ Non-negativity of the expected value, \pageref{sec:mean-nonneg}

$\bullet$ Non-negativity of the Kullback-Leibler divergence, \pageref{sec:kl-nonneg}

$\bullet$ Non-negativity of the Kullback-Leibler divergence, \pageref{sec:kl-nonneg2}

$\bullet$ Non-negativity of the Shannon entropy, \pageref{sec:ent-nonneg}

$\bullet$ Non-negativity of the variance, \pageref{sec:var-nonneg}

$\bullet$ Non-symmetry of the Kullback-Leibler divergence, \pageref{sec:kl-nonsymm}

$\bullet$ Normal distribution maximizes differential entropy for fixed variance, \pageref{sec:norm-maxent}


\vspace{1em}
\textbf{O}

$\bullet$ One-sample t-test for independent observations, \pageref{sec:ug-ttest1}

$\bullet$ One-sample z-test for independent observations, \pageref{sec:ugkv-ztest1}

$\bullet$ Ordinary least squares for multiple linear regression, \pageref{sec:mlr-ols}

$\bullet$ Ordinary least squares for multiple linear regression, \pageref{sec:mlr-ols2}

$\bullet$ Ordinary least squares for simple linear regression, \pageref{sec:slr-ols}

$\bullet$ Ordinary least squares for simple linear regression, \pageref{sec:slr-ols2}

$\bullet$ Ordinary least squares for the general linear model, \pageref{sec:glm-ols}


\vspace{1em}
\textbf{P}

$\bullet$ Paired t-test for dependent observations, \pageref{sec:ug-ttestp}

$\bullet$ Paired z-test for dependent observations, \pageref{sec:ugkv-ztestp}

$\bullet$ Parameters of the corresponding forward model, \pageref{sec:cfm-para}

$\bullet$ Partition of a covariance matrix into expected values, \pageref{sec:covmat-mean}

$\bullet$ Partition of covariance into expected values, \pageref{sec:cov-mean}

$\bullet$ Partition of sums of squares in ordinary least squares, \pageref{sec:mlr-pss}

$\bullet$ Partition of the log model evidence into accuracy and complexity, \pageref{sec:lme-anc}

$\bullet$ Partition of the mean squared error into bias and variance, \pageref{sec:mse-bnv}

$\bullet$ Partition of variance into expected values, \pageref{sec:var-mean}

$\bullet$ Posterior credibility region against the omnibus null hypothesis for Bayesian linear regression, \pageref{sec:blr-pcr}

$\bullet$ Posterior density is proportional to joint likelihood, \pageref{sec:post-jl}

$\bullet$ Posterior distribution for Bayesian linear regression, \pageref{sec:blr-post}

$\bullet$ Posterior distribution for binomial observations, \pageref{sec:bin-post}

$\bullet$ Posterior distribution for multinomial observations, \pageref{sec:mult-post}

$\bullet$ Posterior distribution for multivariate Bayesian linear regression, \pageref{sec:mblr-post}

$\bullet$ Posterior distribution for Poisson-distributed data, \pageref{sec:poiss-post}

$\bullet$ Posterior distribution for the Poisson distribution with exposure values, \pageref{sec:poissexp-post}

$\bullet$ Posterior distribution for the univariate Gaussian, \pageref{sec:ug-post}

$\bullet$ Posterior distribution for the univariate Gaussian with known variance, \pageref{sec:ugkv-post}

$\bullet$ Posterior model probabilities in terms of Bayes factors, \pageref{sec:pmp-bf}

$\bullet$ Posterior model probabilities in terms of log model evidences, \pageref{sec:pmp-lme}

$\bullet$ Posterior model probability in terms of log Bayes factor, \pageref{sec:pmp-lbf}

$\bullet$ Posterior probability of the alternative hypothesis for Bayesian linear regression, \pageref{sec:blr-pp}

$\bullet$ Probability and log-odds in logistic regression, \pageref{sec:logreg-pnlo}

$\bullet$ Probability density function is first derivative of cumulative distribution function, \pageref{sec:pdf-cdf}

$\bullet$ Probability density function of a linear function of a continuous random vector, \pageref{sec:pdf-linfct}

$\bullet$ Probability density function of a strictly decreasing function of a continuous random variable, \pageref{sec:pdf-sdfct}

$\bullet$ Probability density function of a strictly increasing function of a continuous random variable, \pageref{sec:pdf-sifct}

$\bullet$ Probability density function of a sum of independent discrete random variables, \pageref{sec:pdf-sumind}

$\bullet$ Probability density function of an invertible function of a continuous random vector, \pageref{sec:pdf-invfct}

$\bullet$ Probability density function of the beta distribution, \pageref{sec:beta-pdf}

$\bullet$ Probability density function of the chi-squared distribution, \pageref{sec:chi2-pdf}

$\bullet$ Probability density function of the continuous uniform distribution, \pageref{sec:cuni-pdf}

$\bullet$ Probability density function of the Dirichlet distribution, \pageref{sec:dir-pdf}

$\bullet$ Probability density function of the exponential distribution, \pageref{sec:exp-pdf}

$\bullet$ Probability density function of the F-distribution, \pageref{sec:f-pdf}

$\bullet$ Probability density function of the gamma distribution, \pageref{sec:gam-pdf}

$\bullet$ Probability density function of the matrix-normal distribution, \pageref{sec:matn-pdf}

$\bullet$ Probability density function of the multivariate normal distribution, \pageref{sec:mvn-pdf}

$\bullet$ Probability density function of the normal distribution, \pageref{sec:norm-pdf}

$\bullet$ Probability density function of the normal-gamma distribution, \pageref{sec:ng-pdf}

$\bullet$ Probability density function of the t-distribution, \pageref{sec:t-pdf}

$\bullet$ Probability density function of the Wald distribution, \pageref{sec:wald-pdf}

$\bullet$ Probability integral transform using cumulative distribution function, \pageref{sec:cdf-pit}

$\bullet$ Probability mass function of a strictly decreasing function of a discrete random variable, \pageref{sec:pmf-sdfct}

$\bullet$ Probability mass function of a strictly increasing function of a discrete random variable, \pageref{sec:pmf-sifct}

$\bullet$ Probability mass function of a sum of independent discrete random variables, \pageref{sec:pmf-sumind}

$\bullet$ Probability mass function of an invertible function of a random vector, \pageref{sec:pmf-invfct}

$\bullet$ Probability mass function of the Bernoulli distribution, \pageref{sec:bern-pmf}

$\bullet$ Probability mass function of the binomial distribution, \pageref{sec:bin-pmf}

$\bullet$ Probability mass function of the categorical distribution, \pageref{sec:cat-pmf}

$\bullet$ Probability mass function of the discrete uniform distribution, \pageref{sec:duni-pmf}

$\bullet$ Probability mass function of the multinomial distribution, \pageref{sec:mult-pmf}

$\bullet$ Probability mass function of the Poisson distribution, \pageref{sec:poiss-pmf}

$\bullet$ Probability of exhaustive events, \pageref{sec:prob-exh}

$\bullet$ Probability of the complement, \pageref{sec:prob-comp}

$\bullet$ Probability of the empty set, \pageref{sec:prob-emp}

$\bullet$ Probability under mutual exclusivity, \pageref{sec:prob-exc}

$\bullet$ Probability under statistical independence, \pageref{sec:prob-ind}

$\bullet$ Projection matrix and residual-forming matrix are idempotent, \pageref{sec:mlr-idem}

$\bullet$ Projection of a data point to the regression line, \pageref{sec:slr-proj}


\vspace{1em}
\textbf{Q}

$\bullet$ Quantile function is inverse of strictly monotonically increasing cumulative distribution function, \pageref{sec:qf-cdf}

$\bullet$ Quantile function of the continuous uniform distribution, \pageref{sec:cuni-qf}

$\bullet$ Quantile function of the discrete uniform distribution, \pageref{sec:duni-qf}

$\bullet$ Quantile function of the exponential distribution, \pageref{sec:exp-qf}

$\bullet$ Quantile function of the gamma distribution, \pageref{sec:gam-qf}

$\bullet$ Quantile function of the normal distribution, \pageref{sec:norm-qf}


\vspace{1em}
\textbf{R}

$\bullet$ Range of probability, \pageref{sec:prob-range}

$\bullet$ Relation of continuous Kullback-Leibler divergence to differential entropy, \pageref{sec:kl-dent}

$\bullet$ Relation of continuous mutual information to joint and conditional differential entropy, \pageref{sec:cmi-jcde}

$\bullet$ Relation of continuous mutual information to marginal and conditional differential entropy, \pageref{sec:cmi-mcde}

$\bullet$ Relation of continuous mutual information to marginal and joint differential entropy, \pageref{sec:cmi-mjde}

$\bullet$ Relation of Kullback-Leibler divergence to entropy, \pageref{sec:kl-ent}

$\bullet$ Relation of mutual information to joint and conditional entropy, \pageref{sec:dmi-jce}

$\bullet$ Relation of mutual information to marginal and conditional entropy, \pageref{sec:dmi-mce}

$\bullet$ Relation of mutual information to marginal and joint entropy, \pageref{sec:dmi-mje}

$\bullet$ Relationship between coefficient of determination and correlation coefficient in simple linear regression, \pageref{sec:slr-rsq}

$\bullet$ Relationship between correlation coefficient and slope estimate in simple linear regression, \pageref{sec:slr-corr}

$\bullet$ Relationship between covariance and correlation, \pageref{sec:cov-corr}

$\bullet$ Relationship between covariance matrix and correlation matrix, \pageref{sec:covmat-corrmat}

$\bullet$ Relationship between gamma distribution and standard gamma distribution, \pageref{sec:gam-sgam}

$\bullet$ Relationship between gamma distribution and standard gamma distribution, \pageref{sec:gam-sgam2}

$\bullet$ Relationship between multivariate t-distribution and F-distribution, \pageref{sec:mvt-f}

$\bullet$ Relationship between non-standardized t-distribution and t-distribution, \pageref{sec:nst-t}

$\bullet$ Relationship between normal distribution and chi-squared distribution, \pageref{sec:norm-chi2}

$\bullet$ Relationship between normal distribution and standard normal distribution, \pageref{sec:norm-snorm}

$\bullet$ Relationship between normal distribution and standard normal distribution, \pageref{sec:norm-snorm2}

$\bullet$ Relationship between normal distribution and standard normal distribution, \pageref{sec:norm-snorm3}

$\bullet$ Relationship between normal distribution and t-distribution, \pageref{sec:norm-t}

$\bullet$ Relationship between precision matrix and correlation matrix, \pageref{sec:precmat-corrmat}

$\bullet$ Relationship between RÂ² and maximum log-likelihood, \pageref{sec:rsq-mll}

$\bullet$ Relationship between residual variance and sample variance in simple linear regression, \pageref{sec:slr-resvar}

$\bullet$ Relationship between second raw moment, variance and mean, \pageref{sec:momraw-2nd}

$\bullet$ Relationship between signal-to-noise ratio and RÂ², \pageref{sec:snr-rsq}


\vspace{1em}
\textbf{S}

$\bullet$ Sampling from the matrix-normal distribution, \pageref{sec:matn-samp}

$\bullet$ Savage-Dickey Density Ratio for computing Bayes Factors, \pageref{sec:bf-sddr}

$\bullet$ Scaling of the variance upon multiplication with a constant, \pageref{sec:var-scal}

$\bullet$ Second central moment is variance, \pageref{sec:momcent-2nd}

$\bullet$ Simple linear regression is a special case of multiple linear regression, \pageref{sec:slr-mlr}

$\bullet$ Sums of squares for simple linear regression, \pageref{sec:slr-sss}


\vspace{1em}
\textbf{T}

$\bullet$ The regression line goes through the center of mass point, \pageref{sec:slr-comp}

$\bullet$ The residuals and the covariate are uncorrelated in simple linear regression, \pageref{sec:slr-rescorr}

$\bullet$ The sum of residuals is zero in simple linear regression, \pageref{sec:slr-ressum}

$\bullet$ Transformation matrices for ordinary least squares, \pageref{sec:mlr-mat}

$\bullet$ Transformation matrices for simple linear regression, \pageref{sec:slr-mat}

$\bullet$ Transitivity of Bayes Factors, \pageref{sec:bf-trans}

$\bullet$ Transposition of a matrix-normal random variable, \pageref{sec:matn-trans}

$\bullet$ Two-sample t-test for independent observations, \pageref{sec:ug-ttest2}

$\bullet$ Two-sample z-test for independent observations, \pageref{sec:ugkv-ztest2}


\vspace{1em}
\textbf{V}

$\bullet$ Variance of constant is zero, \pageref{sec:var-const}

$\bullet$ Variance of parameter estimates for simple linear regression, \pageref{sec:slr-olsvar}

$\bullet$ Variance of the beta distribution, \pageref{sec:beta-var}

$\bullet$ Variance of the gamma distribution, \pageref{sec:gam-var}

$\bullet$ Variance of the linear combination of two random variables, \pageref{sec:var-lincomb}

$\bullet$ Variance of the normal distribution, \pageref{sec:norm-var}

$\bullet$ Variance of the Poisson distribution, \pageref{sec:poiss-var}

$\bullet$ Variance of the sum of two random variables, \pageref{sec:var-sum}

$\bullet$ Variance of the Wald distribution, \pageref{sec:wald-var}


\vspace{1em}
\textbf{W}

$\bullet$ Weighted least squares for multiple linear regression, \pageref{sec:mlr-wls}

$\bullet$ Weighted least squares for multiple linear regression, \pageref{sec:mlr-wls2}

$\bullet$ Weighted least squares for simple linear regression, \pageref{sec:slr-wls}

$\bullet$ Weighted least squares for simple linear regression, \pageref{sec:slr-wls2}

$\bullet$ Weighted least squares for the general linear model, \pageref{sec:glm-wls}




\pagebreak
\section{Definition by Topic}

\textbf{A}

$\bullet$ Akaike information criterion, \pageref{sec:aic}

$\bullet$ Alternative hypothesis, \pageref{sec:h1}


\vspace{1em}
\textbf{B}

$\bullet$ Bayes factor, \pageref{sec:bf}

$\bullet$ Bayesian information criterion, \pageref{sec:bic}

$\bullet$ Bayesian model averaging, \pageref{sec:bma}

$\bullet$ Bernoulli distribution, \pageref{sec:bern}

$\bullet$ Beta distribution, \pageref{sec:beta}

$\bullet$ Beta-distributed data, \pageref{sec:beta-data}

$\bullet$ Binomial distribution, \pageref{sec:bin}

$\bullet$ Binomial observations, \pageref{sec:bin-data}


\vspace{1em}
\textbf{C}

$\bullet$ Categorical distribution, \pageref{sec:cat}

$\bullet$ Central moment, \pageref{sec:mom-cent}

$\bullet$ Characteristic function, \pageref{sec:cf}

$\bullet$ Chi-squared distribution, \pageref{sec:chi2}

$\bullet$ Coefficient of determination, \pageref{sec:rsq}

$\bullet$ Conditional differential entropy, \pageref{sec:dent-cond}

$\bullet$ Conditional entropy, \pageref{sec:ent-cond}

$\bullet$ Conditional independence, \pageref{sec:ind-cond}

$\bullet$ Conditional probability distribution, \pageref{sec:dist-cond}

$\bullet$ Conjugate and non-conjugate prior distribution, \pageref{sec:prior-conj}

$\bullet$ Constant, \pageref{sec:const}

$\bullet$ Continuous uniform distribution, \pageref{sec:cuni}

$\bullet$ Correlation, \pageref{sec:corr}

$\bullet$ Correlation matrix, \pageref{sec:corrmat}

$\bullet$ Corresponding forward model, \pageref{sec:cfm}

$\bullet$ Covariance, \pageref{sec:cov}

$\bullet$ Covariance matrix, \pageref{sec:covmat}

$\bullet$ Critical value, \pageref{sec:cval}

$\bullet$ Cross-entropy, \pageref{sec:ent-cross}

$\bullet$ Cross-validated log model evidence, \pageref{sec:cvlme}

$\bullet$ Cumulant-generating function, \pageref{sec:cgf}

$\bullet$ Cumulative distribution function, \pageref{sec:cdf}


\vspace{1em}
\textbf{D}

$\bullet$ Deviance information criterion, \pageref{sec:dic}

$\bullet$ Differential cross-entropy, \pageref{sec:dent-cross}

$\bullet$ Differential entropy, \pageref{sec:dent}

$\bullet$ Dirichlet distribution, \pageref{sec:dir}

$\bullet$ Dirichlet-distributed data, \pageref{sec:dir-data}

$\bullet$ Discrete and continuous random variable, \pageref{sec:rvar-disc}

$\bullet$ Discrete uniform distribution, \pageref{sec:duni}


\vspace{1em}
\textbf{E}

$\bullet$ Empirical and theoretical prior distribution, \pageref{sec:prior-emp}

$\bullet$ Empirical Bayes, \pageref{sec:eb}

$\bullet$ Empirical Bayes prior distribution, \pageref{sec:prior-eb}

$\bullet$ Empirical Bayesian log model evidence, \pageref{sec:eblme}

$\bullet$ Encompassing model, \pageref{sec:encm}

$\bullet$ Estimation matrix, \pageref{sec:emat}

$\bullet$ Event space, \pageref{sec:eve-spc}

$\bullet$ Exceedance probability, \pageref{sec:prob-exc}

$\bullet$ Expected value, \pageref{sec:mean}

$\bullet$ Expected value of a random matrix, \pageref{sec:mean-rmat}

$\bullet$ Expected value of a random vector, \pageref{sec:mean-rvec}

$\bullet$ Explained sum of squares, \pageref{sec:ess}

$\bullet$ Exponential distribution, \pageref{sec:exp}


\vspace{1em}
\textbf{F}

$\bullet$ F-distribution, \pageref{sec:f}

$\bullet$ Flat, hard and soft prior distribution, \pageref{sec:prior-flat}

$\bullet$ Full probability model, \pageref{sec:fpm}

$\bullet$ Full width at half maximum, \pageref{sec:fwhm}


\vspace{1em}
\textbf{G}

$\bullet$ Gamma distribution, \pageref{sec:gam}

$\bullet$ General linear model, \pageref{sec:glm}

$\bullet$ Generative model, \pageref{sec:gm}


\vspace{1em}
\textbf{I}

$\bullet$ Informative and non-informative prior distribution, \pageref{sec:prior-inf}

$\bullet$ Inverse general linear model, \pageref{sec:iglm}


\vspace{1em}
\textbf{J}

$\bullet$ Joint cumulative distribution function, \pageref{sec:cdf-joint}

$\bullet$ Joint differential entropy, \pageref{sec:dent-joint}

$\bullet$ Joint entropy, \pageref{sec:ent-joint}

$\bullet$ Joint likelihood, \pageref{sec:jl}

$\bullet$ Joint probability, \pageref{sec:prob-joint}

$\bullet$ Joint probability distribution, \pageref{sec:dist-joint}


\vspace{1em}
\textbf{K}

$\bullet$ Kolmogorov axioms of probability, \pageref{sec:prob-ax}

$\bullet$ Kullback-Leibler divergence, \pageref{sec:kl}


\vspace{1em}
\textbf{L}

$\bullet$ Law of conditional probability, \pageref{sec:prob-cond}

$\bullet$ Law of marginal probability, \pageref{sec:prob-marg}

$\bullet$ Likelihood function, \pageref{sec:lf}

$\bullet$ Likelihood function, \pageref{sec:lf}

$\bullet$ Log Bayes factor, \pageref{sec:lbf}

$\bullet$ Log family evidence, \pageref{sec:lfe}

$\bullet$ Log model evidence, \pageref{sec:lme}

$\bullet$ Log-likelihood function, \pageref{sec:llf}

$\bullet$ Logistic regression, \pageref{sec:logreg}


\vspace{1em}
\textbf{M}

$\bullet$ Marginal likelihood, \pageref{sec:ml}

$\bullet$ Marginal probability distribution, \pageref{sec:dist-marg}

$\bullet$ Matrix-normal distribution, \pageref{sec:matn}

$\bullet$ Maximum, \pageref{sec:max}

$\bullet$ Maximum entropy prior distribution, \pageref{sec:prior-maxent}

$\bullet$ Maximum likelihood estimation, \pageref{sec:mle}

$\bullet$ Maximum log-likelihood, \pageref{sec:mll}

$\bullet$ Median, \pageref{sec:med}

$\bullet$ Method-of-moments estimation, \pageref{sec:mome}

$\bullet$ Minimum, \pageref{sec:min}

$\bullet$ Mode, \pageref{sec:mode}

$\bullet$ Moment, \pageref{sec:mom}

$\bullet$ Moment-generating function, \pageref{sec:mgf}

$\bullet$ Multinomial distribution, \pageref{sec:mult}

$\bullet$ Multinomial observations, \pageref{sec:mult-data}

$\bullet$ Multiple linear regression, \pageref{sec:mlr}

$\bullet$ Multivariate normal distribution, \pageref{sec:mvn}

$\bullet$ Multivariate t-distribution, \pageref{sec:mvt}

$\bullet$ Mutual exclusivity, \pageref{sec:exc}

$\bullet$ Mutual information, \pageref{sec:mi}

$\bullet$ Mutual information, \pageref{sec:mi}


\vspace{1em}
\textbf{N}

$\bullet$ Non-standardized t-distribution, \pageref{sec:nst}

$\bullet$ Normal distribution, \pageref{sec:norm}

$\bullet$ Normal-gamma distribution, \pageref{sec:ng}

$\bullet$ Null hypothesis, \pageref{sec:h0}


\vspace{1em}
\textbf{O}

$\bullet$ One-tailed and two-tailed hypothesis, \pageref{sec:hyp-tail}

$\bullet$ One-tailed and two-tailed test, \pageref{sec:test-tail}


\vspace{1em}
\textbf{P}

$\bullet$ p-value, \pageref{sec:pval}

$\bullet$ Point and set hypothesis, \pageref{sec:hyp-point}

$\bullet$ Poisson distribution, \pageref{sec:poiss}

$\bullet$ Poisson distribution with exposure values, \pageref{sec:poissexp}

$\bullet$ Poisson-distributed data, \pageref{sec:poiss-data}

$\bullet$ Posterior distribution, \pageref{sec:post}

$\bullet$ Posterior model probability, \pageref{sec:pmp}

$\bullet$ Power of a statistical test, \pageref{sec:power}

$\bullet$ Precision, \pageref{sec:prec}

$\bullet$ Precision matrix, \pageref{sec:precmat}

$\bullet$ Prior distribution, \pageref{sec:prior}

$\bullet$ Probability, \pageref{sec:prob}

$\bullet$ Probability density function, \pageref{sec:pdf}

$\bullet$ Probability distribution, \pageref{sec:dist}

$\bullet$ Probability mass function, \pageref{sec:pmf}

$\bullet$ Probability space, \pageref{sec:prob-spc}

$\bullet$ Probability-generating function, \pageref{sec:pgf}

$\bullet$ Projection matrix, \pageref{sec:pmat}


\vspace{1em}
\textbf{Q}

$\bullet$ Quantile function, \pageref{sec:qf}


\vspace{1em}
\textbf{R}

$\bullet$ Random event, \pageref{sec:reve}

$\bullet$ Random experiment, \pageref{sec:rexp}

$\bullet$ Random matrix, \pageref{sec:rmat}

$\bullet$ Random variable, \pageref{sec:rvar}

$\bullet$ Random vector, \pageref{sec:rvec}

$\bullet$ Raw moment, \pageref{sec:mom-raw}

$\bullet$ Reference prior distribution, \pageref{sec:prior-ref}

$\bullet$ Regression line, \pageref{sec:regline}

$\bullet$ Residual sum of squares, \pageref{sec:rss}

$\bullet$ Residual variance, \pageref{sec:resvar}

$\bullet$ Residual-forming matrix, \pageref{sec:rfmat}


\vspace{1em}
\textbf{S}

$\bullet$ Sample correlation coefficient, \pageref{sec:corr-samp}

$\bullet$ Sample correlation matrix, \pageref{sec:corrmat-samp}

$\bullet$ Sample covariance, \pageref{sec:cov-samp}

$\bullet$ Sample covariance matrix, \pageref{sec:covmat-samp}

$\bullet$ Sample mean, \pageref{sec:mean-samp}

$\bullet$ Sample space, \pageref{sec:samp-spc}

$\bullet$ Sample variance, \pageref{sec:var-samp}

$\bullet$ Sampling distribution, \pageref{sec:dist-samp}

$\bullet$ Shannon entropy, \pageref{sec:ent}

$\bullet$ Signal-to-noise ratio, \pageref{sec:snr}

$\bullet$ Significance level, \pageref{sec:alpha}

$\bullet$ Simple and composite hypothesis, \pageref{sec:hyp-simp}

$\bullet$ Simple linear regression, \pageref{sec:slr}

$\bullet$ Size of a statistical test, \pageref{sec:size}

$\bullet$ Standard deviation, \pageref{sec:std}

$\bullet$ Standard gamma distribution, \pageref{sec:sgam}

$\bullet$ Standard normal distribution, \pageref{sec:snorm}

$\bullet$ Standard uniform distribution, \pageref{sec:suni}

$\bullet$ Standardized moment, \pageref{sec:mom-stand}

$\bullet$ Statistical hypothesis, \pageref{sec:hyp}

$\bullet$ Statistical hypothesis test, \pageref{sec:test}

$\bullet$ Statistical independence, \pageref{sec:ind}


\vspace{1em}
\textbf{T}

$\bullet$ t-distribution, \pageref{sec:t}

$\bullet$ Test statistic, \pageref{sec:tstat}

$\bullet$ Total sum of squares, \pageref{sec:tss}

$\bullet$ Transformed general linear model, \pageref{sec:tglm}


\vspace{1em}
\textbf{U}

$\bullet$ Uniform and non-uniform prior distribution, \pageref{sec:prior-uni}

$\bullet$ Uniform-prior log model evidence, \pageref{sec:uplme}

$\bullet$ Univariate and multivariate random variable, \pageref{sec:rvar-uni}

$\bullet$ Univariate Gaussian, \pageref{sec:ug}

$\bullet$ Univariate Gaussian with known variance, \pageref{sec:ugkv}


\vspace{1em}
\textbf{V}

$\bullet$ Variance, \pageref{sec:var}

$\bullet$ Variational Bayes, \pageref{sec:vb}

$\bullet$ Variational Bayesian log model evidence, \pageref{sec:vblme}


\vspace{1em}
\textbf{W}

$\bullet$ Wald distribution, \pageref{sec:wald}

$\bullet$ Wishart distribution, \pageref{sec:wish}




\end{document}