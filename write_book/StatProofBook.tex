\documentclass[a4paper,12pt,twoside]{book}

%%% Packages %%%
\usepackage[cm,headings]{fullpage}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{gensymb}
\usepackage{url}
\usepackage{csquotes}
\usepackage{enumitem}
\usepackage{setspace}

%%% Settings %%%
\pagestyle{headings}
\setlength{\parindent}{0pt}
\raggedbottom
\frenchspacing
\urlstyle{same}
\MakeOuterQuote{"}
\setlist{nolistsep}
\setlist[itemize]{leftmargin=*}
\setlist[enumerate]{leftmargin=*}
\setcounter{tocdepth}{3}
\setcounter{secnumdepth}{3}

%%% Format %%%
\renewcommand\thechapter{\Roman{chapter}}
\renewcommand\thesection{\arabic{section}}
\renewcommand\theequation{\arabic{equation}}
\let\Chaptermark\chaptermark
\def\chaptermark#1{\def\Chaptername{#1}\Chaptermark{#1}}
\let\Sectionmark\sectionmark
\def\sectionmark#1{\def\Sectionname{#1}\Sectionmark{#1}}

%%% Title %%%
\title{\Huge{The Book of Statistical Proofs}}
\author{https://statproofbook.github.io/ \\ StatProofBook@gmail.com}
\date{2020-08-26, 15:54}

\begin{document}


%%% Title %%%
\maketitle

%%% Contents %%%
\pagebreak
\pagenumbering{roman}
\tableofcontents

%%% Text %%%
\newpage
\pagenumbering{arabic}


% Chapter 1 %
\chapter{General Theorems} \label{sec:General Theorems} \newpage

\pagebreak
\section{Probability theory}

\subsection{Random variables}

\subsubsection[\textit{Random variable}]{Random variable} \label{sec:rvar}
\setcounter{equation}{0}

\textbf{Definition:} A random variable may be understood

\begin{itemize}

\item informally, as a real number $X \in \mathbb{R}$ whose value is the outcome of a random experiment ($\rightarrow$ Definition "rexp");

\item formally, as a measurable function ($\rightarrow$ Definition "meas-fct") $X$ defined on a probability space ($\rightarrow$ Definition "prob-spc") $(\Omega, \mathcal{F}, P)$ that maps from a sample space $\Omega$ to the real numbers $\mathbb{R}$ using an event space $\mathcal{F}$ and a probability function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) $P$;

\item more broadly, as any random quantity $X$ such as a random scalar ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}), a random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}) or a random matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rmat}).

\end{itemize}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Random variable"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-05-27; URL: \url{https://en.wikipedia.org/wiki/Random_variable#Definition}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D65 | shortcut: rvar | author: JoramSoch | date: 2020-05-27, 22:36.
\vspace{1em}



\subsubsection[\textit{Random vector}]{Random vector} \label{sec:rvec}
\setcounter{equation}{0}

\textbf{Definition:} A random vector, also called "multivariate random variable", is an $n$-dimensional column vector $X \in \mathbb{R}^{n \times 1}$ whose entries are random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Multivariate random variable"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-05-27; URL: \url{https://en.wikipedia.org/wiki/Multivariate_random_variable}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D66 | shortcut: rvec | author: JoramSoch | date: 2020-05-27, 22:44.
\vspace{1em}



\subsubsection[\textit{Random matrix}]{Random matrix} \label{sec:rmat}
\setcounter{equation}{0}

\textbf{Definition:} A random matrix, also called "matrix-valued random variable", is an $n \times p$ matrix $X \in \mathbb{R}^{n \times p}$ whose entries are random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}). Equivalently, a random matrix is an $n \times p$ matrix whose columns are $n$-dimensional random vectors ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Random matrix"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-05-27; URL: \url{https://en.wikipedia.org/wiki/Random_matrix}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D67 | shortcut: rmat | author: JoramSoch | date: 2020-05-27, 22:48.
\vspace{1em}



\subsection{Probability}

\subsubsection[\textit{Probability}]{Probability} \label{sec:prob}
\setcounter{equation}{0}

\textbf{Definition:} Let $E$ be a statement about an arbitrary event such as the outcome of a random experiment ($\rightarrow$ Definition "rexp"). Then, $p(E)$ is called the probability of $E$ and may be interpreted as

\begin{itemize}

\item (objectivist interpretation of probability:) some physical state of affairs, e.g. the relative frequency of occurrence of $E$, when repeating the experiment ("Frequentist probability"); or

\item (subjectivist interpretation of probability:) a degree of belief in $E$, e.g. the price at which someone would buy or sell a bet that pays 1 unit of utility if $E$ and 0 if not $E$ ("Bayesian probability").

\end{itemize}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Probability"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-05-10; URL: \url{https://en.wikipedia.org/wiki/Probability#Interpretations}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D48 | shortcut: prob | author: JoramSoch | date: 2020-05-10, 19:41.
\vspace{1em}



\subsubsection[\textit{Joint probability}]{Joint probability} \label{sec:prob-joint}
\setcounter{equation}{0}

\textbf{Definition:} Let $A$ and $B$ be two arbitrary statements about random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}), such as statements about the presence or absence of an event or about the value of a scalar, vector or matrix. Then, $p(A,B)$ is called the joint probability of $A$ and $B$ and is defined as the probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob}) that $A$ and $B$ are both true.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Joint probability distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-05-10; URL: \url{https://en.wikipedia.org/wiki/Joint_probability_distribution}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D49 | shortcut: prob-joint | author: JoramSoch | date: 2020-05-10, 19:49.
\vspace{1em}



\subsubsection[\textit{Marginal probability}]{Marginal probability} \label{sec:prob-marg}
\setcounter{equation}{0}

\textbf{Definition:} Let $A$ and $X$ be two arbitrary statements about random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}), such as statements about the presence or absence of an event or about the value of a scalar, vector or matrix. Furthermore, assume a joint probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) distribution $p(A,X)$. Then, $p(A)$ is called the marginal probability of $A$ and,

1) if $X$ is a discrete random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with domain $\mathcal{X}$, is given by

\begin{equation} \label{eq:prob-marg-prob-marg-disc}
p(A) = \sum_{x \in \mathcal{X}} p(A,x) \; ;
\end{equation}

2) if $X$ is a continuous random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with domain $\mathcal{X}$, is given by

\begin{equation} \label{eq:prob-marg-prob-marg-cont}
p(A) = \int_{\mathcal{X}} p(A,x) \, \mathrm{d}x \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Marginal distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-05-10; URL: \url{https://en.wikipedia.org/wiki/Marginal_distribution#Definition}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D50 | shortcut: prob-marg | author: JoramSoch | date: 2020-05-10, 20:01.
\vspace{1em}



\subsubsection[\textit{Conditional probability}]{Conditional probability} \label{sec:prob-cond}
\setcounter{equation}{0}

\textbf{Definition:} Let $A$ and $B$ be two arbitrary statements about random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}), such as statements about the presence or absence of an event or about the value of a scalar, vector or matrix. Furthermore, assume a joint probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) distribution $p(A,B)$. Then, $p(A \vert B)$ is called the conditional probability that $A$ is true, given that $B$ is true, and is given by

\begin{equation} \label{eq:prob-cond-prob-cond}
p(A|B) = \frac{p(A,B)}{p(B)}
\end{equation}

where $p(B)$ is the marginal probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}) of $B$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Conditional probability"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-05-10; URL: \url{https://en.wikipedia.org/wiki/Conditional_probability#Definition}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D51 | shortcut: prob-cond | author: JoramSoch | date: 2020-05-10, 20:06.
\vspace{1em}



\subsubsection[\textit{Statistical independence}]{Statistical independence} \label{sec:ind}
\setcounter{equation}{0}

\textbf{Definition:} Generally speaking, random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) are statistically independent, if their joint probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) can be expressed in terms of their marginal probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}).

\vspace{1em}
1) A set of discrete random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X_1, \ldots, X_n$ with possible values $\mathcal{X}_1, \ldots, \mathcal{X}_n$ is called statistically independent, if

\begin{equation} \label{eq:ind-disc-ind}
p(X_1 = x_1, \ldots, X_n = x_n) = \prod_{i=1}^{n} p(X_i = x_i) \quad \text{for all} \; x_i \in \mathcal{X}_i, \; i = 1, \ldots, n
\end{equation}

where $p(x_1, \ldots, x_n)$ are the joint probabilities ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) of $X_1, \ldots, X_n$ and $p(x_i)$ are the marginal probabilities ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}) of $X_i$.

\vspace{1em}
2) A set of continuous random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X_1, \ldots, X_n$ defined on the domains $\mathcal{X}_1, \ldots, \mathcal{X}_n$ is called statistically independent, if

\begin{equation} \label{eq:ind-cont-ind-F}
F_{X_1,\ldots,X_n}(x_1,\ldots,x_n) = \prod_{i=1}^{n} F_{X_i}(x_i) \quad \text{for all} \; x_i \in \mathcal{X}_i, \; i = 1, \ldots, n
\end{equation}

or equivalently, if the probability densities ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) exist,

\begin{equation} \label{eq:ind-cont-ind-f}
f_{X_1,\ldots,X_n}(x_1,\ldots,x_n) = \prod_{i=1}^{n} f_{X_i}(x_i) \quad \text{for all} \; x_i \in \mathcal{X}_i, \; i = 1, \ldots, n
\end{equation}

where $F$ are the joint ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-joint}) or marginal ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-marg}) cumulative distribution functions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) and $f$ are the respective probability density functions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Independence (probability theory)"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-06-06; URL: \url{https://en.wikipedia.org/wiki/Independence_(probability_theory)#Definition}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D75 | shortcut: ind | author: JoramSoch | date: 2020-06-06, 07:16.
\vspace{1em}



\subsection{Probability distributions}

\subsubsection[\textit{Probability distribution}]{Probability distribution} \label{sec:dist}
\setcounter{equation}{0}

**Definition**: Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with the set of possible outcomes $\mathcal{X}$. Then, a probability distribution of $X$ is a mathematical function that gives the probabilities ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob}) of occurrence of all possible outcomes $x \in \mathcal{X}$ of this random variable.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Probability distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-05-17; URL: \url{https://en.wikipedia.org/wiki/Probability_distribution}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D55 | shortcut: dist | author: JoramSoch | date: 2020-05-17, 20:23.
\vspace{1em}



\subsubsection[\textit{Joint distribution}]{Joint distribution} \label{sec:dist-joint}
\setcounter{equation}{0}

**Definition**: Let $X$ and $Y$ be random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with sets of possible outcomes $\mathcal{X}$ and $\mathcal{Y}$. Then, a joint distribution of $X$ and $Y$ is a probability distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist}) that specifies the probability of the event that $X = x$ and $Y = y$ for each possible combination of $x \in \mathcal{X}$ and $y \in \mathcal{Y}$.

\begin{itemize}

\item The joint distribution of two scalar random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) is called a bivariate distribution.

\item The joint distribution of a random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}) is called a multivariate distribution.

\item The joint distribution of a random matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rmat}) is called a matrix-variate distribution.

\end{itemize}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Joint probability distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-05-17; URL: \url{https://en.wikipedia.org/wiki/Joint_probability_distribution}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D56 | shortcut: dist-joint | author: JoramSoch | date: 2020-05-17, 20:43.
\vspace{1em}



\subsubsection[\textit{Marginal distribution}]{Marginal distribution} \label{sec:dist-marg}
\setcounter{equation}{0}

**Definition**: Let $X$ and $Y$ be random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with sets of possible outcomes $\mathcal{X}$ and $\mathcal{Y}$. Then, the marginal distribution of $X$ is a probability distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist}) that specifies the probability of the event that $X = x$ irrespective of the value of $Y$ for each possible value $x \in \mathcal{X}$. The marginal distribution can be obtained from the joint distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-joint}) of $X$ and $Y$ using the law of marginal probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Marginal distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-05-17; URL: \url{https://en.wikipedia.org/wiki/Marginal_distribution}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D57 | shortcut: dist-marg | author: JoramSoch | date: 2020-05-17, 21:02.
\vspace{1em}



\subsubsection[\textit{Conditional distribution}]{Conditional distribution} \label{sec:dist-cond}
\setcounter{equation}{0}

**Definition**: Let $X$ and $Y$ be random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with sets of possible outcomes $\mathcal{X}$ and $\mathcal{Y}$. Then, the conditional distribution of $X$ given that $Y$ is a probability distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist}) that specifies the probability of the event that $X = x$ given that $Y = y$ for each possible combination of $x \in \mathcal{X}$ and $y \in \mathcal{Y}$. The conditional distribution of $X$ can be obtained from the joint distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-joint}) of $X$ and $Y$ and the marginal distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-marg}) of $Y$ using the law of conditional probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-cond}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Conditional probability distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-05-17; URL: \url{https://en.wikipedia.org/wiki/Conditional_probability_distribution}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D58 | shortcut: dist-cond | author: JoramSoch | date: 2020-05-17, 21:25.
\vspace{1em}



\subsection{Probability functions}

\subsubsection[\textit{Probability mass function}]{Probability mass function} \label{sec:pmf}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a discrete random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with possible outcomes $\mathcal{X}$. Then, $f_X(x): \mathbb{R} \to [0,1]$ is the probability mass function of $X$, if

\begin{equation} \label{eq:pmf-pmf-def-s0}
f_X(x) = 0
\end{equation}

for all $x \notin \mathcal{X}$,

\begin{equation} \label{eq:pmf-pmf-def-s1}
\mathrm{Pr}(X = x) = f_X(x)
\end{equation}

for all $x \in \mathcal{X}$ and

\begin{equation} \label{eq:pmf-pmf-def-s2}
\sum_{x \in \mathcal{X}} f_X(x) = 1 \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Probability mass function"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-02-13; URL: \url{https://en.wikipedia.org/wiki/Probability_mass_function}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D9 | shortcut: pmf | author: JoramSoch | date: 2020-02-13, 19:09.
\vspace{1em}



\subsubsection[\textit{Probability density function}]{Probability density function} \label{sec:pdf}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a continuous random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with possible outcomes $\mathcal{X}$. Then, $f_X(x): \mathbb{R} \to \mathbb{R}$ is the probability density function of $X$, if

\begin{equation} \label{eq:pdf-pdf-def-s0}
f_X(x) \geq 0
\end{equation}

for all $x \in \mathbb{R}$,

\begin{equation} \label{eq:pdf-pdf-def-s1}
\mathrm{Pr}(X \in A) = \int_{A} f_X(x) \, \mathrm{d}x
\end{equation}

for any $A \subset \mathcal{X}$ and

\begin{equation} \label{eq:pdf-pdf-def-s2}
\int_{\mathcal{X}} f_X(x) \, \mathrm{d}x = 1 \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Probability density function"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-02-13; URL: \url{https://en.wikipedia.org/wiki/Probability_density_function}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D10 | shortcut: pdf | author: JoramSoch | date: 2020-02-13, 19:26.
\vspace{1em}



\subsubsection[\textit{Cumulative distribution function}]{Cumulative distribution function} \label{sec:cdf}
\setcounter{equation}{0}

\textbf{Definition:}

1) Let $X$ be a discrete random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with possible outcomes $\mathcal{X}$ and the probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) $f_X(x)$. Then, the function $F_X(x): \mathbb{R} \to [0,1]$ with

\begin{equation} \label{eq:cdf-cdf-disc}
F_X(x) = \sum_{\overset{z \in \mathcal{X}}{z \leq x}} f_X(z)
\end{equation}

is the cumulative distribution function of $X$.

\vspace{1em}
2) Let $X$ be a scalar continuous random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) $f_X(x)$. Then, the function $F_X(x): \mathbb{R} \to [0,1]$ with

\begin{equation} \label{eq:cdf-cdf-cont}
F_X(x) = \int_{-\infty}^{x} f_X(z) \, \mathrm{d}z
\end{equation}

is the cumulative distribution function of $X$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Probability density function"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-02-17; URL: \url{https://en.wikipedia.org/wiki/Cumulative_distribution_function#Definition}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D13 | shortcut: cdf | author: JoramSoch | date: 2020-02-17, 22:07.
\vspace{1em}



\subsubsection[\textit{Quantile function}]{Quantile function} \label{sec:qf}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) (CDF) $F_X(x)$. Then, the function $Q_X(p): [0,1] \to \mathbb{R}$ which is the inverse CDF

\begin{equation} \label{eq:qf-qf}
Q_X(p) = F_X^{-1}(x)
\end{equation}

is the quantile function (QF) of $X$. More precisly, the QF is the function that, for a given quantile $p \in [0,1]$, returns the smallest $x$ for which $F_X(x) = p$:

\begin{equation} \label{eq:qf-qf-prec}
Q_X(p) = \min \left\lbrace x \in \mathbb{R} \, \vert \, F_X(x) = p \right\rbrace \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Probability density function"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-02-17; URL: \url{https://en.wikipedia.org/wiki/Quantile_function#Definition}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D14 | shortcut: qf | author: JoramSoch | date: 2020-02-17, 22:18.
\vspace{1em}



\subsubsection[\textit{Moment-generating function}]{Moment-generating function} \label{sec:mgf}
\setcounter{equation}{0}

\textbf{Definition:}

1) The moment-generating function of a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X \in \mathbb{R}$ is

\begin{equation} \label{eq:mgf-mgf-var}
M_X(t) = \mathrm{E} \left[ e^{tX} \right], \quad t \in \mathbb{R} \; .
\end{equation}

2) The moment-generating function of a random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}) $X \in \mathbb{R}^n$ is

\begin{equation} \label{eq:mgf-mgf-vec}
M_X(t) = \mathrm{E} \left[ e^{t^\mathrm{T}X} \right], \quad t \in \mathbb{R}^n \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Moment-generating function"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-01-22; URL: \url{https://en.wikipedia.org/wiki/Moment-generating_function#Definition}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D2 | shortcut: mgf | author: JoramSoch | date: 2020-01-22, 10:58.
\vspace{1em}



\subsubsection[\textbf{Moment-generating function of linear transformation}]{Moment-generating function of linear transformation} \label{sec:mgf-ltt}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be an $n \times 1$ random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}) with the moment-generating function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mgf}) $M_X(t)$. Then, the moment-generating function of the linear transformation $Y = A X + b$ is given by

\begin{equation} \label{eq:mgf-ltt-mgf-ltt}
M_Y(t) = \exp \left[ t^\mathrm{T} b \right] \cdot M_X(At)
\end{equation}

where $A$ is an $m \times n$ matrix and $b$ is an $m \times 1$ vector.


\vspace{1em}
\textbf{Proof:} The moment-generating function of a random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mgf}) $X$ is

\begin{equation} \label{eq:mgf-ltt-mfg-vect}
M_X(t) = \mathrm{E} \left( \exp \left[ t^\mathrm{T} X \right] \right)
\end{equation}

and therefore the moment-generating function of the random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}) $Y$ is given by

\begin{equation} \label{eq:mgf-ltt-mgf-ltt-qed}
\begin{split}
M_Y(t) &= \mathrm{E} \left( \exp \left[ t^\mathrm{T} (AX + b) \right] \right) \\
&= \mathrm{E} \left( \exp \left[ t^\mathrm{T} A X \right] \cdot \exp \left[ t^\mathrm{T} b \right] \right) \\
&= \exp \left[ t^\mathrm{T} b \right] \cdot \mathrm{E} \left( \exp \left[ (A t)^\mathrm{T} X \right] \right) \\
&= \exp \left[ t^\mathrm{T} b \right] \cdot M_X(At) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item ProofWiki (2020): "Moment Generating Function of Linear Transformation of Random Variable"; in: \textit{ProofWiki}, retrieved on 2020-08-19; URL: \url{https://proofwiki.org/wiki/Moment_Generating_Function_of_Linear_Transformation_of_Random_Variable}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P154 | shortcut: mgf-ltt | author: JoramSoch | date: 2020-08-19, 08:09.
\vspace{1em}



\subsubsection[\textbf{Moment-generating function of linear combination}]{Moment-generating function of linear combination} \label{sec:mgf-lincomb}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X_1, \ldots, X_n$ be $n$ independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}) random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with moment-generating functions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mgf}) $M_{X_i}(t)$. Then, the moment-generating function of the linear combination $X = \sum_{i=1}^{n} a_i X_i$ is given by

\begin{equation} \label{eq:mgf-lincomb-mgf-lincomb}
M_X(t) = \prod_{i=1}^{n} M_{X_i}(a_i t)
\end{equation}

where $a_1, \ldots, a_n$ are $n$ real numbers.


\vspace{1em}
\textbf{Proof:} The moment-generating function of a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mgf}) $X_i$ is

\begin{equation} \label{eq:mgf-lincomb-mfg-vect}
M_{X_i}(t) = \mathrm{E} \left( \exp \left[ t X_i \right] \right)
\end{equation}

and therefore the moment-generating function of the linear combination $X$ is given by

\begin{equation} \label{eq:mgf-lincomb-mgf-lincomb-s1}
\begin{split}
M_X(t) &= \mathrm{E} \left( \exp \left[ t X \right] \right) \\
&= \mathrm{E} \left( \exp \left[ t \sum_{i=1}^{n} a_i X_i \right] \right) \\
&= \mathrm{E} \left( \prod_{i=1}^{n} \exp \left[ t \, a_i X_i \right] \right) \; .
\end{split}
\end{equation}

Because the expected value is multiplicative for independent random variables ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-mult}), we have

\begin{equation} \label{eq:mgf-lincomb-mgf-lincomb-s2}
\begin{split}
M_X(t) &= \prod_{i=1}^{n} \mathrm{E} \left( \exp \left[ (a_i t) X_i \right] \right) \\
&= \prod_{i=1}^{n} M_{X_i}(a_i t) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item ProofWiki (2020): "Moment Generating Function of Linear Combination of Independent Random Variables"; in: \textit{ProofWiki}, retrieved on 2020-08-19; URL: \url{https://proofwiki.org/wiki/Moment_Generating_Function_of_Linear_Combination_of_Independent_Random_Variables}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P155 | shortcut: mgf-lincomb | author: JoramSoch | date: 2020-08-19, 08:36.
\vspace{1em}



\subsubsection[\textit{Cumulant-generating function}]{Cumulant-generating function} \label{sec:cgf}
\setcounter{equation}{0}

\textbf{Definition:}

1) The cumulant-generating function of a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X \in \mathbb{R}$ is

\begin{equation} \label{eq:cgf-cgf-var}
K_X(t) = \log \mathrm{E} \left[ e^{tX} \right], \quad t \in \mathbb{R} \; .
\end{equation}

2) The cumulant-generating function of a random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}) $X \in \mathbb{R}^n$ is

\begin{equation} \label{eq:cgf-cgf-vec}
K_X(t) = \log \mathrm{E} \left[ e^{t^\mathrm{T}X} \right], \quad t \in \mathbb{R}^n \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Cumulant"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-05-31; URL: \url{https://en.wikipedia.org/wiki/Cumulant#Definition}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D68 | shortcut: cgf | author: JoramSoch | date: 2020-05-31, 23:46.
\vspace{1em}



\subsubsection[\textit{Probability-generating function}]{Probability-generating function} \label{sec:pgf}
\setcounter{equation}{0}

\textbf{Definition:}

1) If $X$ is a discrete random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) taking values in the non-negative integers $\left\lbrace 0, 1, \ldots \right\rbrace$, then the probability-generating function of $X$ is defined as

\begin{equation} \label{eq:pgf-pgf-var}
G_X(z) = \mathrm{E} \left[ z^X \right] = \sum_{x=0}^{\infty} p(x) \, z^x
\end{equation}

where $z \in \mathbb{C}$ and $p(x)$ is the probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) of $X$.

2) If $X$ is a discrete random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}) taking values in the $n$-dimensional integer lattice $x \in \left\lbrace 0, 1, \ldots \right\rbrace^n$, then the probability-generating function of $X$ is defined as

\begin{equation} \label{eq:pgf-cgf-vec}
G_X(z) = \mathrm{E} \left[ {z_1}^{X_1} \cdot \ldots \cdot {z_n}^{X_n} \right] = \sum_{x_1=0}^{\infty} \cdots \sum_{x_n=0}^{\infty} p(x_1,\ldots,x_n) \, {z_1}^{x_1} \cdot \ldots \cdot {z_n}^{x_n}
\end{equation}

where $z \in \mathbb{C}^n$ and $p(x)$ is the probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) of $X$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Probability-generating function"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-05-31; URL: \url{https://en.wikipedia.org/wiki/Probability-generating_function#Definition}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D69 | shortcut: pgf | author: JoramSoch | date: 2020-05-31, 23:59.
\vspace{1em}



\subsection{Expected value}

\subsubsection[\textit{Definition}]{Definition} \label{sec:mean}
\setcounter{equation}{0}

\textbf{Definition:}

1) The expected value (or, mean) of a discrete random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X$ with domain $\mathcal{X}$ is

\begin{equation} \label{eq:mean-mean-disc}
\mathrm{E}(X) = \sum_{x \in \mathcal{X}} x \cdot f_X(x)
\end{equation}

where $f_X(x)$ is the probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) of $X$.

\vspace{1em}
2) The expected value (or, mean) of a continuous random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X$ with domain $\mathcal{X}$ is

\begin{equation} \label{eq:mean-mean-cont}
\mathrm{E}(X) = \int_{\mathcal{X}} x \cdot f_X(x) \, \mathrm{d}x
\end{equation}

where $f_X(x)$ is the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $X$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Expected value"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-02-13; URL: \url{https://en.wikipedia.org/wiki/Expected_value#Definition}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D11 | shortcut: mean | author: JoramSoch | date: 2020-02-13, 19:38.
\vspace{1em}



\subsubsection[\textbf{Non-negative random variable}]{Non-negative random variable} \label{sec:mean-nnrvar}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a non-negative random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}). Then, the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of $X$ is

\begin{equation} \label{eq:mean-nnrvar-mean-cdf}
\mathrm{E}(X) = \int_{0}^{\infty} (1 - F_X(x)) \, \mathrm{d}x
\end{equation}

where $F_X(x)$ is the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) of $X$.


\vspace{1em}
\textbf{Proof:} Because the cumulative distribution function gives the probability of a random variable being smaller than a given value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}),

\begin{equation} \label{eq:mean-nnrvar-cdf-Pr-leq}
F_X(x) = \mathrm{Pr}(X \leq x) \; ,
\end{equation}

we have

\begin{equation} \label{eq:mean-nnrvar-cdf-Pr-geq}
1 - F_X(x) = \mathrm{Pr}(X > x) \; ,
\end{equation}

such that

\begin{equation} \label{eq:mean-nnrvar-mean-cdf-s1}
\int_{0}^{\infty} (1 - F_X(x)) \, \mathrm{d}x = \int_{0}^{\infty} \mathrm{Pr}(X > x) \, \mathrm{d}x
\end{equation}

which, using the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $X$, can be rewritten as

\begin{equation} \label{eq:mean-nnrvar-mean-cdf-s2}
\begin{split}
\int_{0}^{\infty} (1 - F_X(x)) \, \mathrm{d}x &= \int_{0}^{\infty} \int_{x}^{\infty} f_X(z) \, \mathrm{d}z \, \mathrm{d}x \\
&= \int_{0}^{\infty} \int_{0}^{z} f_X(z) \, \mathrm{d}x \, \mathrm{d}z \\
&= \int_{0}^{\infty} f_X(z) \int_{0}^{z} 1 \, \mathrm{d}x \, \mathrm{d}z \\
&= \int_{0}^{\infty} [x]_{0}^{z} \cdot f_X(z) \, \mathrm{d}z \\
&= \int_{0}^{\infty} z \cdot f_X(z) \, \mathrm{d}z \\
\end{split}
\end{equation}

and by applying the definition of the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}), we see that

\begin{equation} \label{eq:mean-nnrvar-mean-cdf-s3}
\int_{0}^{\infty} (1 - F_X(x)) \, \mathrm{d}x = \int_{0}^{\infty} z \cdot f_X(z) \, \mathrm{d}z = \mathrm{E}(X)
\end{equation}

which proves the identity given above.



\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Kemp, Graham (2014): "Expected value of a non-negative random variable"; in: \textit{StackExchange Mathematics}, retrieved on 2020-05-18; URL: \url{https://math.stackexchange.com/questions/958472/expected-value-of-a-non-negative-random-variable}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P103 | shortcut: mean-nnrvar | author: JoramSoch | date: 2020-05-18, 23:54.
\vspace{1em}



\subsubsection[\textbf{Non-negativity}]{Non-negativity} \label{sec:mean-nonneg}
\setcounter{equation}{0}

\textbf{Theorem:} If a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) is strictly non-negative, its expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) is also non-negative, i.e.

\begin{equation} \label{eq:mean-nonneg-mean-nonneg}
\mathrm{E}(X) \geq 0, \quad \text{if} \quad X \geq 0 \; .
\end{equation}


\vspace{1em}
\textbf{Proof:}

1) If $X \geq 0$ is a discrete random variable, then, because the probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) is always non-negative, all the addends in

\begin{equation} \label{eq:mean-nonneg-mean-disc}
\mathrm{E}(X) = \sum_{x \in \mathcal{X}} x \cdot f_X(x)
\end{equation}

are non-negative, thus the entire sum must be non-negative.

\vspace{1em}
2) If $X \geq 0$ is a continuous random variable, then, because the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) is always non-negative, the integrand in

\begin{equation} \label{eq:mean-nonneg-mean-cont}
\mathrm{E}(X) = \int_{\mathcal{X}} x \cdot f_X(x) \, \mathrm{d}x
\end{equation}

is strictly non-negative, thus the term on the right-hand side is a Lebesgue integral, so that the result on the left-hand side must be non-negative.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Expected value"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-02-13; URL: \url{https://en.wikipedia.org/wiki/Expected_value#Basic_properties}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P52 | shortcut: mean-nonneg | author: JoramSoch | date: 2020-02-13, 20:14.
\vspace{1em}



\subsubsection[\textbf{Linearity}]{Linearity} \label{sec:mean-lin}
\setcounter{equation}{0}

\textbf{Theorem:} The expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) is a linear operator, i.e.

\begin{equation} \label{eq:mean-lin-mean-lin}
\begin{split}
\mathrm{E}(X + Y) &= \mathrm{E}(X) + \mathrm{E}(Y) \\
\mathrm{E}(a\,X) &= a\,\mathrm{E}(X)
\end{split}
\end{equation}

for random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X$ and $Y$ and a constant $a$.


\vspace{1em}
\textbf{Proof:}

1) If $X$ and $Y$ are discrete random variables, the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) is

\begin{equation} \label{eq:mean-lin-mean-disc}
\mathrm{E}(X) = \sum_{x \in \mathcal{X}} x \cdot f_X(x)
\end{equation}

and the law of marginal probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}) states that

\begin{equation} \label{eq:mean-lin-lmp-disc}
p(x) = \sum_{y \in \mathcal{Y}} p(x,y) \; .
\end{equation}

Applying this, we have

\begin{equation} \label{eq:mean-lin-mean-lin-s1-disc}
\begin{split}
\mathrm{E}(X + Y) &= \sum_{x \in \mathcal{X}} \sum_{y \in \mathcal{Y}} (x+y) \cdot f_{X,Y}(x,y) \\
&= \sum_{x \in \mathcal{X}} \sum_{y \in \mathcal{Y}} x \cdot f_{X,Y}(x,y) + \sum_{x \in \mathcal{X}} \sum_{y \in \mathcal{Y}} y \cdot f_{X,Y}(x,y) \\
&= \sum_{x \in \mathcal{X}} x \sum_{y \in \mathcal{Y}} f_{X,Y}(x,y) + \sum_{y \in \mathcal{Y}} y \sum_{x \in \mathcal{X}} f_{X,Y}(x,y) \\
&\overset{\eqref{eq:mean-lin-lmp-disc}}{=} \sum_{x \in \mathcal{X}} x \cdot f_X(x) + \sum_{y \in \mathcal{Y}} y \cdot f_{Y}(y) \\
&\overset{\eqref{eq:mean-lin-mean-disc}}{=} \mathrm{E}(X) + \mathrm{E}(Y)
\end{split}
\end{equation}

as well as

\begin{equation} \label{eq:mean-lin-mean-lin-s2-disc}
\begin{split}
\mathrm{E}(a\,X) &= \sum_{x \in \mathcal{X}} a \, x \cdot f_X(x) \\
&= a \, \sum_{x \in \mathcal{X}} x \cdot f_X(x) \\
&\overset{\eqref{eq:mean-lin-mean-disc}}{=} a \, \mathrm{E}(X) \; .
\end{split}
\end{equation}

\vspace{1em}
2) If $X$ and $Y$ are continuous random variables, the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) is

\begin{equation} \label{eq:mean-lin-mean-cont}
\mathrm{E}(X) = \int_{\mathcal{X}} x \cdot f_X(x) \, \mathrm{d}x
\end{equation}

and the law of marginal probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}) states that

\begin{equation} \label{eq:mean-lin-lmp-cont}
p(x) = \int_{\mathcal{Y}} p(x,y) \, \mathrm{d}y \; .
\end{equation}

Applying this, we have

\begin{equation} \label{eq:mean-lin-mean-lin-s1-cont}
\begin{split}
\mathrm{E}(X + Y) &= \int_{\mathcal{X}} \int_{\mathcal{Y}} (x+y) \cdot f_{X,Y}(x,y) \, \mathrm{d}y \, \mathrm{d}x \\
&= \int_{\mathcal{X}} \int_{\mathcal{Y}} x \cdot f_{X,Y}(x,y) \, \mathrm{d}y \, \mathrm{d}x + \int_{\mathcal{X}} \int_{\mathcal{Y}} y \cdot f_{X,Y}(x,y) \, \mathrm{d}y \, \mathrm{d}x \\
&= \int_{\mathcal{X}} x \int_{\mathcal{Y}} f_{X,Y}(x,y) \, \mathrm{d}y \, \mathrm{d}x + \int_{\mathcal{Y}} y \int_{\mathcal{X}} f_{X,Y}(x,y) \, \mathrm{d}x \, \mathrm{d}y \\
&\overset{\eqref{eq:mean-lin-lmp-cont}}{=} \int_{\mathcal{X}} x \cdot f_X(x) \, \mathrm{d}x + \int_{\mathcal{Y}} y \cdot f_Y(y) \, \mathrm{d}y \\
&\overset{\eqref{eq:mean-lin-mean-cont}}{=} \mathrm{E}(X) + \mathrm{E}(Y)
\end{split}
\end{equation}

as well as

\begin{equation} \label{eq:mean-lin-mean-lin-s2-cont}
\begin{split}
\mathrm{E}(a\,X) &= \int_{\mathcal{X}} a \, x \cdot f_X(x) \, \mathrm{d}x \\
&= a \int_{\mathcal{X}} x \cdot f_X(x) \, \mathrm{d}x \\
&\overset{\eqref{eq:mean-lin-mean-cont}}{=} a \, \mathrm{E}(X) \; .
\end{split}
\end{equation}

\vspace{1em}
Collectively, this shows that both requirements for linearity are fulfilled for the expected value, for discrete as well as for continuous random variables.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Expected value"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-02-13; URL: \url{https://en.wikipedia.org/wiki/Expected_value#Basic_properties}.
\item Michael B, Kuldeep Guha Mazumder, Geoff Pilling et al. (2020): "Linearity of Expectation"; in: \textit{brilliant.org}, retrieved on 2020-02-13; URL: \url{https://brilliant.org/wiki/linearity-of-expectation/}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P53 | shortcut: mean-lin | author: JoramSoch | date: 2020-02-13, 21:08.
\vspace{1em}



\subsubsection[\textbf{Monotonicity}]{Monotonicity} \label{sec:mean-mono}
\setcounter{equation}{0}

\textbf{Theorem:} The expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) is monotonic, i.e.

\begin{equation} \label{eq:mean-mono-mean-mono}
\mathrm{E}(X) \leq \mathrm{E}(Y), \quad \text{if} \quad X \leq Y \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} Let $Z = Y - X$. Due to the linearity of the expected value ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-lin}), we have

\begin{equation} \label{eq:mean-mono-mean-XYZ}
\mathrm{E}(Z) = \mathrm{E}(Y-X) = \mathrm{E}(Y) - \mathrm{E}(X) \; .
\end{equation}

With the non-negativity property of the expected value ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-nonneg}), it also holds that

\begin{equation} \label{eq:mean-mono-mean-Z}
Z \geq 0 \quad \Rightarrow \quad \mathrm{E}(Z) \geq 0 \; .
\end{equation}

Together with \eqref{eq:mean-mono-mean-XYZ}, this yields

\begin{equation} \label{eq:mean-mono-mean-mono-qed}
\mathrm{E}(Y) - \mathrm{E}(X) \geq 0 \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Expected value"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-02-17; URL: \url{https://en.wikipedia.org/wiki/Expected_value#Basic_properties}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P54 | shortcut: mean-mono | author: JoramSoch | date: 2020-02-17, 21:00.
\vspace{1em}



\subsubsection[\textbf{(Non-)Multiplicativity}]{(Non-)Multiplicativity} \label{sec:mean-mult}
\setcounter{equation}{0}

\textbf{Theorem:}

1) If two random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X$ and $Y$ are independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}), the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) is multiplicative, i.e.

\begin{equation} \label{eq:mean-mult-mean-mult}
\mathrm{E}(X\,Y) = \mathrm{E}(X) \, \mathrm{E}(Y) \; .
\end{equation}

2) If two random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X$ and $Y$ are dependent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}), the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) is not necessarily multiplicative, i.e. there exist $X$ and $Y$ such that

\begin{equation} \label{eq:mean-mult-mean-nonmult}
\mathrm{E}(X\,Y) \neq \mathrm{E}(X) \, \mathrm{E}(Y) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:}

1) If $X$ and $Y$ are independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}), it holds that

\begin{equation} \label{eq:mean-mult-ind}
p(x,y) = p(x) \, p(y) \quad \text{for all} \quad x \in \mathcal{X}, y \in \mathcal{Y} \; .
\end{equation}

Applying this to the expected value for discrete random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}), we have

\begin{equation} \label{eq:mean-mult-mean-mult-disc}
\begin{split}
\mathrm{E}(X\,Y) &= \sum_{x \in \mathcal{X}} \sum_{y \in \mathcal{Y}} (x \cdot y) \cdot f_{X,Y}(x,y) \\
&\overset{\eqref{eq:mean-mult-ind}}{=} \sum_{x \in \mathcal{X}} \sum_{y \in \mathcal{Y}} (x \cdot y) \cdot \left( f_X(x) \cdot f_Y(y) \right) \\
&= \sum_{x \in \mathcal{X}} x \cdot f_X(x) \, \sum_{y \in \mathcal{Y}} y \cdot f_Y(y) \\
&= \sum_{x \in \mathcal{X}} x \cdot f_X(x) \cdot \mathrm{E}(Y) \\
&= \mathrm{E}(X) \, \mathrm{E}(Y) \; . \\
\end{split}
\end{equation}

And applying it to the expected value for continuous random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}), we have

\begin{equation} \label{eq:mean-mult-mean-mult-cont}
\begin{split}
\mathrm{E}(X\,Y) &= \int_{\mathcal{X}} \int_{\mathcal{Y}} (x \cdot y) \cdot f_{X,Y}(x,y) \, \mathrm{d}y \, \mathrm{d}x \\
&\overset{\eqref{eq:mean-mult-ind}}{=} \int_{\mathcal{X}} \int_{\mathcal{Y}} (x \cdot y) \cdot \left( f_X(x) \cdot f_Y(y) \right) \, \mathrm{d}y \, \mathrm{d}x \\
&= \int_{\mathcal{X}} x \cdot f_X(x) \, \int_{\mathcal{Y}} y \cdot f_Y(y)  \, \mathrm{d}y \, \mathrm{d}x \\
&= \int_{\mathcal{X}} x \cdot f_X(x) \cdot \mathrm{E}(Y) \, \mathrm{d}x \\
&= \mathrm{E}(X) \, \mathrm{E}(Y) \; . \\
\end{split}
\end{equation}

\vspace{1em}
2) Let $X$ and $Y$ be Bernoulli random variables ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:bern}) with the following joint probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf})

\begin{equation} \label{eq:mean-mult-joint}
\begin{split}
p(X=0, Y=0) &= 1/2 \\
p(X=0, Y=1) &= 0 \\
p(X=1, Y=0) &= 0 \\
p(X=1, Y=1) &= 1/2
\end{split}
\end{equation}

and thus, the following marginal probabilities:

\begin{equation} \label{eq:mean-mult-marg}
\begin{split}
p(X=0) = p(X=1) &= 1/2 \\
p(Y=0) = p(Y=1) &= 1/2 \; .
\end{split}
\end{equation}

Then, $X$ and $Y$ are dependent, because

\begin{equation} \label{eq:mean-mult-dep}
p(X=0, Y=1) \overset{\eqref{eq:mean-mult-joint}}{=} 0 \neq \frac{1}{2} \cdot \frac{1}{2} \overset{\eqref{eq:mean-mult-marg}}{=} p(X=0) \, p(Y=1) \; ,
\end{equation}

and the expected value of their product is

\begin{equation} \label{eq:mean-mult-mean-prod}
\begin{split}
\mathrm{E}(X\,Y) &= \sum_{x \in \left\lbrace 0,1 \right\rbrace} \sum_{y \in \left\lbrace 0,1 \right\rbrace} (x \cdot y) \cdot p(x,y) \\
&= (1 \cdot 1) \cdot p(X=1, Y=1) \\
&\overset{\eqref{eq:mean-mult-joint}}{=} \frac{1}{2}
\end{split}
\end{equation}

while the product of their expected values is

\begin{equation} \label{eq:mean-mult-prod-mean}
\begin{split}
\mathrm{E}(X) \, \mathrm{E}(Y) &= \left( \sum_{x \in \left\lbrace 0,1 \right\rbrace} x \cdot p(x) \right) \cdot \left( \sum_{y \in \left\lbrace 0,1 \right\rbrace} y \cdot p(y) \right) \\
&= \left( 1 \cdot p(X=1) \right) \cdot \left( 1 \cdot p(Y=1) \right) \\
&\overset{\eqref{eq:mean-mult-marg}}{=} \frac{1}{4}
\end{split}
\end{equation}

and thus,

\begin{equation} \label{eq:mean-mult-mean-nonmult-qed}
\mathrm{E}(X\,Y) \neq \mathrm{E}(X) \, \mathrm{E}(Y) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Expected value"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-02-17; URL: \url{https://en.wikipedia.org/wiki/Expected_value#Basic_properties}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P55 | shortcut: mean-mult | author: JoramSoch | date: 2020-02-17, 21:51.
\vspace{1em}



\subsubsection[\textbf{Expectation of a quadratic form}]{Expectation of a quadratic form} \label{sec:mean-qf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be an $n \times 1$ random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}) with mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) $\mu$ and covariance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cov}) $\Sigma$ and let $A$ be a symmetric $n \times n$ matrix. Then, the expectation of the quadratic form $X^\mathrm{T} A X$ is

\begin{equation} \label{eq:mean-qf-mean-qf}
\mathrm{E}\left[ X^\mathrm{T} A X \right] = \mu^\mathrm{T} A \mu + \mathrm{tr}(A \Sigma) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} Note that $X^\mathrm{T} A X$ is a $1 \times 1$ matrix. We can therefore write

\begin{equation} \label{eq:mean-qf-mean-qf-s1}
\mathrm{E}\left[ X^\mathrm{T} A X \right] =  \mathrm{E}\left[ \mathrm{tr} \left( X^\mathrm{T} A X \right) \right] \; .
\end{equation}

Using the trace property $\mathrm{tr}(ABC) = \mathrm{tr}(BCA)$, this becomes

\begin{equation} \label{eq:mean-qf-mean-qf-s2}
\mathrm{E}\left[ X^\mathrm{T} A X \right] =  \mathrm{E}\left[ \mathrm{tr} \left( A X X^\mathrm{T} \right) \right] \; .
\end{equation}

Because mean and trace are linear operators ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-lin}), we have

\begin{equation} \label{eq:mean-qf-mean-qf-s3}
\mathrm{E}\left[ X^\mathrm{T} A X \right] =  \mathrm{tr} \left( A \; \mathrm{E}\left[ X X^\mathrm{T} \right] \right) \; .
\end{equation}

Note that the covariance matrix can be partitioned into expected values ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:covmat-mean})

\begin{equation} \label{eq:mean-qf-covmat-mean}
\mathrm{Cov}(X,X) = \mathrm{E}(X X^\mathrm{T}) - \mathrm{E}(X) \mathrm{E}(X)^\mathrm{T} \; ,
\end{equation}

such that the expected value of the quadratic form becomes

\begin{equation} \label{eq:mean-qf-mean-qf-s4}
\mathrm{E}\left[ X^\mathrm{T} A X \right] =  \mathrm{tr} \left( A \left[ \mathrm{Cov}(X,X) + \mathrm{E}(X) \mathrm{E}(X)^\mathrm{T} \right] \right) \; .
\end{equation}

Finally, applying mean and covariance of $X$, we have

\begin{equation} \label{eq:mean-qf-mean-qf-s5}
\begin{split}
\mathrm{E}\left[ X^\mathrm{T} A X \right] &= \mathrm{tr} \left( A \left[ \Sigma + \mu \mu^\mathrm{T} \right] \right) \\
&= \mathrm{tr} \left( A \Sigma + A \mu \mu^\mathrm{T} \right) \\
&= \mathrm{tr}(A \Sigma) + \mathrm{tr}(A \mu \mu^\mathrm{T}) \\
&= \mathrm{tr}(A \Sigma) + \mathrm{tr}(\mu^\mathrm{T} A \mu) \\
&= \mu^\mathrm{T} A \mu + \mathrm{tr}(A \Sigma) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Kendrick, David (1981): "Expectation of a quadratic form"; in: \textit{Stochastic Control for Economic Models}, pp. 170-171.
\item Wikipedia (2020): "Multivariate random variable"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-07-13; URL: \url{https://en.wikipedia.org/wiki/Multivariate_random_variable#Expectation_of_a_quadratic_form}.
\item Halvorsen, Kjetil B. (2012): "Expected value and variance of trace function"; in: \textit{StackExchange CrossValidated}, retrieved on 2020-07-13; URL: \url{https://stats.stackexchange.com/questions/34477/expected-value-and-variance-of-trace-function}.
\item Sarwate, Dilip (2013): "Expected Value of Quadratic Form"; in: \textit{StackExchange CrossValidated}, retrieved on 2020-07-13; URL: \url{https://stats.stackexchange.com/questions/48066/expected-value-of-quadratic-form}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P131 | shortcut: mean-qf | author: JoramSoch | date: 2020-07-13, 21:59.
\vspace{1em}



\subsubsection[\textbf{Law of the unconscious statistician}]{Law of the unconscious statistician} \label{sec:mean-lotus}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) and let $Y = g(X)$ be a function of this random variable.

1) If $X$ is a discrete random variable with possible outcomes $\mathcal{X}$ and probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) $f_X(x)$, the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of $g(X)$ is

\begin{equation} \label{eq:mean-lotus-mean-lotus-disc}
\mathrm{E}[g(X)] = \sum_{x \in \mathcal{X}} g(x) f_X(x) \; .
\end{equation}

2) If $X$ is a continuous random variable with possible outcomes $\mathcal{X}$ and probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) $f_X(x)$, the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of $g(X)$ is

\begin{equation} \label{eq:mean-lotus-mean-lotus-cont}
\mathrm{E}[g(X)] = \int_{\mathcal{X}} g(x) f_X(x) \, \mathrm{d}x \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} Suppose that $g$ is differentiable and that its inverse $g^{-1}$ is monotonic.

1) The expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of $Y = g(X)$ is defined as

\begin{equation} \label{eq:mean-lotus-mean-lotus-disc-s1}
\mathrm{E}[Y] = \sum_{y \in \mathcal{Y}} y \, f_Y(y) \; .
\end{equation}

Writing the probability mass function $f_Y(y)$ in terms of $y = g(x)$, we have:

\begin{equation} \label{eq:mean-lotus-mean-lotus-disc-s2}
\mathrm{E}[g(X)] = \sum_{y \in \mathcal{Y}} y \, \mathrm{Pr}(g(x) = y) \; .
\end{equation}

Replacing the probability that $g(x) = y$ in terms of $f_X(x)$, this becomes:

\begin{equation} \label{eq:mean-lotus-mean-lotus-disc-s3}
\mathrm{E}[g(X)] = \sum_{y \in \mathcal{Y}} y \sum_{x: \; g(x) = y} f_X(x) \; .
\end{equation}

Observe that $y = g(x)$ can be moved into the inner sum. Finally, noting that "for all $y$, then for all $x$, such that $g(x) = y$" is equivalent to "for all $x$" if $g^{-1}$ is a monotonic function, we can conclude that

\begin{equation} \label{eq:mean-lotus-mean-lotus-disc-s4}
\mathrm{E}[g(X)] = \sum_{x \in \mathcal{X}} g(x) f_X(x) \; .
\end{equation}

\vspace{1em}
2) Let $y = g(x)$. The derivative of an inverse function is

\begin{equation} \label{eq:mean-lotus-der-inv}
\frac{\mathrm{d}}{\mathrm{d}y} (g^{-1}(y)) = \frac{1}{g'(g^{-1}(y))}
\end{equation}

Because $x = g^{-1}(y)$, this can be rearranged into

\begin{equation} \label{eq:mean-lotus-dx-dy}
\mathrm{d}x = \frac{1}{g'(g^{-1}(y))} \, \mathrm{d}y
\end{equation}

and subsitituing \eqref{eq:mean-lotus-dx-dy} into \eqref{eq:mean-lotus-mean-lotus-cont}, we get

\begin{equation} \label{eq:mean-lotus-mean-lotus-cont-s1}
\int_{\mathcal{X}} g(x) f_X(x) \, \mathrm{d}x = \int_{\mathcal{Y}} y \, f_X(g^{-1}(y)) \, \frac{1}{g'(g^{-1}(y))} \, \mathrm{d}y \; .
\end{equation}

Considering the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) of $Y$, one can deduce:

\begin{equation} \label{eq:mean-lotus-Y-cdf}
\begin{split}
F_Y(y) &= \mathrm{Pr}(Y \leq y) \\
&= \mathrm{Pr}(g(X) \leq y) \\
&= \mathrm{Pr}(X \leq g^{-1}(y)) \\
&= F_X(g^{-1}(y)) \; .
\end{split}
\end{equation}

Differentiating to get the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $Y$, the result is:

\begin{equation} \label{eq:mean-lotus-Y-pdf}
\begin{split}
f_Y(y) &= \frac{\mathrm{d}}{\mathrm{d}y} F_Y(y) \\
&\overset{\eqref{eq:mean-lotus-Y-cdf}}{=} \frac{\mathrm{d}}{\mathrm{d}y} F_X(g^{-1}(y)) \\
&= f_X(g^{-1}(y)) \, \frac{\mathrm{d}}{\mathrm{d}y} (g^{-1}(y)) \\
&\overset{\eqref{eq:mean-lotus-der-inv}}{=} f_X(g^{-1}(y)) \, \frac{1}{g'(g^{-1}(y))} \; .
\end{split}
\end{equation}

Finally, substituing \eqref{eq:mean-lotus-Y-pdf} into \eqref{eq:mean-lotus-mean-lotus-cont-s1}, we have:

\begin{equation} \label{eq:mean-lotus-mean-lotus-cont-s2}
\int_{\mathcal{X}} g(x) f_X(x) \, \mathrm{d}x = \int_{\mathcal{Y}} y \, f_Y(y) \, \mathrm{d}y = \mathrm{E}[Y] = \mathrm{E}[g(X)] \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Law of the unconscious statistician"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-07-22; URL: \url{https://en.wikipedia.org/wiki/Law_of_the_unconscious_statistician#Proof}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P138 | shortcut: mean-lotus | author: JoramSoch | date: 2020-07-22, 08:30.
\vspace{1em}



\subsection{Variance}

\subsubsection[\textit{Definition}]{Definition} \label{sec:var}
\setcounter{equation}{0}

\textbf{Definition:} The variance of a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X$ is defined as the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of the squared deviation from its expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}):

\begin{equation} \label{eq:var-var}
\mathrm{Var}(X) = \mathrm{E}\left[ (X-\mathrm{E}(X))^2 \right] \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Variance"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-02-13; URL: \url{https://en.wikipedia.org/wiki/Variance#Definition}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D12 | shortcut: var | author: JoramSoch | date: 2020-02-13, 19:55.
\vspace{1em}



\subsubsection[\textbf{Partition into expected values}]{Partition into expected values} \label{sec:var-mean}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}). Then, the variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) of $X$ is equal to the mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of the square of $X$ minus the square of the mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of $X$:

\begin{equation} \label{eq:var-mean-var-mean}
\mathrm{Var}(X) = \mathrm{E}(X^2) - \mathrm{E}(X)^2 \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) of $X$ is defined as

\begin{equation} \label{eq:var-mean-var}
\mathrm{Var}(X) = \mathrm{E}\left[ \left( X - \mathrm{E}[X] \right)^2 \right]
\end{equation}

which, due to the linearity of the expected value ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-lin}), can be rewritten as

\begin{equation} \label{eq:var-mean-var-mean-qed}
\begin{split}
\mathrm{Var}(X) &= \mathrm{E}\left[ \left( X - \mathrm{E}[X] \right)^2 \right] \\
&= \mathrm{E}\left[ X^2 - 2 \, X \, \mathrm{E}(X) + \mathrm{E}(X)^2 \right] \\
&= \mathrm{E}(X^2) - 2 \, \mathrm{E}(X) \, \mathrm{E}(X) + \mathrm{E}(X)^2 \\
&= \mathrm{E}(X^2) - \mathrm{E}(X)^2 \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Variance"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-05-19; URL: \url{https://en.wikipedia.org/wiki/Variance#Definition}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P104 | shortcut: var-mean | author: JoramSoch | date: 2020-05-19, 00:17.
\vspace{1em}



\subsubsection[\textbf{Non-negativity}]{Non-negativity} \label{sec:var-nonneg}
\setcounter{equation}{0}

\textbf{Theorem:} The variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) is always non-negative, i.e.

\begin{equation} \label{eq:var-nonneg-var-nonneg}
\mathrm{Var}(X) \geq 0 \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) of a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) is defined as

\begin{equation} \label{eq:var-nonneg-var}
\mathrm{Var}(X) = \mathrm{E}\left[ (X-\mathrm{E}(X))^2 \right] \; .
\end{equation}

\vspace{1em}
1) If $X$ is a discrete random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}), then, because squares and probabilities are stricly non-negative, all the addends in

\begin{equation} \label{eq:var-nonneg-var-disc}
\mathrm{Var}(X) = \sum_{x \in \mathcal{X}} (x-\mathrm{E}(X))^2 \cdot f_X(x)
\end{equation}

are also non-negative, thus the entire sum must be non-negative.

\vspace{1em}
2) If $X$ is a continuous random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}), then, because squares and probability densities are strictly non-negative, the integrand in

\begin{equation} \label{eq:var-nonneg-var-cont}
\mathrm{Var}(X) = \int_{\mathcal{X}} (x-\mathrm{E}(X))^2 \cdot f_X(x) \, \mathrm{d}x
\end{equation}

is always non-negative, thus the term on the right-hand side is a Lebesgue integral, so that the result on the left-hand side must be non-negative.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Variance"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-06-06; URL: \url{https://en.wikipedia.org/wiki/Variance#Basic_properties}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P123 | shortcut: var-nonneg | author: JoramSoch | date: 2020-06-06, 07:29.
\vspace{1em}



\subsubsection[\textbf{Variance of a constant}]{Variance of a constant} \label{sec:var-const}
\setcounter{equation}{0}

\textbf{Theorem:} The variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) of a constant ($\rightarrow$ Definition "const") is zero:

\begin{equation} \label{eq:var-const-var-const}
a = \text{const.} \quad \Rightarrow \quad \mathrm{Var}(a) = 0 \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} A constant ($\rightarrow$ Definition "const") is a quantity that always has the same value. Thus, if understood as a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}), the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of a constant is equal to itself:

\begin{equation} \label{eq:var-const-mean-const}
\mathrm{E}(a) = a \; .
\end{equation}

Plugged into the formula of the variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}), we have

\begin{equation} \label{eq:var-const-var-const-s1}
\begin{split}
\mathrm{Var}(a) &= \mathrm{E}\left[ (a-\mathrm{E}(a))^2 \right] \\
&= \mathrm{E}\left[ (a-a)^2 \right] \\
&= \mathrm{E}(0) \; .
\end{split}
\end{equation}

Applied to the formula of the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}), this gives

\begin{equation} \label{eq:var-const-var-const-s2}
\mathrm{E}(0) = \sum_{x=0} x \cdot f_X(x) = 0 \cdot 1 = 0 \; .
\end{equation}

Together, \eqref{eq:var-const-var-const-s1} and \eqref{eq:var-const-var-const-s2} imply \eqref{eq:var-const-var-const}.



\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Variance"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-06-27; URL: \url{https://en.wikipedia.org/wiki/Variance#Basic_properties}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P124 | shortcut: var-const | author: JoramSoch | date: 2020-06-27, 06:44.
\vspace{1em}



\subsubsection[\textbf{Variance equals zero}]{Variance equals zero} \label{sec:var-zero}
\setcounter{equation}{0}

\textbf{Theorem:} If the variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) of $X$ is zero, then $X$ is a constant ($\rightarrow$ Definition "const"):

\begin{equation} \label{eq:var-zero-var-zero}
\mathrm{Var}(X) = 0 \quad \Rightarrow \quad X = \text{const.}
\end{equation}


\vspace{1em}
\textbf{Proof:} The variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) is defined as

\begin{equation} \label{eq:var-zero-var}
\mathrm{Var}(X) = \mathrm{E}\left[ (X-\mathrm{E}(X))^2 \right] \; .
\end{equation}

Because $(X-\mathrm{E}(X))^2$ is strictly non-negative ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-nonneg}), the only way for the variance to become zero is, if the squared deviation is always zero:

\begin{equation} \label{eq:var-zero-sqr-dev-zero}
(X-\mathrm{E}(X))^2 = 0 \; .
\end{equation}

Thus, in turn, requires that $X$ is equal to its expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean})

\begin{equation} \label{eq:var-zero-X-eq-E-X}
X = \mathrm{E}(X)
\end{equation}

which can only be the case, if $X$ always has the same value ($\rightarrow$ Definition "const"):

\begin{equation} \label{eq:var-zero-X-const}
X = \text{const.}
\end{equation}



\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Variance"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-06-27; URL: \url{https://en.wikipedia.org/wiki/Variance#Basic_properties}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P125 | shortcut: var-zero | author: JoramSoch | date: 2020-06-27, 07:05.
\vspace{1em}



\subsubsection[\textbf{Invariance under addition}]{Invariance under addition} \label{sec:var-inv}
\setcounter{equation}{0}

\textbf{Theorem:} The variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) is invariant under addition of a constant ($\rightarrow$ Definition "const"):

\begin{equation} \label{eq:var-inv-var-inv}
\mathrm{Var}(X+a) = \mathrm{Var}(X)
\end{equation}


\vspace{1em}
\textbf{Proof:} The variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) is defined in terms of the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) as

\begin{equation} \label{eq:var-inv-var}
\mathrm{Var}(X) = \mathrm{E}\left[ (X-\mathrm{E}(X))^2 \right] \; .
\end{equation}

Using this and the linearity of the expected value ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-lin}), we can derive \eqref{eq:var-inv-var-inv} as follows:

\begin{equation} \label{eq:var-inv-var-inv-qed}
\begin{split}
\mathrm{Var}(X+a) &\overset{\eqref{eq:var-inv-var}}{=} \mathrm{E}\left[ ((X+a)-\mathrm{E}(X+a))^2 \right] \\
&= \mathrm{E}\left[ (X + a - \mathrm{E}(X) - a)^2 \right] \\
&= \mathrm{E}\left[ (X-\mathrm{E}(X))^2 \right] \\
&\overset{\eqref{eq:var-inv-var}}{=} \mathrm{Var}(X) \; . \\
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Variance"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-07-07; URL: \url{https://en.wikipedia.org/wiki/Variance#Basic_properties}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P126 | shortcut: var-inv | author: JoramSoch | date: 2020-07-07, 05:23.
\vspace{1em}



\subsubsection[\textbf{Scaling upon multiplication}]{Scaling upon multiplication} \label{sec:var-scal}
\setcounter{equation}{0}

\textbf{Theorem:} The variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) scales upon multiplication with a constant ($\rightarrow$ Definition "const"):

\begin{equation} \label{eq:var-scal-var-scal}
\mathrm{Var}(aX) = a^2 \, \mathrm{Var}(X)
\end{equation}


\vspace{1em}
\textbf{Proof:} The variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) is defined in terms of the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) as

\begin{equation} \label{eq:var-scal-var}
\mathrm{Var}(X) = \mathrm{E}\left[ (X-\mathrm{E}(X))^2 \right] \; .
\end{equation}

Using this and the linearity of the expected value ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-lin}), we can derive \eqref{eq:var-scal-var-scal} as follows:

\begin{equation} \label{eq:var-scal-var-scal-qed}
\begin{split}
\mathrm{Var}(aX) &\overset{\eqref{eq:var-scal-var}}{=} \mathrm{E}\left[ ((aX)-\mathrm{E}(aX))^2 \right] \\
&= \mathrm{E}\left[ (aX - a\mathrm{E}(X))^2 \right] \\
&= \mathrm{E}\left[ (a [X - \mathrm{E}(X)])^2 \right] \\
&= \mathrm{E}\left[ a^2 (X - \mathrm{E}(X))^2 \right] \\
&= a^2 \, \mathrm{E}\left[ (X - \mathrm{E}(X))^2 \right] \\
&\overset{\eqref{eq:var-scal-var}}{=} a^2 \, \mathrm{Var}(X) \; . \\
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Variance"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-07-07; URL: \url{https://en.wikipedia.org/wiki/Variance#Basic_properties}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P127 | shortcut: var-scal | author: JoramSoch | date: 2020-07-07, 05:38.
\vspace{1em}



\subsubsection[\textbf{Variance of a sum}]{Variance of a sum} \label{sec:var-sum}
\setcounter{equation}{0}

\textbf{Theorem:} The variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) of the sum of two random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) equals the sum of the variances of those random variables, plus two times their covariance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cov}):

\begin{equation} \label{eq:var-sum-var-sum}
\mathrm{Var}(X+Y) = \mathrm{Var}(X) + \mathrm{Var}(Y) + 2 \, \mathrm{Cov}(X,Y) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) is defined in terms of the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) as

\begin{equation} \label{eq:var-sum-var}
\mathrm{Var}(X) = \mathrm{E}\left[ (X-\mathrm{E}(X))^2 \right] \; .
\end{equation}

Using this and the linearity of the expected value ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-lin}), we can derive \eqref{eq:var-sum-var-sum} as follows:

\begin{equation} \label{eq:var-sum-var-sum-qed}
\begin{split}
\mathrm{Var}(X+Y) &\overset{\eqref{eq:var-sum-var}}{=} \mathrm{E}\left[ ((X+Y)-\mathrm{E}(X+Y))^2 \right] \\
&= \mathrm{E}\left[ ([X-\mathrm{E}(X)] + [Y-\mathrm{E}(Y)])^2 \right] \\
&= \mathrm{E}\left[ (X-\mathrm{E}(X))^2 + (Y-\mathrm{E}(Y))^2 + 2 \, (X-\mathrm{E}(X)) (Y-\mathrm{E}(Y)) \right] \\
&= \mathrm{E}\left[ (X-\mathrm{E}(X))^2 \right] + \mathrm{E}\left[ (Y-\mathrm{E}(Y))^2 \right] + \mathrm{E}\left[ 2 \, (X-\mathrm{E}(X)) (Y-\mathrm{E}(Y)) \right] \\
&\overset{\eqref{eq:var-sum-var}}{=} \mathrm{Var}(X) + \mathrm{Var}(Y) + 2 \, \mathrm{Cov}(X,Y) \; . \\
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Variance"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-07-07; URL: \url{https://en.wikipedia.org/wiki/Variance#Basic_properties}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P128 | shortcut: var-sum | author: JoramSoch | date: 2020-07-07, 06:10.
\vspace{1em}



\subsubsection[\textbf{Variance of linear combination}]{Variance of linear combination} \label{sec:var-lincomb}
\setcounter{equation}{0}

\textbf{Theorem:} The variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) of the linear combination of two random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) is a function of the variances as well as the covariance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cov}) of those random variables:

\begin{equation} \label{eq:var-lincomb-var-lincomb}
\mathrm{Var}(aX+bY) = a^2 \, \mathrm{Var}(X) + b^2 \, \mathrm{Var}(Y) + 2ab \, \mathrm{Cov}(X,Y) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) is defined in terms of the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) as

\begin{equation} \label{eq:var-lincomb-var}
\mathrm{Var}(X) = \mathrm{E}\left[ (X-\mathrm{E}(X))^2 \right] \; .
\end{equation}

Using this and the linearity of the expected value ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-lin}), we can derive \eqref{eq:var-lincomb-var-lincomb} as follows:

\begin{equation} \label{eq:var-lincomb-var-lincomb-qed}
\begin{split}
\mathrm{Var}(aX+bY) &\overset{\eqref{eq:var-lincomb-var}}{=} \mathrm{E}\left[ ((aX+bY)-\mathrm{E}(aX+bY))^2 \right] \\
&= \mathrm{E}\left[ (a [X-\mathrm{E}(X)] + b [Y-\mathrm{E}(Y)])^2 \right] \\
&= \mathrm{E}\left[ a^2 \, (X-\mathrm{E}(X))^2 + b^2 \, (Y-\mathrm{E}(Y))^2 + 2ab \, (X-\mathrm{E}(X)) (Y-\mathrm{E}(Y)) \right] \\
&= \mathrm{E}\left[ a^2 \, (X-\mathrm{E}(X))^2 \right] + \mathrm{E}\left[ b^2 \, (Y-\mathrm{E}(Y))^2 \right] + \mathrm{E}\left[ 2ab \, (X-\mathrm{E}(X)) (Y-\mathrm{E}(Y)) \right] \\
&\overset{\eqref{eq:var-lincomb-var}}{=} a^2 \, \mathrm{Var}(X) + b^2 \, \mathrm{Var}(Y) + 2ab \, \mathrm{Cov}(X,Y) \; . \\
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Variance"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-07-07; URL: \url{https://en.wikipedia.org/wiki/Variance#Basic_properties}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P129 | shortcut: var-lincomb | author: JoramSoch | date: 2020-07-07, 06:21.
\vspace{1em}



\subsubsection[\textbf{Additivity under independence}]{Additivity under independence} \label{sec:var-add}
\setcounter{equation}{0}

\textbf{Theorem:} The variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) is additive for independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}) random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}):

\begin{equation} \label{eq:var-add-var-add}
p(X,Y) = p(X) \, p(Y) \quad \Rightarrow \quad \mathrm{Var}(X+Y) = \mathrm{Var}(X) + \mathrm{Var}(Y) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The variance of the sum of two random variables ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:var-sum}) is given by

\begin{equation} \label{eq:var-add-var-sum}
\mathrm{Var}(X+Y) = \mathrm{Var}(X) + \mathrm{Var}(Y) + 2 \, \mathrm{Cov}(X,Y) \; .
\end{equation}

The covariance of independent random variables ($\rightarrow$ Proof "cov-ind") is zero:

\begin{equation} \label{eq:var-add-cov-ind}
p(X,Y) = p(X) \, p(Y) \quad \Rightarrow \quad \mathrm{Cov}(X,Y) = 0 \; .
\end{equation}

Combining \eqref{eq:var-add-var-sum} and \eqref{eq:var-add-cov-ind}, we have:

\begin{equation} \label{eq:var-add-var-add-qed}
\mathrm{Var}(X+Y) = \mathrm{Var}(X) + \mathrm{Var}(Y) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Variance"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-07-07; URL: \url{https://en.wikipedia.org/wiki/Variance#Basic_properties}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P130 | shortcut: var-add | author: JoramSoch | date: 2020-07-07, 06:52.
\vspace{1em}



\subsection{Covariance}

\subsubsection[\textit{Definition}]{Definition} \label{sec:cov}
\setcounter{equation}{0}

\textbf{Definition:} The covariance of two random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X$ and $Y$ is defined as the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of the product of their deviations from their individual expected values ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}):

\begin{equation} \label{eq:cov-cov}
\mathrm{Cov}(X,Y) = \mathrm{E}\left[ (X-\mathrm{E}[X]) (Y-\mathrm{E}[Y]) \right] \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Covariance"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-02-06; URL: \url{https://en.wikipedia.org/wiki/Covariance#Definition}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D70 | shortcut: cov | author: JoramSoch | date: 2020-06-02, 20:20.
\vspace{1em}



\subsubsection[\textbf{Partition into expected values}]{Partition into expected values} \label{sec:cov-mean}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ and $Y$ be random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}). Then, the covariance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cov}) of $X$ and $Y$ is equal to the mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of the product of $X$ and $Y$ minus the product of the means ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of $X$ and $Y$:

\begin{equation} \label{eq:cov-mean-cov-mean}
\mathrm{Cov}(X,Y) = \mathrm{E}(X Y) - \mathrm{E}(X) \mathrm{E}(Y) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The covariance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cov}) of $X$ and $Y$ is defined as

\begin{equation} \label{eq:cov-mean-cov}
\mathrm{Cov}(X,Y) = \mathrm{E}\left[ (X-\mathrm{E}[X]) (Y-\mathrm{E}[Y]) \right] \; .
\end{equation}

which, due to the linearity of the expected value ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-lin}), can be rewritten as

\begin{equation} \label{eq:cov-mean-cov-mean-qed}
\begin{split}
\mathrm{Cov}(X,Y) &= \mathrm{E}\left[ (X-\mathrm{E}[X]) (Y-\mathrm{E}[Y]) \right] \\
&= \mathrm{E}\left[ X Y - X \, \mathrm{E}(Y) - \mathrm{E}(X) \, Y + \mathrm{E}(X) \mathrm{E}(Y) \right] \\
&= \mathrm{E}(X Y) - \mathrm{E}(X) \mathrm{E}(Y) - \mathrm{E}(X) \mathrm{E}(Y) + \mathrm{E}(X) \mathrm{E}(Y) \\
&= \mathrm{E}(X Y) - \mathrm{E}(X) \mathrm{E}(Y) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Covariance"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-06-02; URL: \url{https://en.wikipedia.org/wiki/Covariance#Definition}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P118 | shortcut: cov-mean | author: JoramSoch | date: 2020-06-02, 20:50.
\vspace{1em}



\subsubsection[\textbf{Relationship to correlation}]{Relationship to correlation} \label{sec:cov-corr}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ and $Y$ be random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}). Then, the covariance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cov}) of $X$ and $Y$ is equal to the product of their correlation ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:corr}) and the standard deviations ($\rightarrow$ Definition "std") of $X$ and $Y$:

\begin{equation} \label{eq:cov-corr-cov-corr}
\mathrm{Cov}(X,Y) = \sigma_X \, \mathrm{Corr}(X,Y) \, \sigma_Y \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The correlation ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:corr}) of $X$ and $Y$ is defined as

\begin{equation} \label{eq:cov-corr-corr}
\mathrm{Corr}(X,Y) = \frac{\mathrm{Cov}(X,Y)}{\sigma_X \sigma_Y} \; .
\end{equation}

which can be rearranged for the covariance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cov}) to give

\begin{equation} \label{eq:cov-corr-cov-corr-qed}
\mathrm{Cov}(X,Y) = \sigma_X \, \mathrm{Corr}(X,Y) \, \sigma_Y
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P119 | shortcut: cov-corr | author: JoramSoch | date: 2020-06-02, 21:00.
\vspace{1em}



\subsubsection[\textit{Covariance matrix}]{Covariance matrix} \label{sec:covmat}
\setcounter{equation}{0}

\textbf{Definition:} Let $X = [X_1, \ldots, X_n]^\mathrm{T}$ be a random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}). Then, the covariance matrix of $X$ is defined as the $n \times n$ matrix in which the entry $(i,j)$ is the covariance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cov}) of $X_i$ and $X_j$:

\begin{equation} \label{eq:covmat-covmat}
\Sigma_{XX} =
\begin{bmatrix}
\mathrm{Cov}(X_1,X_1) & \ldots & \mathrm{Cov}(X_1,X_n) \\
\vdots & \ddots & \vdots \\
\mathrm{Cov}(X_n,X_1) & \ldots & \mathrm{Cov}(X_n,X_n)
\end{bmatrix} =
\begin{bmatrix}
\mathrm{E}\left[ (X_1-\mathrm{E}[X_1]) (X_1-\mathrm{E}[X_1]) \right] & \ldots & \mathrm{E}\left[ (X_1-\mathrm{E}[X_1]) (X_n-\mathrm{E}[X_n]) \right] \\
\vdots & \ddots & \vdots \\
\mathrm{E}\left[ (X_n-\mathrm{E}[X_n]) (X_1-\mathrm{E}[X_1]) \right] & \ldots & \mathrm{E}\left[ (X_n-\mathrm{E}[X_n]) (X_n-\mathrm{E}[X_n]) \right]
\end{bmatrix} \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Covariance matrix"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-06-06; URL: \url{https://en.wikipedia.org/wiki/Covariance_matrix#Definition}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D72 | shortcut: covmat | author: JoramSoch | date: 2020-06-06, 04:24.
\vspace{1em}



\subsubsection[\textbf{Covariance matrix and expected values}]{Covariance matrix and expected values} \label{sec:covmat-mean}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}). Then, the covariance matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:covmat}) of $X$ is equal to the mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of the outer product of $X$ with itself minus the outer product of the mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of $X$ with itself:

\begin{equation} \label{eq:covmat-mean-covmat-mean}
\Sigma_{XX} = \mathrm{E}(X X^\mathrm{T}) - \mathrm{E}(X) \mathrm{E}(X)^\mathrm{T} \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The covariance matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:covmat}) of $X$ is defined as

\begin{equation} \label{eq:covmat-mean-covmat1}
\Sigma_{XX} =
\begin{bmatrix}
\mathrm{E}\left[ (X_1-\mathrm{E}[X_1]) (X_1-\mathrm{E}[X_1]) \right] & \ldots & \mathrm{E}\left[ (X_1-\mathrm{E}[X_1]) (X_n-\mathrm{E}[X_n]) \right] \\
\vdots & \ddots & \vdots \\
\mathrm{E}\left[ (X_n-\mathrm{E}[X_n]) (X_1-\mathrm{E}[X_1]) \right] & \ldots & \mathrm{E}\left[ (X_n-\mathrm{E}[X_n]) (X_n-\mathrm{E}[X_n]) \right]
\end{bmatrix}
\end{equation}

which can also be expressed using matrix multiplication as

\begin{equation} \label{eq:covmat-mean-covmat2}
\Sigma_{XX} = \mathrm{E}\left[ (X-\mathrm{E}[X]) (X-\mathrm{E}[X])^\mathrm{T} \right]
\end{equation}

Due to the linearity of the expected value ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-lin}), this can be rewritten as

\begin{equation} \label{eq:covmat-mean-covmat-mean-qed}
\begin{split}
\Sigma_{XX} &= \mathrm{E}\left[ (X-\mathrm{E}[X]) (X-\mathrm{E}[X])^\mathrm{T} \right] \\
&= \mathrm{E}\left[ X X^\mathrm{T} - X \, \mathrm{E}(X)^\mathrm{T} - \mathrm{E}(X) \, X^\mathrm{T} + \mathrm{E}(X) \mathrm{E}(X)^\mathrm{T} \right] \\
&= \mathrm{E}(X X^\mathrm{T}) - \mathrm{E}(X) \mathrm{E}(X)^\mathrm{T} - \mathrm{E}(X) \mathrm{E}(X)^\mathrm{T} + \mathrm{E}(X) \mathrm{E}(X)^\mathrm{T} \\
&= \mathrm{E}(X X^\mathrm{T}) - \mathrm{E}(X) \mathrm{E}(X)^\mathrm{T} \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Taboga, Marco (2010): "Covariance matrix"; in: \textit{Lectures on probability and statistics}, retrieved on 2020-06-06; URL: \url{https://www.statlect.com/fundamentals-of-probability/covariance-matrix}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P120 | shortcut: covmat-mean | author: JoramSoch | date: 2020-06-06, 05:31.
\vspace{1em}



\subsubsection[\textbf{Covariance matrix and correlation matrix}]{Covariance matrix and correlation matrix} \label{sec:covmat-corrmat}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}). Then, the covariance matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:covmat}) of $X$ can be expressed in terms of its correlation matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:corrmat}) as follows

\begin{equation} \label{eq:covmat-corrmat-covmat-corrmat}
\Sigma_{XX} = \mathrm{D}_X \cdot \mathrm{C}_{XX} \cdot \mathrm{D}_X \; ,
\end{equation}

where $\mathrm{D}_X$ is a diagonal matrix with the standard deviations ($\rightarrow$ Definition "std") of $X_1, \ldots, X_n$ as entries on the diagonal:

\begin{equation} \label{eq:covmat-corrmat-diagmat}
\mathrm{D}_X = \mathrm{diag}(\sigma_{X_1},\ldots,\sigma_{X_n}) =
\begin{bmatrix}
\sigma_{X_1} & \ldots & 0 \\
\vdots & \ddots & \vdots \\
0 & \ldots & \sigma_{X_n}
\end{bmatrix} \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} Reiterating \eqref{eq:covmat-corrmat-covmat-corrmat} and applying \eqref{eq:covmat-corrmat-diagmat}, we have:

\begin{equation} \label{eq:covmat-corrmat-covmat-corrmat-s1}
\Sigma_{XX} =
\begin{bmatrix}
\sigma_{X_1} & \ldots & 0 \\
\vdots & \ddots & \vdots \\
0 & \ldots & \sigma_{X_n}
\end{bmatrix} \cdot
\mathrm{C}_{XX} \cdot
\begin{bmatrix}
\sigma_{X_1} & \ldots & 0 \\
\vdots & \ddots & \vdots \\
0 & \ldots & \sigma_{X_n}
\end{bmatrix} \; .
\end{equation}

Together with the definition of the correlation matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:corrmat}), this gives

\begin{equation} \label{eq:covmat-corrmat-covmat-corrmat-s2}
\begin{split}
\Sigma_{XX} &=
\begin{bmatrix}
\sigma_{X_1} & \ldots & 0 \\
\vdots & \ddots & \vdots \\
0 & \ldots & \sigma_{X_n}
\end{bmatrix} \cdot
\begin{bmatrix}
\frac{\mathrm{E}\left[(X_1-\mathrm{E}[X_1]) (X_1-\mathrm{E}[X_1])\right]}{\sigma_{X_1} \, \sigma_{X_1}} & \ldots & \frac{\mathrm{E}\left[(X_1-\mathrm{E}[X_1]) (X_n-\mathrm{E}[X_n])\right]}{\sigma_{X_1} \, \sigma_{X_n}} \\
\vdots & \ddots & \vdots \\
\frac{\mathrm{E}\left[(X_n-\mathrm{E}[X_n]) (X_1-\mathrm{E}[X_1])\right]}{\sigma_{X_n} \, \sigma_{X_1}} & \ldots & \frac{\mathrm{E}\left[(X_n-\mathrm{E}[X_n]) (X_n-\mathrm{E}[X_n])\right]}{\sigma_{X_n} \, \sigma_{X_n}}
\end{bmatrix} \cdot
\begin{bmatrix}
\sigma_{X_1} & \ldots & 0 \\
\vdots & \ddots & \vdots \\
0 & \ldots & \sigma_{X_n}
\end{bmatrix} \\
&=
\begin{bmatrix}
\frac{\sigma_{X_1} \cdot \mathrm{E}\left[(X_1-\mathrm{E}[X_1]) (X_1-\mathrm{E}[X_1])\right]}{\sigma_{X_1} \, \sigma_{X_1}} & \ldots & \frac{\sigma_{X_1} \cdot \mathrm{E}\left[(X_1-\mathrm{E}[X_1]) (X_n-\mathrm{E}[X_n])\right]}{\sigma_{X_1} \, \sigma_{X_n}} \\
\vdots & \ddots & \vdots \\
\frac{\sigma_{X_n} \cdot \mathrm{E}\left[(X_n-\mathrm{E}[X_n]) (X_1-\mathrm{E}[X_1])\right]}{\sigma_{X_n} \, \sigma_{X_1}} & \ldots & \frac{\sigma_{X_n} \cdot \mathrm{E}\left[(X_n-\mathrm{E}[X_n]) (X_n-\mathrm{E}[X_n])\right]}{\sigma_{X_n} \, \sigma_{X_n}}
\end{bmatrix} \cdot
\begin{bmatrix}
\sigma_{X_1} & \ldots & 0 \\
\vdots & \ddots & \vdots \\
0 & \ldots & \sigma_{X_n}
\end{bmatrix} \\
&=
\begin{bmatrix}
\frac{\sigma_{X_1} \cdot \mathrm{E}\left[(X_1-\mathrm{E}[X_1]) (X_1-\mathrm{E}[X_1])\right] \cdot \sigma_{X_1}}{\sigma_{X_1} \, \sigma_{X_1}} & \ldots & \frac{\sigma_{X_1} \cdot \mathrm{E}\left[(X_1-\mathrm{E}[X_1]) (X_n-\mathrm{E}[X_n])\right] \cdot \sigma_{X_n}}{\sigma_{X_1} \, \sigma_{X_n}} \\
\vdots & \ddots & \vdots \\
\frac{\sigma_{X_n} \cdot \mathrm{E}\left[(X_n-\mathrm{E}[X_n]) (X_1-\mathrm{E}[X_1])\right] \cdot \sigma_{X_1}}{\sigma_{X_n} \, \sigma_{X_1}} & \ldots & \frac{\sigma_{X_n} \cdot \mathrm{E}\left[(X_n-\mathrm{E}[X_n]) (X_n-\mathrm{E}[X_n])\right] \cdot \sigma_{X_n}}{\sigma_{X_n} \, \sigma_{X_n}}
\end{bmatrix} \\
&=
\begin{bmatrix}
\mathrm{E}\left[ (X_1-\mathrm{E}[X_1]) (X_1-\mathrm{E}[X_1]) \right] & \ldots & \mathrm{E}\left[ (X_1-\mathrm{E}[X_1]) (X_n-\mathrm{E}[X_n]) \right] \\
\vdots & \ddots & \vdots \\
\mathrm{E}\left[ (X_n-\mathrm{E}[X_n]) (X_1-\mathrm{E}[X_1]) \right] & \ldots & \mathrm{E}\left[ (X_n-\mathrm{E}[X_n]) (X_n-\mathrm{E}[X_n]) \right]
\end{bmatrix}
\end{split}
\end{equation}

which is nothing else than the definition of the covariance matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:covmat}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Penny, William (2006): "The correlation matrix"; in: \textit{Mathematics for Brain Imaging}, ch. 1.4.5, p. 28, eq. 1.60; URL: \url{https://ueapsylabs.co.uk/sites/wpenny/mbi/mbi_course.pdf}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P121 | shortcut: covmat-corrmat | author: JoramSoch | date: 2020-06-06, 06:02.
\vspace{1em}



\subsubsection[\textit{Precision matrix}]{Precision matrix} \label{sec:precmat}
\setcounter{equation}{0}

\textbf{Definition:} Let $X = [X_1, \ldots, X_n]^\mathrm{T}$ be a random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}). Then, the precision matrix of $X$ is defined as the inverse of the covariance matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:covmat}) of $X$:

\begin{equation} \label{eq:precmat-corrmat}
\Lambda_{XX} = \Sigma_{XX}^{-1} =
\begin{bmatrix}
\mathrm{Cov}(X_1,X_1) & \ldots & \mathrm{Cov}(X_1,X_n) \\
\vdots & \ddots & \vdots \\
\mathrm{Cov}(X_n,X_1) & \ldots & \mathrm{Cov}(X_n,X_n)
\end{bmatrix}^{-1} \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Precision (statistics)"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-06-06; URL: \url{https://en.wikipedia.org/wiki/Precision_(statistics)}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D74 | shortcut: precmat | author: JoramSoch | date: 2020-06-06, 05:08.
\vspace{1em}



\subsubsection[\textbf{Precision matrix and correlation matrix}]{Precision matrix and correlation matrix} \label{sec:precmat-corrmat}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}). Then, the precision matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:precmat}) of $X$ can be expressed in terms of its correlation matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:corrmat}) as follows

\begin{equation} \label{eq:precmat-corrmat-precmat-corrmat}
\Lambda_{XX} = \mathrm{D}_X^{-1} \cdot \mathrm{C}_{XX}^{-1} \cdot \mathrm{D}_X^{-1} \; ,
\end{equation}

where $\mathrm{D}_X^{-1}$ is a diagonal matrix with the inverse standard deviations ($\rightarrow$ Definition "std") of $X_1, \ldots, X_n$ as entries on the diagonal:

\begin{equation} \label{eq:precmat-corrmat-invdiagmat}
\mathrm{D}_X^{-1} = \mathrm{diag}(1/\sigma_{X_1},\ldots,1/\sigma_{X_n}) =
\begin{bmatrix}
\frac{1}{\sigma_{X_1}} & \ldots & 0 \\
\vdots & \ddots & \vdots \\
0 & \ldots & \frac{1}{\sigma_{X_n}}
\end{bmatrix} \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The precision matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:precmat}) is defined as the inverse of the covariance matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:covmat})

\begin{equation} \label{eq:precmat-corrmat-precmat-covmat}
\Lambda_{XX} = \Sigma_{XX}^{-1}
\end{equation}

and the relation between covariance matrix and correlation matrix ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:covmat-corrmat}) is given by

\begin{equation} \label{eq:precmat-corrmat-covmat-corrmat}
\Sigma_{XX} = \mathrm{D}_X \cdot \mathrm{C}_{XX} \cdot \mathrm{D}_X
\end{equation}

where

\begin{equation} \label{eq:precmat-corrmat-diagmat}
\mathrm{D}_X = \mathrm{diag}(\sigma_{X_1},\ldots,\sigma_{X_n}) =
\begin{bmatrix}
\sigma_{X_1} & \ldots & 0 \\
\vdots & \ddots & \vdots \\
0 & \ldots & \sigma_{X_n}
\end{bmatrix} \; .
\end{equation}

Using the matrix product property

\begin{equation} \label{eq:precmat-corrmat-matprod-inv}
\left(A \cdot B \cdot C\right)^{-1} = C^{-1} \cdot B^{-1} \cdot A^{-1}
\end{equation}

and the diagonal matrix property

\begin{equation} \label{eq:precmat-corrmat-diagmat-inv}
\mathrm{diag}(a_1,\ldots,a_n)^{-1} =
\begin{bmatrix}
a_1 & \ldots & 0 \\
\vdots & \ddots & \vdots \\
0 & \ldots & a_n
\end{bmatrix}^{-1} =
\begin{bmatrix}
\frac{1}{a_1} & \ldots & 0 \\
\vdots & \ddots & \vdots \\
0 & \ldots & \frac{1}{a_n}
\end{bmatrix} =
\mathrm{diag}(1/a_1,\ldots,1/a_n) \; ,
\end{equation}

we obtain

\begin{equation} \label{eq:precmat-corrmat-precmat-corrmat-qed}
\begin{split}
\Lambda_{XX} &\overset{\eqref{eq:precmat-corrmat-precmat-covmat}}{=} \Sigma_{XX}^{-1} \\
&\overset{\eqref{eq:precmat-corrmat-covmat-corrmat}}{=} \left( \mathrm{D}_X \cdot \mathrm{C}_{XX} \cdot \mathrm{D}_X \right)^{-1} \\
&\overset{\eqref{eq:precmat-corrmat-matprod-inv}}{=} \mathrm{D}_X^{-1} \cdot \mathrm{C}_{XX}^{-1} \cdot \mathrm{D}_X^{-1} \\
&\overset{\eqref{eq:precmat-corrmat-diagmat-inv}}{=}
\begin{bmatrix}
\frac{1}{\sigma_{X_1}} & \ldots & 0 \\
\vdots & \ddots & \vdots \\
0 & \ldots & \frac{1}{\sigma_{X_n}}
\end{bmatrix} \cdot
\mathrm{C}_{XX}^{-1} \cdot
\begin{bmatrix}
\frac{1}{\sigma_{X_1}} & \ldots & 0 \\
\vdots & \ddots & \vdots \\
0 & \ldots & \frac{1}{\sigma_{X_n}}
\end{bmatrix}
\end{split}
\end{equation}

which conforms to equation \eqref{eq:precmat-corrmat-precmat-corrmat}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P122 | shortcut: precmat-corrmat | author: JoramSoch | date: 2020-06-06, 06:28.
\vspace{1em}



\subsection{Correlation}

\subsubsection[\textit{Definition}]{Definition} \label{sec:corr}
\setcounter{equation}{0}

\textbf{Definition:} The correlation of two random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X$ and $Y$, also called Pearson product-moment correlation coefficient (PPMCC), is defined as the ratio of the covariance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cov}) of $X$ and $Y$ relative to the product of their standard deviations ($\rightarrow$ Definition "std"):

\begin{equation} \label{eq:corr-corr}
\mathrm{Corr}(X,Y) = \frac{\sigma_{XY}}{\sigma_X \sigma_Y} = \frac{\mathrm{Cov}(X,Y)}{\sqrt{\mathrm{Var}(X)} \sqrt{\mathrm{Var}(Y)}} = \frac{\mathrm{E}\left[ (X-\mathrm{E}[X]) (Y-\mathrm{E}[Y]) \right]}{\sqrt{\mathrm{E}\left[ (X-\mathrm{E}[X])^2 \right]} \sqrt{\mathrm{E}\left[ (Y-\mathrm{E}[Y])^2 \right]}} \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Correlation and dependence"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-02-06; URL: \url{https://en.wikipedia.org/wiki/Correlation_and_dependence#Pearson's_product-moment_coefficient}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D71 | shortcut: corr | author: JoramSoch | date: 2020-06-02, 20:34.
\vspace{1em}



\subsubsection[\textit{Correlation matrix}]{Correlation matrix} \label{sec:corrmat}
\setcounter{equation}{0}

\textbf{Definition:} Let $X = [X_1, \ldots, X_n]^\mathrm{T}$ be a random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}). Then, the correlation matrix of $X$ is defined as the $n \times n$ matrix in which the entry $(i,j)$ is the correlation ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:corr}) of $X_i$ and $X_j$:

\begin{equation} \label{eq:corrmat-corrmat}
\mathrm{C}_{XX} =
\begin{bmatrix}
\mathrm{Corr}(X_1,X_1) & \ldots & \mathrm{Corr}(X_1,X_n) \\
\vdots & \ddots & \vdots \\
\mathrm{Corr}(X_n,X_1) & \ldots & \mathrm{Corr}(X_n,X_n)
\end{bmatrix} =
\begin{bmatrix}
\frac{\mathrm{E}\left[(X_1-\mathrm{E}[X_1]) (X_1-\mathrm{E}[X_1])\right]}{\sigma_{X_1} \, \sigma_{X_1}} & \ldots & \frac{\mathrm{E}\left[(X_1-\mathrm{E}[X_1]) (X_n-\mathrm{E}[X_n])\right]}{\sigma_{X_1} \, \sigma_{X_n}} \\
\vdots & \ddots & \vdots \\
\frac{\mathrm{E}\left[(X_n-\mathrm{E}[X_n]) (X_1-\mathrm{E}[X_1])\right]}{\sigma_{X_n} \, \sigma_{X_1}} & \ldots & \frac{\mathrm{E}\left[(X_n-\mathrm{E}[X_n]) (X_n-\mathrm{E}[X_n])\right]}{\sigma_{X_n} \, \sigma_{X_n}}
\end{bmatrix} \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Correlation and dependence"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-06-06; URL: \url{https://en.wikipedia.org/wiki/Correlation_and_dependence#Correlation_matrices}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D73 | shortcut: corrmat | author: JoramSoch | date: 2020-06-06, 04:56.
\vspace{1em}



\subsection{Measures of statistical dispersion}

\subsubsection[\textit{Full width at half maximum}]{Full width at half maximum} \label{sec:fwhm}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a continuous random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with a unimodal probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) $f_X(x)$ and mode ($\rightarrow$ Definition "mode") $x_M$. Then, the full width at half maximum of $X$ is defined as

\begin{equation} \label{eq:fwhm-FWHM}
\mathrm{FHWM}(X) = \Delta x = x_2 - x_1
\end{equation}

where $x_1$ and $x_2$ are specified, such that

\begin{equation} \label{eq:fwhm-x12}
f_X(x_1) = f_X(x_2) = \frac{1}{2} f_X(x_M) \quad \text{and} \quad x_1 < x_M < x_2
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Full width at half maximum"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-08-19; URL: \url{https://en.wikipedia.org/wiki/Full_width_at_half_maximum}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D91 | shortcut: fwhm | author: JoramSoch | date: 2020-08-19, 05:40.
\vspace{1em}



\subsection{Further moments}

\subsubsection[\textit{Moment}]{Moment} \label{sec:mom}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) and let $n$ be a positive integer. Then, the $n$-th moment of $X$, also called ($n$-th) "raw moment" or "crude moment", is defined as the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of the $n$-th power of $X$:

\begin{equation} \label{eq:mom-mom}
\mu_n = \mathrm{E}[X^n] \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Moment (mathematics)"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-08-19; URL: \url{https://en.wikipedia.org/wiki/Moment_(mathematics)#Significance_of_the_moments}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D90 | shortcut: mom | author: JoramSoch | date: 2020-08-19, 05:24.
\vspace{1em}



\subsubsection[\textbf{Moment in terms of moment-generating function}]{Moment in terms of moment-generating function} \label{sec:mom-mgf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a scalar random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with the moment-generating function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mgf}) $M_X(t)$. Then, the $n$-th moment ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mom}) of $X$ can be calculated from the moment-generating function via

\begin{equation} \label{eq:mom-mgf-mom-mgf}
\mathrm{E}(X^n) = M_X^{(n)}(0)
\end{equation}

where $n$ is a positive integer and $M_X^{(n)}(t)$ is the $n$-th derivative of $M_X(t)$.


\vspace{1em}
\textbf{Proof:} Using the definition of the moment-generating function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mgf}), we can write:

\begin{equation} \label{eq:mom-mgf-mom-mgf-s1}
M_X^{(n)}(t) = \frac{\mathrm{d}^n}{\mathrm{d}t^n} \mathrm{E}(e^{tX}) \; .
\end{equation}

Using the power series expansion of the exponential function

\begin{equation} \label{eq:mom-mgf-exp-ps}
e^x = \sum_{n=0}^\infty \frac{x^n}{n!} \; ,
\end{equation}

equation \eqref{eq:mom-mgf-mom-mgf-s1} becomes

\begin{equation} \label{eq:mom-mgf-mom-mgf-s2}
M_X^{(n)}(t) = \frac{\mathrm{d}^n}{\mathrm{d}t^n} \mathrm{E}\left( \sum_{m=0}^\infty \frac{t^m X^m}{m!} \right) \; .
\end{equation}

Because the expected value is a linear operator ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-lin}), we have:

\begin{equation} \label{eq:mom-mgf-mom-mgf-s3}
\begin{split}
M_X^{(n)}(t) &= \frac{\mathrm{d}^n}{\mathrm{d}t^n} \sum_{m=0}^\infty \mathrm{E}\left( \frac{t^m X^m}{m!} \right) \\
&= \sum_{m=0}^\infty \frac{\mathrm{d}^n}{\mathrm{d}t^n} \frac{t^m}{m!} \mathrm{E}\left( X^m \right) \; .
\end{split}
\end{equation}

Using the $n$-th derivative of the $m$-th power

\begin{equation} \label{eq:mom-mgf-dndx-xm}
\frac{\mathrm{d}^n}{\mathrm{d}x^n} x^m = \left\{
\begin{array}{rl}
m^{\underline{n}} \, x^{m-n} \; , & \text{if} \; n \leq m \\
0 \; , & \text{if} \; n > m \; .
\end{array}
\right.
\end{equation}

with the falling factorial

\begin{equation} \label{eq:mom-mgf-fact-fall}
m^{\underline{n}} = \prod_{i=0}^{n-1} (m-i) = \frac{m!}{(m-n)!} \; ,
\end{equation}

equation \eqref{eq:mom-mgf-mom-mgf-s3} becomes

\begin{equation} \label{eq:mom-mgf-mom-mgf-s4}
\begin{split}
M_X^{(n)}(t) &= \sum_{m=n}^\infty \frac{m^{\underline{n}} \, t^{m-n}}{m!} \mathrm{E}\left( X^m \right) \\
&\overset{\eqref{eq:mom-mgf-fact-fall}}{=} \sum_{m=n}^\infty \frac{m! \, t^{m-n}}{(m-n)! \, m!} \mathrm{E}\left( X^m \right) \\
&= \sum_{m=n}^\infty \frac{t^{m-n}}{(m-n)!} \mathrm{E}\left( X^m \right) \\
&= \frac{t^{n-n}}{(n-n)!} \mathrm{E}\left( X^n \right) + \sum_{m=n+1}^\infty \frac{t^{m-n}}{(m-n)!} \mathrm{E}\left( X^m \right) \\
&= \frac{t^0}{0!} \, \mathrm{E}\left( X^n \right) + \sum_{m=n+1}^\infty \frac{t^{m-n}}{(m-n)!} \mathrm{E}\left( X^m \right) \\
&= \mathrm{E}\left( X^n \right) + \sum_{m=n+1}^\infty \frac{t^{m-n}}{(m-n)!} \mathrm{E}\left( X^m \right) \; .
\end{split}
\end{equation}

Setting $t = 0$ in \eqref{eq:mom-mgf-mom-mgf-s4} yields

\begin{equation} \label{eq:mom-mgf-mom-mgf-s5}
\begin{split}
M_X^{(n)}(0) &= \mathrm{E}\left( X^n \right) + \sum_{m=n+1}^\infty \frac{0^{m-n}}{(m-n)!} \mathrm{E}\left( X^m \right) \\
&= \mathrm{E}\left( X^n \right)
\end{split}
\end{equation}

which conforms to equation \eqref{eq:mom-mgf-mom-mgf}.



\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item ProofWiki (2020): "Moment in terms of Moment Generating Function"; in: \textit{ProofWiki}, retrieved on 2020-08-19; URL: \url{https://proofwiki.org/wiki/Moment_in_terms_of_Moment_Generating_Function}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P153 | shortcut: mom-mgf | author: JoramSoch | date: 2020-08-19, 07:51.
\vspace{1em}



\pagebreak
\section{Information theory}

\subsection{Shannon entropy}

\subsubsection[\textit{Definition}]{Definition} \label{sec:ent}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a discrete random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with possible outcomes $\mathcal{X}$ and the (observed or assumed) probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) $p(x) = f_X(x)$. Then, the entropy (also referred to as "Shannon entropy") of $X$ is defined as

\begin{equation} \label{eq:ent-ent}
\mathrm{H}(X) = - \sum_{x \in \mathcal{X}} p(x) \cdot \log_b p(x)
\end{equation}

where $b$ is the base of the logarithm specifying in which unit the entropy is determined.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Shannon CE (1948): "A Mathematical Theory of Communication"; in: \textit{Bell System Technical Journal}, vol. 27, iss. 3, pp. 379-423; URL: \url{https://ieeexplore.ieee.org/document/6773024}; DOI: 10.1002/j.1538-7305.1948.tb01338.x.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D15 | shortcut: ent | author: JoramSoch | date: 2020-02-19, 17:36.
\vspace{1em}



\subsubsection[\textbf{Non-negativity}]{Non-negativity} \label{sec:ent-nonneg}
\setcounter{equation}{0}

\textbf{Theorem:} The entropy of a discrete random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) is a non-negative number:

\begin{equation} \label{eq:ent-nonneg-ent-nonneg}
\mathrm{H}(X) \geq 0 \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The entropy of a discrete random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ent}) is defined as

\begin{equation} \label{eq:ent-nonneg-ent}
\mathrm{H}(X) = - \sum_{i=1}^{k} p(x_i) \cdot \log_b p(x_i)
\end{equation}

The minus sign can be moved into the sum:

\begin{equation} \label{eq:ent-nonneg-ent-dev}
\mathrm{H}(X) = \sum_{i=1}^{k} \left[ p(x_i) \cdot \left( - \log_b p(x_i) \right) \right]
\end{equation}

Because the co-domain of probability mass functions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) is $[0,1]$, we can deduce:

\begin{equation} \label{eq:ent-nonneg-nonneg}
\begin{array}{rcccl}
0 &\leq &p(x_i) &\leq &1 \\
-\infty &\leq &\log_b p(x_i) &\leq &0 \\
0 &\leq &-\log_b p(x_i) &\leq &+\infty \\
0 &\leq &p(x_i) \cdot \left(-\log_b p(x_i)\right) &\leq &+\infty \; .
\end{array}
\end{equation}

By convention, $0 \cdot \log_b(0)$ is taken to be $0$ when calculating entropy, consistent with

\begin{equation} \label{eq:ent-nonneg-lim-0log0}
\lim_{p \to 0} \left[ p \log_b(p) \right] = 0 \; .
\end{equation}

Taking this together, each addend in \eqref{eq:ent-nonneg-ent-dev} is positive or zero and thus, the entire sum must also be non-negative.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Cover TM, Thomas JA (1991): "Elements of Information Theory", p. 15; URL: \url{https://www.wiley.com/en-us/Elements+of+Information+Theory%2C+2nd+Edition-p-9780471241959}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P57 | shortcut: ent-nonneg | author: JoramSoch | date: 2020-02-19, 19:10.
\vspace{1em}



\subsubsection[\textbf{Concavity}]{Concavity} \label{sec:ent-conc}
\setcounter{equation}{0}

\textbf{Theorem:} The entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ent}) is concave in the probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) $p$, i.e.

\begin{equation} \label{eq:ent-conc-ent-conc}
\mathrm{H}[\lambda p_1 + (1-\lambda) p_2] \geq \lambda \mathrm{H}[p_1] + (1-\lambda) \mathrm{H}[p_2]
\end{equation}

where $p_1$ and $p_2$ are probability mass functions and $0 \leq \lambda \leq 1$.


\vspace{1em}
\textbf{Proof:} Let $X$ be a discrete random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with possible outcomes $\mathcal{X}$ and let $u(x)$ be the probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) of a discrete uniform distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:duni}) on $X \in \mathcal{X}$. Then, the entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ent}) of an arbitrary probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) $p(x)$ can be rewritten as

\begin{equation} \label{eq:ent-conc-ent-kl}
\begin{split}
\mathrm{H}[p] &= - \sum_{x \in \mathcal{X}} p(x) \cdot \log p(x) \\
&= - \sum_{x \in \mathcal{X}} p(x) \cdot \log \frac{p(x)}{u(x)} u(x) \\
&= - \sum_{x \in \mathcal{X}} p(x) \cdot \log \frac{p(x)}{u(x)} - \sum_{x \in \mathcal{X}} p(x) \cdot \log u(x) \\
&= - \mathrm{KL}[p||u] - \log \frac{1}{|\mathcal{X}|} \sum_{x \in \mathcal{X}} p(x) \\
&= \log |\mathcal{X}| - \mathrm{KL}[p||u] \\
\log |\mathcal{X}| - \mathrm{H}[p] &= \mathrm{KL}[p||u]
\end{split}
\end{equation}

where we have applied the definition of the Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}), the probability mass function of the discrete uniform distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:duni-pmf}) and the total sum over the probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}).

Note that the KL divergence is convex ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:kl-conv}) in the pair of probability distributions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist}) $(p,q)$:

\begin{equation} \label{eq:ent-conc-kl-conv}
\mathrm{KL}[\lambda p_1 + (1-\lambda) p_2||\lambda q_1 + (1-\lambda) q_2] \leq \lambda \mathrm{KL}[p_1||q_1] + (1-\lambda) \mathrm{KL}[p_2||q_2]
\end{equation}

A special case of this is given by

\begin{equation} \label{eq:ent-conc-kl-conv-u}
\begin{split}
\mathrm{KL}[\lambda p_1 + (1-\lambda) p_2||\lambda u + (1-\lambda) u] &\leq \lambda \mathrm{KL}[p_1||u] + (1-\lambda) \mathrm{KL}[p_2||u] \\
\mathrm{KL}[\lambda p_1 + (1-\lambda) p_2||u] &\leq \lambda \mathrm{KL}[p_1||u] + (1-\lambda) \mathrm{KL}[p_2||u]
\end{split}
\end{equation}

and applying equation \eqref{eq:ent-conc-ent-kl}, we have

\begin{equation} \label{eq:ent-conc-ent-conc-qed}
\begin{split}
\log |\mathcal{X}| - \mathrm{H}[\lambda p_1 + (1-\lambda) p_2] &\leq \lambda \left( \log |\mathcal{X}| - \mathrm{H}[p_1] \right) + (1-\lambda) \left( \log |\mathcal{X}| - \mathrm{H}[p_2] \right) \\
\log |\mathcal{X}| - \mathrm{H}[\lambda p_1 + (1-\lambda) p_2] &\leq \log |\mathcal{X}| - \lambda \mathrm{H}[p_1] - (1-\lambda) \mathrm{H}[p_2] \\
- \mathrm{H}[\lambda p_1 + (1-\lambda) p_2] &\leq - \lambda \mathrm{H}[p_1] - (1-\lambda) \mathrm{H}[p_2] \\
\mathrm{H}[\lambda p_1 + (1-\lambda) p_2] &\geq \lambda \mathrm{H}[p_1] + (1-\lambda) \mathrm{H}[p_2]
\end{split}
\end{equation}

which is equivalent to \eqref{eq:ent-conc-ent-conc}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Entropy (information theory)"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-08-11; URL: \url{https://en.wikipedia.org/wiki/Entropy_(information_theory)#Further_properties}.
\item Cover TM, Thomas JA (1991): "Elements of Information Theory", p. 30; URL: \url{https://www.wiley.com/en-us/Elements+of+Information+Theory%2C+2nd+Edition-p-9780471241959}.
\item Xie, Yao (2012): "Chain Rules and Inequalities"; in: \textit{ECE587: Information Theory}, Lecture 3, Slide 25; URL: \url{https://www2.isye.gatech.edu/~yxie77/ece587/Lecture3.pdf}.
\item Goh, Siong Thye (2016): "Understanding the proof of the concavity of entropy"; in: \textit{StackExchange Mathematics}, retrieved on 2020-11-08; URL: \url{https://math.stackexchange.com/questions/2000194/understanding-the-proof-of-the-concavity-of-entropy}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P149 | shortcut: ent-conc | author: JoramSoch | date: 2020-08-11, 08:29.
\vspace{1em}



\subsubsection[\textit{Conditional entropy}]{Conditional entropy} \label{sec:ent-cond}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ and $Y$ be discrete random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with possible outcomes $\mathcal{X}$ and $\mathcal{Y}$ and probability mass functions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) $p(x)$ and $p(y)$. Then, the conditional entropy of $Y$ given $X$ or, entropy of $Y$ conditioned on $X$, is defined as

\begin{equation} \label{eq:ent-cond-ent-cond}
\mathrm{H}(Y|X) = \sum_{x \in \mathcal{X}} p(x) \cdot \mathrm{H}(Y|X=x)
\end{equation}

where $\mathrm{H}(Y \vert X=x)$ is the (marginal) entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ent}) of $Y$, evaluated at $x$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Cover TM, Thomas JA (1991): "Joint Entropy and Conditional Entropy"; in: \textit{Elements of Information Theory}, ch. 2.2, p. 15; URL: \url{https://www.wiley.com/en-us/Elements+of+Information+Theory%2C+2nd+Edition-p-9780471241959}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D17 | shortcut: ent-cond | author: JoramSoch | date: 2020-02-19, 18:08.
\vspace{1em}



\subsubsection[\textit{Joint entropy}]{Joint entropy} \label{sec:ent-joint}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ and $Y$ be discrete random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with possible outcomes $\mathcal{X}$ and $\mathcal{Y}$ and joint probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) $p(x,y)$. Then, the joint entropy of $X$ and $Y$ is defined as

\begin{equation} \label{eq:ent-joint-ent-joint}
\mathrm{H}(X,Y) = - \sum_{x \in \mathcal{X}} \sum_{y \in \mathcal{Y}} p(x,y) \cdot \log_b p(x,y)
\end{equation}

where $b$ is the base of the logarithm specifying in which unit the entropy is determined.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Cover TM, Thomas JA (1991): "Joint Entropy and Conditional Entropy"; in: \textit{Elements of Information Theory}, ch. 2.2, p. 16; URL: \url{https://www.wiley.com/en-us/Elements+of+Information+Theory%2C+2nd+Edition-p-9780471241959}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D18 | shortcut: ent-joint | author: JoramSoch | date: 2020-02-19, 18:18.
\vspace{1em}



\subsubsection[\textit{Cross-entropy}]{Cross-entropy} \label{sec:ent-cross}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a discrete random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with possible outcomes $\mathcal{X}$ and let $P$ and $Q$ be two probability distributions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist}) on $X$ with the probability mass functions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) $p(x)$ and $q(x)$. Then, the cross-entropy of $Q$ relative to $P$ is defined as

\begin{equation} \label{eq:ent-cross-ent-cross}
\mathrm{H}(P,Q) = - \sum_{x \in \mathcal{X}} p(x) \cdot \log_b q(x)
\end{equation}

where $b$ is the base of the logarithm specifying in which unit the cross-entropy is determined.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Cross entropy"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-07-28; URL: \url{https://en.wikipedia.org/wiki/Cross_entropy#Definition}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D85 | shortcut: ent-cross | author: JoramSoch | date: 2020-07-28, 02:51.
\vspace{1em}



\subsubsection[\textbf{Convexity of cross-entropy}]{Convexity of cross-entropy} \label{sec:entcross-conv}
\setcounter{equation}{0}

\textbf{Theorem:} The cross-entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ent-cross}) is convex in the probability distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist}) $q$, i.e.

\begin{equation} \label{eq:entcross-conv-ent-cross-conv}
\mathrm{H}[p,\lambda q_1 + (1-\lambda) q_2] \leq \lambda \mathrm{H}[p,q_1] + (1-\lambda) \mathrm{H}[p,q_2]
\end{equation}

where $p$ is a fixed and $q_1$ and $q_2$ are any two probability distributions and $0 \leq \lambda \leq 1$.


\vspace{1em}
\textbf{Proof:} The relationship between Kullback-Leibler divergence, entropy and cross-entropy ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:kl-ent}) is:

\begin{equation} \label{eq:entcross-conv-kl-ent}
\mathrm{KL}[P||Q] = \mathrm{H}(P,Q) - \mathrm{H}(P) \; .
\end{equation}

Note that the KL divergence is convex ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:kl-conv}) in the pair of probability distributions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist}) $(p,q)$:

\begin{equation} \label{eq:entcross-conv-kl-conv}
\mathrm{KL}[\lambda p_1 + (1-\lambda) p_2||\lambda q_1 + (1-\lambda) q_2] \leq \lambda \mathrm{KL}[p_1||q_1] + (1-\lambda) \mathrm{KL}[p_2||q_2]
\end{equation}

A special case of this is given by

\begin{equation} \label{eq:entcross-conv-kl-conv-p}
\begin{split}
\mathrm{KL}[\lambda p + (1-\lambda) p||\lambda q_1 + (1-\lambda) q_2] &\leq \lambda \mathrm{KL}[p||q_1] + (1-\lambda) \mathrm{KL}[p||q_2] \\
\mathrm{KL}[p||\lambda q_1 + (1-\lambda) q_2] &\leq \lambda \mathrm{KL}[p||q_1] + (1-\lambda) \mathrm{KL}[p||q_2]
\end{split}
\end{equation}

and applying equation \eqref{eq:entcross-conv-kl-ent}, we have

\begin{equation} \label{eq:entcross-conv-ent-cross-conv-qed}
\begin{split}
\mathrm{H}[p,\lambda q_1 + (1-\lambda) q_2] - \mathrm{H}[p] &\leq \lambda \left( \mathrm{H}[p,q_1] - \mathrm{H}[p] \right) + (1-\lambda) \left( \mathrm{H}[p,q_2] - \mathrm{H}[p] \right) \\
\mathrm{H}[p,\lambda q_1 + (1-\lambda) q_2] - \mathrm{H}[p] &\leq \lambda \mathrm{H}[p,q_1] + (1-\lambda) \mathrm{H}[p,q_2] - \mathrm{H}[p] \\
\mathrm{H}[p,\lambda q_1 + (1-\lambda) q_2] &\leq \lambda \mathrm{H}[p,q_1] + (1-\lambda) \mathrm{H}[p,q_2]
\end{split}
\end{equation}

which is equivalent to \eqref{eq:entcross-conv-ent-cross-conv}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Cross entropy"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-08-11; URL: \url{https://en.wikipedia.org/wiki/Cross_entropy#Definition}.
\item gunes (2019): "Convexity of cross entropy"; in: \textit{StackExchange CrossValidated}, retrieved on 2020-11-08; URL: \url{https://stats.stackexchange.com/questions/394463/convexity-of-cross-entropy}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P150 | shortcut: entcross-conv | author: JoramSoch | date: 2020-08-11, 09:16.
\vspace{1em}



\subsection{Differential entropy}

\subsubsection[\textit{Definition}]{Definition} \label{sec:dent}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a continuous random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with possible outcomes $\mathcal{X}$ and the (estimated or assumed) probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) $p(x) = f_X(x)$. Then, the differential entropy (also referred to as "continuous entropy") of $X$ is defined as

\begin{equation} \label{eq:dent-dent}
\mathrm{h}(X) = - \int_{\mathcal{X}} p(x) \log_b p(x) \, \mathrm{d}x
\end{equation}

where $b$ is the base of the logarithm specifying in which unit the entropy is determined.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Cover TM, Thomas JA (1991): "Differential Entropy"; in: \textit{Elements of Information Theory}, ch. 8.1, p. 243; URL: \url{https://www.wiley.com/en-us/Elements+of+Information+Theory%2C+2nd+Edition-p-9780471241959}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D16 | shortcut: dent | author: JoramSoch | date: 2020-02-19, 17:53.
\vspace{1em}



\subsubsection[\textbf{Negativity}]{Negativity} \label{sec:dent-neg}
\setcounter{equation}{0}

\textbf{Theorem:} Unlike its discrete analogue ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:ent-nonneg}), the differential entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent}) can become negative.


\vspace{1em}
\textbf{Proof:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a continuous uniform distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:cuni}) with minimum $0$ and maximum $1/2$:

\begin{equation} \label{eq:dent-neg-X}
X \sim \mathcal{U}(0, 1/2) \; .
\end{equation}

Then, its probability density function ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:cuni-pdf}) is:

\begin{equation} \label{eq:dent-neg-X-pdf}
f_X(x) = 2 \quad \text{for} \quad 0 \leq x \leq \frac{1}{2} \; .
\end{equation}

Thus, the differential entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent}) follows as

\begin{equation} \label{eq:dent-neg-X-dent}
\begin{split}
\mathrm{h}(X) &= - \int_{\mathcal{X}} f_X(x) \log_b f_X(x) \, \mathrm{d}x \\
&= - \int_{0}^{\frac{1}{2}} 2 \, \log_b(2) \, \mathrm{d}x \\
&= -\log_b(2) \int_{0}^{\frac{1}{2}} 2 \, \mathrm{d}x \\
&= -\log_b(2) \left[ 2x \right]_{0}^{\frac{1}{2}} \\
&= -\log_b(2)
\end{split}
\end{equation}

which is negative for any base $b > 1$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Differential entropy"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-03-02; URL: \url{https://en.wikipedia.org/wiki/Differential_entropy#Definition}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P68 | shortcut: dent-neg | author: JoramSoch | date: 2020-03-02, 20:32.
\vspace{1em}



\subsubsection[\textit{Conditional differential entropy}]{Conditional differential entropy} \label{sec:dent-cond}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ and $Y$ be continuous random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with possible outcomes $\mathcal{X}$ and $\mathcal{Y}$ and probability density functions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) $p(x)$ and $p(y)$. Then, the conditional differential entropy of $Y$ given $X$ or, differential entropy of $Y$ conditioned on $X$, is defined as

\begin{equation} \label{eq:dent-cond-dent-cond}
\mathrm{h}(Y|X) = \int_{x \in \mathcal{X}} p(x) \cdot \mathrm{h}(Y|X=x)
\end{equation}

where $\mathrm{h}(Y \vert X=x)$ is the (marginal) differential entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent}) of $Y$, evaluated at $x$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D34 | shortcut: dent-cond | author: JoramSoch | date: 2020-03-21, 12:27.
\vspace{1em}



\subsubsection[\textit{Joint differential entropy}]{Joint differential entropy} \label{sec:dent-joint}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ and $Y$ be continuous random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with possible outcomes $\mathcal{X}$ and $\mathcal{Y}$ and joint probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) $p(x,y)$. Then, the joint differential entropy of $X$ and $Y$ is defined as

\begin{equation} \label{eq:dent-joint-dent-joint}
\mathrm{h}(X,Y) = - \int_{x \in \mathcal{X}} \int_{y \in \mathcal{Y}} p(x,y) \cdot \log_b p(x,y) \, \mathrm{d}y \, \mathrm{d}x
\end{equation}

where $b$ is the base of the logarithm specifying in which unit the differential entropy is determined.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D35 | shortcut: dent-joint | author: JoramSoch | date: 2020-03-21, 12:37.
\vspace{1em}



\subsubsection[\textit{Differential cross-entropy}]{Differential cross-entropy} \label{sec:dent-cross}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a continuous random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with possible outcomes $\mathcal{X}$ and let $P$ and $Q$ be two probability distributions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist}) on $X$ with the probability density functions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) $p(x)$ and $q(x)$. Then, the differential cross-entropy of $Q$ relative to $P$ is defined as

\begin{equation} \label{eq:dent-cross-dent-cross}
\mathrm{h}(P,Q) = - \int_{\mathcal{X}} p(x) \log_b q(x) \, \mathrm{d}x
\end{equation}

where $b$ is the base of the logarithm specifying in which unit the differential cross-entropy is determined.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Cross entropy"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-07-28; URL: \url{https://en.wikipedia.org/wiki/Cross_entropy#Definition}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D86 | shortcut: dent-cross | author: JoramSoch | date: 2020-07-28, 03:03.
\vspace{1em}



\subsection{Discrete mutual information}

\subsubsection[\textit{Definition}]{Definition} \label{sec:mi}
\setcounter{equation}{0}

\textbf{Definition:}

1) The mutual information of two discrete random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X$ and $Y$ is defined as

\begin{equation} \label{eq:mi-mi-disc}
\mathrm{I}(X,Y) = - \sum_{x \in \mathcal{X}} \sum_{x \in \mathcal{Y}} p(x,y) \cdot \log \frac{p(x,y)}{p(x) \cdot p(y)}
\end{equation}

where $p(x)$ and $p(y)$ are the probability mass functions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) of $X$ and $Y$ and $p(x,y)$ is the joint probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) mass function of $X$ and $Y$.

2) The mutual information of two continuous random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X$ and $Y$ is defined as

\begin{equation} \label{eq:mi-mi-cont}
\mathrm{I}(X,Y) = - \int_{\mathcal{X}} \int_{\mathcal{Y}} p(x,y) \cdot \log \frac{p(x,y)}{p(x) \cdot p(y)} \, \mathrm{d}y \, \mathrm{d}x
\end{equation}

where $p(x)$ and $p(y)$ are the probability density functions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) of $X$ and $Y$ and $p(x,y)$ is the joint probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) density function of $X$ and $Y$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Cover TM, Thomas JA (1991): "Relative Entropy and Mutual Information"; in: \textit{Elements of Information Theory}, ch. 2.3/8.5, p. 20/251; URL: \url{https://www.wiley.com/en-us/Elements+of+Information+Theory%2C+2nd+Edition-p-9780471241959}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D19 | shortcut: mi | author: JoramSoch | date: 2020-02-19, 18:35.
\vspace{1em}



\subsubsection[\textbf{Relation to marginal and conditional entropy}]{Relation to marginal and conditional entropy} \label{sec:dmi-mce}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ and $Y$ be discrete random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with the joint probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) $p(x,y)$ for $x \in \mathcal{X}$ and $y \in \mathcal{Y}$. Then, the mutual information ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mi}) of $X$ and $Y$ can be expressed as

\begin{equation} \label{eq:dmi-mce-dmi-mce}
\begin{split}
\mathrm{I}(X,Y) &= \mathrm{H}(X) - \mathrm{H}(X|Y) \\
&= \mathrm{H}(Y) - \mathrm{H}(Y|X)
\end{split}
\end{equation}

where $\mathrm{H}(X)$ and $\mathrm{H}(Y)$ are the marginal entropies ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ent}) of $X$ and $Y$ and $\mathrm{H}(X \vert Y)$ and $\mathrm{H}(Y \vert X)$ are the conditional entropies ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ent-cond}).


\vspace{1em}
\textbf{Proof:} The mutual information ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mi}) of $X$ and $Y$ is defined as

\begin{equation} \label{eq:dmi-mce-MI}
\mathrm{I}(X,Y) = \sum_{x \in \mathcal{X}} \sum_{y \in \mathcal{Y}} p(x,y) \log \frac{p(x,y)}{p(x)\,p(y)} \; .
\end{equation}

Separating the logarithm, we have:

\begin{equation} \label{eq:dmi-mce-MI-s1}
\mathrm{I}(X,Y) = \sum_x \sum_y p(x,y) \log \frac{p(x,y)}{p(y)} - \sum_x \sum_y p(x,y) \log p(x) \; .
\end{equation}

Applying the law of conditional probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-cond}), i.e. $p(x,y) = p(x \vert y) \, p(y)$, we get:

\begin{equation} \label{eq:dmi-mce-MI-s2}
\mathrm{I}(X,Y) = \sum_x \sum_y p(x|y) \, p(y) \log p(x|y) - \sum_x \sum_y p(x,y) \log p(x) \; .
\end{equation}

Regrouping the variables, we have:

\begin{equation} \label{eq:dmi-mce-MI-s3}
\mathrm{I}(X,Y) = \sum_y p(y) \sum_x p(x|y) \log p(x|y) - \sum_x \left( \sum_y p(x,y) \right) \log p(x) \; .
\end{equation}

Applying the law of marginal probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}), i.e. $p(x) = \sum_y p(x,y)$, we get:

\begin{equation} \label{eq:dmi-mce-MI-s4}
\mathrm{I}(X,Y) = \sum_y p(y) \sum_x p(x|y) \log p(x|y) - \sum_x p(x) \log p(x) \; .
\end{equation}

Now considering the definitions of marginal ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ent}) and conditional ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ent-cond}) entropy

\begin{equation} \label{eq:dmi-mce-ME-CE}
\begin{split}
\mathrm{H}(X) &= - \sum_{x \in \mathcal{X}} p(x) \log p(x) \\
\mathrm{H}(X|Y) &= \sum_{y \in \mathcal{Y}} p(y) \, \mathrm{H}(X|Y=y) \; ,
\end{split}
\end{equation}

we can finally show:

\begin{equation} \label{eq:dmi-mce-MI-qed}
\begin{split}
\mathrm{I}(X,Y) &= - \mathrm{H}(X|Y) + \mathrm{H}(X) \\
&= \mathrm{H}(X) - \mathrm{H}(X|Y) \; .
\end{split}
\end{equation}

The conditioning of $X$ on $Y$ in this proof is without loss of generality. Thus, the proof for the expression using the reverse conditional entropy of $Y$ given $X$ is obtained by simply switching $x$ and $y$ in the derivation.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Mutual information"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-01-13; URL: \url{https://en.wikipedia.org/wiki/Mutual_information#Relation_to_conditional_and_joint_entropy}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P19 | shortcut: dmi-mce | author: JoramSoch | date: 2020-01-13, 18:20.
\vspace{1em}



\subsubsection[\textbf{Relation to marginal and joint entropy}]{Relation to marginal and joint entropy} \label{sec:dmi-mje}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ and $Y$ be discrete random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with the joint probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) $p(x,y)$ for $x \in \mathcal{X}$ and $y \in \mathcal{Y}$. Then, the mutual information ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mi}) of $X$ and $Y$ can be expressed as

\begin{equation} \label{eq:dmi-mje-dmi-mje}
\mathrm{I}(X,Y) = \mathrm{H}(X) + \mathrm{H}(Y) - \mathrm{H}(X,Y)
\end{equation}

where $\mathrm{H}(X)$ and $\mathrm{H}(Y)$ are the marginal entropies ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ent}) of $X$ and $Y$ and $\mathrm{H}(X,Y)$ is the joint entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ent-joint}).


\vspace{1em}
\textbf{Proof:} The mutual information ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mi}) of $X$ and $Y$ is defined as

\begin{equation} \label{eq:dmi-mje-MI}
\mathrm{I}(X,Y) = \sum_{x \in \mathcal{X}} \sum_{y \in \mathcal{Y}} p(x,y) \log \frac{p(x,y)}{p(x)\,p(y)} \; .
\end{equation}

Separating the logarithm, we have:

\begin{equation} \label{eq:dmi-mje-MI-s1}
\mathrm{I}(X,Y) = \sum_x \sum_y p(x,y) \log p(x,y) - \sum_x \sum_y p(x,y) \log p(x) - \sum_x \sum_y p(x,y) \log p(y) \; .
\end{equation}

Regrouping the variables, this reads:

\begin{equation} \label{eq:dmi-mje-MI-s2}
\mathrm{I}(X,Y) = \sum_x \sum_y p(x,y) \log p(x,y) - \sum_x \left( \sum_y p(x,y) \right) \log p(x) - \sum_y \left( \sum_x p(x,y) \right) \log p(y) \; .
\end{equation}

Applying the law of marginal probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}), i.e. $p(x) = \sum_y p(x,y)$, we get:

\begin{equation} \label{eq:dmi-mje-MI-s3}
\mathrm{I}(X,Y) = \sum_x \sum_y p(x,y) \log p(x,y) - \sum_x p(x) \log p(x) - \sum_y p(y) \log p(y) \; .
\end{equation}

Now considering the definitions of marginal ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ent}) and joint ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ent-joint}) entropy

\begin{equation} \label{eq:dmi-mje-ME-JE}
\begin{split}
\mathrm{H}(X) &= - \sum_{x \in \mathcal{X}} p(x) \log p(x) \\
\mathrm{H}(X,Y) &= - \sum_{x \in \mathcal{X}} \sum_{y \in \mathcal{Y}} p(x,y) \log p(x,y) \; ,
\end{split}
\end{equation}

we can finally show:

\begin{equation} \label{eq:dmi-mje-MI-qed}
\begin{split}
\mathrm{I}(X,Y) &= - \mathrm{H}(X,Y) + \mathrm{H}(X) + \mathrm{H}(Y) \\
&= \mathrm{H}(X) + \mathrm{H}(Y) - \mathrm{H}(X,Y) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Mutual information"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-01-13; URL: \url{https://en.wikipedia.org/wiki/Mutual_information#Relation_to_conditional_and_joint_entropy}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P20 | shortcut: dmi-mje | author: JoramSoch | date: 2020-01-13, 21:53.
\vspace{1em}



\subsubsection[\textbf{Relation to joint and conditional entropy}]{Relation to joint and conditional entropy} \label{sec:dmi-jce}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ and $Y$ be discrete random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with the joint probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) $p(x,y)$ for $x \in \mathcal{X}$ and $y \in \mathcal{Y}$. Then, the mutual information ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mi}) of $X$ and $Y$ can be expressed as

\begin{equation} \label{eq:dmi-jce-dmi-jce}
\mathrm{I}(X,Y) = \mathrm{H}(X,Y) - \mathrm{H}(X|Y) - \mathrm{H}(Y|X)
\end{equation}

where $\mathrm{H}(X,Y)$ is the joint entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ent-joint}) of $X$ and $Y$ and $\mathrm{H}(X \vert Y)$ and $\mathrm{H}(Y \vert X)$ are the conditional entropies ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ent-cond}).


\vspace{1em}
\textbf{Proof:} The existence of the joint probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) ensures that the mutual information ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mi}) is defined:

\begin{equation} \label{eq:dmi-jce-MI}
\mathrm{I}(X,Y) = \sum_{x \in \mathcal{X}} \sum_{y \in \mathcal{Y}} p(x,y) \log \frac{p(x,y)}{p(x)\,p(y)} \; .
\end{equation}

The relation of mutual information to conditional entropy ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:dmi-mce}) is:

\begin{equation} \label{eq:dmi-jce-dmi-mce1}
\mathrm{I}(X,Y) = \mathrm{H}(X) - \mathrm{H}(X|Y)
\end{equation}

\begin{equation} \label{eq:dmi-jce-dmi-mce2}
\mathrm{I}(X,Y) = \mathrm{H}(Y) - \mathrm{H}(Y|X)
\end{equation}

The relation of mutual information to joint entropy ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:dmi-mje}) is:

\begin{equation} \label{eq:dmi-jce-dmi-mje}
\mathrm{I}(X,Y) = \mathrm{H}(X) + \mathrm{H}(Y) - \mathrm{H}(X,Y) \; .
\end{equation}

It is true that

\begin{equation} \label{eq:dmi-jce-MI-s1}
\mathrm{I}(X,Y) = \mathrm{I}(X,Y) + \mathrm{I}(X,Y) - \mathrm{I}(X,Y) \; .
\end{equation}

Plugging in \eqref{eq:dmi-jce-dmi-mce1}, \eqref{eq:dmi-jce-dmi-mce2} and \eqref{eq:dmi-jce-dmi-mje} on the right-hand side, we have

\begin{equation} \label{eq:dmi-jce-MI-s2}
\begin{split}
\mathrm{I}(X,Y) &= \mathrm{H}(X) - \mathrm{H}(X|Y) + \mathrm{H}(Y) - \mathrm{H}(Y|X) - \mathrm{H}(X) - \mathrm{H}(Y) + \mathrm{H}(X,Y) \\
&= \mathrm{H}(X,Y) - \mathrm{H}(X|Y) - \mathrm{H}(Y|X)
\end{split}
\end{equation}

which proves the identity given above.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Mutual information"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-01-13; URL: \url{https://en.wikipedia.org/wiki/Mutual_information#Relation_to_conditional_and_joint_entropy}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P21 | shortcut: dmi-jce | author: JoramSoch | date: 2020-01-13, 22:17.
\vspace{1em}



\subsection{Continuous mutual information}

\subsubsection[\textit{Definition}]{Definition} \label{sec:mi}
\setcounter{equation}{0}

\textbf{Definition:}

1) The mutual information of two discrete random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X$ and $Y$ is defined as

\begin{equation} \label{eq:mi-mi-disc}
\mathrm{I}(X,Y) = - \sum_{x \in \mathcal{X}} \sum_{x \in \mathcal{Y}} p(x,y) \cdot \log \frac{p(x,y)}{p(x) \cdot p(y)}
\end{equation}

where $p(x)$ and $p(y)$ are the probability mass functions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) of $X$ and $Y$ and $p(x,y)$ is the joint probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) mass function of $X$ and $Y$.

2) The mutual information of two continuous random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X$ and $Y$ is defined as

\begin{equation} \label{eq:mi-mi-cont}
\mathrm{I}(X,Y) = - \int_{\mathcal{X}} \int_{\mathcal{Y}} p(x,y) \cdot \log \frac{p(x,y)}{p(x) \cdot p(y)} \, \mathrm{d}y \, \mathrm{d}x
\end{equation}

where $p(x)$ and $p(y)$ are the probability density functions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) of $X$ and $Y$ and $p(x,y)$ is the joint probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) density function of $X$ and $Y$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Cover TM, Thomas JA (1991): "Relative Entropy and Mutual Information"; in: \textit{Elements of Information Theory}, ch. 2.3/8.5, p. 20/251; URL: \url{https://www.wiley.com/en-us/Elements+of+Information+Theory%2C+2nd+Edition-p-9780471241959}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D19 | shortcut: mi | author: JoramSoch | date: 2020-02-19, 18:35.
\vspace{1em}



\subsubsection[\textbf{Relation to marginal and conditional differential entropy}]{Relation to marginal and conditional differential entropy} \label{sec:cmi-mcde}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ and $Y$ be continuous random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with the joint probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) $p(x,y)$ for $x \in \mathcal{X}$ and $y \in \mathcal{Y}$. Then, the mutual information ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mi}) of $X$ and $Y$ can be expressed as

\begin{equation} \label{eq:cmi-mcde-cmi-mcde}
\begin{split}
\mathrm{I}(X,Y) &= \mathrm{h}(X) - \mathrm{h}(X|Y) \\
&= \mathrm{h}(Y) - \mathrm{h}(Y|X)
\end{split}
\end{equation}

where $\mathrm{h}(X)$ and $\mathrm{h}(Y)$ are the marginal differential entropies ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent}) of $X$ and $Y$ and $\mathrm{h}(X \vert Y)$ and $\mathrm{h}(Y \vert X)$ are the conditional differential entropies ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent-cond}).


\vspace{1em}
\textbf{Proof:} The mutual information ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mi}) of $X$ and $Y$ is defined as

\begin{equation} \label{eq:cmi-mcde-MI}
\mathrm{I}(X,Y) = \int_{\mathcal{X}} \int_{\mathcal{Y}} p(x,y) \log \frac{p(x,y)}{p(x)\,p(y)} \, \mathrm{d}y \, \mathrm{d}x \; .
\end{equation}

Separating the logarithm, we have:

\begin{equation} \label{eq:cmi-mcde-MI-s1}
\mathrm{I}(X,Y) = \int_{\mathcal{X}} \int_{\mathcal{Y}} p(x,y) \log \frac{p(x,y)}{p(y)} \, \mathrm{d}y \, \mathrm{d}x - \int_{\mathcal{X}} \int_{\mathcal{Y}} p(x,y) \log p(x) \, \mathrm{d}x \, \mathrm{d}y \; .
\end{equation}

Applying the law of conditional probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-cond}), i.e. $p(x,y) = p(x \vert y) \, p(y)$, we get:

\begin{equation} \label{eq:cmi-mcde-MI-s2}
\mathrm{I}(X,Y) = \int_{\mathcal{X}} \int_{\mathcal{Y}} p(x|y) \, p(y) \log p(x|y) \, \mathrm{d}y \, \mathrm{d}x - \int_{\mathcal{X}} \int_{\mathcal{Y}} p(x,y) \log p(x) \, \mathrm{d}y \, \mathrm{d}x \; .
\end{equation}

Regrouping the variables, we have:

\begin{equation} \label{eq:cmi-mcde-MI-s3}
\mathrm{I}(X,Y) = \int_{\mathcal{Y}} p(y) \int_{\mathcal{X}} p(x|y) \log p(x|y) \, \mathrm{d}x \, \mathrm{d}y - \int_{\mathcal{X}} \left( \int_{\mathcal{Y}} p(x,y) \, \mathrm{d}y \right) \log p(x)\, \mathrm{d}x \; .
\end{equation}

Applying the law of marginal probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}), i.e. $p(x) = \int_{\mathcal{Y}} p(x,y) \, \mathrm{d}y$, we get:

\begin{equation} \label{eq:cmi-mcde-MI-s4}
\mathrm{I}(X,Y) = \int_{\mathcal{Y}} p(y) \int_{\mathcal{X}} p(x|y) \log p(x|y) \, \mathrm{d}x \, \mathrm{d}y - \int_{\mathcal{X}} p(x) \log p(x) \, \mathrm{d}x \; .
\end{equation}

Now considering the definitions of marginal ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent}) and conditional ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent-cond}) differential entropy

\begin{equation} \label{eq:cmi-mcde-MDE-CDE}
\begin{split}
\mathrm{h}(X) &= - \int_{\mathcal{X}} p(x) \log p(x) \, \mathrm{d}x \\
\mathrm{h}(X|Y) &= \int_{\mathcal{Y}} p(y) \, \mathrm{h}(X|Y=y) \, \mathrm{d}y \; ,
\end{split}
\end{equation}

we can finally show:

\begin{equation} \label{eq:cmi-mcde-MI-qed}
\mathrm{I}(X,Y) = - \mathrm{h}(X|Y) + \mathrm{h}(X) = \mathrm{h}(X) - \mathrm{h}(X|Y) \; .
\end{equation}

The conditioning of $X$ on $Y$ in this proof is without loss of generality. Thus, the proof for the expression using the reverse conditional differential entropy of $Y$ given $X$ is obtained by simply switching $x$ and $y$ in the derivation.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Mutual information"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-02-21; URL: \url{https://en.wikipedia.org/wiki/Mutual_information#Relation_to_conditional_and_joint_entropy}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P58 | shortcut: cmi-mcde | author: JoramSoch | date: 2020-02-21, 16:53.
\vspace{1em}



\subsubsection[\textbf{Relation to marginal and joint differential entropy}]{Relation to marginal and joint differential entropy} \label{sec:cmi-mjde}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ and $Y$ be continuous random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with the joint probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) $p(x,y)$ for $x \in \mathcal{X}$ and $y \in \mathcal{Y}$. Then, the mutual information ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mi}) of $X$ and $Y$ can be expressed as

\begin{equation} \label{eq:cmi-mjde-cmi-mjde}
\mathrm{I}(X,Y) = \mathrm{h}(X) + \mathrm{h}(Y) - \mathrm{h}(X,Y)
\end{equation}

where $\mathrm{h}(X)$ and $\mathrm{h}(Y)$ are the marginal differential entropies ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent}) of $X$ and $Y$ and $\mathrm{h}(X,Y)$ is the joint differential entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent-joint}).


\vspace{1em}
\textbf{Proof:} The mutual information ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mi}) of $X$ and $Y$ is defined as

\begin{equation} \label{eq:cmi-mjde-MI}
\mathrm{I}(X,Y) = \int_{\mathcal{X}} \int_{\mathcal{Y}} p(x,y) \log \frac{p(x,y)}{p(x)\,p(y)} \, \mathrm{d}y \, \mathrm{d}x \; .
\end{equation}

Separating the logarithm, we have:

\begin{equation} \label{eq:cmi-mjde-MI-s1}
\mathrm{I}(X,Y) = \int_{\mathcal{X}} \int_{\mathcal{Y}} p(x,y) \log p(x,y) \, \mathrm{d}y \, \mathrm{d}x - \int_{\mathcal{X}} \int_{\mathcal{Y}} p(x,y) \log p(x) \, \mathrm{d}y \, \mathrm{d}x - \int_{\mathcal{X}} \int_{\mathcal{Y}} p(x,y) \log p(y) \, \mathrm{d}y \, \mathrm{d}x \; .
\end{equation}

Regrouping the variables, this reads:

\begin{equation} \label{eq:cmi-mjde-MI-s2}
\mathrm{I}(X,Y) = \int_{\mathcal{X}} \int_{\mathcal{Y}} p(x,y) \log p(x,y) \, \mathrm{d}y \, \mathrm{d}x - \int_{\mathcal{X}} \left( \int_{\mathcal{Y}} p(x,y) \, \mathrm{d}y \right) \log p(x) \, \mathrm{d}x - \int_{\mathcal{Y}} \left( \int_{\mathcal{X}} p(x,y) \, \mathrm{d}x \right) \log p(y) \, \mathrm{d}y \; .
\end{equation}

Applying the law of marginal probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}), i.e. $p(x) = \int_{\mathcal{Y}} p(x,y)$, we get:

\begin{equation} \label{eq:cmi-mjde-MI-s3}
\mathrm{I}(X,Y) = \int_{\mathcal{X}} \int_{\mathcal{Y}} p(x,y) \log p(x,y) \, \mathrm{d}y \, \mathrm{d}x - \int_{\mathcal{X}} p(x) \log p(x) \, \mathrm{d}x - \int_{\mathcal{Y}} p(y) \log p(y) \, \mathrm{d}y \; .
\end{equation}

Now considering the definitions of marginal ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent}) and joint ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent-joint}) differential entropy

\begin{equation} \label{eq:cmi-mjde-MDE-JDE}
\begin{split}
\mathrm{h}(X) &= - \int_{\mathcal{X}} p(x) \log p(x) \, \mathrm{d}x \\
\mathrm{h}(X,Y) &= - \int_{\mathcal{X}} \int_{\mathcal{Y}} p(x,y) \log p(x,y) \, \mathrm{d}y \, \mathrm{d}x \; ,
\end{split}
\end{equation}

we can finally show:

\begin{equation} \label{eq:cmi-mjde-MI-qed}
\begin{split}
\mathrm{I}(X,Y) &= - \mathrm{h}(X,Y) + \mathrm{h}(X) + \mathrm{h}(Y) \\
&= \mathrm{h}(X) + \mathrm{h}(Y) - \mathrm{h}(X,Y) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Mutual information"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-02-21; URL: \url{https://en.wikipedia.org/wiki/Mutual_information#Relation_to_conditional_and_joint_entropy}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P59 | shortcut: cmi-mjde | author: JoramSoch | date: 2020-02-21, 17:13.
\vspace{1em}



\subsubsection[\textbf{Relation to joint and conditional differential entropy}]{Relation to joint and conditional differential entropy} \label{sec:cmi-jcde}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ and $Y$ be continuous random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with the joint probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) $p(x,y)$ for $x \in \mathcal{X}$ and $y \in \mathcal{Y}$. Then, the mutual information ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mi}) of $X$ and $Y$ can be expressed as

\begin{equation} \label{eq:cmi-jcde-dmi-jce}
\mathrm{I}(X,Y) = \mathrm{h}(X,Y) - \mathrm{h}(X|Y) - \mathrm{h}(Y|X)
\end{equation}

where $\mathrm{h}(X,Y)$ is the joint differential entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent-joint}) of $X$ and $Y$ and $\mathrm{h}(X \vert Y)$ and $\mathrm{h}(Y \vert X)$ are the conditional differential entropies ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent-cond}).


\vspace{1em}
\textbf{Proof:} The existence of the joint probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) ensures that the mutual information ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mi}) is defined:

\begin{equation} \label{eq:cmi-jcde-MI}
\mathrm{I}(X,Y) = \int_{\mathcal{X}} \int_{\mathcal{Y}} p(x,y) \log \frac{p(x,y)}{p(x)\,p(y)} \, \mathrm{d}y \, \mathrm{d}x \; .
\end{equation}

The relation of mutual information to conditional differential entropy ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:cmi-mcde}) is:

\begin{equation} \label{eq:cmi-jcde-cmi-mcde1}
\mathrm{I}(X,Y) = \mathrm{h}(X) - \mathrm{h}(X|Y)
\end{equation}

\begin{equation} \label{eq:cmi-jcde-cmi-mcde2}
\mathrm{I}(X,Y) = \mathrm{h}(Y) - \mathrm{h}(Y|X)
\end{equation}

The relation of mutual information to joint differential entropy ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:cmi-mjde}) is:

\begin{equation} \label{eq:cmi-jcde-cmi-mjde}
\mathrm{I}(X,Y) = \mathrm{h}(X) + \mathrm{h}(Y) - \mathrm{h}(X,Y) \; .
\end{equation}

It is true that

\begin{equation} \label{eq:cmi-jcde-MI-s1}
\mathrm{I}(X,Y) = \mathrm{I}(X,Y) + \mathrm{I}(X,Y) - \mathrm{I}(X,Y) \; .
\end{equation}

Plugging in \eqref{eq:cmi-jcde-cmi-mcde1}, \eqref{eq:cmi-jcde-cmi-mcde2} and \eqref{eq:cmi-jcde-cmi-mjde} on the right-hand side, we have

\begin{equation} \label{eq:cmi-jcde-MI-s2}
\begin{split}
\mathrm{I}(X,Y) &= \mathrm{h}(X) - \mathrm{h}(X|Y) + \mathrm{h}(Y) - \mathrm{h}(Y|X) - \mathrm{h}(X) - \mathrm{h}(Y) + \mathrm{h}(X,Y) \\
&= \mathrm{h}(X,Y) - \mathrm{h}(X|Y) - \mathrm{h}(Y|X)
\end{split}
\end{equation}

which proves the identity given above.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Mutual information"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-02-21; URL: \url{https://en.wikipedia.org/wiki/Mutual_information#Relation_to_conditional_and_joint_entropy}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P60 | shortcut: cmi-jcde | author: JoramSoch | date: 2020-02-21, 17:23.
\vspace{1em}



\subsection{Kullback-Leibler divergence}

\subsubsection[\textit{Definition}]{Definition} \label{sec:kl}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with possible outcomes $\mathcal{X}$ and let $P$ and $Q$ be two probability distributions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist}) on $X$.

1) The Kullback-Leibler divergence of $P$ from $Q$ for a discrete random variable $X$ is defined as

\begin{equation} \label{eq:kl-KL-disc}
\mathrm{KL}[P||Q] = \sum_{x \in \mathcal{X}} p(x) \cdot \log \frac{p(x)}{q(x)}
\end{equation}

where $p(x)$ and $q(x)$ are the probability mass functions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) of $P$ and $Q$.

2) The Kullback-Leibler divergence of $P$ from $Q$ for a continuous random variable $X$ is defined as

\begin{equation} \label{eq:kl-KL-cont}
\mathrm{KL}[P||Q] = \int_{\mathcal{X}} p(x) \cdot \log \frac{p(x)}{q(x)} \, \mathrm{d}x
\end{equation}

where $p(x)$ and $q(x)$ are the probability density functions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $P$ and $Q$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item MacKay, David J.C. (2003): "Probability, Entropy, and Inference"; in: \textit{Information Theory, Inference, and Learning Algorithms}, ch. 2.6, eq. 2.45, p. 34; URL: \url{https://www.inference.org.uk/itprnn/book.pdf}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D52 | shortcut: kl | author: JoramSoch | date: 2020-05-10, 20:20.
\vspace{1em}



\subsubsection[\textbf{Non-negativity}]{Non-negativity} \label{sec:kl-nonneg}
\setcounter{equation}{0}

\textbf{Theorem:} The Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) is always non-negative

\begin{equation} \label{eq:kl-nonneg-KL-nonneg}
\mathrm{KL}[P||Q] \geq 0
\end{equation}

with $\mathrm{KL}[P \vert \vert Q] = 0$, if and only if $P = Q$.


\vspace{1em}
\textbf{Proof:} The discrete Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) is defined as

\begin{equation} \label{eq:kl-nonneg-KL}
\mathrm{KL}[P||Q] = \sum_{x \in \mathcal{X}} p(x) \cdot \log \frac{p(x)}{q(x)} \, \mathrm{d}x
\end{equation}

which can be reformulated into

\begin{equation} \label{eq:kl-nonneg-KL-dev}
\mathrm{KL}[P||Q] = \sum_{x \in \mathcal{X}} p(x) \cdot \log p(x) - \sum_{x \in \mathcal{X}} p(x) \cdot \log q(x) \, \mathrm{d}x \; .
\end{equation}

Gibbs' inequality ($\rightarrow$ Proof "gibbs-ineq") states that the entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ent}) of a probability distribution is always less than or equal to the cross-entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ent-cross}) with another probability distribution – with equality only if the distributions are identical –,

\begin{equation} \label{eq:kl-nonneg-Gibbs-ineq}
- \sum_{i=1}^n p(x_i) \, \log p(x_i) \leq - \sum_{i=1}^n p(x_i) \, \log q(x_i)
\end{equation}

which can be reformulated into

\begin{equation} \label{eq:kl-nonneg-Gibbs-ineq-dev}
\sum_{i=1}^n p(x_i) \, \log p(x_i) - \sum_{i=1}^n p(x_i) \, \log q(x_i) \geq 0 \; .
\end{equation}

Applying \eqref{eq:kl-nonneg-Gibbs-ineq-dev} to \eqref{eq:kl-nonneg-KL-dev}, this proves equation \eqref{eq:kl-nonneg-KL-nonneg}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Kullback-Leibler divergence"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-05-31; URL: \url{https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence#Properties}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P117 | shortcut: kl-nonneg | author: JoramSoch | date: 2020-05-31, 23:43.
\vspace{1em}



\subsubsection[\textbf{Non-symmetry}]{Non-symmetry} \label{sec:kl-nonsymm}
\setcounter{equation}{0}

\textbf{Theorem:}  The Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) is non-symmetric, i.e.

\begin{equation} \label{eq:kl-nonsymm-KL-nonsymm}
\mathrm{KL}[P||Q] \neq \mathrm{KL}[Q||P]
\end{equation}

for some [probability distributions](dist) $P$ and $Q$.


\vspace{1em}
\textbf{Proof:} Let $X \in \mathcal{X} = \left\lbrace 0, 1, 2 \right\rbrace$ be a discrete random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) and consider the two [probability distributions](dist)

\begin{equation} \label{eq:kl-nonsymm-P-Q}
\begin{split}
P : \, X &\sim \mathrm{Bin}(2, 0.5) \\
Q : \, X &\sim \mathcal{U}(0, 2)
\end{split}
\end{equation}

where $\mathrm{Bin}(n, p)$ indicates a binomial distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:bin}) and $\mathcal{U}(a, b)$ indicates a discrete uniform distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:duni}).

Then, the probability mass function of the binomial distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:bin-pmf}) entails that

\begin{equation} \label{eq:kl-nonsymm-p(x)}
p(x) = \left\{
\begin{array}{rl}
1/4 \; , & \text{if} \; x = 0 \\
1/2 \; , & \text{if} \; x = 1 \\
1/4 \; , & \text{if} \; x = 2
\end{array}
\right.
\end{equation}

and the probability mass function of the discrete uniform distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:duni-pmf}) entails that

\begin{equation} \label{eq:kl-nonsymm-q(x)}
q(x) = \frac{1}{3} \; ,
\end{equation}

such that the Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) of $P$ from $Q$ is

\begin{equation} \label{eq:kl-nonsymm-KL-P-Q}
\begin{split}
\mathrm{KL}[P||Q] &= \sum_{x \in \mathcal{X}} p(x) \cdot \log \frac{p(x)}{q(x)} \\
&= \frac{1}{4} \log \frac{3}{4} + \frac{1}{2} \log \frac{3}{2} + \frac{1}{4} \log \frac{3}{4} \\
&= \frac{1}{2} \log \frac{3}{4} + \frac{1}{2} \log \frac{3}{2} \\
&= \frac{1}{2} \left( \log \frac{3}{4} + \log \frac{3}{2} \right) \\
&= \frac{1}{2} \log \left( \frac{3}{4} \cdot \frac{3}{2} \right) \\
&= \frac{1}{2} \log \frac{9}{8} = 0.0589
\end{split}
\end{equation}

and the Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) of $Q$ from $P$ is

\begin{equation} \label{eq:kl-nonsymm-KL-Q-P}
\begin{split}
\mathrm{KL}[Q||P] &= \sum_{x \in \mathcal{X}} q(x) \cdot \log \frac{q(x)}{p(x)} \\
&= \frac{1}{3} \log \frac{4}{3} + \frac{1}{3} \log \frac{2}{3} + \frac{1}{3} \log \frac{4}{3} \\
&= \frac{1}{3} \left( \log \frac{4}{3} + \log \frac{2}{3} + \log \frac{4}{3} \right) \\
&= \frac{1}{3} \log \left( \frac{4}{3} \cdot \frac{2}{3} \cdot \frac{4}{3} \right) \\
&= \frac{1}{3} \log \frac{32}{27} = 0.0566
\end{split}
\end{equation}

which provides an example for

\begin{equation} \label{eq:kl-nonsymm-KL-nonsymm-qed}
\mathrm{KL}[P||Q] \neq \mathrm{KL}[Q||P]
\end{equation}

and thus proves the theorem.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Kullback, Solomon (1959): "Divergence"; in: \textit{Information Theory and Statistics}, ch. 1.3, pp. 6ff.; URL: \url{http://index-of.co.uk/Information-Theory/Information%20theory%20and%20statistics%20-%20Solomon%20Kullback.pdf}.
\item Wikipedia (2020): "Kullback-Leibler divergence"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-08-11; URL: \url{https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence#Basic_example}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P147 | shortcut: kl-nonsymm | author: JoramSoch | date: 2020-08-11, 06:57.
\vspace{1em}



\subsubsection[\textbf{Convexity}]{Convexity} \label{sec:kl-conv}
\setcounter{equation}{0}

\textbf{Theorem:}  The Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) is convex in the pair of probability distributions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist}) $(p,q)$, i.e.

\begin{equation} \label{eq:kl-conv-KL-conv}
\mathrm{KL}[\lambda p_1 + (1-\lambda) p_2||\lambda q_1 + (1-\lambda) q_2] \leq \lambda \mathrm{KL}[p_1||q_1] + (1-\lambda) \mathrm{KL}[p_2||q_2]
\end{equation}

where $(p_1,q_1)$ and $(p_2,q_2)$ are two pairs of probability distributions and $0 \leq \lambda \leq 1$.


\vspace{1em}
\textbf{Proof:} The Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) of $P$ from $Q$ is defined as

\begin{equation} \label{eq:kl-conv-KL}
\mathrm{KL}[P||Q] = \sum_{x \in \mathcal{X}} p(x) \cdot \log \frac{p(x)}{q(x)}
\end{equation}

and the log sum inequality ($\rightarrow$ Proof "logsum-ineq") states that

\begin{equation} \label{eq:kl-conv-logsum-ineq}
\sum_{i=1}^n a_i \log \frac{a_i}{b_i} \geq \left( \sum_{i=1}^n a_i \right) \log \frac{\sum_{i=1}^n a_i}{\sum_{i=1}^n b_i}
\end{equation}

where $a_1, \ldots, a_n$ and $b_1, \ldots, b_n$ are non-negative real numbers.

Thus, we can rewrite the KL divergence of the mixture distribution as

\begin{equation} \label{eq:kl-conv-KL-conv-qed}
\begin{split}
&\mathrm{KL}[\lambda p_1 + (1-\lambda) p_2||\lambda q_1 + (1-\lambda) q_2] \\
\overset{\eqref{eq:kl-conv-KL}}{=} &\sum_{x \in \mathcal{X}} \left[ \left[ \lambda p_1(x) + (1-\lambda) p_2(x) \right] \cdot \log \frac{\lambda p_1(x) + (1-\lambda) p_2(x)}{\lambda q_1(x) + (1-\lambda) q_2(x)} \right] \\
\overset{\eqref{eq:kl-conv-logsum-ineq}}{\leq} &\sum_{x \in \mathcal{X}} \left[ \lambda p_1(x) \cdot \log \frac{\lambda p_1(x)}{\lambda q_1(x)} + (1-\lambda) p_2(x) \cdot \log \frac{(1-\lambda) p_2(x)}{(1-\lambda) q_2(x)} \right] \\
= &\lambda \sum_{x \in \mathcal{X}} p_1(x) \cdot \log \frac{p_1(x)}{q_1(x)} + (1-\lambda) \sum_{x \in \mathcal{X}} p_2(x) \cdot \log \frac{p_2(x)}{q_2(x)} \\
\overset{\eqref{eq:kl-conv-KL}}{=} &\lambda \, \mathrm{KL}[p_1||q_1] + (1-\lambda) \, \mathrm{KL}[p_2||q_2]
\end{split}
\end{equation}

which is equivalent to \eqref{eq:kl-conv-KL-conv}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Kullback-Leibler divergence"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-08-11; URL: \url{https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence#Properties}.
\item Xie, Yao (2012): "Chain Rules and Inequalities"; in: \textit{ECE587: Information Theory}, Lecture 3, Slides 22/24; URL: \url{https://www2.isye.gatech.edu/~yxie77/ece587/Lecture3.pdf}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P148 | shortcut: kl-conv | author: JoramSoch | date: 2020-08-11, 07:30.
\vspace{1em}



\subsubsection[\textbf{Additivity for independent distributions}]{Additivity for independent distributions} \label{sec:kl-add}
\setcounter{equation}{0}

\textbf{Theorem:} The Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) is additive for independent distributions, i.e.

\begin{equation} \label{eq:kl-add-KL-add}
\mathrm{KL}[P||Q] = \mathrm{KL}[P_1||Q_1] + \mathrm{KL}[P_2||Q_2]
\end{equation}

where $P_1$ and $P_2$ are independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}) distributions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist}) with the joint distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-joint}) $P$, such that $p(x,y) = p_1(x) \, p_2(y)$, and equivalently for $Q_1$, $Q_2$ and $Q$.


\vspace{1em}
\textbf{Proof:} The continuous Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) is defined as

\begin{equation} \label{eq:kl-add-KL}
\mathrm{KL}[P||Q] = \int_{\mathcal{X}} p(x) \cdot \log \frac{p(x)}{q(x)} \, \mathrm{d}x
\end{equation}

which, applied to the joint distributions $P$ and $Q$, yields

\begin{equation} \label{eq:kl-add-KL-s1}
\mathrm{KL}[P||Q] = \int_{\mathcal{X}} \int_{\mathcal{Y}} p(x,y) \cdot \log \frac{p(x,y)}{q(x,y)} \, \mathrm{d}y \, \mathrm{d}x \; .
\end{equation}

Applying $p(x,y) = p_1(x) \, p_2(y)$ and $q(x,y) = q_1(x) \, q_2(y)$, we have

\begin{equation} \label{eq:kl-add-KL-s2}
\mathrm{KL}[P||Q] = \int_{\mathcal{X}} \int_{\mathcal{Y}} p_1(x) \, p_2(y) \cdot \log \frac{p_1(x) \, p_2(y)}{q_1(x) \, q_2(y)} \, \mathrm{d}y \, \mathrm{d}x \; .
\end{equation}

Now we can separate the logarithm and evaluate the integrals:

\begin{equation} \label{eq:kl-add-KL-qed}
\begin{split}
\mathrm{KL}[P||Q] &= \int_{\mathcal{X}} \int_{\mathcal{Y}} p_1(x) \, p_2(y) \cdot \left( \log \frac{p_1(x)}{q_1(x)} + \log \frac{p_2(y)}{q_2(y)} \right) \, \mathrm{d}y \, \mathrm{d}x \\
&= \int_{\mathcal{X}} \int_{\mathcal{Y}} p_1(x) \, p_2(y) \cdot \log \frac{p_1(x)}{q_1(x)} \, \mathrm{d}y \, \mathrm{d}x + \int_{\mathcal{X}} \int_{\mathcal{Y}} p_1(x) \, p_2(y) \cdot \log \frac{p_2(y)}{q_2(y)} \, \mathrm{d}y \, \mathrm{d}x \\
&= \int_{\mathcal{X}} p_1(x) \cdot \log \frac{p_1(x)}{q_1(x)} \int_{\mathcal{Y}} p_2(y) \, \mathrm{d}y \, \mathrm{d}x + \int_{\mathcal{Y}} p_2(y) \cdot \log \frac{p_2(y)}{q_2(y)} \int_{\mathcal{X}} p_1(x) \, \mathrm{d}x \, \mathrm{d}y \\
&= \int_{\mathcal{X}} p_1(x) \cdot \log \frac{p_1(x)}{q_1(x)} \, \mathrm{d}x + \int_{\mathcal{Y}} p_2(y) \cdot \log \frac{p_2(y)}{q_2(y)} \, \mathrm{d}y \\
&\overset{\eqref{eq:kl-add-KL}}{=} \mathrm{KL}[P_1||Q_1] + \mathrm{KL}[P_2||Q_2] \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Kullback-Leibler divergence"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-05-31; URL: \url{https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence#Properties}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P116 | shortcut: kl-add | author: JoramSoch | date: 2020-05-31, 23:26.
\vspace{1em}



\subsubsection[\textbf{Invariance under parameter transformation}]{Invariance under parameter transformation} \label{sec:kl-inv}
\setcounter{equation}{0}

\textbf{Theorem:} The Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) is invariant under parameter transformation, i.e.

\begin{equation} \label{eq:kl-inv-KL-inv}
\mathrm{KL}[p(x)||q(x)] = \mathrm{KL}[p(y)||q(y)]
\end{equation}

where $y(x) = mx + n$ is an affine transformation of $x$ and $p(x)$ and $q(x)$ are the probability density functions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of the probability distributions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist}) $P$ and $Q$ on the continuous random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) $X$.


\vspace{1em}
\textbf{Proof:} The continuous Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) (KL divergence) is defined as

\begin{equation} \label{eq:kl-inv-KL}
\mathrm{KL}[p(x)||q(x)] = \int_{a}^{b} p(x) \cdot \log \frac{p(x)}{q(x)} \, \mathrm{d}x
\end{equation}

where $a = \mathrm{min}(\mathcal{X})$ and $b = \mathrm{max}(\mathcal{X})$ are the lower and upper bound of the possible outcomes $\mathcal{X}$ of $X$.

Due to the identity of the differentials

\begin{equation} \label{eq:kl-inv-diff}
\begin{split}
p(x) \, \mathrm{d}x &= p(y) \, \mathrm{d}y \\
q(x) \, \mathrm{d}x &= q(y) \, \mathrm{d}y
\end{split}
\end{equation}

which can be rearranged into

\begin{equation} \label{eq:kl-inv-diff-dev}
\begin{split}
p(x) &= p(y) \, \frac{\mathrm{d}y}{\mathrm{d}x} \\
q(x) &= q(y) \, \frac{\mathrm{d}y}{\mathrm{d}x} \; ,
\end{split}
\end{equation}

the KL divergence can be evaluated as follows:

\begin{equation} \label{eq:kl-inv-MDE-DCE}
\begin{split}
\mathrm{KL}[p(x)||q(x)] &= \int_{a}^{b} p(x) \cdot \log \frac{p(x)}{q(x)} \, \mathrm{d}x \\
&= \int_{y(a)}^{y(b)} p(y) \, \frac{\mathrm{d}y}{\mathrm{d}x} \cdot \log \left( \frac{p(y) \, \frac{\mathrm{d}y}{\mathrm{d}x}}{q(y) \, \frac{\mathrm{d}y}{\mathrm{d}x}} \right) \, \mathrm{d}x \\
&= \int_{y(a)}^{y(b)} p(y) \cdot \log \frac{p(y)}{q(y)} \, \mathrm{d}y \\
&= \mathrm{KL}[p(y)||q(y)] \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Kullback-Leibler divergence"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-05-27; URL: \url{https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence#Properties}.
\item shimao (2018): "KL divergence invariant to affine transformation?"; in: \textit{StackExchange CrossValidated}, retrieved on 2020-05-28; URL: \url{https://stats.stackexchange.com/questions/341922/kl-divergence-invariant-to-affine-transformation}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P115 | shortcut: kl-inv | author: JoramSoch | date: 2020-05-28, 00:18.
\vspace{1em}



\subsubsection[\textbf{Relation to discrete entropy}]{Relation to discrete entropy} \label{sec:kl-ent}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a discrete random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with possible outcomes $\mathcal{X}$ and let $P$ and $Q$ be two probability distributions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist}) on $X$. Then, the Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) of $P$ from $Q$ can be expressed as

\begin{equation} \label{eq:kl-ent-kl-ent}
\mathrm{KL}[P||Q] = \mathrm{H}(P,Q) - \mathrm{H}(P)
\end{equation}

where $\mathrm{H}(P,Q)$ is the cross-entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ent-cross}) of $P$ and $Q$ and $\mathrm{H}(P)$ is the marginal entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ent}) of $P$.


\vspace{1em}
\textbf{Proof:} The discrete Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) is defined as

\begin{equation} \label{eq:kl-ent-KL}
\mathrm{KL}[P||Q] = \sum_{x \in \mathcal{X}} p(x) \cdot \log \frac{p(x)}{q(x)}
\end{equation}

where $p(x)$ and $q(x)$ are the probability mass functions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) of $P$ and $Q$.

Separating the logarithm, we have:

\begin{equation} \label{eq:kl-ent-KL-dev}
\mathrm{KL}[P||Q] = - \sum_{x \in \mathcal{X}} p(x) \, \log q(x) + \sum_{x \in \mathcal{X}} p(x) \, \log p(x) \; .
\end{equation}

Now considering the definitions of marginal entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ent}) and cross-entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ent-cross})

\begin{equation} \label{eq:kl-ent-ME-CE}
\begin{split}
\mathrm{H}(P) &= - \sum_{x \in \mathcal{X}} p(x) \, \log p(x) \\
\mathrm{H}(P,Q) &= - \sum_{x \in \mathcal{X}} p(x) \, \log q(x) \; ,
\end{split}
\end{equation}

we can finally show:

\begin{equation} \label{eq:kl-ent-KL-qed}
\mathrm{KL}[P||Q] = \mathrm{H}(P,Q) - \mathrm{H}(P) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Kullback-Leibler divergence"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-05-27; URL: \url{https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence#Motivation}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P113 | shortcut: kl-ent | author: JoramSoch | date: 2020-05-27, 23:20.
\vspace{1em}



\subsubsection[\textbf{Relation to differential entropy}]{Relation to differential entropy} \label{sec:kl-dent}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a continuous random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) with possible outcomes $\mathcal{X}$ and let $P$ and $Q$ be two probability distributions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist}) on $X$. Then, the Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) of $P$ from $Q$ can be expressed as

\begin{equation} \label{eq:kl-dent-kl-dent}
\mathrm{KL}[P||Q] = \mathrm{h}(P,Q) - \mathrm{h}(P)
\end{equation}

where $\mathrm{h}(P,Q)$ is the differential cross-entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent-cross}) of $P$ and $Q$ and $\mathrm{h}(P)$ is the marginal differential entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent}) of $P$.


\vspace{1em}
\textbf{Proof:} The continuous Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) is defined as

\begin{equation} \label{eq:kl-dent-KL}
\mathrm{KL}[P||Q] = \int_{\mathcal{X}} p(x) \cdot \log \frac{p(x)}{q(x)} \, \mathrm{d}x
\end{equation}

where $p(x)$ and $q(x)$ are the probability density functions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $P$ and $Q$.

Separating the logarithm, we have:

\begin{equation} \label{eq:kl-dent-KL-dev}
\mathrm{KL}[P||Q] = - \int_{\mathcal{X}} p(x) \, \log q(x) \, \mathrm{d}x + \int_{\mathcal{X}} p(x) \, \log p(x) \, \mathrm{d}x \; .
\end{equation}

Now considering the definitions of marginal differential entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent}) and differential cross-entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent-cross})

\begin{equation} \label{eq:kl-dent-MDE-DCE}
\begin{split}
\mathrm{h}(P) &= - \int_{\mathcal{X}} p(x) \, \log p(x) \, \mathrm{d}x \\
\mathrm{h}(P,Q) &= - \int_{\mathcal{X}} p(x) \, \log q(x) \, \mathrm{d}x \; ,
\end{split}
\end{equation}

we can finally show:

\begin{equation} \label{eq:kl-dent-KL-qed}
\mathrm{KL}[P||Q] = \mathrm{h}(P,Q) - \mathrm{h}(P) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Kullback-Leibler divergence"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-05-27; URL: \url{https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence#Motivation}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P114 | shortcut: kl-dent | author: JoramSoch | date: 2020-05-27, 23:32.
\vspace{1em}



\pagebreak
\section{Estimation theory}

\subsection{Point estimates}

\subsubsection[\textbf{Partition of the mean squared error into bias and variance}]{Partition of the mean squared error into bias and variance} \label{sec:mse-bnv}
\setcounter{equation}{0}

\textbf{Theorem:} The mean squared error ($\rightarrow$ Definition "mse") can be partitioned into variance and squared bias

\begin{equation} \label{eq:mse-bnv-MSE}
\mathrm{MSE}(\hat{\theta}) = \mathrm{Var}(\hat{\theta}) - \mathrm{Bias}(\hat{\theta},\theta)^2
\end{equation}

where the variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) is given by

\begin{equation} \label{eq:mse-bnv-Var}
\mathrm{Var}(\hat{\theta}) = \mathbb{E}_{\hat{\theta}}\left[ \left( \hat{\theta} - \mathbb{E}_{\hat{\theta}}(\hat{\theta}) \right)^2 \right]
\end{equation}

and the bias ($\rightarrow$ Definition "bias") is given by

\begin{equation} \label{eq:mse-bnv-Bias}
\mathrm{Bias}(\hat{\theta},\theta) = \left( \mathbb{E}_{\hat{\theta}}(\hat{\theta}) - \theta \right) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The mean squared error (MSE) is defined as ($\rightarrow$ Definition "mse") the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of the squared deviation of the estimated value $\hat{\theta}$ from the true value $\theta$ of a parameter, over all values $\hat{\theta}$:

\begin{equation} \label{eq:mse-bnv-MSE-def}
\mathrm{MSE}(\hat{\theta}) = \mathbb{E}_{\hat{\theta}}\left[ \left( \hat{\theta} - \theta \right)^2 \right] \; .
\end{equation}

This formula can be evaluated in the following way:

\begin{equation} \label{eq:mse-bnv-MSE-ref1}
\begin{split}
\mathrm{MSE}(\hat{\theta}) &= \mathbb{E}_{\hat{\theta}}\left[ \left( \hat{\theta} - \theta \right)^2 \right] \\
&= \mathbb{E}_{\hat{\theta}}\left[ \left( \hat{\theta} - \mathbb{E}_{\hat{\theta}}(\hat{\theta}) + \mathbb{E}_{\hat{\theta}}(\hat{\theta}) - \theta \right)^2 \right] \\
&= \mathbb{E}_{\hat{\theta}}\left[ \left( \hat{\theta} - \mathbb{E}_{\hat{\theta}}(\hat{\theta}) \right)^2 + 2 \left( \hat{\theta} - \mathbb{E}_{\hat{\theta}}(\hat{\theta}) \right) \left( \mathbb{E}_{\hat{\theta}}(\hat{\theta}) - \theta \right) + \left( \mathbb{E}_{\hat{\theta}}(\hat{\theta}) - \theta \right)^2 \right] \\
&= \mathbb{E}_{\hat{\theta}}\left[ \left( \hat{\theta} - \mathbb{E}_{\hat{\theta}}(\hat{\theta}) \right)^2 \right] + \mathbb{E}_{\hat{\theta}}\left[ 2 \left( \hat{\theta} - \mathbb{E}_{\hat{\theta}}(\hat{\theta}) \right) \left( \mathbb{E}_{\hat{\theta}}(\hat{\theta}) - \theta \right) \right] + \mathbb{E}_{\hat{\theta}}\left[ \left( \mathbb{E}_{\hat{\theta}}(\hat{\theta}) - \theta \right)^2 \right] \; . \\
\end{split}
\end{equation}

Because $\mathbb{E}_{\hat{\theta}}(\hat{\theta}) - \theta$ is constant as a function of $\hat{\theta}$, we have:

\begin{equation} \label{eq:mse-bnv-MSE-ref2}
\begin{split}
\mathrm{MSE}(\hat{\theta}) &= \mathbb{E}_{\hat{\theta}}\left[ \left( \hat{\theta} - \mathbb{E}_{\hat{\theta}}(\hat{\theta}) \right)^2 \right] + 2  \left( \mathbb{E}_{\hat{\theta}}(\hat{\theta}) - \theta \right) \mathbb{E}_{\hat{\theta}}\left[ \hat{\theta} - \mathbb{E}_{\hat{\theta}}(\hat{\theta}) \right] + \left( \mathbb{E}_{\hat{\theta}}(\hat{\theta}) - \theta \right)^2 \\
&= \mathbb{E}_{\hat{\theta}}\left[ \left( \hat{\theta} - \mathbb{E}_{\hat{\theta}}(\hat{\theta}) \right)^2 \right] + 2  \left( \mathbb{E}_{\hat{\theta}}(\hat{\theta}) - \theta \right) \left( \mathbb{E}_{\hat{\theta}}(\hat{\theta}) - \mathbb{E}_{\hat{\theta}}(\hat{\theta}) \right) + \left( \mathbb{E}_{\hat{\theta}}(\hat{\theta}) - \theta \right)^2 \\
&= \mathbb{E}_{\hat{\theta}}\left[ \left( \hat{\theta} - \mathbb{E}_{\hat{\theta}}(\hat{\theta}) \right)^2 \right] + \left( \mathbb{E}_{\hat{\theta}}(\hat{\theta}) - \theta \right)^2 \; . \\
\end{split}
\end{equation}

This proofs the partition given by \eqref{eq:mse-bnv-MSE}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2019): "Mean squared error"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2019-11-27; URL: \url{https://en.wikipedia.org/wiki/Mean_squared_error#Proof_of_variance_and_bias_relationship}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P5 | shortcut: mse-bnv | author: JoramSoch | date: 2019-11-27, 14:26.
\vspace{1em}



\subsection{Interval estimates}

\subsubsection[\textbf{Construction of confidence intervals using Wilks' theorem}]{Construction of confidence intervals using Wilks' theorem} \label{sec:ci-wilks}
\setcounter{equation}{0}

\textbf{Theorem:} Let $m$ be a generative model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) for measured data $y$ with model parameters $\theta$, consisting of a parameter of interest $\phi$ and nuisance parameters $\lambda$:

\begin{equation} \label{eq:ci-wilks-mod-par}
m: p(y|\theta) = \mathcal{D}(y; \theta), \quad \theta = \left\lbrace \phi, \lambda \right\rbrace \; .
\end{equation}

Further, let $\hat{\theta}$ be an estimate of $\theta$, obtained using maximum-likelihood-estimation ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mle}):

\begin{equation} \label{eq:ci-wilks-theta-mle}
\hat{\theta} = \operatorname*{arg\,max}_{\theta} \log p(y|\theta), \quad \hat{\theta} = \left\lbrace \hat{\phi}, \hat{\lambda} \right\rbrace \; .
\end{equation}

Then, an asymptotic confidence interval ($\rightarrow$ Definition "ci") for $\theta$ is given by

\begin{equation} \label{eq:ci-wilks-ci-wilks}
\mathrm{CI}_{1-\alpha}(\hat{\phi}) = \left\lbrace \phi \, \vert \, \log p(y|\phi,\hat{\lambda}) \geq \log p(y|\hat{\phi},\hat{\lambda}) - \frac{1}{2} \chi^2_{1,1-\alpha} \right\rbrace
\end{equation}

where $1-\alpha$ is the confidence level and $\chi^2_{1,1-\alpha}$ is the $(1-\alpha)$-quantile of the chi-squared distribution ($\rightarrow$ Definition "chi2") with 1 degree of freedom ($\rightarrow$ Definition "dof").


\vspace{1em}
\textbf{Proof:} The confidence interval ($\rightarrow$ Definition "ci") is defined as the interval that, under infinitely repeated random experiments ($\rightarrow$ Definition "rexp"), contains the true parameter value with a certain probability.

Let us define the likelihood ratio ($\rightarrow$ Definition "lr")

\begin{equation} \label{eq:ci-wilks-lr}
\Lambda(\phi) = \frac{p(y|\phi,\hat{\lambda})}{p(y|\hat{\phi},\hat{\lambda})}
\end{equation}

and compute the log-likelihood ratio ($\rightarrow$ Definition "llr")

\begin{equation} \label{eq:ci-wilks-llr}
\log \Lambda(\phi) = \log p(y|\phi,\hat{\lambda}) - \log p(y|\hat{\phi},\hat{\lambda}) \; .
\end{equation}

[Wilks' theorem](llr-wilks) states that, when comparing two statistical models with parameter spaces $\Theta_1$ and $\Theta_0 \subset \Theta_1$, as the sample size approaches infinity, the quantity calculated as $-2$ times the log-ratio of maximum likelihoods follows a chi-squared distribution ($\rightarrow$ Definition "chi2"), if the null hypothesis is true:

\begin{equation} \label{eq:ci-wilks-wilks}
H_0: \theta \in \Theta_0 \quad \Rightarrow \quad -2 \log \frac{\operatorname*{max}_{\theta \in \Theta_0} p(y|\theta)}{\operatorname*{max}_{\theta \in \Theta_1} p(y|\theta)} \sim \chi^2_{\Delta k}
\end{equation}

where $\Delta k$ is the difference in dimensionality between $\Theta_0$ and $\Theta_1$. Applied to our example in \eqref{eq:ci-wilks-llr}, we note that $\Theta_1 = \left\lbrace \phi, \hat{\phi} \right\rbrace$ and $\Theta_0 = \left\lbrace \phi \right\rbrace$, such that $\Delta k = 1$ and Wilks' theorem implies:

\begin{equation} \label{eq:ci-wilks-llr-wilks}
-2 \log \Lambda(\phi) \sim  \chi^2_1 \; .
\end{equation}

Using the quantile function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:qf}) $\chi^2_{k,p}$ of the chi-squared distribution ($\rightarrow$ Definition "chi2"), an $(1-\alpha)$-confidence interval is therefore given by all values $\phi$ that satisfy

\begin{equation} \label{eq:ci-wilks-llr-chi2}
-2 \log \Lambda(\phi) \leq \chi^2_{1,1-\alpha} \; .
\end{equation}

Applying \eqref{eq:ci-wilks-llr} and rearranging, we can evaluate

\begin{equation} \label{eq:ci-wilks-llr-chi2-dev}
\begin{split}
-2 \left[ \log p(y|\phi,\hat{\lambda}) - \log p(y|\hat{\phi},\hat{\lambda}) \right] &\leq \chi^2_{1,1-\alpha} \\
\log p(y|\phi,\hat{\lambda}) - \log p(y|\hat{\phi},\hat{\lambda}) &\geq -\frac{1}{2} \chi^2_{1,1-\alpha} \\
\log p(y|\phi,\hat{\lambda}) &\geq \log p(y|\hat{\phi},\hat{\lambda}) - \frac{1}{2} \chi^2_{1,1-\alpha}
\end{split}
\end{equation}

which is equivalent to the confidence interval given by \eqref{eq:ci-wilks-ci-wilks}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Confidence interval"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-02-19; URL: \url{https://en.wikipedia.org/wiki/Confidence_interval#Methods_of_derivation}.
\item Wikipedia (2020): "Likelihood-ratio test"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-02-19; URL: \url{https://en.wikipedia.org/wiki/Likelihood-ratio_test#Definition}.
\item Wikipedia (2020): "Wilks' theorem"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-02-19; URL: \url{https://en.wikipedia.org/wiki/Wilks%27_theorem}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P56 | shortcut: ci-wilks | author: JoramSoch | date: 2020-02-19, 17:15.
\vspace{1em}



\pagebreak
\section{Frequentist statistics}

\subsection{Likelihood theory}

\subsubsection[\textit{Likelihood function}]{Likelihood function} \label{sec:lf}
\setcounter{equation}{0}

\textbf{Definition:} Let there be a generative model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) $m$ describing measured data $y$ using model parameters $\theta$. Then, the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of the distribution of $y$ given $\theta$ is called the likelihood function of $m$:

\begin{equation} \label{eq:lf-lf}
\mathcal{L}_m(\theta) = p(y|\theta,m) = \mathcal{D}(y; \theta) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D28 | shortcut: lf | author: JoramSoch | date: 2020-03-03, 15:50.
\vspace{1em}



\subsubsection[\textit{Log-likelihood function}]{Log-likelihood function} \label{sec:llf}
\setcounter{equation}{0}

\textbf{Definition:} Let there be a generative model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) $m$ describing measured data $y$ using model parameters $\theta$. Then, the logarithm of the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of the distribution of $y$ given $\theta$ is called the log-likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) of $m$:

\begin{equation} \label{eq:llf-llf}
\mathrm{LL}_m(\theta) = \log p(y|\theta,m) = \log \mathcal{D}(y; \theta) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D59 | shortcut: llf | author: JoramSoch | date: 2020-05-17, 22:52.
\vspace{1em}



\subsubsection[\textit{Maximum likelihood estimation}]{Maximum likelihood estimation} \label{sec:mle}
\setcounter{equation}{0}

\textbf{Definition:} Let there be a generative model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) $m$ describing measured data $y$ using model parameters $\theta$. Then, the parameter values maximizing the likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) or log-likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:llf}) are called maximum likelihood estimates of $\theta$:

\begin{equation} \label{eq:mle-mle}
\hat{\theta} = \operatorname*{arg\,max}_\theta \mathcal{L}_m(\theta) = \operatorname*{arg\,max}_\theta \mathrm{LL}_m(\theta) \; .
\end{equation}

The process of calculating $\hat{\theta}$ is called "maximum likelihood estimation" and the functional form leading from $y$ to $\hat{\theta}$ given $m$ is called "maximum likelihood estimator". Maximum likelihood estimation, estimator and estimates may all be abbreviated as "MLE".


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D60 | shortcut: mle | author: JoramSoch | date: 2020-05-15, 23:05.
\vspace{1em}



\subsubsection[\textit{Maximum log-likelihood}]{Maximum log-likelihood} \label{sec:mll}
\setcounter{equation}{0}

\textbf{Definition:} Let there be a generative model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) $m$ describing measured data $y$ using model parameters $\theta$. Then, the maximum log-likelihood (MLL) of $m$ is the maximal value of the log-likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:llf}) of this model:

\begin{equation} \label{eq:mll-mll}
\mathrm{MLL}(m) = \operatorname*{max}_\theta \mathrm{LL}_m(\theta) \; .
\end{equation}

The maximum log-likelihood can be obtained by plugging the maximum likelihood estimates ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mle}) into the log-likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:llf}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D61 | shortcut: mll | author: JoramSoch | date: 2020-05-15, 23:13.
\vspace{1em}



\pagebreak
\section{Bayesian statistics}

\subsection{Probabilistic modeling}

\subsubsection[\textit{Generative model}]{Generative model} \label{sec:gm}
\setcounter{equation}{0}

\textbf{Definition:} Consider measured data $y$ and some unknown latent parameters $\theta$. A statement about the distribution of $y$ given $\theta$ is called a generative model $m$:

\begin{equation} \label{eq:gm-gm}
m: \, y \sim \mathcal{D}(\theta) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D27 | shortcut: gm | author: JoramSoch | date: 2020-03-03, 15:50.
\vspace{1em}



\subsubsection[\textit{Likelihood function}]{Likelihood function} \label{sec:lf}
\setcounter{equation}{0}

\textbf{Definition:} Let there be a generative model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) $m$ describing measured data $y$ using model parameters $\theta$. Then, the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of the distribution of $y$ given $\theta$ is called the likelihood function of $m$:

\begin{equation} \label{eq:lf-lf}
\mathcal{L}_m(\theta) = p(y|\theta,m) = \mathcal{D}(y; \theta) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D28 | shortcut: lf | author: JoramSoch | date: 2020-03-03, 15:50.
\vspace{1em}



\subsubsection[\textit{Prior distribution}]{Prior distribution} \label{sec:prior}
\setcounter{equation}{0}

\textbf{Definition:} Consider measured data $y$ and some unknown latent parameters $\theta$. A distribution of $\theta$ unconditional on $y$ is called a prior distribution:

\begin{equation} \label{eq:prior-prior}
\theta \sim \mathcal{D}(\lambda) \; .
\end{equation}

The parameters $\lambda$ of this distribution are called the prior hyperparameters and the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) is called the prior density:

\begin{equation} \label{eq:prior-prior-pdf}
p(\theta|m) = \mathcal{D}(\theta; \lambda) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D29 | shortcut: prior | author: JoramSoch | date: 2020-03-03, 16:09.
\vspace{1em}



\subsubsection[\textit{Full probability model}]{Full probability model} \label{sec:fpm}
\setcounter{equation}{0}

\textbf{Definition:} Consider measured data $y$ and some unknown latent parameters $\theta$. The combination of a generative model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) for $y$ and a prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) on $\theta$ is called a full probability model $m$:

\begin{equation} \label{eq:fpm-fpm}
m: \, y \sim \mathcal{D}(\theta), \, \theta \sim \mathcal{D}(\lambda) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D30 | shortcut: fpm | author: JoramSoch | date: 2020-03-03, 16:16.
\vspace{1em}



\subsubsection[\textit{Joint likelihood}]{Joint likelihood} \label{sec:jl}
\setcounter{equation}{0}

\textbf{Definition:} Let there be a generative model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) $m$ describing measured data $y$ using model parameters $\theta$ and a prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) on $\theta$. Then, the joint probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $y$ and $\theta$ is called the joint likelihood:

\begin{equation} \label{eq:jl-jl}
p(y,\theta|m) = p(y|\theta,m) \, p(\theta|m) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D31 | shortcut: jl | author: JoramSoch | date: 2020-03-03, 16:36.
\vspace{1em}



\subsubsection[\textbf{Joint likelihood is product of likelihood and prior}]{Joint likelihood is product of likelihood and prior} \label{sec:jl-lfnprior}
\setcounter{equation}{0}

\textbf{Theorem:} Let there be a generative model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) $m$ describing measured data $y$ using model parameters $\theta$ and a prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) on $\theta$. Then, the joint likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:jl}) is equal to the product of likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) and prior density ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}):

\begin{equation} \label{eq:jl-lfnprior-jl}
p(y,\theta|m) = p(y|\theta,m) \, p(\theta|m) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The joint likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:jl}) is defined as the joint probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of data $y$ and parameters $\theta$:

\begin{equation} \label{eq:jl-lfnprior-jl-def}
p(y,\theta|m) \; .
\end{equation}

Applying the law of conditional probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-cond}), we have:

\begin{equation} \label{eq:jl-lfnprior-jl-qed}
\begin{split}
p(y|\theta,m) &= \frac{p(y,\theta|m)}{p(\theta|m)} \\
&\Leftrightarrow \\
p(y,\theta|m) &= p(y|\theta,m) \, p(\theta|m) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P89 | shortcut: jl-lfnprior | author: JoramSoch | date: 2020-05-05, 04:21.
\vspace{1em}



\subsubsection[\textit{Posterior distribution}]{Posterior distribution} \label{sec:post}
\setcounter{equation}{0}

\textbf{Definition:} Consider measured data $y$ and some unknown latent parameters $\theta$. The distribution of $\theta$ conditional on $y$ is called the posterior distribution:

\begin{equation} \label{eq:post-post}
\theta|y \sim \mathcal{D}(\phi) \; .
\end{equation}

The parameters $\phi$ of this distribution are called the posterior hyperparameters and the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) is called the posterior density:

\begin{equation} \label{eq:post-prior-pdf}
p(\theta|y,m) = \mathcal{D}(\theta; \phi) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D32 | shortcut: post | author: JoramSoch | date: 2020-03-03, 16:43.
\vspace{1em}



\subsubsection[\textbf{Posterior density is proportional to joint likelihood}]{Posterior density is proportional to joint likelihood} \label{sec:post-jl}
\setcounter{equation}{0}

\textbf{Theorem:} In a full probability model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:fpm}) $m$ describing measured data $y$ using model parameters $\theta$, the posterior density ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) over the model parameters is proportional to the joint likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:jl}):

\begin{equation} \label{eq:post-jl-post}
p(\theta|y,m) \propto p(y,\theta|m) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} In a full probability model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:fpm}), the posterior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) can be expressed using Bayes' theorem ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:bayes-th}):

\begin{equation} \label{eq:post-jl-post-s1}
p(\theta|y,m) = \frac{p(y|\theta,m) \, p(\theta|m)}{p(y|m)} \; .
\end{equation}

Applying the law of conditional probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-cond}) to the numerator, we have:

\begin{equation} \label{eq:post-jl-post-s2}
p(\theta|y,m) = \frac{p(y,\theta|m)}{p(y|m)} \; .
\end{equation}

Because the denominator does not depend on $\theta$, it is constant in $\theta$ and thus acts a proportionality factor between the posterior distribution and the joint likelihood:

\begin{equation} \label{eq:post-jl-post-qed}
p(\theta|y,m) \propto p(y,\theta|m) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P90 | shortcut: post-jl | author: JoramSoch | date: 2020-05-05, 04:46.
\vspace{1em}



\subsubsection[\textit{Marginal likelihood}]{Marginal likelihood} \label{sec:ml}
\setcounter{equation}{0}

\textbf{Definition:} Let there be a generative model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) $m$ describing measured data $y$ using model parameters $\theta$ and a prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) on $\theta$. Then, the marginal probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}) density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $y$ across the parameter space $\Theta$ is called the marginal likelihood:

\begin{equation} \label{eq:ml-ml}
p(y|m) = \int_{\Theta} p(y|\theta,m) \, p(\theta|m) \, \mathrm{d}\theta \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D33 | shortcut: ml | author: JoramSoch | date: 2020-03-03, 16:49.
\vspace{1em}



\subsubsection[\textbf{Marginal likelihood is integral of joint likelihood}]{Marginal likelihood is integral of joint likelihood} \label{sec:ml-jl}
\setcounter{equation}{0}

\textbf{Theorem:} In a full probability model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:fpm}) $m$ describing measured data $y$ using model parameters $\theta$, the marginal likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ml}) is the integral of the joint likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:jl}) across the parameter space $\Theta$:

\begin{equation} \label{eq:ml-jl-ml}
p(y|m) = \int_{\Theta} p(y,\theta|m) \, \mathrm{d}\theta \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} In a full probability model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:fpm}), the marginal likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ml}) is defined as the marginal probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}) of the data $y$, given only the model $m$:

\begin{equation} \label{eq:ml-jl-ml-def}
p(y|m) \; .
\end{equation}

Using the law of marginal probabililty ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}), this can be obtained by integrating over the product of likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) and prior density ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}):

\begin{equation} \label{eq:ml-jl-ml-int}
p(y|m) = \int_{\Theta} p(y|\theta,m) \, p(\theta|m) \, \mathrm{d}\theta \; .
\end{equation}

Applying the law of conditional probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-cond}) to the integrand, we have:

\begin{equation} \label{eq:ml-jl-ml-qed}
p(y|m) = \int_{\Theta} p(y,\theta|m) \, \mathrm{d}\theta \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P91 | shortcut: ml-jl | author: JoramSoch | date: 2020-05-05, 04:59.
\vspace{1em}



\subsection{Bayesian inference}

\subsubsection[\textbf{Bayes' theorem}]{Bayes' theorem} \label{sec:bayes-th}
\setcounter{equation}{0}

\textbf{Theorem:} Let $A$ and $B$ be two arbitrary statements about random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}), such as statements about the presence or absence of an event or about the value of a scalar, vector or matrix. Then, the conditional probability that $A$ is true, given that $B$ is true, is equal to

\begin{equation} \label{eq:bayes-th-BT}
p(A|B) = \frac{p(B|A) \, p(A)}{p(B)} \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The conditional probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-cond}) is defined as the ratio of joint probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}), i.e. the probability of both statements being true, and marginal probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}), i.e. the probability of only the second one being true:

\begin{equation} \label{eq:bayes-th-LCP}
p(A|B) = \frac{p(A,B)}{p(B)} \; .
\end{equation}

It can also be written down for the reverse situation, i.e. to calculate the probability that $B$ is true, given that $A$ is true:

\begin{equation} \label{eq:bayes-th-LCP-rev}
p(B|A) = \frac{p(A,B)}{p(A)} \; .
\end{equation}

Both equations can be rearranged for the joint probability

\begin{equation} \label{eq:bayes-th-JP}
p(A|B) \, p(B) \overset{\eqref{eq:bayes-th-LCP}}{=} p(A,B) \overset{\eqref{eq:bayes-th-LCP-rev}}{=} p(B|A) \, p(A)
\end{equation}

from which Bayes' theorem can be directly derived:

\begin{equation} \label{eq:bayes-th-BT-proof}
p(A|B) \overset{\eqref{eq:bayes-th-JP}}{=} \frac{p(B|A) \, p(A)}{p(B)} \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Koch, Karl-Rudolf (2007): "Rules of Probability"; in: \textit{Introduction to Bayesian Statistics}, Springer, Berlin/Heidelberg, 2007, pp. 6/13, eqs. 2.12/2.38; URL: \url{https://www.springer.com/de/book/9783540727231}; DOI: 10.1007/978-3-540-72726-2.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P4 | shortcut: bayes-th | author: JoramSoch | date: 2019-09-27, 16:24.
\vspace{1em}



\subsubsection[\textbf{Bayes' rule}]{Bayes' rule} \label{sec:bayes-rule}
\setcounter{equation}{0}

\textbf{Theorem:} Let $A_1$, $A_2$ and $B$ be arbitrary statements about random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) where $A_1$ and $A_2$ are mutually exclusive. Then, Bayes' rule states that the posterior odds ($\rightarrow$ Definition "post-odd") are equal to the Bayes factor ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lbf}) times the prior odds ($\rightarrow$ Definition "prior-odd"), i.e.

\begin{equation} \label{eq:bayes-rule-bayes-rule}
\frac{p(A_1|B)}{p(A_2|B)} = \frac{p(B|A_1)}{p(B|A_2)} \cdot \frac{p(A_1)}{p(A_2)} \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} Using Bayes' theorem ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:bayes-th}), the conditional probabilities ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-cond}) on the left are given by

\begin{equation} \label{eq:bayes-rule-bayes-th-A1}
p(A_1|B) = \frac{p(B|A_1) \cdot p(A_1)}{p(B)}
\end{equation}

\begin{equation} \label{eq:bayes-rule-bayes-th-A2}
p(A_2|B) = \frac{p(B|A_2) \cdot p(A_2)}{p(B)} \; .
\end{equation}

Dividing the two conditional probabilities by each other

\begin{equation} \label{eq:bayes-rule-bayes-rule-qed}
\begin{split}
\frac{p(A_1|B)}{p(A_2|B)} &= \frac{p(B|A_1) \cdot p(A_1) / p(B)}{p(B|A_2) \cdot p(A_2) / p(B)} \\
&= \frac{p(B|A_1)}{p(B|A_2)} \cdot \frac{p(A_1)}{p(A_2)} \; ,
\end{split}
\end{equation}

one obtains the posterior odds ratio as given by the theorem.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2019): "Bayes' theorem"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-01-06; URL: \url{https://en.wikipedia.org/wiki/Bayes%27_theorem#Bayes%E2%80%99_rule}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P12 | shortcut: bayes-rule | author: JoramSoch | date: 2020-01-06, 20:55.
\vspace{1em}





% Chapter 2 %
\chapter{Probability Distributions} \label{sec:Probability Distributions} \newpage

\pagebreak
\section{Univariate discrete distributions}

\subsection{Discrete uniform distribution}

\subsubsection[\textit{Definition}]{Definition} \label{sec:duni}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a discrete random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}). Then, $X$ is said to be uniformly distributed with minimum $a$ and maximum $b$

\begin{equation} \label{eq:duni-duni}
X \sim \mathcal{U}(a, b) \; ,
\end{equation}

if and only if each integer between and including $a$ and $b$ occurs with the same probability.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Discrete uniform distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-07-28; URL: \url{https://en.wikipedia.org/wiki/Discrete_uniform_distribution}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D88 | shortcut: duni | author: JoramSoch | date: 2020-07-28, 04:05.
\vspace{1em}



\subsubsection[\textbf{Probability mass function}]{Probability mass function} \label{sec:duni-pmf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a discrete uniform distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:duni}):

\begin{equation} \label{eq:duni-pmf-duni}
X \sim \mathcal{U}(a, b) \; .
\end{equation}

Then, the probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) of $X$ is

\begin{equation} \label{eq:duni-pmf-duni-pmf}
f_X(x) = \frac{1}{b-a+1} \quad \text{where} \quad x \in \left\lbrace a, a+1, \ldots, b-1, b \right\rbrace \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} A discrete uniform variable is defined as ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:duni}) having the same probability for each integer between and including $a$ and $b$. The number of integers between and including $a$ and $b$ is

\begin{equation} \label{eq:duni-pmf-n}
n = b - a + 1
\end{equation}

and because the sum across all probabilities ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) is

\begin{equation} \label{eq:duni-pmf-1}
\sum_{x=a}^{b} f_X(x) = 1 \; ,
\end{equation}

we have

\begin{equation} \label{eq:duni-pmf-duni-pmf-qed}
f_X(x) = \frac{1}{n} = \frac{1}{b-a+1} \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P140 | shortcut: duni-pmf | author: JoramSoch | date: 2020-07-28, 04:57.
\vspace{1em}



\subsubsection[\textbf{Cumulative distribution function}]{Cumulative distribution function} \label{sec:duni-cdf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a discrete uniform distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:duni}):

\begin{equation} \label{eq:duni-cdf-duni}
X \sim \mathcal{U}(a, b) \; .
\end{equation}

Then, the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) of $X$ is

\begin{equation} \label{eq:duni-cdf-duni-cdf}
F_X(x) = \left\{
\begin{array}{rl}
0 \; , & \text{if} \; x < a \\
\frac{\left\lfloor{x}\right\rfloor - a + 1}{b - a + 1} \; , & \text{if} \; a \leq x \leq b \\
1 \; , & \text{if} \; x > b \; .
\end{array}
\right.
\end{equation}


\vspace{1em}
\textbf{Proof:} The probability mass function of the discrete uniform distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:duni-pmf}) is

\begin{equation} \label{eq:duni-cdf-duni-pmf}
\mathcal{U}(x; a, b) = \frac{1}{b-a+1} \quad \text{where} \quad x \in \left\lbrace a, a+1, \ldots, b-1, b \right\rbrace \; .
\end{equation}

Thus, the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) is:

\begin{equation} \label{eq:duni-cdf-duni-cdf-s1}
F_X(x) = \int_{-\infty}^{x} \mathcal{U}(z; a, b) \, \mathrm{d}z
\end{equation}

From \eqref{eq:duni-cdf-duni-pmf}, it follows that the cumulative probability increases step-wise by $1/n$ at each integer between and including $a$ and $b$ where

\begin{equation} \label{eq:duni-cdf-n}
n = b - a + 1
\end{equation}

is the number of integers between and including $a$ and $b$. This can be expressed by noting that

\begin{equation} \label{eq:duni-cdf-duni-cdf-s2b}
F_X(x) \overset{\eqref{eq:duni-cdf-duni-pmf}}{=} \frac{\left\lfloor{x}\right\rfloor - a + 1}{n}, \; \text{if} \; a \leq x \leq b \; .
\end{equation}

Also, because $\mathrm{Pr}(X < a) = 0$, we have

\begin{equation} \label{eq:duni-cdf-duni-cdf-s2a}
F_X(x) \overset{\eqref{eq:duni-cdf-duni-cdf-s1}}{=} \int_{-\infty}^{x} 0 \, \mathrm{d}z = 0, \; \text{if} \; x < a
\end{equation}

and because $\mathrm{Pr}(X > b) = 0$, we have

\begin{equation} \label{eq:duni-cdf-duni-cdf-s2c}
\begin{split}
F_X(x) &\overset{\eqref{eq:duni-cdf-duni-cdf-s1}}{=} \int_{-\infty}^{x} \mathcal{U}(z; a, b) \, \mathrm{d}z \\
&= \int_{-\infty}^{b} \mathcal{U}(z; a, b) \, \mathrm{d}z + \int_{b}^{x} \mathcal{U}(z; a, b) \, \mathrm{d}z \\
&= F_X(b) + \int_{b}^{x} 0 \, \mathrm{d}z \overset{\eqref{eq:duni-cdf-duni-cdf-s2b}}{=} 1 + 0 \\
&= 1, \; \text{if} \; x > b \; .
\end{split}
\end{equation}

This completes the proof.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P141 | shortcut: duni-cdf | author: JoramSoch | date: 2020-07-28, 05:34.
\vspace{1em}



\subsubsection[\textbf{Quantile function}]{Quantile function} \label{sec:duni-qf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a discrete uniform distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:duni}):

\begin{equation} \label{eq:duni-qf-duni}
X \sim \mathcal{U}(a, b) \; .
\end{equation}

Then, the quantile function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:qf}) of $X$ is

\begin{equation} \label{eq:duni-qf-duni-qf}
Q_X(p) = a (1-p) + (b+1) p - 1 \quad \text{where} \quad p \in \left\lbrace \frac{1}{n}, \frac{2}{n}, \ldots, \frac{b-a}{n}, 1 \right\rbrace
\end{equation}

with $n = b - a + 1$.


\vspace{1em}
\textbf{Proof:} The cumulative distribution function of the discrete uniform distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:duni-cdf}) is:

\begin{equation} \label{eq:duni-qf-duni-cdf}
F_X(x) = \left\{
\begin{array}{rl}
0 \; , & \text{if} \; x < a \\
\frac{\left\lfloor{x}\right\rfloor - a + 1}{b - a + 1} \; , & \text{if} \; a \leq x \leq b \\
1 \; , & \text{if} \; x > b \; .
\end{array}
\right.
\end{equation}

Because the CDF only returns ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:duni-cdf}) multiples of $1/n$ with $n = b - a + 1$, the quantile function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:qf}) is only defined for such values. Since the cumulative probability increases step-wise ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:duni-cdf}) by $1/n$ at each integer between and including $a$ and $b$, the minimum $x$ at which

\begin{equation} \label{eq:duni-qf-duni-cdf-p}
F_X(x) = \frac{c}{n} \quad \text{where} \quad c \in \left\lbrace 1, \ldots, n \right\rbrace
\end{equation}

is given by

\begin{equation} \label{eq:duni-qf-duni-qf-p}
Q_X\left( \frac{c}{n} \right) = a + \frac{c}{n} \cdot n - 1 \; .
\end{equation}

Substituting $p = c/n$ and $n = b - a + 1$, we can finally show:

\begin{equation} \label{eq:duni-qf-duni-qf-qed}
\begin{split}
Q_X(p) &= a + p \cdot (b-a+1) - 1 \\
&= a + pb - pa + p - 1 \\
&= a (1-p) + (b+1) p - 1 \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P142 | shortcut: duni-qf | author: JoramSoch | date: 2020-07-28, 06:17.
\vspace{1em}



\subsection{Bernoulli distribution}

\subsubsection[\textit{Definition}]{Definition} \label{sec:bern}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}). Then, $X$ is said to follow a Bernoulli distribution with success probability $p$

\begin{equation} \label{eq:bern-bern}
X \sim \mathrm{Bern}(p) \; ,
\end{equation}

if $X = 1$ with probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob}) $p$ and $X = 0$ with probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob}) $q = 1-p$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Bernoulli distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-03-22; URL: \url{https://en.wikipedia.org/wiki/Bernoulli_distribution}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D44 | shortcut: bern | author: JoramSoch | date: 2020-03-22, 17:40.
\vspace{1em}



\subsubsection[\textbf{Probability mass function}]{Probability mass function} \label{sec:bern-pmf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a Bernoulli distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:bern}):

\begin{equation} \label{eq:bern-pmf-Bern}
X \sim \mathrm{Bern}(p) \; .
\end{equation}

Then, the probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) of $X$ is

\begin{equation} \label{eq:bern-pmf-Bern-pmf}
f_X(x) = \left\{
\begin{array}{rl}
p \; , & \text{if} \; x = 1 \\
1-p \; , & \text{if} \; x = 0 \; . \\
\end{array}
\right. \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} This follows directly from the definition of the Bernoulli distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:bern}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P96 | shortcut: bern-pmf | author: JoramSoch | date: 2020-05-11, 22:10.
\vspace{1em}



\subsubsection[\textbf{Mean}]{Mean} \label{sec:bern-mean}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a Bernoulli distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:bern}):

\begin{equation} \label{eq:bern-mean-bern}
X \sim \mathrm{Bern}(p) \; .
\end{equation}

Then, the mean or expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of $X$ is

\begin{equation} \label{eq:bern-mean-bern-mean}
\mathrm{E}(X) = p \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) is the probability-weighted average of all possible values:

\begin{equation} \label{eq:bern-mean-mean}
\mathrm{E}(X) = \sum_{x \in \mathcal{X}} x \cdot \mathrm{Pr}(X = x) \; .
\end{equation}

Since there are only two possible outcomes for a Bernoulli random variable ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:bern-pmf}), we have:

\begin{equation} \label{eq:bern-mean-bern-mean-qed}
\begin{split}
\mathrm{E}(X) &= 0 \cdot \mathrm{Pr}(X = 0) + 1 \cdot \mathrm{Pr}(X = 1) \\
&= 0 \cdot (1-p) + 1 \cdot p \\
&= p \; . \\
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Bernoulli distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-01-16; URL: \url{https://en.wikipedia.org/wiki/Bernoulli_distribution#Mean}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P22 | shortcut: bern-mean | author: JoramSoch | date: 2020-01-16, 10:58.
\vspace{1em}



\subsection{Binomial distribution}

\subsubsection[\textit{Definition}]{Definition} \label{sec:bin}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}). Then, $X$ is said to follow a binomial distribution with number of trials $n$ and success probability $p$

\begin{equation} \label{eq:bin-bin}
X \sim \mathrm{Bin}(n, p) \; ,
\end{equation}

if $X$ is the number of successes observed in $n$ independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}) trials, where each trial has two possible outcomes ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:bern}) (success/failure) and the probability of success and failure are identical across trials ($p$/$q = 1-p$).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Binomial distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-03-22; URL: \url{https://en.wikipedia.org/wiki/Binomial_distribution}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D45 | shortcut: bin | author: JoramSoch | date: 2020-03-22, 17:52.
\vspace{1em}



\subsubsection[\textbf{Probability mass function}]{Probability mass function} \label{sec:bin-pmf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a binomial distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:bin}):

\begin{equation} \label{eq:bin-pmf-bin}
X \sim \mathrm{Bin}(n,p) \; .
\end{equation}

Then, the probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) of $X$ is

\begin{equation} \label{eq:bin-pmf-bin-pmf}
f_X(x) = {n \choose x} \, p^x \, (1-p)^{n-x} \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} A binomial variable is defined as ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:bin}) the number of successes observed in $n$ independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}) trials, where each trial has two possible outcomes ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:bern}) (success/failure) and the probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob}) of success and failure are identical across trials ($p$/$q = 1-p$).

If one has obtained $x$ successes in $n$ trials, one has also obtained $(n-x)$ failures. The probability of a particular series of $x$ successes and $(n-x)$ failures, when order does matter, is

\begin{equation} \label{eq:bin-pmf-bin-prob}
p^x \, (1-p)^{n-x} \; .
\end{equation}

When order does not matter, there is a number of series consisting of $x$ successes and $(n-x)$ failures. This number is equal to the number of possibilities in which $x$ objects can be choosen from $n$ objects which is given by the binomial coefficient:

\begin{equation} \label{eq:bin-pmf-bin-coeff}
{n \choose x} \; .
\end{equation}

In order to obtain the probability of $x$ successes and $(n-x)$ failures, when order does not matter, the probability in \eqref{eq:bin-pmf-bin-prob} has to be multiplied with the number of possibilities in \eqref{eq:bin-pmf-bin-coeff} which gives

\begin{equation} \label{eq:bin-pmf-bin-pmf-qed}
p(X=x|n,p) = {n \choose x} \, p^x \, (1-p)^{n-x}
\end{equation}

which is equivalent to the expression above.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P97 | shortcut: bin-pmf | author: JoramSoch | date: 2020-05-11, 22:35.
\vspace{1em}



\subsubsection[\textbf{Mean}]{Mean} \label{sec:bin-mean}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a binomial distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:bin}):

\begin{equation} \label{eq:bin-mean-bin}
X \sim \mathrm{Bin}(n,p) \; .
\end{equation}

Then, the mean or expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of $X$ is

\begin{equation} \label{eq:bin-mean-bin-mean}
\mathrm{E}(X) = n p \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} By definition, a binomial random variable ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:bin}) is the sum of $n$ independent and identical Bernoulli trials ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:bern}) with success probability $p$. Therefore, the expected value is

\begin{equation} \label{eq:bin-mean-bin-mean-s1}
\mathrm{E}(X) = \mathrm{E}(X_1 + \ldots + X_n)
\end{equation}

and because the expected value is a linear operator ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-lin}), this is equal to

\begin{equation} \label{eq:bin-mean-bin-mean-s2}
\begin{split}
\mathrm{E}(X) &= \mathrm{E}(X_1) + \ldots + \mathrm{E}(X_n) \\
&= \sum_{i=1}^{n} \mathrm{E}(X_i) \; .
\end{split}
\end{equation}

With the expected value of the Bernoulli distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:bern-mean}), we have:

\begin{equation} \label{eq:bin-mean-bin-mean-s3}
\mathrm{E}(X) = \sum_{i=1}^{n} p = n p \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Binomial distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-01-16; URL: \url{https://en.wikipedia.org/wiki/Binomial_distribution#Expected_value_and_variance}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P23 | shortcut: bin-mean | author: JoramSoch | date: 2020-01-16, 11:06.
\vspace{1em}



\subsection{Poisson distribution}

\subsubsection[\textit{Definition}]{Definition} \label{sec:poiss}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}). Then, $X$ is said to follow a Poisson distribution with rate $\lambda$

\begin{equation} \label{eq:poiss-poiss}
X \sim \mathrm{Poiss}(\lambda) \; ,
\end{equation}

if and only if its probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) is given by

\begin{equation} \label{eq:poiss-poiss-pmf}
\mathrm{Poiss}(x; \lambda) = \frac{\lambda^x \, e^{-\lambda}}{x!}
\end{equation}

where $x \in \mathbb{N}_0$ and $\lambda > 0$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Poisson distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-05-25; URL: \url{https://en.wikipedia.org/wiki/Poisson_distribution#Definitions}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D62 | shortcut: poiss | author: JoramSoch | date: 2020-05-25, 23:34.
\vspace{1em}



\subsubsection[\textbf{Probability mass function}]{Probability mass function} \label{sec:poiss-pmf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a Poisson distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:poiss}):

\begin{equation} \label{eq:poiss-pmf-Poiss}
X \sim \mathrm{Poiss}(\lambda) \; .
\end{equation}

Then, the probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) of $X$ is

\begin{equation} \label{eq:poiss-pmf-Poiss-pmf}
f_X(x) = \frac{\lambda^x \, e^{-\lambda}}{x!}, \; x \in \mathbb{N}_0 \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} This follows directly from the definition of the Poisson distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:poiss}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P102 | shortcut: poiss-pmf | author: JoramSoch | date: 2020-05-14, 20:39.
\vspace{1em}



\subsubsection[\textbf{Mean}]{Mean} \label{sec:poiss-mean}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a Poisson distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:poiss}):

\begin{equation} \label{eq:poiss-mean-poiss}
X \sim \mathrm{Poiss}(\lambda) \; .
\end{equation}

Then, the mean or expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of $X$ is

\begin{equation} \label{eq:poiss-mean-poiss-mean}
\mathrm{E}(X) = \lambda \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The expected value of a discrete random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) is defined as

\begin{equation} \label{eq:poiss-mean-mean}
\mathrm{E}(X) = \sum_{x \in \mathcal{X}} x \cdot f_X(x) \; ,
\end{equation}

such that, with the probability mass function of the Poisson distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:poiss-pmf}), we have:

\begin{equation} \label{eq:poiss-mean-poiss-mean-s1}
\begin{split}
\mathrm{E}(X) &= \sum_{x=0}^\infty x \cdot \frac{\lambda^x \, e^{-\lambda}}{x!} \\
&= \sum_{x=1}^\infty x \cdot \frac{\lambda^x \, e^{-\lambda}}{x!} \\
&= e^{-\lambda} \cdot \sum_{x=1}^\infty \frac{x}{x!} \lambda^x \\
&= \lambda e^{-\lambda} \cdot \sum_{x=1}^\infty \frac{\lambda^{x-1}}{(x-1)!} \; .
\end{split}
\end{equation}

Substituting $z = x-1$, such that $x = z+1$, we get:

\begin{equation} \label{eq:poiss-mean-poiss-mean-s2}
\mathrm{E}(X) = \lambda e^{-\lambda} \cdot \sum_{z=0}^\infty \frac{\lambda^z}{z!} \; .
\end{equation}

Using the power series expansion of the exponential function

\begin{equation} \label{eq:poiss-mean-exp-ps}
e^x = \sum_{n=0}^\infty \frac{x^n}{n!} \; ,
\end{equation}

the expected value of $X$ finally becomes

\begin{equation} \label{eq:poiss-mean-poiss-mean-s3}
\begin{split}
\mathrm{E}(X) &= \lambda e^{-\lambda} \cdot e^{\lambda} \\
&= \lambda \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item ProofWiki (2020): "Expectation of Poisson Distribution"; in: \textit{ProofWiki}, retrieved on 2020-08-19; URL: \url{https://proofwiki.org/wiki/Expectation_of_Poisson_Distribution}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P151 | shortcut: poiss-mean | author: JoramSoch | date: 2020-08-19, 06:09.
\vspace{1em}



\pagebreak
\section{Multivariate discrete distributions}

\subsection{Categorical distribution}

\subsubsection[\textit{Definition}]{Definition} \label{sec:cat}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}). Then, $X$ is said to follow a categorical distribution with success probability $p_1, \ldots, p_k$

\begin{equation} \label{eq:cat-cat}
X \sim \mathrm{Cat}(\left[p_1, \ldots, p_k \right]) \; ,
\end{equation}

if $X = e_i$ with probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob}) $p_i$ for all $i = 1, \ldots, k$, where $e_i$ is the $i$-th elementary row vector, i.e. a $1 \times k$ vector of zeros with a one in $i$-th position.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Categorical distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-03-22; URL: \url{https://en.wikipedia.org/wiki/Categorical_distribution}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D46 | shortcut: cat | author: JoramSoch | date: 2020-03-22, 18:09.
\vspace{1em}



\subsubsection[\textbf{Probability mass function}]{Probability mass function} \label{sec:cat-pmf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}) following a categorical distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:cat}):

\begin{equation} \label{eq:cat-pmf-cat}
X \sim \mathrm{Cat}(\left[p_1, \ldots, p_k \right]) \; .
\end{equation}

Then, the probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) of $X$ is

\begin{equation} \label{eq:cat-pmf-cat-pmf}
f_X(x) = \left\{
\begin{array}{rl}
p_1 \; , & \text{if} \; x = e_1 \\
\vdots \; \hphantom{,} & \quad \vdots \\
p_k \; , & \text{if} \; x = e_k \; . \\
\end{array}
\right.
\end{equation}

where $e_1, \ldots, e_k$ are the $1 \times k$ elementary row vectors.


\vspace{1em}
\textbf{Proof:} This follows directly from the definition of the categorical distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:cat}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P98 | shortcut: cat-pmf | author: JoramSoch | date: 2020-05-11, 22:58.
\vspace{1em}



\subsubsection[\textbf{Mean}]{Mean} \label{sec:cat-mean}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}) following a categorical distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:cat}):

\begin{equation} \label{eq:cat-mean-cat}
X \sim \mathrm{Cat}(\left[p_1, \ldots, p_k \right]) \; .
\end{equation}

Then, the mean or expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of $X$ is

\begin{equation} \label{eq:cat-mean-cat-mean}
\mathrm{E}(X) = \left[p_1, \ldots, p_k \right] \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} If we conceive the outcome of a categorical distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:cat}) to be a $1 \times k$ vector, then the elementary row vectors $e_1 = \left[1, 0, \ldots, 0 \right]$, ..., $e_k = \left[0, \ldots, 0, 1 \right]$ are all the possible outcomes and they occur with probabilities $\mathrm{Pr}(X = e_1) = p_1$, ..., $\mathrm{Pr}(X = e_k) = p_k$. Consequently, the expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) is

\begin{equation} \label{eq:cat-mean-cat-mean-qed}
\begin{split}
\mathrm{E}(X) &= \sum_{x \in \mathcal{X}} x \cdot \mathrm{Pr}(X = x) \\
&= \sum_{i=1}^k e_i \cdot \mathrm{Pr}(X = e_i) \\
&= \sum_{i=1}^k e_i \cdot p_i \\
&= \left[p_1, \ldots, p_k \right] \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P24 | shortcut: cat-mean | author: JoramSoch | date: 2020-01-16, 11:17.
\vspace{1em}



\subsection{Multinomial distribution}

\subsubsection[\textit{Definition}]{Definition} \label{sec:mult}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}). Then, $X$ is said to follow a multinomial distribution with number of trials $n$ and category probabilities $p_1, \ldots, p_k$

\begin{equation} \label{eq:mult-mult}
X \sim \mathrm{Mult}(n, \left[p_1, \ldots, p_k \right]) \; ,
\end{equation}

if $X$ are the numbers of observations belonging to $k$ distinct categories in $n$ independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}) trials, where each trial has $k$ possible outcomes ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:cat}) and the category probabilities are identical across trials.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Binomial distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-03-22; URL: \url{https://en.wikipedia.org/wiki/Multinomial_distribution}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D47 | shortcut: mult | author: JoramSoch | date: 2020-03-22, 17:52.
\vspace{1em}



\subsubsection[\textbf{Probability mass function}]{Probability mass function} \label{sec:mult-pmf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}) following a multinomial distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mult}):

\begin{equation} \label{eq:mult-pmf-mult}
X \sim \mathrm{Mult}(n, \left[p_1, \ldots, p_k \right]) \; .
\end{equation}

Then, the probability mass function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pmf}) of $X$ is

\begin{equation} \label{eq:mult-pmf-mult-pmf}
f_X(x) = {n \choose {x_1, \ldots, x_k}} \, \prod_{i=1}^k {p_i}^{x_i} \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} A multinomial variable is defined as ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mult}) a vector of the numbers of observations belonging to $k$ distinct categories in $n$ independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}) trials, where each trial has $k$ possible outcomes ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:cat}) and the category probabilities ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob}) are identical across trials.

The probability of a particular series of $x_1$ observations for category $1$, $x_2$ observations for category $2$ etc., when order does matter, is

\begin{equation} \label{eq:mult-pmf-mult-prob}
\prod_{i=1}^k {p_i}^{x_i} \; .
\end{equation}

When order does not matter, there is a number of series consisting of $x_1$ observations for category $1$, ..., $x_k$ observations for category $k$. This number is equal to the number of possibilities in which $x_1$ category $1$ objects, ..., $x_k$ category $k$ objects can be distributed in a sequence of $n$ objects which is given by the multinomial coefficient that can be expressed in terms of factorials:

\begin{equation} \label{eq:mult-pmf-mult-coeff}
{n \choose {x_1, \ldots, x_k}} = \frac{n!}{x_1! \cdot \ldots \cdot x_k!} \; .
\end{equation}

In order to obtain the probability of $x_1$ observations for category $1$, ..., $x_k$ observations for category $k$, when order does not matter, the probability in \eqref{eq:mult-pmf-mult-prob} has to be multiplied with the number of possibilities in \eqref{eq:mult-pmf-mult-coeff} which gives

\begin{equation} \label{eq:mult-pmf-mult-pmf-qed}
p(X=x|n,\left[p_1, \ldots, p_k \right]) = {n \choose {x_1, \ldots, x_k}} \, \prod_{i=1}^k {p_i}^{x_i}
\end{equation}

which is equivalent to the expression above.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P99 | shortcut: mult-pmf | author: JoramSoch | date: 2020-05-11, 23:30.
\vspace{1em}



\subsubsection[\textbf{Mean}]{Mean} \label{sec:mult-mean}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}) following a multinomial distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mult}):

\begin{equation} \label{eq:mult-mean-mult}
X \sim \mathrm{Mult}(n,\left[p_1, \ldots, p_k \right]) \; .
\end{equation}

Then, the mean or expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of $X$ is

\begin{equation} \label{eq:mult-mean-bin-mean}
\mathrm{E}(X) = \left[n p_1, \ldots, n p_k \right] \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} By definition, a multinomial random variable ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mult}) is the sum of $n$ independent and identical categorical trials ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:cat}) with category probabilities $p_1, \ldots, p_k$. Therefore, the expected value is

\begin{equation} \label{eq:mult-mean-mult-mean-s1}
\mathrm{E}(X) = \mathrm{E}(X_1 + \ldots + X_n)
\end{equation}

and because the expected value is a linear operator ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-lin}), this is equal to

\begin{equation} \label{eq:mult-mean-mult-mean-s2}
\begin{split}
\mathrm{E}(X) &= \mathrm{E}(X_1) + \ldots + \mathrm{E}(X_n) \\
&= \sum_{i=1}^{n} \mathrm{E}(X_i) \; .
\end{split}
\end{equation}

With the expected value of the categorical distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:cat-mean}), we have:

\begin{equation} \label{eq:mult-mean-mult-mean-s3}
\mathrm{E}(X) = \sum_{i=1}^{n} \left[p_1, \ldots, p_k \right] = n \cdot \left[p_1, \ldots, p_k \right] = \left[n p_1, \ldots, n p_k \right] \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P25 | shortcut: mult-mean | author: JoramSoch | date: 2020-01-16, 11:26.
\vspace{1em}



\pagebreak
\section{Univariate continuous distributions}

\subsection{Continuous uniform distribution}

\subsubsection[\textit{Definition}]{Definition} \label{sec:cuni}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a continuous random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}). Then, $X$ is said to be uniformly distributed with minimum $a$ and maximum $b$

\begin{equation} \label{eq:cuni-cuni}
X \sim \mathcal{U}(a, b) \; ,
\end{equation}

if and only if each value between and including $a$ and $b$ occurs with the same probability.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Uniform distribution (continuous)"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-01-27; URL: \url{https://en.wikipedia.org/wiki/Uniform_distribution_(continuous)}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D3 | shortcut: cuni | author: JoramSoch | date: 2020-01-27, 14:05.
\vspace{1em}



\subsubsection[\textbf{Probability density function}]{Probability density function} \label{sec:cuni-pdf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a continuous uniform distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:cuni}):

\begin{equation} \label{eq:cuni-pdf-cuni}
X \sim \mathcal{U}(a, b) \; .
\end{equation}

Then, the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $X$ is

\begin{equation} \label{eq:cuni-pdf-cuni-pdf}
f_X(x) = \left\{
\begin{array}{rl}
\frac{1}{b-a} \; , & \text{if} \; a \leq x \leq b \\
0 \; , & \text{otherwise} \; .
\end{array}
\right.
\end{equation}


\vspace{1em}
\textbf{Proof:} A continuous uniform variable is defined as ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:cuni}) having a constant probability density between minimum $a$ and maximum $b$. Therefore,

\begin{equation} \label{eq:cuni-pdf-cuni-pdf-s1}
\begin{split}
f_X(x) &\propto 1 \quad \text{for all} \quad x \in [a,b] \quad \text{and} \\
f_X(x) &= 0, \quad\!\! \text{if} \quad x < a \quad \text{or} \quad x > b \; .
\end{split}
\end{equation}

To ensure that $f_X(x)$ is a proper probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}), the integral over all non-zero probabilities has to sum to $1$. Therefore,

\begin{equation} \label{eq:cuni-pdf-cuni-pdf-s2}
f_X(x) = \frac{1}{c(a,b)} \quad \text{for all} \quad x \in [a,b]
\end{equation}

where the normalization factor $c(a,b)$ is specified, such that

\begin{equation} \label{eq:cuni-pdf-cuni-pdf-s3}
\frac{1}{c(a,b)} \int_{a}^{b} 1 \, \mathrm{d}x = 1 \; .
\end{equation}

Solving this for $c(a,b)$, we obtain:

\begin{equation} \label{eq:cuni-pdf-cuni-pdf-s4}
\begin{split}
\int_{a}^{b} 1 \, \mathrm{d}x &= c(a,b) \\
[x]_a^b &= c(a,b) \\
c(a,b) &= b-a \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P37 | shortcut: cuni-pdf | author: JoramSoch | date: 2020-01-31, 15:41.
\vspace{1em}



\subsubsection[\textbf{Cumulative distribution function}]{Cumulative distribution function} \label{sec:cuni-cdf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a continuous uniform distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:cuni}):

\begin{equation} \label{eq:cuni-cdf-cuni}
X \sim \mathcal{U}(a, b) \; .
\end{equation}

Then, the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) of $X$ is

\begin{equation} \label{eq:cuni-cdf-cuni-cdf}
F_X(x) = \left\{
\begin{array}{rl}
0 \; , & \text{if} \; x < a \\
\frac{x-a}{b-a} \; , & \text{if} \; a \leq x \leq b \\
1 \; , & \text{if} \; x > b \; .
\end{array}
\right.
\end{equation}


\vspace{1em}
\textbf{Proof:} The probability density function of the continuous uniform distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:cuni-pdf}) is:

\begin{equation} \label{eq:cuni-cdf-cuni-pdf}
\mathcal{U}(x; a, b) = \left\{
\begin{array}{rl}
\frac{1}{b-a} \; , & \text{if} \; a \leq x \leq b \\
0 \; , & \text{otherwise} \; .
\end{array}
\right.
\end{equation}

Thus, the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) is:

\begin{equation} \label{eq:cuni-cdf-cuni-cdf-s1}
F_X(x) = \int_{-\infty}^{x} \mathcal{U}(z; a, b) \, \mathrm{d}z
\end{equation}

First of all, if $x < a$, we have

\begin{equation} \label{eq:cuni-cdf-cuni-cdf-s2a}
F_X(x) = \int_{-\infty}^{x} 0 \, \mathrm{d}z = 0 \; .
\end{equation}

Moreover, if $a \leq x \leq b$, we have using \eqref{eq:cuni-cdf-cuni-pdf}

\begin{equation} \label{eq:cuni-cdf-cuni-cdf-s2b}
\begin{split}
F_X(x) &= \int_{-\infty}^{a} \mathcal{U}(z; a, b) \, \mathrm{d}z + \int_{a}^{x} \mathcal{U}(z; a, b) \, \mathrm{d}z \\
&= \int_{-\infty}^{a} 0 \, \mathrm{d}z + \int_{a}^{x} \frac{1}{b-a} \, \mathrm{d}z \\
&= 0 + \frac{1}{b-a} [z]_a^x \\
&= \frac{x-a}{b-a} \; .
\end{split}
\end{equation}

Finally, if $x > b$, we have

\begin{equation} \label{eq:cuni-cdf-cuni-cdf-s2c}
\begin{split}
F_X(x) &= \int_{-\infty}^{b} \mathcal{U}(z; a, b) \, \mathrm{d}z + \int_{b}^{x} \mathcal{U}(z; a, b) \, \mathrm{d}z \\
&= F_X(b) + \int_{b}^{x} 0 \, \mathrm{d}z \\
&= \frac{b-a}{b-a} + 0 \\
&= 1 \; .
\end{split}
\end{equation}

This completes the proof.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P38 | shortcut: cuni-cdf | author: JoramSoch | date: 2020-01-02, 18:05.
\vspace{1em}



\subsubsection[\textbf{Quantile function}]{Quantile function} \label{sec:cuni-qf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a continuous uniform distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:cuni}):

\begin{equation} \label{eq:cuni-qf-cuni}
X \sim \mathcal{U}(a, b) \; .
\end{equation}

Then, the quantile function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:qf}) of $X$ is

\begin{equation} \label{eq:cuni-qf-cuni-qf}
Q_X(p) = bp + a(1-p) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The cumulative distribution function of the continuous uniform distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:cuni-cdf}) is:

\begin{equation} \label{eq:cuni-qf-cuni-cdf}
F_X(x) = \left\{
\begin{array}{rl}
0 \; , & \text{if} \; x < a \\
\frac{x-a}{b-a} \; , & \text{if} \; a \leq x \leq b \\
1 \; , & \text{if} \; x > b \; .
\end{array}
\right.
\end{equation}

Thus, the quantile function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:qf}) is:

\begin{equation} \label{eq:cuni-qf-cuni-qf-s1}
Q_X(p) = F_X^{-1}(x) \; .
\end{equation}

This can be derived by rearranging equation \eqref{eq:cuni-qf-cuni-cdf}:

\begin{equation} \label{eq:cuni-qf-cuni-cdf-s2}
\begin{split}
p &= \frac{x-a}{b-a} \\
x &= p(b-a) + a \\
x &= bp + a(1-p) = Q_X(p) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P39 | shortcut: cuni-qf | author: JoramSoch | date: 2020-01-02, 18:27.
\vspace{1em}



\subsubsection[\textbf{Mean}]{Mean} \label{sec:cuni-mean}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a continuous uniform distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:cuni}):

\begin{equation} \label{eq:cuni-mean-cuni}
X \sim \mathcal{U}(a, b) \; .
\end{equation}

Then, the mean or expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of $X$ is

\begin{equation} \label{eq:cuni-mean-cuni-mean}
\mathrm{E}(X) = \frac{1}{2} (a+b) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) is the probability-weighted average over all possible values:

\begin{equation} \label{eq:cuni-mean-mean}
\mathrm{E}(X) = \int_{\mathbb{R}} x \cdot f_X(x) \, \mathrm{d}x \; .
\end{equation}

With the probability density function of the continuous uniform distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:cuni-pdf}), this becomes:

\begin{equation} \label{eq:cuni-mean-cuni-mean-qed}
\begin{split}
\mathrm{E}(X) &= \int_a^b x \cdot \frac{1}{b-a} \, \mathrm{d}x \\
&= \left[ \frac{1}{2} \, \frac{x^2}{b-a} \right]_a^b \\
&= \frac{1}{2} \, \frac{b^2 - a^2}{b-a} \\
&= \frac{1}{2} \, \frac{(b+a)(b-a)}{b-a} \\
&= \frac{1}{2} (a+b) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P82 | shortcut: cuni-mean | author: JoramSoch | date: 2020-03-16, 16:12.
\vspace{1em}



\subsubsection[\textbf{Median}]{Median} \label{sec:cuni-med}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a continuous uniform distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:cuni}):

\begin{equation} \label{eq:cuni-med-cuni}
X \sim \mathcal{U}(a, b) \; .
\end{equation}

Then, the median ($\rightarrow$ Definition "med") of $X$ is

\begin{equation} \label{eq:cuni-med-cuni-med}
\mathrm{median}(X) = \frac{1}{2} (a+b) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The median ($\rightarrow$ Definition "med") is the value at which the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) is $1/2$:

\begin{equation} \label{eq:cuni-med-median}
F_X(\mathrm{median}(X)) = \frac{1}{2} \; .
\end{equation}

The cumulative distribution function of the continuous uniform distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:cuni-cdf}) is

\begin{equation} \label{eq:cuni-med-cuni-cdf}
F_X(x) = \left\{
\begin{array}{rl}
0 \; , & \text{if} \; x < a \\
\frac{x-a}{b-a} \; , & \text{if} \; a \leq x \leq b \\
1 \; , & \text{if} \; x > b \; .
\end{array}
\right.
\end{equation}

Thus, the inverse CDF ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:cuni-qf}) is

\begin{equation} \label{eq:cuni-med-cuni-cdf-inv}
x = bp + a(1-p) \; .
\end{equation}

Setting $p = 1/2$, we obtain:

\begin{equation} \label{eq:cuni-med-cuni-med-qed}
\mathrm{median}(X) = b \cdot \frac{1}{2} + a \cdot \left( 1-\frac{1}{2} \right) = \frac{1}{2} (a+b) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P83 | shortcut: cuni-med | author: JoramSoch | date: 2020-03-16, 16:19.
\vspace{1em}



\subsubsection[\textbf{Mode}]{Mode} \label{sec:cuni-med}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a continuous uniform distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:cuni}):

\begin{equation} \label{eq:cuni-med-cuni}
X \sim \mathcal{U}(a, b) \; .
\end{equation}

Then, the mode ($\rightarrow$ Definition "mode") of $X$ is

\begin{equation} \label{eq:cuni-med-cuni-mode}
\mathrm{mode}(X) \in [a,b] \; .
\end{equation}


\vspace{1em}
\textbf{Proof:}  The mode ($\rightarrow$ Definition "mode") is the value which maximizes the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}):

\begin{equation} \label{eq:cuni-med-mode}
\mathrm{mode}(X) = \operatorname*{arg\,max}_x f_X(x) \; .
\end{equation}

The probability density function of the continuous uniform distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:cuni-pdf}) is:

\begin{equation} \label{eq:cuni-med-cuni-pdf}
f_X(x) = \left\{
\begin{array}{rl}
\frac{1}{b-a} \; , & \text{if} \; a \leq x \leq b \\
0 \; , & \text{otherwise} \; .
\end{array}
\right.
\end{equation}

Since the PDF attains its only non-zero value whenever $a \leq x \leq b$,

\begin{equation} \label{eq:cuni-med-cuni-pdf-max}
\operatorname*{max}_x f_X(x) = \frac{1}{b-a} \; ,
\end{equation}

any value in the interval $[a,b]$ may be considered the mode of $X$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P84 | shortcut: cuni-med | author: JoramSoch | date: 2020-03-16, 16:29.
\vspace{1em}



\subsection{Normal distribution}

\subsubsection[\textit{Definition}]{Definition} \label{sec:norm}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}). Then, $X$ is said to be normally distributed with mean $\mu$ and variance $\sigma^2$ (or, standard deviation $\sigma$)

\begin{equation} \label{eq:norm-norm}
X \sim \mathcal{N}(\mu, \sigma^2) \; ,
\end{equation}

if and only if its probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) is given by

\begin{equation} \label{eq:norm-norm-pdf}
\mathcal{N}(x; \mu, \sigma^2) = \frac{1}{\sqrt{2 \pi} \sigma} \cdot \exp \left[ -\frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right]
\end{equation}

where $\mu \in \mathbb{R}$ and $\sigma^2 > 0$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Normal distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-01-27; URL: \url{https://en.wikipedia.org/wiki/Normal_distribution}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D4 | shortcut: norm | author: JoramSoch | date: 2020-01-27, 14:15.
\vspace{1em}



\subsubsection[\textit{Standard normal distribution}]{Standard normal distribution} \label{sec:snorm}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}). Then, $X$ is said to be standard normally distributed, if $X$ follows a normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}) with mean $\mu = 0$ and variance $\sigma^2 = 1$:

\begin{equation} \label{eq:snorm-snorm}
X \sim \mathcal{N}(0, 1) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Normal distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-05-26; URL: \url{https://en.wikipedia.org/wiki/Normal_distribution#Standard_normal_distribution}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D63 | shortcut: snorm | author: JoramSoch | date: 2020-05-26, 23:32.
\vspace{1em}



\subsubsection[\textbf{Relation to standard normal distribution}]{Relation to standard normal distribution} \label{sec:norm-snorm}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}) with mean $\mu$ and variance $\sigma^2$:

\begin{equation} \label{eq:norm-snorm-X-norm}
X \sim \mathcal{N}(\mu, \sigma^2) \; .
\end{equation}

Then, the quantity $Z = (X-\mu)/\sigma$ will have a standard normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:snorm}) with mean $0$ and variance $1$:

\begin{equation} \label{eq:norm-snorm-Z-snorm}
Z = \frac{X-\mu}{\sigma} \sim \mathcal{N}(0, 1) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} Rearranging to get $X$ in terms of $Z$, we have

\begin{equation} \label{eq:norm-snorm-X-Z}
X = \sigma Z + \mu \; .
\end{equation}

The cumulative distribution function of the normally distributed ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-cdf}) $X$ is

\begin{equation} \label{eq:norm-snorm-norm-cdf}
F_X(t) = \int_{-\infty}^{t} \frac{1}{\sqrt{2 \pi} \sigma} \cdot \exp \left[ -\frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right] \, \mathrm{d}x \; .
\end{equation}

Substituting \eqref{eq:norm-snorm-X-Z} into \eqref{eq:norm-snorm-norm-cdf}, we obtain

\begin{equation} \label{eq:norm-snorm-snorm-cdf}
\begin{split}
F_Z(t) &= \int_{-\infty}^{t} \frac{1}{\sqrt{2 \pi} \sigma} \cdot \exp \left[ -\frac{1}{2} \left( \frac{(\sigma z + \mu)-\mu}{\sigma} \right)^2 \right] \, \mathrm{d}(\sigma z + \mu) \\
&= \int_{-\infty}^{t} \frac{\sigma}{\sqrt{2 \pi} \sigma} \cdot \exp \left[ -\frac{1}{2} z^2 \right] \, \mathrm{d}z \\
&= \int_{-\infty}^{t} \frac{1}{\sqrt{2 \pi}} \cdot \exp \left[ -\frac{1}{2} z^2 \right] \, \mathrm{d}z
\end{split}
\end{equation}

which is the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) of the standard normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:snorm}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P111 | shortcut: norm-snorm | author: JoramSoch | date: 2020-05-26, 23:01.
\vspace{1em}



\subsubsection[\textbf{Probability density function}]{Probability density function} \label{sec:norm-pdf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}):

\begin{equation} \label{eq:norm-pdf-norm}
X \sim \mathcal{N}(\mu, \sigma^2) \; .
\end{equation}

Then, the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $X$ is

\begin{equation} \label{eq:norm-pdf-norm-pdf}
f_X(x) = \frac{1}{\sqrt{2 \pi} \sigma} \cdot \exp \left[ -\frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right] \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} This follows directly from the definition of the normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P33 | shortcut: norm-pdf | author: JoramSoch | date: 2020-01-27, 15:15.
\vspace{1em}



\subsubsection[\textbf{Cumulative distribution function}]{Cumulative distribution function} \label{sec:norm-cdf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a normal distributions ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}):

\begin{equation} \label{eq:norm-cdf-norm}
X \sim \mathcal{N}(\mu, \sigma^2) \; .
\end{equation}

Then, the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) of $X$ is

\begin{equation} \label{eq:norm-cdf-norm-cdf}
F_X(x) = \frac{1}{2} \left[ 1 + \mathrm{erf}\left( \frac{x-\mu}{\sqrt{2} \sigma} \right) \right]
\end{equation}

where $\mathrm{erf}(x)$ is the error function defined as

\begin{equation} \label{eq:norm-cdf-erf}
\mathrm{erf}(x) = \frac{2}{\sqrt{\pi}} \int_{0}^{x} \exp(-t^2) \, \mathrm{d}t \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The probability density function of the normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-pdf}) is:

\begin{equation} \label{eq:norm-cdf-norm-pdf}
f_X(x) = \frac{1}{\sqrt{2 \pi} \sigma} \cdot \exp \left[ -\frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right] \; .
\end{equation}

Thus, the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) is:

\begin{equation} \label{eq:norm-cdf-norm-cdf-s1}
\begin{split}
F_X(x) &= \int_{-\infty}^{x} \mathcal{N}(z; \mu, \sigma^2) \, \mathrm{d}z \\
&= \int_{-\infty}^{x} \frac{1}{\sqrt{2 \pi} \sigma} \cdot \exp \left[ -\frac{1}{2} \left( \frac{z-\mu}{\sigma} \right)^2 \right] \, \mathrm{d}z \\
&= \frac{1}{\sqrt{2 \pi} \sigma} \int_{-\infty}^{x} \exp \left[ -\left( \frac{z-\mu}{\sqrt{2} \sigma} \right)^2 \right] \, \mathrm{d}z \; .
\end{split}
\end{equation}

Substituting $t = (z-\mu)/(\sqrt{2} \sigma)$, i.e. $z = \sqrt{2} \sigma t + \mu$, this becomes:

\begin{equation} \label{eq:norm-cdf-norm-cdf-s2}
\begin{split}
F_X(x) &= \frac{1}{\sqrt{2 \pi} \sigma} \int_{(-\infty-\mu)/(\sqrt{2} \sigma)}^{(x-\mu)/(\sqrt{2} \sigma)} \exp(-t^2) \, \mathrm{d}\left( \sqrt{2} \sigma t + \mu \right) \\
&= \frac{\sqrt{2} \sigma}{\sqrt{2 \pi} \sigma} \int_{-\infty}^{\frac{x-\mu}{\sqrt{2} \sigma}} \exp(-t^2) \, \mathrm{d}t \\
&= \frac{1}{\sqrt{\pi}} \int_{-\infty}^{\frac{x-\mu}{\sqrt{2} \sigma}} \exp(-t^2) \, \mathrm{d}t \\
&= \frac{1}{\sqrt{\pi}} \int_{-\infty}^{0} \exp(-t^2) \, \mathrm{d}t + \frac{1}{\sqrt{\pi}} \int_{0}^{\frac{x-\mu}{\sqrt{2} \sigma}} \exp(-t^2) \, \mathrm{d}t \\
&= \frac{1}{\sqrt{\pi}} \int_{0}^{\infty} \exp(-t^2) \, \mathrm{d}t + \frac{1}{\sqrt{\pi}} \int_{0}^{\frac{x-\mu}{\sqrt{2} \sigma}} \exp(-t^2) \, \mathrm{d}t \; .
\end{split}
\end{equation}

Applying \eqref{eq:norm-cdf-erf} to \eqref{eq:norm-cdf-norm-cdf-s2}, we have:

\begin{equation} \label{eq:norm-cdf-norm-cdf-s3}
\begin{split}
F_X(x) &= \frac{1}{2} \lim_{x \to \infty} \mathrm{erf}(x) + \frac{1}{2} \, \mathrm{erf}\left( \frac{x-\mu}{\sqrt{2} \sigma} \right) \\
&= \frac{1}{2} + \frac{1}{2} \, \mathrm{erf}\left( \frac{x-\mu}{\sqrt{2} \sigma} \right) \\
&= \frac{1}{2} \left[ 1 + \mathrm{erf}\left( \frac{x-\mu}{\sqrt{2} \sigma} \right) \right] \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Normal distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-03-20; URL: \url{https://en.wikipedia.org/wiki/Normal_distribution#Cumulative_distribution_function}.
\item Wikipedia (2020): "Error function"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-03-20; URL: \url{https://en.wikipedia.org/wiki/Error_function}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P85 | shortcut: norm-cdf | author: JoramSoch | date: 2020-03-20, 01:33.
\vspace{1em}



\subsubsection[\textbf{Cumulative distribution function without error function}]{Cumulative distribution function without error function} \label{sec:norm-cdfwerf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a normal distributions ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}):

\begin{equation} \label{eq:norm-cdfwerf-norm}
X \sim \mathcal{N}(\mu, \sigma^2) \; .
\end{equation}

Then, the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) of $X$ can be expressed as

\begin{equation} \label{eq:norm-cdfwerf-norm-cdf}
f_X(x) = \Phi_{\mu,\sigma}(x) = \varphi\left( \frac{x-\mu}{\sigma} \right) \cdot \sum_{i=1}^{\infty} \frac{\left( \frac{x-\mu}{\sigma} \right)^{2i-1}}{(2i-1)!!} + \frac{1}{2}
\end{equation}

where $\varphi(x)$ is the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of the standard normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:snorm}) and $n!!$ is a double factorial.


\vspace{1em}
\textbf{Proof:}

1) First, consider the standard normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:snorm}) $\mathcal{N}(0, 1)$ which has the probability density function ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-pdf})

\begin{equation} \label{eq:norm-cdfwerf-snorm-pdf}
\varphi(x) = \frac{1}{\sqrt{2 \pi}} \cdot e^{-\frac{1}{2} x^2} \; .
\end{equation}

Let $T(x)$ be the indefinite integral of this function. It can be obtained using infinitely repeated integration by parts as follows:

\begin{equation} \label{eq:norm-cdfwerf-snorm-pdf-ii-s1}
\begin{split}
T(x) &= \int \varphi(x) \, \mathrm{d}x \\
&= \int \frac{1}{\sqrt{2 \pi}} \cdot e^{-\frac{1}{2} x^2} \, \mathrm{d}x \\
&= \frac{1}{\sqrt{2 \pi}} \int 1 \cdot e^{-\frac{1}{2} x^2} \, \mathrm{d}x \\
&= \frac{1}{\sqrt{2 \pi}} \cdot \left[ x \cdot e^{-\frac{1}{2} x^2} + \int x^2 \cdot e^{-\frac{1}{2} x^2} \, \mathrm{d}x \right] \\
&= \frac{1}{\sqrt{2 \pi}} \cdot \left[ x \cdot e^{-\frac{1}{2} x^2} + \left[ \frac{1}{3} x^3 \cdot e^{-\frac{1}{2} x^2} + \int \frac{1}{3} x^4 \cdot e^{-\frac{1}{2} x^2} \, \mathrm{d}x \right] \right] \\
&= \frac{1}{\sqrt{2 \pi}} \cdot \left[ x \cdot e^{-\frac{1}{2} x^2} + \left[ \frac{1}{3} x^3 \cdot e^{-\frac{1}{2} x^2} + \left[ \frac{1}{15} x^5 \cdot e^{-\frac{1}{2} x^2} + \int \frac{1}{15} x^6 \cdot e^{-\frac{1}{2} x^2} \, \mathrm{d}x \right] \right] \right] \\
&= \ldots \\
&= \frac{1}{\sqrt{2 \pi}} \cdot \left[ \sum_{i=1}^{n} \left( \frac{x^{2i-1}}{(2i-1)!!} \cdot e^{-\frac{1}{2} x^2} \right) + \int \left( \frac{x^{2n}}{(2n-1)!!} \cdot e^{-\frac{1}{2} x^2} \right) \, \mathrm{d}x \right] \\
&= \frac{1}{\sqrt{2 \pi}} \cdot \left[ \sum_{i=1}^{\infty} \left( \frac{x^{2i-1}}{(2i-1)!!} \cdot e^{-\frac{1}{2} x^2} \right) + \lim_{n \to \infty} \int \left( \frac{x^{2n}}{(2n-1)!!} \cdot e^{-\frac{1}{2} x^2} \right) \, \mathrm{d}x \right] \; .
\end{split}
\end{equation}

Since $(2n-1)!!$ grows faster than $x^{2n}$, it holds that

\begin{equation} \label{eq:norm-cdfwerf-int-const}
\frac{1}{\sqrt{2 \pi}} \cdot \lim_{n \to \infty} \int \left( \frac{x^{2n}}{(2n-1)!!} \cdot e^{-\frac{1}{2} x^2} \right) \, \mathrm{d}x = \int 0 \, \mathrm{d}x = c
\end{equation}

for constant $c$, such that the indefinite integral becomes

\begin{equation} \label{eq:norm-cdfwerf-snorm-pdf-ii-s2}
\begin{split}
T(x) &= \frac{1}{\sqrt{2 \pi}} \cdot \sum_{i=1}^{\infty} \left( \frac{x^{2i-1}}{(2i-1)!!} \cdot e^{-\frac{1}{2} x^2} \right) + c \\
&= \frac{1}{\sqrt{2 \pi}} \cdot e^{-\frac{1}{2} x^2} \cdot \sum_{i=1}^{\infty} \frac{x^{2i-1}}{(2i-1)!!} + c \\
&\overset{\eqref{eq:norm-cdfwerf-snorm-pdf}}{=} \varphi(x) \cdot \sum_{i=1}^{\infty} \frac{x^{2i-1}}{(2i-1)!!} + c \; .
\end{split}
\end{equation}

2) Next, let $\Phi(x)$ be the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) of the standard normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:snorm}):

\begin{equation} \label{eq:norm-cdfwerf-snorm-cdf}
\Phi(x) = \int_{-\infty}^x \varphi(x) \, \mathrm{d}x \; .
\end{equation}

It can be obtained by matching $T(0)$ to $\Phi(0)$ which is $1/2$, because the standard normal distribution is symmetric around zero:

\begin{equation} \label{eq:norm-cdfwerf-snorm-cdf-c}
\begin{split}
T(0) = \varphi(0) \cdot \sum_{i=1}^{\infty} \frac{0^{2i-1}}{(2i-1)!!} + c &= \frac{1}{2} = \Phi(0) \\
\Leftrightarrow c &= \frac{1}{2} \\
\Rightarrow \Phi(x) = \varphi(x) \cdot \sum_{i=1}^{\infty} \frac{x^{2i-1}}{(2i-1)!!} + \frac{1}{2} \! &\; .
\end{split}
\end{equation}

3) Finally, the cumulative distribution functions of the standard normal distribution and the general normal distribution are related to each other ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-snorm}) as

\begin{equation} \label{eq:norm-cdfwerf-norm-snorm-cdf}
\Phi_{\mu,\sigma}(x) = \Phi\left( \frac{x-\mu}{\sigma} \right) \; .
\end{equation}

Combining \eqref{eq:norm-cdfwerf-norm-snorm-cdf} with \eqref{eq:norm-cdfwerf-snorm-cdf-c}, we have:

\begin{equation} \label{eq:norm-cdfwerf-norm-cdf-qed}
\Phi_{\mu,\sigma}(x) = \varphi\left( \frac{x-\mu}{\sigma} \right) \cdot \sum_{i=1}^{\infty} \frac{\left( \frac{x-\mu}{\sigma} \right)^{2i-1}}{(2i-1)!!} + \frac{1}{2} \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Soch J (2015): "Solution for the Indefinite Integral of the Standard Normal Probability Density Function"; in: \textit{arXiv stat.OT}, arXiv:1512.04858; URL: \url{https://arxiv.org/abs/1512.04858}.
\item Wikipedia (2020): "Normal distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-03-20; URL: \url{https://en.wikipedia.org/wiki/Normal_distribution#Cumulative_distribution_function}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P86 | shortcut: norm-cdfwerf | author: JoramSoch | date: 2020-03-20, 04:26.
\vspace{1em}



\subsubsection[\textbf{Quantile function}]{Quantile function} \label{sec:norm-qf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a normal distributions ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}):

\begin{equation} \label{eq:norm-qf-norm}
X \sim \mathcal{N}(\mu, \sigma^2) \; .
\end{equation}

Then, the quantile function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:qf}) of $X$ is

\begin{equation} \label{eq:norm-qf-norm-qf}
Q_X(p) = \sqrt{2}\sigma \cdot \mathrm{erf}^{-1}(2p-1) + \mu
\end{equation}

where $\mathrm{erf}^{-1}(x)$ is the inverse error function.


\vspace{1em}
\textbf{Proof:} The cumulative distribution function of the normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-cdf}) is:

\begin{equation} \label{eq:norm-qf-norm-cdf}
F_X(x) = \frac{1}{2} \left[ 1 + \mathrm{erf}\left( \frac{x-\mu}{\sqrt{2} \sigma} \right) \right] \; .
\end{equation}

Thus, the quantile function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:qf}) is:

\begin{equation} \label{eq:norm-qf-norm-qf-s1}
Q_X(p) = F_X^{-1}(x) \; .
\end{equation}

This can be derived by rearranging equation \eqref{eq:norm-qf-norm-cdf}:

\begin{equation} \label{eq:norm-qf-norm-qf-s2}
\begin{split}
p &= \frac{1}{2} \left[ 1 + \mathrm{erf}\left( \frac{x-\mu}{\sqrt{2} \sigma} \right) \right] \\
2 p - 1 &= \mathrm{erf}\left( \frac{x-\mu}{\sqrt{2} \sigma} \right) \\
\mathrm{erf}^{-1}(2p-1) &= \frac{x-\mu}{\sqrt{2} \sigma} \\
x &= \sqrt{2}\sigma \cdot \mathrm{erf}^{-1}(2p-1) + \mu \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Normal distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-03-20; URL: \url{https://en.wikipedia.org/wiki/Normal_distribution#Quantile_function}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P87 | shortcut: norm-qf | author: JoramSoch | date: 2020-03-20, 04:47.
\vspace{1em}



\subsubsection[\textbf{Mean}]{Mean} \label{sec:norm-mean}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}):

\begin{equation} \label{eq:norm-mean-norm}
X \sim \mathcal{N}(\mu, \sigma^2) \; .
\end{equation}

Then, the mean or expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of $X$ is

\begin{equation} \label{eq:norm-mean-norm-mean}
\mathrm{E}(X) = \mu \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) is the probability-weighted average over all possible values:

\begin{equation} \label{eq:norm-mean-mean}
\mathrm{E}(X) = \int_{\mathbb{R}} x \cdot f_X(x) \, \mathrm{d}x \; .
\end{equation}

With the probability density function of the normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-pdf}), this reads:

\begin{equation} \label{eq:norm-mean-norm-mean-s1}
\begin{split}
\mathrm{E}(X) &= \int_{-\infty}^{+\infty} x \cdot \frac{1}{\sqrt{2 \pi} \sigma} \cdot \exp \left[ -\frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right] \, \mathrm{d}x \\
&= \frac{1}{\sqrt{2 \pi} \sigma} \int_{-\infty}^{+\infty} x \cdot \exp \left[ -\frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right] \, \mathrm{d}x \; .
\end{split}
\end{equation}

Substituting $z = x -\mu$, we have:

\begin{equation} \label{eq:norm-mean-norm-mean-s2}
\begin{split}
\mathrm{E}(X) &= \frac{1}{\sqrt{2 \pi} \sigma} \int_{-\infty-\mu}^{+\infty-\mu} (z + \mu) \cdot \exp \left[ -\frac{1}{2} \left( \frac{z}{\sigma} \right)^2 \right] \, \mathrm{d}(z + \mu) \\
&= \frac{1}{\sqrt{2 \pi} \sigma} \int_{-\infty}^{+\infty} (z + \mu) \cdot \exp \left[ -\frac{1}{2} \left( \frac{z}{\sigma} \right)^2 \right] \, \mathrm{d}z \\
&= \frac{1}{\sqrt{2 \pi} \sigma} \left( \int_{-\infty}^{+\infty} z \cdot \exp \left[ -\frac{1}{2} \left( \frac{z}{\sigma} \right)^2 \right] \, \mathrm{d}z + \mu \int_{-\infty}^{+\infty} \exp \left[ -\frac{1}{2} \left( \frac{z}{\sigma} \right)^2 \right] \, \mathrm{d}z \right) \\
&= \frac{1}{\sqrt{2 \pi} \sigma} \left( \int_{-\infty}^{+\infty} z \cdot \exp \left[ -\frac{1}{2 \sigma^2} \cdot z^2 \right] \, \mathrm{d}z + \mu \int_{-\infty}^{+\infty} \exp \left[ -\frac{1}{2 \sigma^2} \cdot z^2 \right] \, \mathrm{d}z \right) \; .
\end{split}
\end{equation}

The general antiderivatives are

\begin{equation} \label{eq:norm-mean-exp-erf-anti-der}
\begin{split}
\int x \cdot \exp \left[ -a x^2 \right] \mathrm{d}x &= -\frac{1}{2a} \cdot \exp \left[ -a x^2 \right] \\
\int \exp \left[ -a x^2 \right] \mathrm{d}x &= \frac{1}{2} \sqrt{\frac{\pi}{a}} \cdot \mathrm{erf} \left[ \sqrt{a} x \right]
\end{split}
\end{equation}

where $\mathrm{erf}(x)$ is the error function. Using this, the integrals can be calculated as:

\begin{equation} \label{eq:norm-mean-norm-mean-s3}
\begin{split}
\mathrm{E}(X) &= \frac{1}{\sqrt{2 \pi} \sigma} \left( \left[ -\sigma^2 \cdot \exp \left[ -\frac{1}{2 \sigma^2} \cdot z^2 \right] \right]_{-\infty}^{+\infty} + \mu \left[ \sqrt{\frac{\pi}{2}} \sigma \cdot \mathrm{erf} \left[ \frac{1}{\sqrt{2} \sigma} z \right] \right]_{-\infty}^{+\infty} \right) \\
&= \frac{1}{\sqrt{2 \pi} \sigma} \left( \left[ \lim_{z \to \infty} \left( -\sigma^2 \cdot \exp \left[ -\frac{1}{2 \sigma^2} \cdot z^2 \right] \right) - \lim_{z \to -\infty} \left( -\sigma^2 \cdot \exp \left[ -\frac{1}{2 \sigma^2} \cdot z^2 \right] \right) \right] \right. \\
&\hphantom{\sqrt{2 \pi}\sigma \;} + \mu \left. \left[ \lim_{z \to \infty} \left( \sqrt{\frac{\pi}{2}} \sigma \cdot \mathrm{erf} \left[ \frac{1}{\sqrt{2} \sigma} z \right] \right) - \lim_{z \to -\infty} \left( \sqrt{\frac{\pi}{2}} \sigma \cdot \mathrm{erf} \left[ \frac{1}{\sqrt{2} \sigma} z \right] \right) \right] \right) \\
&= \frac{1}{\sqrt{2 \pi} \sigma} \left( [0 - 0] + \mu \left[ \sqrt{\frac{\pi}{2}} \sigma - \left(- \sqrt{\frac{\pi}{2}} \sigma \right) \right] \right) \\
&= \frac{1}{\sqrt{2 \pi} \sigma} \cdot \mu \cdot 2 \sqrt{\frac{\pi}{2}} \sigma \\
&= \mu \; .
\end{split}
\end{equation}



\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Papadopoulos, Alecos (2013): "How to derive the mean and variance of Gaussian random variable?"; in: \textit{StackExchange Mathematics}, retrieved on 2020-01-09; URL: \url{https://math.stackexchange.com/questions/518281/how-to-derive-the-mean-and-variance-of-a-gaussian-random-variable}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P15 | shortcut: norm-mean | author: JoramSoch | date: 2020-01-09, 15:04.
\vspace{1em}



\subsubsection[\textbf{Median}]{Median} \label{sec:norm-med}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}):

\begin{equation} \label{eq:norm-med-norm}
X \sim \mathcal{N}(\mu, \sigma^2) \; .
\end{equation}

Then, the median ($\rightarrow$ Definition "med") of $X$ is

\begin{equation} \label{eq:norm-med-norm-median}
\mathrm{median}(X) = \mu \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The median ($\rightarrow$ Definition "med") is the value at which the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) is $1/2$:

\begin{equation} \label{eq:norm-med-median}
F_X(\mathrm{median}(X)) = \frac{1}{2} \; .
\end{equation}

The cumulative distribution function of the normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-cdf}) is

\begin{equation} \label{eq:norm-med-norm-cdf}
F_X(x) = \frac{1}{2} \left[ 1 + \mathrm{erf} \left( \frac{x-\mu}{\sqrt{2}\sigma} \right) \right]
\end{equation}

where $\mathrm{erf}(x)$ is the error function. Thus, the inverse CDF is

\begin{equation} \label{eq:norm-med-norm-cdf-inv}
x = \sqrt{2}\sigma \cdot \mathrm{erf}^{-1}(2p-1) + \mu
\end{equation}

where $\mathrm{erf}^{-1}(x)$ is the inverse error function. Setting $p = 1/2$, we obtain:

\begin{equation} \label{eq:norm-med-norm-med-qed}
\mathrm{median}(X) = \sqrt{2}\sigma \cdot \mathrm{erf}^{-1}(0) + \mu = \mu \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P16 | shortcut: norm-med | author: JoramSoch | date: 2020-01-09, 15:33.
\vspace{1em}



\subsubsection[\textbf{Mode}]{Mode} \label{sec:norm-mode}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}):

\begin{equation} \label{eq:norm-mode-norm}
X \sim \mathcal{N}(\mu, \sigma^2) \; .
\end{equation}

Then, the mode ($\rightarrow$ Definition "mode") of $X$ is

\begin{equation} \label{eq:norm-mode-norm-mode}
\mathrm{mode}(X) = \mu \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The mode ($\rightarrow$ Definition "mode") is the value which maximizes the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}):

\begin{equation} \label{eq:norm-mode-mode}
\mathrm{mode}(X) = \operatorname*{arg\,max}_x f_X(x) \; .
\end{equation}

The probability density function of the normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-pdf}) is:

\begin{equation} \label{eq:norm-mode-norm-pdf}
f_X(x) = \frac{1}{\sqrt{2 \pi} \sigma} \cdot \exp \left[ -\frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right] \; .
\end{equation}

The first two deriatives of this function are:

\begin{equation} \label{eq:norm-mode-norm-pdf-der1}
f'_X(x) = \frac{\mathrm{d}f_X(x)}{\mathrm{d}x} = \frac{1}{\sqrt{2 \pi} \sigma^3} \cdot (-x + \mu) \cdot \exp \left[ -\frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right]
\end{equation}

\begin{equation} \label{eq:norm-mode-norm-pdf-der2}
f''_X(x) = \frac{\mathrm{d}^2f_X(x)}{\mathrm{d}x^2} = -\frac{1}{\sqrt{2 \pi} \sigma^3} \cdot \exp \left[ -\frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right] + \frac{1}{\sqrt{2 \pi} \sigma^5} \cdot (-x + \mu)^2 \cdot \exp \left[ -\frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right] \; .
\end{equation}

We now calculate the root of the first derivative \eqref{eq:norm-mode-norm-pdf-der1}:

\begin{equation} \label{eq:norm-mode-norm-mode-s1}
\begin{split}
f'_X(x) = 0 &= \frac{1}{\sqrt{2 \pi} \sigma^3} \cdot (-x + \mu) \cdot \exp \left[ -\frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right] \\
0 &= -x + \mu \\
x &= \mu \; .
\end{split}
\end{equation}

By plugging this value into the second deriative \eqref{eq:norm-mode-norm-pdf-der2},

\begin{equation} \label{eq:norm-mode-norm-mode-s2}
\begin{split}
f''_X(\mu) &= -\frac{1}{\sqrt{2 \pi} \sigma^3} \cdot \exp(0) + \frac{1}{\sqrt{2 \pi} \sigma^5} \cdot (0)^2 \cdot \exp(0) \\
&= -\frac{1}{\sqrt{2 \pi} \sigma^3} < 0 \; ,
\end{split}
\end{equation}

we confirm that it is in fact a maximum which shows that

\begin{equation} \label{eq:norm-mode-norm-mode-qed}
\mathrm{mode}(X) = \mu \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P17 | shortcut: norm-mode | author: JoramSoch | date: 2020-01-09, 15:58.
\vspace{1em}



\subsubsection[\textbf{Variance}]{Variance} \label{sec:norm-var}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}):

\begin{equation} \label{eq:norm-var-norm}
X \sim \mathcal{N}(\mu, \sigma^2) \; .
\end{equation}

Then, the variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) of $X$ is

\begin{equation} \label{eq:norm-var-norm-var}
\mathrm{Var}(X) = \sigma^2 \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) is the probability-weighted average of the squared deviation from the mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}):

\begin{equation} \label{eq:norm-var-var}
\mathrm{Var}(X) = \int_{\mathbb{R}} (x - \mathrm{E}(X))^2 \cdot f_\mathrm{X}(x) \, \mathrm{d}x \; .
\end{equation}

With the expected value ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-mean}) and probability density function ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-pdf}) of the normal distribution, this reads:

\begin{equation} \label{eq:norm-var-norm-var-s1}
\begin{split}
\mathrm{Var}(X) &= \int_{-\infty}^{+\infty} (x - \mu)^2 \cdot \frac{1}{\sqrt{2 \pi} \sigma} \cdot \exp \left[ -\frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right] \, \mathrm{d}x \\
&= \frac{1}{\sqrt{2 \pi} \sigma} \int_{-\infty}^{+\infty} (x - \mu)^2 \cdot \exp \left[ -\frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right] \, \mathrm{d}x \; .
\end{split}
\end{equation}

Substituting $z = x -\mu$, we have:

\begin{equation} \label{eq:norm-var-norm-var-s2}
\begin{split}
\mathrm{Var}(X) &= \frac{1}{\sqrt{2 \pi} \sigma} \int_{-\infty-\mu}^{+\infty-\mu} z^2 \cdot \exp \left[ -\frac{1}{2} \left( \frac{z}{\sigma} \right)^2 \right] \, \mathrm{d}(z + \mu) \\
&= \frac{1}{\sqrt{2 \pi} \sigma} \int_{-\infty}^{+\infty} z^2 \cdot \exp \left[ -\frac{1}{2} \left( \frac{z}{\sigma} \right)^2 \right] \, \mathrm{d}z \; .
\end{split}
\end{equation}

Now substituting $z = \sqrt{2} \sigma x$, we have:

\begin{equation} \label{eq:norm-var-norm-var-s3}
\begin{split}
\mathrm{Var}(X) &= \frac{1}{\sqrt{2 \pi} \sigma} \int_{-\infty}^{+\infty} (\sqrt{2} \sigma x)^2 \cdot \exp \left[ -\frac{1}{2} \left( \frac{\sqrt{2} \sigma x}{\sigma} \right)^2 \right] \, \mathrm{d}(\sqrt{2} \sigma x) \\
&= \frac{1}{\sqrt{2 \pi} \sigma} \cdot 2 \sigma^2 \cdot \sqrt{2} \sigma \int_{-\infty}^{+\infty} x^2 \cdot \exp \left[ -x^2 \right] \, \mathrm{d}x \\
&= \frac{2 \sigma^2}{\sqrt{\pi}} \int_{-\infty}^{+\infty} x^2 \cdot e^{-x^2} \, \mathrm{d}x \; .
\end{split}
\end{equation}

Since the integrand is symmetric with respect to $x = 0$, we can write:

\begin{equation} \label{eq:norm-var-norm-var-s4}
\mathrm{Var}(X) = \frac{4 \sigma^2}{\sqrt{\pi}} \int_{0}^{\infty} x^2 \cdot e^{-x^2} \, \mathrm{d}x \; .
\end{equation}

If we define $z = x^2$, then $x = \sqrt{z}$ and $\mathrm{d}x = 1/2 \, z^{-1/2} \, \mathrm{d}z$. Substituting this into the integral

\begin{equation} \label{eq:norm-var-norm-var-s5}
\mathrm{Var}(X) = \frac{4 \sigma^2}{\sqrt{\pi}} \int_{0}^{\infty} z \cdot e^{-z} \cdot \frac{1}{2} z^{-\frac{1}{2}} \, \mathrm{d}z = \frac{2 \sigma^2}{\sqrt{\pi}} \int_{0}^{\infty} z^{\frac{3}{2}-1} \cdot e^{-z} \, \mathrm{d}z
\end{equation}

and using the definition of the gamma function

\begin{equation} \label{eq:norm-var-gam-fct}
\Gamma(x) = \int_{0}^{\infty} z^{x-1} \cdot e^{-z} \, \mathrm{d}z \; ,
\end{equation}

we can finally show that

\begin{equation} \label{eq:norm-var-norm-var-s6}
\mathrm{Var}(X) = \frac{2 \sigma^2}{\sqrt{\pi}} \cdot \Gamma\!\left(\frac{3}{2}\right) = \frac{2 \sigma^2}{\sqrt{\pi}} \cdot \frac{\sqrt{\pi}}{2} = \sigma^2 \; .
\end{equation}



\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Papadopoulos, Alecos (2013): "How to derive the mean and variance of Gaussian random variable?"; in: \textit{StackExchange Mathematics}, retrieved on 2020-01-09; URL: \url{https://math.stackexchange.com/questions/518281/how-to-derive-the-mean-and-variance-of-a-gaussian-random-variable}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P18 | shortcut: norm-var | author: JoramSoch | date: 2020-01-09, 22:47.
\vspace{1em}



\subsubsection[\textbf{Full width at half maximum}]{Full width at half maximum} \label{sec:norm-fwhm}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}):

\begin{equation} \label{eq:norm-fwhm-norm}
X \sim \mathcal{N}(\mu, \sigma^2) \; .
\end{equation}

Then, the full width at half maximum ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:fwhm}) (FWHM) of $X$ is

\begin{equation} \label{eq:norm-fwhm-norm-fwhm}
\mathrm{FWHM}(X) = 2 \sqrt{2 \ln 2} \sigma \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The probability density function of the normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-pdf}) is

\begin{equation} \label{eq:norm-fwhm-norm-pdf}
f_X(x) = \frac{1}{\sqrt{2 \pi} \sigma} \cdot \exp \left[ -\frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right]
\end{equation}

and the mode of the normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-mode}) is

\begin{equation} \label{eq:norm-fwhm-norm-mode}
\mathrm{mode}(X) = \mu \; ,
\end{equation}

such that

\begin{equation} \label{eq:norm-fwhm-norm-pdf-max}
f_\mathrm{max} = f_X(\mathrm{mode}(X)) \overset{\eqref{eq:norm-fwhm-norm-mode}}{=} f_X(\mu) \overset{\eqref{eq:norm-fwhm-norm-pdf}}{=} \frac{1}{\sqrt{2 \pi} \sigma} \; .
\end{equation}

The FWHM bounds satisfy the equation ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:fwhm})

\begin{equation} \label{eq:norm-fwhm-x-FHWM}
f_X(x_\mathrm{FWHM}) = \frac{1}{2} f_\mathrm{max} \overset{\eqref{eq:norm-fwhm-norm-pdf-max}}{=} \frac{1}{2 \sqrt{2 \pi} \sigma} \; .
\end{equation}

Using \eqref{eq:norm-fwhm-norm-pdf}, we can develop this equation as follows:

\begin{equation} \label{eq:norm-fwhm-x-FHWM-s1}
\begin{split}
\frac{1}{\sqrt{2 \pi} \sigma} \cdot \exp \left[ -\frac{1}{2} \left( \frac{x_\mathrm{FWHM}-\mu}{\sigma} \right)^2 \right] &= \frac{1}{2 \sqrt{2 \pi} \sigma} \\
\exp \left[ -\frac{1}{2} \left( \frac{x_\mathrm{FWHM}-\mu}{\sigma} \right)^2 \right] &= \frac{1}{2} \\
-\frac{1}{2} \left( \frac{x_\mathrm{FWHM}-\mu}{\sigma} \right)^2 &= \ln \frac{1}{2} \\
\left( \frac{x_\mathrm{FWHM}-\mu}{\sigma} \right)^2 &= -2 \ln \frac{1}{2} \\
\frac{x_\mathrm{FWHM}-\mu}{\sigma} &= \pm \sqrt{2 \ln 2} \\
x_\mathrm{FWHM}-\mu &= \pm \sqrt{2 \ln 2} \sigma \\
x_\mathrm{FWHM} &= \pm \sqrt{2 \ln 2} \sigma + \mu \; .
\end{split}
\end{equation}

This implies the following two solutions for $x_\mathrm{FWHM}$

\begin{equation} \label{eq:norm-fwhm-x-FHWM-s2}
\begin{split}
x_1 &= \mu - \sqrt{2 \ln 2} \sigma \\
x_2 &= \mu + \sqrt{2 \ln 2} \sigma \; ,
\end{split}
\end{equation}

such that the full width at half maximum ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:fwhm}) of $X$ is

\begin{equation} \label{eq:norm-fwhm-norm-fwhm-qed}
\begin{split}
\mathrm{FWHM}(X) &= \Delta x = x_2 - x_1 \\
&\overset{\eqref{eq:norm-fwhm-x-FHWM-s2}}{=} \left( \mu + \sqrt{2 \ln 2} \sigma \right) - \left( \mu - \sqrt{2 \ln 2} \sigma \right) \\
&= 2 \sqrt{2 \ln 2} \sigma \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Full width at half maximum"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-08-19; URL: \url{https://en.wikipedia.org/wiki/Full_width_at_half_maximum}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P152 | shortcut: norm-fwhm | author: JoramSoch | date: 2020-08-19, 06:39.
\vspace{1em}



\subsubsection[\textbf{Differential entropy}]{Differential entropy} \label{sec:norm-dent}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}):

\begin{equation} \label{eq:norm-dent-norm}
X \sim \mathcal{N}(\mu, \sigma^2) \; .
\end{equation}

Then, the differential entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent}) of $X$ is

\begin{equation} \label{eq:norm-dent-norm-dent}
\mathrm{h}(X) = \frac{1}{2} \ln\left( 2 \pi \sigma^2 e \right) \; .
\end{equation}

\vspace{1em}
\textbf{Proof:} The differential entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent}) of a random variable is defined as

\begin{equation} \label{eq:norm-dent-dent}
\mathrm{h}(X) = - \int_{\mathcal{X}} p(x) \, \log_b p(x) \, \mathrm{d}x \; .
\end{equation}

To measure $h(X)$ in nats, we set $b = e$, such that ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean})

\begin{equation} \label{eq:norm-dent-dent-nats}
\mathrm{h}(X) = - \mathrm{E}\left[ \ln p(x) \right] \; .
\end{equation}

With the probability density function of the normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-pdf}), the differential entropy of $X$ is:

\begin{equation} \label{eq:norm-dent-mvn-dent-s1}
\begin{split}
\mathrm{h}(X) &= - \mathrm{E}\left[ \ln \left( \frac{1}{\sqrt{2 \pi} \sigma} \cdot \exp \left[ -\frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right] \right) \right] \\
&= - \mathrm{E}\left[ - \frac{1}{2} \ln(2\pi\sigma^2) - \frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right] \\
&= \frac{1}{2} \ln(2 \pi \sigma^2) + \frac{1}{2} \, \mathrm{E}\left[ \left( \frac{x-\mu}{\sigma} \right)^2 \right] \\
&= \frac{1}{2} \ln(2 \pi \sigma^2) + \frac{1}{2} \cdot \frac{1}{\sigma^2} \cdot \mathrm{E}\left[ (x-\mu)^2 \right] \\
&= \frac{1}{2} \ln(2 \pi \sigma^2) + \frac{1}{2} \cdot \frac{1}{\sigma^2} \cdot \sigma^2 \\
&= \frac{1}{2} \ln(2 \pi \sigma^2) + \frac{1}{2} \\
&= \frac{1}{2} \ln(2 \pi \sigma^2 e) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wang, Peng-Hua (2012): "Differential Entropy"; in: \textit{National Taipei University}; URL: \url{https://web.ntpu.edu.tw/~phwang/teaching/2012s/IT/slides/chap08.pdf}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P101 | shortcut: norm-dent | author: JoramSoch | date: 2020-05-14, 20:09.
\vspace{1em}



\subsubsection[\textbf{Moment-generating function}]{Moment-generating function} \label{sec:norm-mgf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}):

\begin{equation} \label{eq:norm-mgf-norm}
X \sim \mathcal{N}(\mu, \sigma^2) \; .
\end{equation}

Then, the moment-generating function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mgf}) of $X$ is

\begin{equation} \label{eq:norm-mgf-norm-mgf}
M_X(t) = \exp\left[ \mu t + \frac{1}{2} \sigma^2 t^2 \right] \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The probability density function of the normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:norm-pdf}) is

\begin{equation} \label{eq:norm-mgf-norm-pdf}
f_X(x) = \frac{1}{\sqrt{2 \pi} \sigma} \cdot \exp \left[ -\frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right]
\end{equation}

and the moment-generating function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mgf}) is defined as

\begin{equation} \label{eq:norm-mgf-mgf-var}
M_X(t) = \mathrm{E} \left[ e^{tX} \right] \; .
\end{equation}

Using the expected value for continuous random variables ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}), the moment-generating function of $X$ therefore is

\begin{equation} \label{eq:norm-mgf-norm-mgf-s1}
\begin{split}
M_X(t) &= \int_{-\infty}^{+\infty} \exp[tx] \cdot \frac{1}{\sqrt{2 \pi} \sigma} \cdot \exp \left[ -\frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right] \, \mathrm{d}x \\
&= \frac{1}{\sqrt{2 \pi} \sigma} \int_{-\infty}^{+\infty} \exp\left[ tx - \frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right] \, \mathrm{d}x \; .
\end{split}
\end{equation}

Substituting $u = (x-\mu)/(\sqrt{2}\sigma)$, i.e. $x = \sqrt{2}\sigma u + \mu$, we have

\begin{equation} \label{eq:norm-mgf-norm-mgf-s2}
\begin{split}
M_X(t) &= \frac{1}{\sqrt{2 \pi} \sigma} \int_{(-\infty-\mu)/(\sqrt{2}\sigma)}^{(+\infty-\mu)/(\sqrt{2}\sigma)} \exp\left[ t\left( \sqrt{2} \sigma u + \mu \right) - \frac{1}{2} \left( \frac{ \sqrt{2} \sigma u + \mu - \mu}{\sigma} \right)^2 \right] \, \mathrm{d}\left( \sqrt{2} \sigma u + \mu \right) \\
&= \frac{\sqrt{2} \sigma}{\sqrt{2 \pi} \sigma} \int_{-\infty}^{+\infty} \exp\left[ \left( \sqrt{2} \sigma u + \mu \right) t - u^2 \right] \, \mathrm{d}u \\
&= \frac{\exp(\mu t)}{\sqrt{\pi}} \int_{-\infty}^{+\infty} \exp\left[ \sqrt{2} \sigma u t - u^2 \right] \, \mathrm{d}u \\
&= \frac{\exp(\mu t)}{\sqrt{\pi}} \int_{-\infty}^{+\infty} \exp\left[ - \left( u^2 - \sqrt{2} \sigma u t \right) \right] \, \mathrm{d}u \\
&= \frac{\exp(\mu t)}{\sqrt{\pi}} \int_{-\infty}^{+\infty} \exp\left[ - \left( u - \frac{\sqrt{2}}{2} \sigma t \right)^2 + \frac{1}{2} \sigma^2 t^2 \right] \, \mathrm{d}u \\
&= \frac{\exp\left[ \mu t + \frac{1}{2} \sigma^2 t^2 \right]}{\sqrt{\pi}} \int_{-\infty}^{+\infty} \exp\left[ - \left( u - \frac{\sqrt{2}}{2} \sigma t \right)^2 \right] \, \mathrm{d}u
\end{split}
\end{equation}

Now substituting $v = u - \sqrt{2}/2 \, \sigma t$, i.e. $u = v + \sqrt{2}/2 \, \sigma t$, we have

\begin{equation} \label{eq:norm-mgf-norm-mgf-s3}
\begin{split}
M_X(t) &= \frac{\exp\left[ \mu t + \frac{1}{2} \sigma^2 t^2 \right]}{\sqrt{\pi}} \int_{-\infty - \sqrt{2}/2 \, \sigma t}^{+\infty - \sqrt{2}/2 \, \sigma t} \exp\left[ -v^2 \right] \, \mathrm{d}\left( v + \sqrt{2}/2 \, \sigma t \right) \\
&= \frac{\exp\left[ \mu t + \frac{1}{2} \sigma^2 t^2 \right]}{\sqrt{\pi}} \int_{-\infty}^{+\infty} \exp\left[ -v^2 \right] \, \mathrm{d}v \; .
\end{split}
\end{equation}

With the Gaussian integral ($\rightarrow$ Proof "norm-gi")

\begin{equation} \label{eq:norm-mgf-gauss}
\int_{-\infty}^{+\infty} \exp\left[ -x^2 \right] \, \mathrm{d}x = \sqrt{\pi} \; ,
\end{equation}

this finally becomes

\begin{equation} \label{eq:norm-mgf-norm-mgf-qed}
M_X(t) = \exp\left[ \mu t + \frac{1}{2} \sigma^2 t^2 \right] \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item ProofWiki (2020): "Moment Generating Function of Gaussian Distribution"; in: \textit{ProofWiki}, retrieved on 2020-03-03; URL: \url{https://proofwiki.org/wiki/Moment_Generating_Function_of_Gaussian_Distribution}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P71 | shortcut: norm-mgf | author: JoramSoch | date: 2020-03-03, 11:29.
\vspace{1em}



\subsection{Gamma distribution}

\subsubsection[\textit{Definition}]{Definition} \label{sec:gam}
\setcounter{equation}{0}

**Definition**: Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}). Then, $X$ is said to follow a gamma distribution with shape $a$ and rate $b$

\begin{equation} \label{eq:gam-gam}
X \sim \mathrm{Gam}(a, b) \; ,
\end{equation}

if and only if its probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) is given by

\begin{equation} \label{eq:gam-gam-pdf}
\mathrm{Gam}(x; a, b) = \frac{b^a}{\Gamma(a)} x^{a-1} \exp[-b x], \quad x > 0
\end{equation}

where $a > 0$ and $b > 0$, and the density is zero, if $x \leq 0$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Koch, Karl-Rudolf (2007): "Gamma Distribution"; in: \textit{Introduction to Bayesian Statistics}, Springer, Berlin/Heidelberg, 2007, p. 47, eq. 2.172; URL: \url{https://www.springer.com/de/book/9783540727231}; DOI: 10.1007/978-3-540-72726-2.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D7 | shortcut: gam | author: JoramSoch | date: 2020-02-08, 23:29.
\vspace{1em}



\subsubsection[\textit{Standard gamma distribution}]{Standard gamma distribution} \label{sec:sgam}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}). Then, $X$ is said to have a standard gamma distribution, if $X$ follows a gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:gam}) with shape $a > 0$ and rate $b = 1$:

\begin{equation} \label{eq:sgam-sgam}
X \sim \mathrm{Gam}(a, 1) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item JoramSoch (2017): "Gamma-distributed random numbers"; in: \textit{MACS – a new SPM toolbox for model assessment, comparison and selection}, retrieved on 2020-05-26; URL: \url{https://github.com/JoramSoch/MACS/blob/master/MD_gamrnd.m}; DOI: 10.5281/zenodo.845404.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D64 | shortcut: sgam | author: JoramSoch | date: 2020-05-26, 23:36.
\vspace{1em}



\subsubsection[\textbf{Relation to standard gamma distribution}]{Relation to standard gamma distribution} \label{sec:gam-sgam}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:gam}) with shape $a$ and rate $b$:

\begin{equation} \label{eq:gam-sgam-X-gam}
X \sim \mathrm{Gam}(a,b) \; .
\end{equation}

Then, the quantity $Z = b X$ will have a standard gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:sgam}) with shape $a$ and rate $1$:

\begin{equation} \label{eq:gam-sgam-Z-snorm}
Z = b X \sim \mathrm{Gam}(a,1) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} Rearranging to get $X$ in terms of $Z$, we have

\begin{equation} \label{eq:gam-sgam-X-Z}
X = \frac{1}{b} Z \; .
\end{equation}

The cumulative distribution function of the gamma-distributed ($\rightarrow$ Proof "gam-cdf") $X$ is

\begin{equation} \label{eq:gam-sgam-gam-cdf}
F_X(t) = \int_{-\infty}^{t} \frac{b^a}{\Gamma(a)} x^{a-1} \exp[-b x] \, \mathrm{d}x \; .
\end{equation}

Substituting \eqref{eq:gam-sgam-X-Z} into \eqref{eq:gam-sgam-gam-cdf}, we obtain

\begin{equation} \label{eq:gam-sgam-sgam-cdf}
\begin{split}
F_Z(t) &= \int_{-\infty}^{t} \frac{b^a}{\Gamma(a)} \left(\frac{1}{b} z\right)^{a-1} \exp\left[-b \left(\frac{1}{b} z\right)\right] \, \mathrm{d}\left(\frac{1}{b} z\right) \\
&= \int_{-\infty}^{t} \frac{b^a}{b} \left(\frac{1}{b}\right)^{a-1} \cdot \frac{1}{\Gamma(a)} z^{a-1} \exp[-z] \, \mathrm{d}z \\
&= \int_{-\infty}^{t} \frac{1}{\Gamma(a)} z^{a-1} \exp[-z] \, \mathrm{d}z
\end{split}
\end{equation}

which is the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) of the standard gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:sgam}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P112 | shortcut: gam-sgam | author: JoramSoch | date: 2020-05-26, 23:14.
\vspace{1em}



\subsubsection[\textbf{Probability density function}]{Probability density function} \label{sec:gam-pdf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a positive random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:gam}):

\begin{equation} \label{eq:gam-pdf-gam}
X \sim \mathrm{Gam}(a, b) \; .
\end{equation}

Then, the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $X$ is

\begin{equation} \label{eq:gam-pdf-gam-pdf}
f_X(x) = \frac{b^a}{\Gamma(a)} x^{a-1} \exp[-b x] \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} This follows directly from the definition of the gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:gam}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P45 | shortcut: gam-pdf | author: JoramSoch | date: 2020-02-08, 23:41.
\vspace{1em}



\subsubsection[\textbf{Mean}]{Mean} \label{sec:gam-mean}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:gam}):

\begin{equation} \label{eq:gam-mean-gam}
X \sim \mathrm{Gam}(a, b) \; .
\end{equation}

Then, the mean or expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of $X$ is

\begin{equation} \label{eq:gam-mean-gam-mean}
\mathrm{E}(X) = \frac{a}{b} \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) is the probability-weighted average over all possible values:

\begin{equation} \label{eq:gam-mean-mean}
\mathrm{E}(X) = \int_{\mathbb{R}} x \cdot f_X(x) \, \mathrm{d}x \; .
\end{equation}

With the probability density function of the gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-pdf}), this reads:

\begin{equation} \label{eq:gam-mean-gam-mean-s1}
\begin{split}
\mathrm{E}(X) &= \int_{0}^{\infty} x \cdot \frac{b^a}{\Gamma(a)} x^{a-1} \exp[-b x] \, \mathrm{d}x \\
&= \int_{0}^{\infty} \frac{b^a}{\Gamma(a)} x^{(a+1)-1} \exp[-b x] \, \mathrm{d}x \\
&= \int_{0}^{\infty} \frac{1}{b} \cdot \frac{b^{a+1}}{\Gamma(a)} x^{(a+1)-1} \exp[-b x] \, \mathrm{d}x \; .
\end{split}
\end{equation}

Employing the relation $\Gamma(x+1) = \Gamma(x) \cdot x$, we have

\begin{equation} \label{eq:gam-mean-gam-mean-s2}
\mathrm{E}(X) = \int_{0}^{\infty} \frac{a}{b} \cdot \frac{b^{a+1}}{\Gamma(a+1)} x^{(a+1)-1} \exp[-b x] \, \mathrm{d}x
\end{equation}

and again using the density of the gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-pdf}), we get

\begin{equation} \label{eq:gam-mean-gam-mean-s3}
\begin{split}
\mathrm{E}(X) &= \frac{a}{b} \int_{0}^{\infty} \mathrm{Gam}(x; a+1, b) \, \mathrm{d}x \\
&= \frac{a}{b} \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Turlapaty, Anish (2013): "Gamma random variable: mean \& variance"; in: \textit{YouTube}, retrieved on 2020-05-19; URL: \url{https://www.youtube.com/watch?v=Sy4wP-Y2dmA}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P108 | shortcut: gam-mean | author: JoramSoch | date: 2020-05-19, 06:54.
\vspace{1em}



\subsubsection[\textbf{Variance}]{Variance} \label{sec:gam-var}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:gam}):

\begin{equation} \label{eq:gam-var-gam}
X \sim \mathrm{Gam}(a, b) \; .
\end{equation}

Then, the variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) of $X$ is

\begin{equation} \label{eq:gam-var-gam-var}
\mathrm{Var}(X) = \frac{a}{b^2} \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) can be expressed in terms of expected values ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:var-mean}) as

\begin{equation} \label{eq:gam-var-var-mean}
\mathrm{Var}(X) = \mathrm{E}(X^2) - \mathrm{E}(X)^2 \; .
\end{equation}

The expected value of a gamma random variable ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-mean}) is

\begin{equation} \label{eq:gam-var-gam-mean}
\mathrm{E}(X) = \frac{a}{b} \; .
\end{equation}

With the probability density function of the gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-pdf}), the expected value of a squared gamma random variable is

\begin{equation} \label{eq:gam-var-gam-sqr-mean-s1}
\begin{split}
\mathrm{E}(X^2) &= \int_{0}^{\infty} x^2 \cdot \frac{b^a}{\Gamma(a)} x^{a-1} \exp[-b x] \, \mathrm{d}x \\
&= \int_{0}^{\infty} \frac{b^a}{\Gamma(a)} x^{(a+2)-1} \exp[-b x] \, \mathrm{d}x \\
&= \int_{0}^{\infty} \frac{1}{b^2} \cdot \frac{b^{a+2}}{\Gamma(a)} x^{(a+2)-1} \exp[-b x] \, \mathrm{d}x \; .
\end{split}
\end{equation}

Twice-applying the relation $\Gamma(x+1) = \Gamma(x) \cdot x$, we have

\begin{equation} \label{eq:gam-var-gam-sqr-mean-s2}
\mathrm{E}(X^2) = \int_{0}^{\infty} \frac{a \, (a+1)}{b^2} \cdot \frac{b^{a+2}}{\Gamma(a+2)} x^{(a+2)-1} \exp[-b x] \, \mathrm{d}x
\end{equation}

and again using the density of the gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-pdf}), we get

\begin{equation} \label{eq:gam-var-gam-sqr-mean-s3}
\begin{split}
\mathrm{E}(X^2) &= \frac{a \, (a+1)}{b^2} \int_{0}^{\infty} \mathrm{Gam}(x; a+2, b) \, \mathrm{d}x \\
&= \frac{a^2+a}{b^2} \; .
\end{split}
\end{equation}

Plugging \eqref{eq:gam-var-gam-sqr-mean-s3} and \eqref{eq:gam-var-gam-mean} into \eqref{eq:gam-var-var-mean}, the variance of a gamma random variable finally becomes

\begin{equation} \label{eq:gam-var-gam-var-qed}
\begin{split}
\mathrm{Var}(X) &= \frac{a^2+a}{b^2} - \left( \frac{a}{b} \right)^2 \\
&= \frac{a}{b^2} \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Turlapaty, Anish (2013): "Gamma random variable: mean \& variance"; in: \textit{YouTube}, retrieved on 2020-05-19; URL: \url{https://www.youtube.com/watch?v=Sy4wP-Y2dmA}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P109 | shortcut: gam-var | author: JoramSoch | date: 2020-05-19, 07:20.
\vspace{1em}



\subsubsection[\textbf{Logarithmic expectation}]{Logarithmic expectation} \label{sec:gam-logmean}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:gam}):

\begin{equation} \label{eq:gam-logmean-gam}
X \sim \mathrm{Gam}(a, b) \; .
\end{equation}

Then, the expectation ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of the natural logarithm of $X$ is

\begin{equation} \label{eq:gam-logmean-gam-logmean}
\mathrm{E}(\ln X) = \psi(a) - \ln(b) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} Let $Y = \ln(X)$, such that $\mathrm{E}(Y) = \mathrm{E}(\ln X)$ and consider the special case that $b = 1$. In this case, the probability density function of the gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-pdf}) is

\begin{equation} \label{eq:gam-logmean-X-pdf-s1}
f_X(x) = \frac{1}{\Gamma(a)} \, x^{a-1} \, \mathrm{exp} [-x] \; .
\end{equation}

Multiplying this function with $\mathrm{d}x$, we obtain

\begin{equation} \label{eq:gam-logmean-X-pdf-s2}
f_X(x) \, \mathrm{d}x = \frac{1}{\Gamma(a)} \, x^a \, \mathrm{exp} [-x] \, \frac{\mathrm{d}x}{x} \; .
\end{equation}

Substituting $y = \ln x$, i.e. $x = e^y$, such that $\mathrm{d}x/\mathrm{d}y = x$, i.e. $\mathrm{d}x/x = \mathrm{d}y$, we get

\begin{equation} \label{eq:gam-logmean-Y-pdf-s1}
\begin{split}
f_Y(y) \, \mathrm{d}y &= \frac{1}{\Gamma(a)} \, \left( e^y \right)^a \, \mathrm{exp} [-e^y] \, \mathrm{d}y \\
&= \frac{1}{\Gamma(a)} \, \mathrm{exp}\left[ ay - e^y \right] \, \mathrm{d}y \; .
\end{split}
\end{equation}

Because $f_Y(y)$ integrates to one, we have

\begin{equation} \label{eq:gam-logmean-Y-pdf-s2}
\begin{split}
1 &= \int_{\mathbb{R}} f_Y(y) \, \mathrm{d}y \\
1 &= \int_{\mathbb{R}} \frac{1}{\Gamma(a)} \, \mathrm{exp}\left[ ay - e^y \right] \, \mathrm{d}y \\
\Gamma(a) &= \int_{\mathbb{R}} \mathrm{exp}\left[ ay - e^y \right] \, \mathrm{d}y \; .
\end{split}
\end{equation}

Note that the integrand in \eqref{eq:gam-logmean-Y-pdf-s2} is differentiable with respect to $a$:

\begin{equation} \label{eq:gam-logmean-dfy-da}
\begin{split}
\frac{\mathrm{d}}{\mathrm{d}a} \mathrm{exp}\left[ ay - e^y \right] \, \mathrm{d}y &= y \, \mathrm{exp}\left[ ay - e^y \right] \, \mathrm{d}y \\
&\overset{\eqref{eq:gam-logmean-Y-pdf-s1}}{=} \Gamma(a) \, y \, f_Y(y) \, \mathrm{d}y \; .
\end{split}
\end{equation}

Now we can calculate the expected value of $Y = \ln(X)$:

\begin{equation} \label{eq:gam-logmean-E-Y-s1}
\begin{split}
\mathrm{E}(Y) &= \int_{\mathbb{R}} y \, f_Y(y) \, \mathrm{d}y \\
&\overset{\eqref{eq:gam-logmean-dfy-da}}{=} \frac{1}{\Gamma(a)} \int_{\mathbb{R}} \frac{\mathrm{d}}{\mathrm{d}a} \mathrm{exp}\left[ ay - e^y \right] \, \mathrm{d}y \\
&= \frac{1}{\Gamma(a)} \frac{\mathrm{d}}{\mathrm{d}a} \int_{\mathbb{R}} \mathrm{exp}\left[ ay - e^y \right] \, \mathrm{d}y \\
&\overset{\eqref{eq:gam-logmean-Y-pdf-s2}}{=} \frac{1}{\Gamma(a)} \frac{\mathrm{d}}{\mathrm{d}a} \Gamma(a) \\
&= \frac{\Gamma'(a)}{\Gamma(a)} \; .
\end{split}
\end{equation}

Using the derivative of a logarithmized function

\begin{equation} \label{eq:gam-logmean-log-der}
\frac{\mathrm{d}}{\mathrm{d}x} \ln f(x) = \frac{f'(x)}{f(x)}
\end{equation}

and the definition of the digamma function

\begin{equation} \label{eq:gam-logmean-psi}
\psi(x) = \frac{\mathrm{d}}{\mathrm{d}x} \ln \Gamma(x) \; ,
\end{equation}

we have

\begin{equation} \label{eq:gam-logmean-E-Y-s2}
\mathrm{E}(Y) = \psi(a) \; .
\end{equation}

Finally, noting that $1/b$ acts as a scaling parameter ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-sgam}) on a gamma-distributed ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:gam}) random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}),

\begin{equation} \label{eq:gam-logmean-gam-sgam}
X \sim \mathrm{Gam}(a,1) \quad \Rightarrow \quad \frac{1}{b} X \sim \mathrm{Gam}(a,b) \; ,
\end{equation}

and that a scaling parameter acts additively on the logarithmic expectation of a random variable,

\begin{equation} \label{eq:gam-logmean-logmean}
\mathrm{E}\left[\ln(cX)\right] = \mathrm{E}\left[\ln(X) + \ln(c)\right] = \mathrm{E}\left[\ln(X)\right] + \ln(c) \; ,
\end{equation}

it follows that

\begin{equation} \label{eq:gam-logmean-E-Y-s3}
X \sim \mathrm{Gam}(a,b) \quad \Rightarrow \quad \mathrm{E}(\ln X) = \psi(a) - \ln(b) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item whuber (2018): "What is the expected value of the logarithm of Gamma distribution?"; in: \textit{StackExchange CrossValidated}, retrieved on 2020-05-25; URL: \url{https://stats.stackexchange.com/questions/370880/what-is-the-expected-value-of-the-logarithm-of-gamma-distribution}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P110 | shortcut: gam-logmean | author: JoramSoch | date: 2020-05-25, 21:28.
\vspace{1em}



\subsubsection[\textbf{Kullback-Leibler divergence}]{Kullback-Leibler divergence} \label{sec:gam-kl}
\setcounter{equation}{0}

\textbf{Theorem:} Let $x$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}). Assume two gamma distributions ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:gam}) $P$ and $Q$ specifying the probability distribution of $x$ as

\begin{equation} \label{eq:gam-kl-gams}
\begin{split}
P: \; x &\sim \mathrm{Gam}(a_1, b_1) \\
Q: \; x &\sim \mathrm{Gam}(a_2, b_2) \; . \\
\end{split}
\end{equation}

Then, the Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) of $P$ from $Q$ is given by

\begin{equation} \label{eq:gam-kl-gam-KL}
\mathrm{KL}[P\,||\,Q] = a_2 \, \ln \frac{b_1}{b_2} - \ln \frac{\Gamma(a_1)}{\Gamma(a_2)} + (a_1 - a_2) \, \psi(a_1) - (b_1 - b_2) \, \frac{a_1}{b_1} \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The KL divergence for a continuous random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) is given by 

\begin{equation} \label{eq:gam-kl-KL-cont}
\mathrm{KL}[P\,||\,Q] = \int_{\mathcal{X}} p(x) \, \ln \frac{p(x)}{q(x)} \, \mathrm{d}x
\end{equation}

which, applied to the gamma distributions ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:gam}) in \eqref{eq:gam-kl-gams}, yields

\begin{equation} \label{eq:gam-kl-gam-KL-s1}
\begin{split}
\mathrm{KL}[P\,||\,Q] &= \int_{-\infty}^{+\infty} \mathrm{Gam}(x; a_1, b_1) \, \ln \frac{\mathrm{Gam}(x; a_1, b_1)}{\mathrm{Gam}(x; a_2, b_2)} \, \mathrm{d}x \\
&= \left\langle \ln \frac{\mathrm{Gam}(x; a_1, b_1)}{\mathrm{Gam}(x; a_2, b_2)} \right\rangle_{p(x)} \; .
\end{split}
\end{equation}

Using the probability density function of the gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-pdf}), this becomes:

\begin{equation} \label{eq:gam-kl-gam-KL-s2}
\begin{split}
\mathrm{KL}[P\,||\,Q] &= \left\langle \ln \frac{ \frac{ {b_1}^{a_1}}{\Gamma(a_1)} x^{a_1-1} \exp[-b_1 x] }{ \frac{ {b_2}^{a_2}}{\Gamma(a_2)} x^{a_2-1} \exp[-b_2 x] } \right\rangle_{p(x)} \\
&= \left\langle \ln \left( \frac{ {b_1}^{a_1}}{ {b_2}^{a_2}} \cdot \frac{\Gamma(a_2)}{\Gamma(a_1)} \cdot x^{a_1-a_2} \cdot \exp[-(b_1-b_2) x] \right) \right\rangle_{p(x)} \\
&= \left\langle a_1 \cdot \ln b_1 - a_2 \cdot \ln b_2 - \ln \Gamma(a_1) + \ln \Gamma(a_2) + (a_1-a_2) \cdot \ln x - (b_1-b_2) \cdot x \right\rangle_{p(x)} \; .
\end{split}
\end{equation}

Using the mean of the gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-mean}) and the expected value of a logarithmized gamma variate ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-logmean})

\begin{equation} \label{eq:gam-kl-gam-means}
\begin{split}
x \sim \mathrm{Gam}(a,b) \quad \Rightarrow \quad &\left\langle x \right\rangle = \frac{a}{b} \quad \text{and} \\
&\left\langle \ln x \right\rangle = \psi(a) - \ln(b) \; ,
\end{split}
\end{equation}

the Kullback-Leibler divergence from \eqref{eq:gam-kl-gam-KL-s2} becomes:

\begin{equation} \label{eq:gam-kl-gam-KL-s3}
\begin{split}
\mathrm{KL}[P\,||\,Q] &= a_1 \cdot \ln b_1 - a_2 \cdot \ln b_2 - \ln \Gamma(a_1) + \ln \Gamma(a_2) + (a_1-a_2) \cdot \left( \psi(a_1) - \ln(b_1) \right) - (b_1-b_2) \cdot \frac{a_1}{b_1} \\
&= a_2 \cdot \ln b_1 - a_2 \cdot \ln b_2 - \ln \Gamma(a_1) + \ln \Gamma(a_2) + (a_1-a_2) \cdot \psi(a_1) - (b_1-b_2) \cdot \frac{a_1}{b_1} \; .
\end{split}
\end{equation}

Finally, combining the logarithms, we get:

\begin{equation} \label{eq:gam-kl-gam-KL-qed}
\mathrm{KL}[P\,||\,Q] = a_2 \, \ln \frac{b_1}{b_2} - \ln \frac{\Gamma(a_1)}{\Gamma(a_2)} + (a_1 - a_2) \, \psi(a_1) - (b_1 - b_2) \, \frac{a_1}{b_1} \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Penny, William D. (2001): "KL-Divergences of Normal, Gamma, Dirichlet and Wishart densities"; in: \textit{University College, London}; URL: \url{https://www.fil.ion.ucl.ac.uk/~wpenny/publications/densities.ps}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P93 | shortcut: gam-kl | author: JoramSoch | date: 2020-05-05, 08:41.
\vspace{1em}



\subsection{Exponential distribution}

\subsubsection[\textit{Definition}]{Definition} \label{sec:exp}
\setcounter{equation}{0}

**Definition**: Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}). Then, $X$ is said to be exponentially distributed with rate (or, inverse scale) $\lambda$

\begin{equation} \label{eq:exp-exp}
X \sim \mathrm{Exp}(\lambda) \; ,
\end{equation}

if and only if its probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) is given by

\begin{equation} \label{eq:exp-exp-pdf}
\mathrm{Exp}(x; \lambda) = \lambda \exp[-\lambda x], \quad x \geq 0
\end{equation}

where $\lambda > 0$, and the density is zero, if $x < 0$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Exponential distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-02-08; URL: \url{https://en.wikipedia.org/wiki/Exponential_distribution#Definitions}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D8 | shortcut: exp | author: JoramSoch | date: 2020-02-08, 23:48.
\vspace{1em}



\subsubsection[\textbf{Special case of gamma distribution}]{Special case of gamma distribution} \label{sec:exp-gam}
\setcounter{equation}{0}

\textbf{Theorem:} The exponential distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:exp}) is a special case of the gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:gam}) with shape $a = 1$ and rate $b = \lambda$.


\vspace{1em}
\textbf{Proof:} The probability density function of the gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-pdf}) is

\begin{equation} \label{eq:exp-gam-gam-pdf}
\mathrm{Gam}(x; a, b) = \frac{b^a}{\Gamma(a)} x^{a-1} \exp[-b x] \; .
\end{equation}

Setting $a = 1$ and $b = \lambda$, we obtain

\begin{equation} \label{eq:exp-gam-exp-pdf}
\begin{split}
\mathrm{Gam}(x; 1, \lambda) &= \frac{\lambda^1}{\Gamma(1)} x^{1-1} \exp[-\lambda x] \\
&= \frac{x^0}{\Gamma(1)} \lambda \exp[-\lambda x] \\
&= \lambda \exp[-\lambda x]
\end{split}
\end{equation}

which is equivalent to the probability density function of the exponential distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:exp-pdf}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P69 | shortcut: exp-gam | author: JoramSoch | date: 2020-03-02, 20:49.
\vspace{1em}



\subsubsection[\textbf{Probability density function}]{Probability density function} \label{sec:exp-pdf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a non-negative random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following an exponential distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:exp}):

\begin{equation} \label{eq:exp-pdf-exp}
X \sim \mathrm{Exp}(\lambda) \; .
\end{equation}

Then, the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $X$ is

\begin{equation} \label{eq:exp-pdf-gam-pdf}
f_X(x) = \lambda \exp[-\lambda x] \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} This follows directly from the definition of the exponential distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:exp}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P46 | shortcut: exp-pdf | author: JoramSoch | date: 2020-02-08, 23:53.
\vspace{1em}



\subsubsection[\textbf{Cumulative distribution function}]{Cumulative distribution function} \label{sec:exp-cdf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following an exponential distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:exp}):

\begin{equation} \label{eq:exp-cdf-exp}
X \sim \mathrm{Exp}(\lambda) \; .
\end{equation}

Then, the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) of $X$ is

\begin{equation} \label{eq:exp-cdf-exp-cdf}
F_X(x) = \left\{
\begin{array}{rl}
0 \; , & \text{if} \; x < 0 \\
1 - \exp[-\lambda x] \; , & \text{if} \; x \geq 0 \; .
\end{array}
\right.
\end{equation}


\vspace{1em}
\textbf{Proof:}  The probability density function of the exponential distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:exp-pdf}) is:

\begin{equation} \label{eq:exp-cdf-exp-pdf}
\mathrm{Exp}(x; \lambda) = \left\{
\begin{array}{rl}
0 \; , & \text{if} \; x < 0 \\
\lambda \exp[-\lambda x] \; , & \text{if} \; x \geq 0 \; .
\end{array}
\right.
\end{equation}

Thus, the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) is:

\begin{equation} \label{eq:exp-cdf-exp-cdf-s1}
F_X(x) = \int_{-\infty}^{x} \mathrm{Exp}(z; \lambda) \, \mathrm{d}z \; .
\end{equation}

If $x < 0$, we have:

\begin{equation} \label{eq:exp-cdf-exp-cdf-s2a}
F_X(x) = \int_{-\infty}^{x} 0 \, \mathrm{d}z = 0 \; .
\end{equation}

If $x \geq 0$, we have using \eqref{eq:exp-cdf-exp-pdf}:

\begin{equation} \label{eq:exp-cdf-exp-cdf-s2b}
\begin{split}
F_X(x) &= \int_{-\infty}^{0} \mathrm{Exp}(z; \lambda) \, \mathrm{d}z + \int_{0}^{x} \mathrm{Exp}(z; \lambda) \, \mathrm{d}z \\
&= \int_{-\infty}^{0} 0 \, \mathrm{d}z + \int_{0}^{x} \lambda \exp[-\lambda z] \, \mathrm{d}z \\
&= 0 + \lambda \left[ -\frac{1}{\lambda} \exp[-\lambda z] \right]_{0}^{x} \\
&= \lambda \left[ \left( -\frac{1}{\lambda} \exp[-\lambda x] \right) - \left( -\frac{1}{\lambda} \exp[-\lambda \cdot 0] \right) \right] \\
&= 1 - \exp[-\lambda x] \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P48 | shortcut: exp-cdf | author: JoramSoch | date: 2020-02-11, 14:48.
\vspace{1em}



\subsubsection[\textbf{Quantile function}]{Quantile function} \label{sec:exp-qf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following an exponential distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:exp}):

\begin{equation} \label{eq:exp-qf-exp}
X \sim \mathrm{Exp}(\lambda) \; .
\end{equation}

Then, the quantile function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:qf}) of $X$ is

\begin{equation} \label{eq:exp-qf-exp-qf}
Q_X(p) = -\frac{\ln(1-p)}{\lambda} \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The cumulative distribution function of the exponential distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:exp-cdf}) is:

\begin{equation} \label{eq:exp-qf-exp-cdf}
F_X(x) = \left\{
\begin{array}{rl}
0 \; , & \text{if} \; x < 0 \\
1 - \exp[-\lambda x] \; , & \text{if} \; x \geq 0 \; .
\end{array}
\right.
\end{equation}

Thus, the quantile function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:qf}) is:

\begin{equation} \label{eq:exp-qf-exp-qf-s1}
Q_X(p) = F_X^{-1}(x) \; .
\end{equation}

This can be derived by rearranging equation \eqref{eq:exp-qf-exp-cdf}:

\begin{equation} \label{eq:exp-qf-exp-qf-s2}
\begin{split}
p &= 1 - \exp[-\lambda x] \\
\exp[-\lambda x] &= 1-p \\
-\lambda x &= \ln(1-p) \\
x &= -\frac{\ln(1-p)}{\lambda} \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P50 | shortcut: exp-qf | author: JoramSoch | date: 2020-02-12, 15:48.
\vspace{1em}



\subsubsection[\textbf{Mean}]{Mean} \label{sec:exp-mean}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following an exponential distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:exp}):

\begin{equation} \label{eq:exp-mean-exp}
X \sim \mathrm{Exp}(\lambda) \; .
\end{equation}

Then, the mean or expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of $X$ is

\begin{equation} \label{eq:exp-mean-exp-mean}
\mathrm{E}(X) = \frac{1}{\lambda} \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) is the probability-weighted average over all possible values:

\begin{equation} \label{eq:exp-mean-mean}
\mathrm{E}(X) = \int_{\mathbb{R}} x \cdot f_\mathrm{X}(x) \, \mathrm{d}x \; .
\end{equation}

With the probability density function of the exponential distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:exp-pdf}), this reads:

\begin{equation} \label{eq:exp-mean-exp-mean-s1}
\begin{split}
\mathrm{E}(X) &= \int_{0}^{+\infty} x \cdot \lambda \exp(-\lambda x) \, \mathrm{d}x \\
&= \lambda \int_{0}^{+\infty} x \cdot \exp(-\lambda x) \, \mathrm{d}x \; .
\end{split}
\end{equation}

Using the following anti-deriative

\begin{equation} \label{eq:exp-mean-exp-mean-s2}
\int x \cdot \exp(-\lambda x) \, \mathrm{d}x = \left( - \frac{1}{\lambda} x - \frac{1}{\lambda^2} \right) \exp(-\lambda x) \; ,
\end{equation}

the expected value becomes

\begin{equation} \label{eq:exp-mean-exp-mean-s3}
\begin{split}
\mathrm{E}(X) &= \lambda \left[ \left( - \frac{1}{\lambda} x - \frac{1}{\lambda^2} \right) \exp(-\lambda x) \right]_{0}^{+\infty} \\
&= \lambda \left[ \lim_{x \to \infty} \left( - \frac{1}{\lambda} x - \frac{1}{\lambda^2} \right) \exp(-\lambda x) - \left( - \frac{1}{\lambda} \cdot 0 - \frac{1}{\lambda^2} \right) \exp(-\lambda \cdot 0) \right] \\
&= \lambda \left[ 0 + \frac{1}{\lambda^2} \right] \\
&= \frac{1}{\lambda} \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Koch, Karl-Rudolf (2007): "Expected Value"; in: \textit{Introduction to Bayesian Statistics}, Springer, Berlin/Heidelberg, 2007, p. 39, eq. 2.142a; URL: \url{https://www.springer.com/de/book/9783540727231}; DOI: 10.1007/978-3-540-72726-2.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P47 | shortcut: exp-mean | author: JoramSoch | date: 2020-02-10, 21:57.
\vspace{1em}



\subsubsection[\textbf{Median}]{Median} \label{sec:exp-med}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following an exponential distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:exp}):

\begin{equation} \label{eq:exp-med-exp}
X \sim \mathrm{Exp}(\lambda) \; .
\end{equation}

Then, the median ($\rightarrow$ Definition "med") of $X$ is

\begin{equation} \label{eq:exp-med-exp-med}
\mathrm{median}(X) = \frac{\ln 2}{\lambda} \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The median ($\rightarrow$ Definition "med") is the value at which the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) is $1/2$:

\begin{equation} \label{eq:exp-med-median}
F_X(\mathrm{median}(X)) = \frac{1}{2} \; .
\end{equation}

The cumulative distribution function of the exponential distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:exp-cdf}) is

\begin{equation} \label{eq:exp-med-exp-cdf}
F_X(x) = 1 - \exp[-\lambda x], \quad x \geq 0 \; .
\end{equation}

Thus, the inverse CDF is

\begin{equation} \label{eq:exp-med-exp-cdf-inv}
x = -\frac{\ln(1-p)}{\lambda}
\end{equation}

and setting $p = 1/2$, we obtain:

\begin{equation} \label{eq:exp-med-exp-med-qed}
\mathrm{median}(X) = -\frac{\ln(1-\frac{1}{2})}{\lambda} = \frac{\ln 2}{\lambda} \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P49 | shortcut: exp-med | author: JoramSoch | date: 2020-02-11, 15:03.
\vspace{1em}



\subsubsection[\textbf{Mode}]{Mode} \label{sec:exp-mode}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following an exponential distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:exp}):

\begin{equation} \label{eq:exp-mode-exp}
X \sim \mathrm{Exp}(\lambda) \; .
\end{equation}

Then, the mode ($\rightarrow$ Definition "mode") of $X$ is

\begin{equation} \label{eq:exp-mode-exp-mode}
\mathrm{mode}(X) = 0 \; .
\end{equation}


\vspace{1em}
\textbf{Proof:}  The mode ($\rightarrow$ Definition "mode") is the value which maximizes the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}):

\begin{equation} \label{eq:exp-mode-mode}
\mathrm{mode}(X) = \operatorname*{arg\,max}_x f_X(x) \; .
\end{equation}

The probability density function of the exponential distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:exp-pdf}) is:

\begin{equation} \label{eq:exp-mode-exp-pdf}
f_X(x) = \left\{
\begin{array}{rl}
0 \; , & \text{if} \; x < 0 \\
\lambda \exp[-\lambda x] \; , & \text{if} \; x \geq 0 \; .
\end{array}
\right.
\end{equation}

Since

\begin{equation} \label{eq:exp-mode-exp-pdf-eq0}
\lim_{x \to 0} f_X(x) = \infty
\end{equation}

and

\begin{equation} \label{eq:exp-mode-exp-pdf-neq0}
f_X(x) < \infty \quad \text{for any} \quad x \neq 0 \; ,
\end{equation}

it follows that

\begin{equation} \label{eq:exp-mode-exp-mode-qed}
\mathrm{mode}(X) = 0 \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P51 | shortcut: exp-mode | author: JoramSoch | date: 2020-02-12, 15:53.
\vspace{1em}



\subsection{Beta distribution}

\subsubsection[\textit{Definition}]{Definition} \label{sec:beta}
\setcounter{equation}{0}

**Definition**: Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}). Then, $X$ is said to follow a beta distribution with shape parameters $\alpha$ and $\beta$

\begin{equation} \label{eq:beta-beta}
X \sim \mathrm{Bet}(\alpha, \beta) \; ,
\end{equation}

if and only if its probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) is given by

\begin{equation} \label{eq:beta-beta-pdf}
\mathrm{Bet}(x; \alpha, \beta) = \frac{1}{\mathrm{B}(\alpha, \beta)} \, x^{\alpha-1} \, (1-x)^{\beta-1}
\end{equation}

where $\alpha > 0$ and $\beta > 0$, and the density is zero, if $x \notin [0,1]$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Beta distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-05-10; URL: \url{https://en.wikipedia.org/wiki/Beta_distribution#Definitions}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D53 | shortcut: beta | author: JoramSoch | date: 2020-05-10, 20:29.
\vspace{1em}



\subsubsection[\textbf{Probability density function}]{Probability density function} \label{sec:beta-pdf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) following a beta distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:beta}):

\begin{equation} \label{eq:beta-pdf-beta}
X \sim \mathrm{Bet}(\alpha, \beta) \; .
\end{equation}

Then, the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $X$ is

\begin{equation} \label{eq:beta-pdf-beta-pdf}
f_X(x) = \frac{1}{\mathrm{B}(\alpha, \beta)} \, x^{\alpha-1} \, (1-x)^{\beta-1} \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} This follows directly from the definition of the beta distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:beta}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P94 | shortcut: beta-pdf | author: JoramSoch | date: 2020-05-05, 21:03.
\vspace{1em}



\pagebreak
\section{Multivariate continuous distributions}

\subsection{Multivariate normal distribution}

\subsubsection[\textit{Definition}]{Definition} \label{sec:mvn}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be an $n \times 1$ random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}). Then, $X$ is said to be multivariate normally distributed with mean $\mu$ and covariance $\Sigma$

\begin{equation} \label{eq:mvn-mvn}
X \sim \mathcal{N}(\mu, \Sigma) \; ,
\end{equation}

if and only if its probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) is given by

\begin{equation} \label{eq:mvn-mvn-pdf}
\mathcal{N}(x; \mu, \Sigma) = \frac{1}{\sqrt{(2 \pi)^n |\Sigma|}} \cdot \exp \left[ -\frac{1}{2} (x-\mu)^\mathrm{T} \Sigma^{-1} (x-\mu) \right]
\end{equation}

where $\mu$ is an $n \times 1$ real vector and $\Sigma$ is an $n \times n$ positive definite matrix.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Koch KR (2007): "Multivariate Normal Distribution"; in: \textit{Introduction to Bayesian Statistics}, ch. 2.5.1, pp. 51-53, eq. 2.195; URL: \url{https://www.springer.com/gp/book/9783540727231}; DOI: 10.1007/978-3-540-72726-2.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D1 | shortcut: mvn | author: JoramSoch | date: 2020-01-22, 05:20.
\vspace{1em}



\subsubsection[\textbf{Probability density function}]{Probability density function} \label{sec:mvn-pdf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}) following a multivariate normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mvn}):

\begin{equation} \label{eq:mvn-pdf-mvn}
X \sim \mathcal{N}(\mu, \Sigma) \; .
\end{equation}

Then, the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $X$ is

\begin{equation} \label{eq:mvn-pdf-mvn-pdf}
f_X(x) = \frac{1}{\sqrt{(2 \pi)^n |\Sigma|}} \cdot \exp \left[ -\frac{1}{2} (x-\mu)^\mathrm{T} \Sigma^{-1} (x-\mu) \right] \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} This follows directly from the definition of the multivariate normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mvn}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P34 | shortcut: mvn-pdf | author: JoramSoch | date: 2020-01-27, 15:23.
\vspace{1em}



\subsubsection[\textbf{Differential entropy}]{Differential entropy} \label{sec:mvn-dent}
\setcounter{equation}{0}

\textbf{Theorem:} Let $x$ follow a multivariate normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mvn})

\begin{equation} \label{eq:mvn-dent-mvn}
x \sim \mathcal{N}(\mu, \Sigma) \; .
\end{equation}

Then, the differential entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent}) of $x$ in nats is

\begin{equation} \label{eq:mvn-dent-mvn-dent}
\mathrm{h}(x) = \frac{n}{2} \ln(2\pi) + \frac{1}{2} \ln|\Sigma| + \frac{1}{2} n \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The differential entropy ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dent}) of a random variable is defined as

\begin{equation} \label{eq:mvn-dent-dent}
\mathrm{h}(X) = - \int_{\mathcal{X}} p(x) \, \log_b p(x) \, \mathrm{d}x \; .
\end{equation}

To measure $h(X)$ in nats, we set $b = e$, such that ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean})

\begin{equation} \label{eq:mvn-dent-dent-nats}
\mathrm{h}(X) = - \mathrm{E}\left[ \ln p(x) \right] \; .
\end{equation}

With the probability density function of the multivariate normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mvn-pdf}), the differential entropy of $x$ is:

\begin{equation} \label{eq:mvn-dent-mvn-dent-s1}
\begin{split}
\mathrm{h}(x) &= - \mathrm{E}\left[ \ln \left( \frac{1}{\sqrt{(2 \pi)^n |\Sigma|}} \cdot \exp \left[ -\frac{1}{2} (x-\mu)^\mathrm{T} \Sigma^{-1} (x-\mu) \right] \right) \right] \\
&= - \mathrm{E}\left[ - \frac{n}{2} \ln(2\pi) - \frac{1}{2} \ln|\Sigma| - \frac{1}{2} (x-\mu)^\mathrm{T} \Sigma^{-1} (x-\mu) \right] \\
&= \frac{n}{2} \ln(2\pi) + \frac{1}{2} \ln|\Sigma| + \frac{1}{2} \, \mathrm{E}\left[ (x-\mu)^\mathrm{T} \Sigma^{-1} (x-\mu) \right] \; .
\end{split}
\end{equation}

The last term can be evaluted as

\begin{equation} \label{eq:mvn-dent-mvn-dent-t3}
\begin{split}
\mathrm{E}\left[ (x-\mu)^\mathrm{T} \Sigma^{-1} (x-\mu) \right] &= \mathrm{E}\left[ \mathrm{tr}\left( (x-\mu)^\mathrm{T} \Sigma^{-1} (x-\mu) \right) \right] \\
&= \mathrm{E}\left[ \mathrm{tr}\left( \Sigma^{-1} (x-\mu) (x-\mu)^\mathrm{T} \right) \right] \\
&= \mathrm{tr}\left( \Sigma^{-1} \mathrm{E}\left[ (x-\mu) (x-\mu)^\mathrm{T} \right] \right) \\
&= \mathrm{tr}\left( \Sigma^{-1} \Sigma \right) \\
&= \mathrm{tr}\left( I_n \right) \\
&= n \; , \\
\end{split}
\end{equation}

such that the differential entropy is

\begin{equation} \label{eq:mvn-dent-mvn-dent-qed}
\mathrm{h}(x) = \frac{n}{2} \ln(2\pi) + \frac{1}{2} \ln|\Sigma| + \frac{1}{2} \, n \; .
\end{equation}



\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Kiuhnm (2018): "Entropy of the multivariate Gaussian"; in: \textit{StackExchange Mathematics}, retrieved on 2020-05-14; URL: \url{https://math.stackexchange.com/questions/2029707/entropy-of-the-multivariate-gaussian}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P100 | shortcut: mvn-dent | author: JoramSoch | date: 2020-05-14, 19:49.
\vspace{1em}



\subsubsection[\textbf{Kullback-Leibler divergence}]{Kullback-Leibler divergence} \label{sec:mvn-kl}
\setcounter{equation}{0}

\textbf{Theorem:} Let $x$ be an $n \times 1$ random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}). Assume two multivariate normal distributions ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mvn}) $P$ and $Q$ specifying the probability distribution of $x$ as

\begin{equation} \label{eq:mvn-kl-mvns}
\begin{split}
P: \; x &\sim \mathcal{N}(\mu_1, \Sigma_1) \\
Q: \; x &\sim \mathcal{N}(\mu_2, \Sigma_2) \; . \\
\end{split}
\end{equation}

Then, the Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) of $P$ from $Q$ is given by

\begin{equation} \label{eq:mvn-kl-mvn-KL}
\mathrm{KL}[P\,||\,Q] = \frac{1}{2} \left[ (\mu_2 - \mu_1)^T \Sigma_2^{-1} (\mu_2 - \mu_1) + \mathrm{tr}(\Sigma_2^{-1} \Sigma_1) - \ln \frac{|\Sigma_1|}{|\Sigma_2|} - n \right] \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The KL divergence for a continuous random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) is given by 

\begin{equation} \label{eq:mvn-kl-KL-cont}
\mathrm{KL}[P\,||\,Q] = \int_{\mathcal{X}} p(x) \, \ln \frac{p(x)}{q(x)} \, \mathrm{d}x
\end{equation}

which, applied to the multivariate normal distributions ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mvn}) in \eqref{eq:mvn-kl-mvns}, yields

\begin{equation} \label{eq:mvn-kl-mvn-KL-s1}
\begin{split}
\mathrm{KL}[P\,||\,Q] &= \int_{\mathbb{R}^n} \mathcal{N}(x; \mu_1, \Sigma_1) \, \ln \frac{\mathcal{N}(x; \mu_1, \Sigma_1)}{\mathcal{N}(x; \mu_2, \Sigma_2)} \, \mathrm{d}x \\
&= \left\langle \ln \frac{\mathcal{N}(x; \mu_1, \Sigma_1)}{\mathcal{N}(x; \mu_2, \Sigma_2)} \right\rangle_{p(x)} \; .
\end{split}
\end{equation}

Using the probability density function of the multivariate normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mvn-pdf}), this becomes:

\begin{equation} \label{eq:mvn-kl-mvn-KL-s2}
\begin{split}
\mathrm{KL}[P\,||\,Q] &= \left\langle \ln \frac{ \frac{1}{\sqrt{(2 \pi)^n |\Sigma_1|}} \cdot \exp \left[ -\frac{1}{2} (x-\mu_1)^\mathrm{T} \Sigma_1^{-1} (x-\mu_1) \right] }{ \frac{1}{\sqrt{(2 \pi)^n |\Sigma_2|}} \cdot \exp \left[ -\frac{1}{2} (x-\mu_2)^\mathrm{T} \Sigma_2^{-1} (x-\mu_2) \right] } \right\rangle_{p(x)} \\
&= \left\langle \frac{1}{2} \ln \frac{|\Sigma_2|}{|\Sigma_1|} - \frac{1}{2} (x-\mu_1)^\mathrm{T} \Sigma_1^{-1} (x-\mu_1) + \frac{1}{2} (x-\mu_2)^\mathrm{T} \Sigma_2^{-1} (x-\mu_2) \right\rangle_{p(x)} \\
&= \frac{1}{2} \left\langle \ln \frac{|\Sigma_2|}{|\Sigma_1|} - (x-\mu_1)^\mathrm{T} \Sigma_1^{-1} (x-\mu_1) + (x-\mu_2)^\mathrm{T} \Sigma_2^{-1} (x-\mu_2) \right\rangle_{p(x)} \; .
\end{split}
\end{equation}

Now, using the fact that $x = \mathrm{tr}(x)$, if $a$ is scalar, and the trace property $\mathrm{tr}(ABC) = \mathrm{tr}(BCA)$, we have:

\begin{equation} \label{eq:mvn-kl-mvn-KL-s3}
\begin{split}
\mathrm{KL}[P\,||\,Q] &= \frac{1}{2} \left\langle \ln \frac{|\Sigma_2|}{|\Sigma_1|} - \mathrm{tr}\left[ \Sigma_1^{-1} (x-\mu_1) (x-\mu_1)^\mathrm{T} \right] + \mathrm{tr}\left[ \Sigma_2^{-1} (x-\mu_2) (x-\mu_2)^\mathrm{T} \right] \right\rangle_{p(x)} \\
&= \frac{1}{2} \left\langle \ln \frac{|\Sigma_2|}{|\Sigma_1|} - \mathrm{tr}\left[ \Sigma_1^{-1} (x-\mu_1) (x-\mu_1)^\mathrm{T} \right] + \mathrm{tr}\left[ \Sigma_2^{-1} \left( x x^\mathrm{T} - 2 \mu_2 x^\mathrm{T} + \mu_2 \mu_2^\mathrm{T} \right) \right] \right\rangle_{p(x)} \; .
\end{split}
\end{equation}

Because trace function and expected value ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) are both linear operators, the expectation can be moved inside the trace:

\begin{equation} \label{eq:mvn-kl-mvn-KL-s4}
\begin{split}
\mathrm{KL}[P\,||\,Q] &= \frac{1}{2} \left( \ln \frac{|\Sigma_2|}{|\Sigma_1|} - \mathrm{tr}\left[ \Sigma_1^{-1} \left\langle (x-\mu_1) (x-\mu_1)^\mathrm{T} \right\rangle_{p(x)} \right] + \mathrm{tr}\left[ \Sigma_2^{-1} \left\langle x x^\mathrm{T} - 2 \mu_2 x^\mathrm{T} + \mu_2 \mu_2^\mathrm{T} \right\rangle_{p(x)} \right] \right) \\
&= \frac{1}{2} \left( \ln \frac{|\Sigma_2|}{|\Sigma_1|} - \mathrm{tr}\left[ \Sigma_1^{-1} \left\langle (x-\mu_1) (x-\mu_1)^\mathrm{T} \right\rangle_{p(x)} \right] + \mathrm{tr}\left[ \Sigma_2^{-1} \left( \left\langle x x^\mathrm{T} \right\rangle_{p(x)} - \left\langle 2 \mu_2 x^\mathrm{T} \right\rangle_{p(x)} + \left\langle \mu_2 \mu_2^\mathrm{T} \right\rangle_{p(x)} \right) \right] \right) \; .
\end{split}
\end{equation}

Using the expectation of a linear form for the multivariate normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mvn-ltt})

\begin{equation} \label{eq:mvn-kl-mvn-lfmean}
x \sim \mathcal{N}(\mu, \Sigma) \quad \Rightarrow \quad \left\langle A x \right\rangle = A \mu
\end{equation}

and the expectation of a quadratic form for the multivariate normal distribution ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:mean-qf})

\begin{equation} \label{eq:mvn-kl-mvn-qfmean}
x \sim \mathcal{N}(\mu, \Sigma) \quad \Rightarrow \quad \left\langle x^\mathrm{T} A x \right\rangle = \mu^\mathrm{T} A \mu + \mathrm{tr}(A \Sigma) \; ,
\end{equation}

the Kullback-Leibler divergence from \eqref{eq:mvn-kl-mvn-KL-s4} becomes:

\begin{equation} \label{eq:mvn-kl-mvn-KL-s5}
\begin{split}
\mathrm{KL}[P\,||\,Q] &= \frac{1}{2} \left( \ln \frac{|\Sigma_2|}{|\Sigma_1|} - \mathrm{tr}\left[ \Sigma_1^{-1} \Sigma_1 \right] + \mathrm{tr}\left[ \Sigma_2^{-1} \left( \Sigma_1 + \mu_1 \mu_1^\mathrm{T} - 2 \mu_2 \mu_1^\mathrm{T} + \mu_2 \mu_2^\mathrm{T} \right) \right] \right) \\
&= \frac{1}{2} \left( \ln \frac{|\Sigma_2|}{|\Sigma_1|} - \mathrm{tr}\left[ I_n \right] + \mathrm{tr}\left[ \Sigma_2^{-1} \Sigma_1 \right] + \mathrm{tr}\left[ \Sigma_2^{-1} \left( \mu_1 \mu_1^\mathrm{T} - 2 \mu_2 \mu_1^\mathrm{T} + \mu_2 \mu_2^\mathrm{T} \right) \right] \right) \\
&= \frac{1}{2} \left( \ln \frac{|\Sigma_2|}{|\Sigma_1|} - n + \mathrm{tr}\left[ \Sigma_2^{-1} \Sigma_1 \right] + \mathrm{tr}\left[ \mu_1^\mathrm{T} \Sigma_2^{-1} \mu_1  - 2 \mu_1^\mathrm{T} \Sigma_2^{-1} \mu_2  + \mu_2^\mathrm{T} \Sigma_2^{-1} \mu_2 \right] \right) \\
&= \frac{1}{2} \left[ \ln \frac{|\Sigma_2|}{|\Sigma_1|} - n + \mathrm{tr}\left[ \Sigma_2^{-1} \Sigma_1 \right] + (\mu_2 - \mu_1)^T \Sigma_2^{-1} (\mu_2 - \mu_1) \right] \; .
\end{split}
\end{equation}

Finally, rearranging the terms, we get:

\begin{equation} \label{eq:mvn-kl-mvn-KL-qed}
\mathrm{KL}[P\,||\,Q] = \frac{1}{2} \left[ (\mu_2 - \mu_1)^T \Sigma_2^{-1} (\mu_2 - \mu_1) + \mathrm{tr}(\Sigma_2^{-1} \Sigma_1) - \ln \frac{|\Sigma_1|}{|\Sigma_2|} - n \right] \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Duchi, John (2014): "Derivations for Linear Algebra and Optimization"; in: \textit{University of California, Berkeley}; URL: \url{http://www.eecs.berkeley.edu/~jduchi/projects/general_notes.pdf}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P92 | shortcut: mvn-kl | author: JoramSoch | date: 2020-05-05, 06:57.
\vspace{1em}



\subsubsection[\textbf{Linear transformation}]{Linear transformation} \label{sec:mvn-ltt}
\setcounter{equation}{0}

\textbf{Theorem:} Let $x$ follow a multivariate normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mvn}):

\begin{equation} \label{eq:mvn-ltt-mvn}
x \sim \mathcal{N}(\mu, \Sigma) \; .
\end{equation}

Then, any linear transformation of $x$ is also multivariate normally distributed:

\begin{equation} \label{eq:mvn-ltt-mvn-lt}
y = Ax + b \sim \mathcal{N}(A\mu + b, A \Sigma A^\mathrm{T}) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The moment-generating function of a random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mgf}) $x$ is

\begin{equation} \label{eq:mvn-ltt-vect-mgf}
M_x(t) = \mathbb{E} \left( \exp \left[ t^\mathrm{T} x \right] \right)
\end{equation}

and therefore the moment-generating function of the random vector $y$ is given by

\begin{equation} \label{eq:mvn-ltt-y-mgf-s1}
\begin{split}
M_y(t) &\overset{\eqref{eq:mvn-ltt-mvn-lt}}{=} \mathbb{E} \left( \exp \left[ t^\mathrm{T} (Ax + b) \right] \right) \\
&= \mathbb{E} \left( \exp \left[ t^\mathrm{T} A x \right] \cdot \exp \left[ t^\mathrm{T} b \right] \right) \\
&= \exp \left[ t^\mathrm{T} b \right] \cdot \mathbb{E} \left( \exp \left[ t^\mathrm{T} A x \right] \right) \\
&\overset{\eqref{eq:mvn-ltt-vect-mgf}}{=} \exp \left[ t^\mathrm{T} b \right] \cdot M_x(At) \; .
\end{split}
\end{equation}

The moment-generating function of the multivariate normal distribution ($\rightarrow$ Proof "mvn-mgf") is

\begin{equation} \label{eq:mvn-ltt-mvn-mgf}
M_x(t) = \exp \left[ t^\mathrm{T} \mu + \frac{1}{2} t^\mathrm{T} \Sigma t \right]
\end{equation}

and therefore the moment-generating function of the random vector $y$ becomes

\begin{equation} \label{eq:mvn-ltt-y-mgf-s2}
\begin{split}
M_y(t) &\overset{\eqref{eq:mvn-ltt-y-mgf-s1}}{=} \exp \left[ t^\mathrm{T} b \right] \cdot M_x(At) \\
&\overset{\eqref{eq:mvn-ltt-mvn-mgf}}{=} \exp \left[ t^\mathrm{T} b \right] \cdot \exp \left[ t^\mathrm{T} A \mu + \frac{1}{2} t^\mathrm{T} A \Sigma A^\mathrm{T} t \right] \\
&= \exp \left[ t^\mathrm{T} \left( A \mu + b \right) + \frac{1}{2} t^\mathrm{T} A \Sigma A^\mathrm{T} t \right] \; .
\end{split}
\end{equation}

Because moment-generating function and probability density function of a random variable are equivalent, this demonstrates that $y$ is following a multivariate normal distribution with mean $A \mu + b$ and covariance $A \Sigma A^\mathrm{T}$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Taboga, Marco (2010): "Linear combinations of normal random variables"; in: \textit{Lectures on probability and statistics}, retrieved on 2019-08-27; URL: \url{https://www.statlect.com/probability-distributions/normal-distribution-linear-combinations}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P1 | shortcut: mvn-ltt | author: JoramSoch | date: 2019-08-27, 12:14.
\vspace{1em}



\subsubsection[\textbf{Marginal distributions}]{Marginal distributions} \label{sec:mvn-marg}
\setcounter{equation}{0}

\textbf{Theorem:} Let $x$ follow a multivariate normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mvn}):

\begin{equation} \label{eq:mvn-marg-mvn}
x \sim \mathcal{N}(\mu, \Sigma) \; .
\end{equation}

Then, the marginal distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-marg}) of any subset vector $x_s$ is also a multivariate normal distribution

\begin{equation} \label{eq:mvn-marg-mvn-marg}
x_s \sim \mathcal{N}(\mu_s, \Sigma_s)
\end{equation}

where $\mu_s$ drops the irrelevant variables (the ones not in the subset, i.e. marginalized out) from the mean vector $\mu$ and $\Sigma_s$ drops the corresponding rows and columns from the covariance matrix $\Sigma$.


\vspace{1em}
\textbf{Proof:} Define an $m \times n$ subset matrix $S$ such that $s_{ij} = 1$, if the $j$-th element in $\mu_s$ corresponds to the $i$-th element in $x$, and $s_{ij} = 0$ otherwise. Then,

\begin{equation} \label{eq:mvn-marg-xs}
x_s = S x
\end{equation}

and we can apply the linear transformation theorem ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mvn-ltt}) to give

\begin{equation} \label{eq:mvn-marg-mvn-marg-qed}
x_s \sim \mathcal{N}(S \mu, S \Sigma S^\mathrm{T}) \; .
\end{equation}

Finally, we see that $S \mu = \mu_s$ and $S \Sigma S^\mathrm{T} = \Sigma_s$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P35 | shortcut: mvn-marg | author: JoramSoch | date: 2020-01-29, 15:12.
\vspace{1em}



\subsubsection[\textbf{Conditional distributions}]{Conditional distributions} \label{sec:mvn-cond}
\setcounter{equation}{0}

\textbf{Theorem:} Let $x$ follow a multivariate normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mvn})

\begin{equation} \label{eq:mvn-cond-mvn}
x \sim \mathcal{N}(\mu, \Sigma) \; .
\end{equation}

Then, the conditional distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-cond}) of any subset vector $x_1$, given the complement vector $x_2$, is also a multivariate normal distribution

\begin{equation} \label{eq:mvn-cond-mvn-cond}
x_1|x_2 \sim \mathcal{N}(\mu_{1|2}, \Sigma_{1|2})
\end{equation}

where the conditional mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) and covariance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cov}) are

\begin{equation} \label{eq:mvn-cond-mvn-cond-hyp}
\begin{split}
\mu_{1|2} &= \mu_1 + \Sigma_{12} \Sigma_{22}^{-1} (x_2 - \mu_2) \\
\Sigma_{1|2} &= \Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21}
\end{split}
\end{equation}

with block-wise mean and covariance defined as

\begin{equation} \label{eq:mvn-cond-mvn-joint-hyp}
\begin{split}
\mu &= \begin{bmatrix} \mu_1 \\ \mu_2 \end{bmatrix} \\
\Sigma &= \begin{bmatrix} \Sigma_{11} & \Sigma_{12} \\ \Sigma_{21} & \Sigma_{22} \end{bmatrix} \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Proof:} Without loss of generality, we assume that, in parallel to \eqref{eq:mvn-cond-mvn-joint-hyp},

\begin{equation} \label{eq:mvn-cond-x}
x = \begin{bmatrix} x_1 \\ x_2 \end{bmatrix}
\end{equation}

where $x_1$ is an $n_1 \times 1$ vector, $x_2$ is an $n_2 \times 1$ vector and $x$ is an $n_1 + n_2 = n \times 1$ vector.

\vspace{1em}
By construction, the joint distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-joint}) of $x_1$ and $x_2$ is:

\begin{equation} \label{eq:mvn-cond-mvn-joint}
x_1,x_2 \sim \mathcal{N}(\mu, \Sigma) \; .
\end{equation}

Moreover, the marginal distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-marg}) of $x_2$ follows from ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mvn-marg}) \eqref{eq:mvn-cond-mvn} and \eqref{eq:mvn-cond-mvn-joint-hyp} as

\begin{equation} \label{eq:mvn-cond-mvn-marg}
x_2 \sim \mathcal{N}(\mu_2, \Sigma_{22}) \; .
\end{equation}

According to the law of conditional probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-cond}), it holds that

\begin{equation} \label{eq:mvn-cond-mvn-cond-s1}
p(x_1|x_2) = \frac{p(x_1,x_2)}{p(x_2)}
\end{equation}

Applying \eqref{eq:mvn-cond-mvn-joint} and \eqref{eq:mvn-cond-mvn-marg} to \eqref{eq:mvn-cond-mvn-cond-s1}, we have:

\begin{equation} \label{eq:mvn-cond-mvn-cond-s2}
p(x_1|x_2) = \frac{\mathcal{N}(x; \mu, \Sigma)}{\mathcal{N}(x_2; \mu_2, \Sigma_{22})} \; .
\end{equation}

Using the probability density function of the multivariate normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mvn-pdf}), this becomes:

\begin{equation} \label{eq:mvn-cond-mvn-cond-s3}
\begin{split}
p(x_1|x_2) &= \frac{1/\sqrt{(2 \pi)^n |\Sigma|} \cdot \exp \left[ -\frac{1}{2} (x-\mu)^\mathrm{T} \Sigma^{-1} (x-\mu) \right]}{1/\sqrt{(2 \pi)^{n_2} |\Sigma_{22}|} \cdot \exp \left[ -\frac{1}{2} (x_2-\mu_2)^\mathrm{T} \Sigma_{22}^{-1} (x_2-\mu_2) \right]} \\
&= \frac{1}{\sqrt{(2 \pi)^{n-n_2}}} \cdot \sqrt{\frac{|\Sigma_{22}|}{|\Sigma|}} \cdot \exp \left[ -\frac{1}{2} (x-\mu)^\mathrm{T} \Sigma^{-1} (x-\mu) + \frac{1}{2} (x_2-\mu_2)^\mathrm{T} \Sigma_{22}^{-1} (x_2-\mu_2) \right] \; .
\end{split}
\end{equation}

Writing the inverse of $\Sigma$ as

\begin{equation} \label{eq:mvn-cond-Sigma-inv-def}
\Sigma^{-1} = \begin{bmatrix} \Sigma^{11} & \Sigma^{12} \\ \Sigma^{21} & \Sigma^{22} \end{bmatrix}
\end{equation}

and applying \eqref{eq:mvn-cond-mvn-joint-hyp} to \eqref{eq:mvn-cond-mvn-cond-s3}, we get:

\begin{equation} \label{eq:mvn-cond-mvn-cond-s4}
\begin{split}
p(x_1|x_2) = &\frac{1}{\sqrt{(2 \pi)^{n-n_2}}} \cdot \sqrt{\frac{|\Sigma_{22}|}{|\Sigma|}} \cdot \\
&\exp \left[ -\frac{1}{2} \left( \begin{bmatrix} x_1 \\ x_2 \end{bmatrix} - \begin{bmatrix} \mu_1 \\ \mu_2 \end{bmatrix} \right)^\mathrm{T} \begin{bmatrix} \Sigma^{11} & \Sigma^{12} \\ \Sigma^{21} & \Sigma^{22} \end{bmatrix} \left( \begin{bmatrix} x_1 \\ x_2 \end{bmatrix} - \begin{bmatrix} \mu_1 \\ \mu_2 \end{bmatrix} \right) \right. \\
&\hphantom{\exp \left[\right.} \left. + \frac{1}{2} \, (x_2-\mu_2)^\mathrm{T} \, \Sigma_{22}^{-1} \, (x_2-\mu_2) \right] \; .
\end{split}
\end{equation}

Multiplying out within the exponent of \eqref{eq:mvn-cond-mvn-cond-s4}, we have

\begin{equation} \label{eq:mvn-cond-mvn-cond-s5}
\begin{split}
p(x_1|x_2) = &\frac{1}{\sqrt{(2 \pi)^{n-n_2}}} \cdot \sqrt{\frac{|\Sigma_{22}|}{|\Sigma|}} \cdot \\
&\exp \left[ -\frac{1}{2} \left( (x_1-\mu_1)^\mathrm{T} \Sigma^{11} (x_1-\mu_1) + 2 (x_1-\mu_1)^\mathrm{T} \Sigma^{12} (x_2-\mu_2) + (x_2-\mu_2)^\mathrm{T} \Sigma^{22} (x_2-\mu_2) \right) \right. \\
&\hphantom{\exp \left[\right.} \left. + \frac{1}{2} (x_2-\mu_2)^\mathrm{T} \Sigma_{22}^{-1} (x_2-\mu_2) \right]
\end{split}
\end{equation}

where we have used the fact that ${\Sigma^{21}}^\mathrm{T} = \Sigma^{12}$, because $\Sigma^{-1}$ is a symmetric matrix.

\vspace{1em}
The inverse of a block matrix is

\begin{equation} \label{eq:mvn-cond-Block-inv}
\begin{bmatrix} A & B \\ C & D \end{bmatrix}^{-1} = \begin{bmatrix} (A-BD^{-1}C)^{-1} & -(A-BD^{-1}C)^{-1}BD^{-1} \\ -D^{-1}C(A-BD^{-1}C)^{-1} & D^{-1}+D^{-1}C(A-BD^{-1}C)^{-1}BD^{-1} \end{bmatrix} \; ,
\end{equation}

thus the inverse of $\Sigma$ in \eqref{eq:mvn-cond-Sigma-inv-def} is

\begin{equation} \label{eq:mvn-cond-Sigma-inv}
\begin{bmatrix} \Sigma_{11} & \Sigma_{12} \\ \Sigma_{21} & \Sigma_{22} \end{bmatrix}^{-1} = \begin{bmatrix} (\Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21})^{-1} & -(\Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21})^{-1} \Sigma_{12} \Sigma_{22}^{-1} \\ -\Sigma_{22}^{-1} \Sigma_{21} (\Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21})^{-1} & \Sigma_{22}^{-1} + \Sigma_{22}^{-1} \Sigma_{21} (\Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21})^{-1} \Sigma_{12} \Sigma_{22}^{-1} \end{bmatrix} \; .
\end{equation}

Plugging this into \eqref{eq:mvn-cond-mvn-cond-s5}, we have:

\begin{equation} \label{eq:mvn-cond-mvn-cond-s6}
\begin{split}
p(x_1|x_2) = &\frac{1}{\sqrt{(2 \pi)^{n-n_2}}} \cdot \sqrt{\frac{|\Sigma_{22}|}{|\Sigma|}} \cdot \\
&\exp \left[ -\frac{1}{2} \left( (x_1-\mu_1)^\mathrm{T} (\Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21})^{-1} (x_1-\mu_1) \right. \right. - \\
&\hphantom{\exp \left[ -\frac{1}{2} \left( \right. \right.} 2 (x_1-\mu_1)^\mathrm{T} (\Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21})^{-1} \Sigma_{12} \Sigma_{22}^{-1} (x_2-\mu_2) + \\
&\hphantom{\exp \left[ -\frac{1}{2} \left( \right. \right.} \left. (x_2-\mu_2)^\mathrm{T} \left[ \Sigma_{22}^{-1} + \Sigma_{22}^{-1} \Sigma_{21} (\Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21})^{-1} \Sigma_{12} \Sigma_{22}^{-1} \right] (x_2-\mu_2) \right) \\
&\hphantom{\exp \left[\right.} \left. + \frac{1}{2} \left( (x_2-\mu_2)^\mathrm{T} \Sigma_{22}^{-1} (x_2-\mu_2) \right) \right] \; .
\end{split}
\end{equation}

Eliminating some terms, we have:

\begin{equation} \label{eq:mvn-cond-mvn-cond-s7}
\begin{split}
p(x_1|x_2) = &\frac{1}{\sqrt{(2 \pi)^{n-n_2}}} \cdot \sqrt{\frac{|\Sigma_{22}|}{|\Sigma|}} \cdot \\
&\exp \left[ -\frac{1}{2} \left( (x_1-\mu_1)^\mathrm{T} (\Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21})^{-1} (x_1-\mu_1) \right. \right. - \\
&\hphantom{\exp \left[ -\frac{1}{2} \left( \right. \right.} 2 (x_1-\mu_1)^\mathrm{T} (\Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21})^{-1} \Sigma_{12} \Sigma_{22}^{-1} (x_2-\mu_2) + \\
&\hphantom{\exp \left[ -\frac{1}{2} \left( \right. \right.} \left. \left. (x_2-\mu_2)^\mathrm{T} \Sigma_{22}^{-1} \Sigma_{21} (\Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21})^{-1} \Sigma_{12} \Sigma_{22}^{-1} (x_2-\mu_2) \right) \right] \; .
\end{split}
\end{equation}

Rearranging the terms, we have

\begin{equation} \label{eq:mvn-cond-mvn-cond-s8}
\begin{split}
p(x_1|x_2) = &\frac{1}{\sqrt{(2 \pi)^{n-n_2}}} \cdot \sqrt{\frac{|\Sigma_{22}|}{|\Sigma|}} \cdot \exp \left[ -\frac{1}{2} \cdot \right. \\
&\! \left. \left[ (x_1-\mu_1) - \Sigma_{12}^\mathrm{T} \Sigma_{22}^{-1} (x_2-\mu_2) \right]^\mathrm{T} (\Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21})^{-1} \left[ (x_1-\mu_1) - \Sigma_{12}^\mathrm{T} \Sigma_{22}^{-1} (x_2-\mu_2) \right] \right] \\
= &\frac{1}{\sqrt{(2 \pi)^{n-n_2}}} \cdot \sqrt{\frac{|\Sigma_{22}|}{|\Sigma|}} \cdot \exp \left[ -\frac{1}{2} \cdot \right. \\
&\! \left. \left[ x_1 - \left( \mu_1 + \Sigma_{12}^\mathrm{T} \Sigma_{22}^{-1} (x_2-\mu_2) \right) \right]^\mathrm{T} (\Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21})^{-1} \left[ x_1 - \left( \mu_1 + \Sigma_{12}^\mathrm{T} \Sigma_{22}^{-1} (x_2-\mu_2) \right) \right] \right]
\end{split}
\end{equation}

where we have used the fact that $\Sigma_{21}^\mathrm{T} = \Sigma_{12}$, because $\Sigma$ is a covariance matrix.

\vspace{1em}
The determinant of a block matrix is

\begin{equation} \label{eq:mvn-cond-Block-det}
\begin{vmatrix} A & B \\ C & D \end{vmatrix} = |D| \cdot | A - B D^{-1} C | \; ,
\end{equation}

such that we have for $\Sigma$ that

\begin{equation} \label{eq:mvn-cond-Sigma-det}
\begin{vmatrix} \Sigma_{11} & \Sigma_{12} \\ \Sigma_{21} & \Sigma_{22} \end{vmatrix} = |\Sigma_{22}| \cdot | \Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21} | \; .
\end{equation}

With this and $n - n_2 = n_1$, we finally arrive at

\begin{equation} \label{eq:mvn-cond-mvn-cond-s9}
\begin{split}
p(x_1|x_2) = &\frac{1}{\sqrt{(2 \pi)^{n_1} | \Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21} |}} \cdot \exp \left[ -\frac{1}{2} \cdot \right. \\
&\! \left. \left[ x_1 - \left( \mu_1 + \Sigma_{12}^\mathrm{T} \Sigma_{22}^{-1} (x_2-\mu_2) \right) \right]^\mathrm{T} (\Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21})^{-1} \left[ x_1 - \left( \mu_1 + \Sigma_{12}^\mathrm{T} \Sigma_{22}^{-1} (x_2-\mu_2) \right) \right] \right]
\end{split}
\end{equation}

which is the probability density function of a multivariate normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mvn-pdf})

\begin{equation} \label{eq:mvn-cond-mvn-cond-s10}
p(x_1|x_2) = \mathcal{N}(x_1; \mu_{1|2}, \Sigma_{1|2})
\end{equation}

with the mean $\mu_{1 \vert 2}$ and variance $\Sigma_{1 \vert 2}$ given by \eqref{eq:mvn-cond-mvn-cond-hyp}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wang, Ruye (2006): "Marginal and conditional distributions of multivariate normal distribution"; in: \textit{Computer Image Processing and Analysis}; URL: \url{http://fourier.eng.hmc.edu/e161/lectures/gaussianprocess/node7.html}.
\item Wikipedia (2020): "Multivariate normal distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-03-20; URL: \url{https://en.wikipedia.org/wiki/Multivariate_normal_distribution#Conditional_distributions}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P88 | shortcut: mvn-cond | author: JoramSoch | date: 2020-03-20, 08:44.
\vspace{1em}



\subsection{Normal-gamma distribution}

\subsubsection[\textit{Definition}]{Definition} \label{sec:ng}
\setcounter{equation}{0}

**Definition**: Let $X$ be an $n \times 1$ random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}) and let $Y$ be a positive random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}). Then, $X$ and $Y$ are said to follow a normal-gamma distribution

\begin{equation} \label{eq:ng-ng}
X,Y \sim \mathrm{NG}(\mu, \Lambda, a, b) \; ,
\end{equation}

if and only if their joint probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) is given by

\begin{equation} \label{eq:ng-ng-pdf}
f_{X,Y}(x,y) = \mathcal{N}(x; \mu, (y \Lambda)^{-1}) \cdot \mathrm{Gam}(y; a, b)
\end{equation}

where $\mathcal{N}(x; \mu, \Sigma)$ is the probability density function of the multivariate normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mvn-pdf}) with mean $\mu$ and covariance $\Sigma$ and $\mathrm{Gam}(x; a, b)$ is the probability density function of the gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-pdf}) with shape $a$ and rate $b$. The $n \times n$ matrix $\Lambda$ is referred to as the precision matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:precmat}) of the normal-gamma distribution.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Koch KR (2007): "Normal-Gamma Distribution"; in: \textit{Introduction to Bayesian Statistics}, ch. 2.5.3, pp. 55-56, eq. 2.212; URL: \url{https://www.springer.com/gp/book/9783540727231}; DOI: 10.1007/978-3-540-72726-2.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D5 | shortcut: ng | author: JoramSoch | date: 2020-01-27, 14:28.
\vspace{1em}



\subsubsection[\textbf{Probability density function}]{Probability density function} \label{sec:ng-pdf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $x$ and $y$ follow a normal-gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:ng}):

\begin{equation} \label{eq:ng-pdf-ng}
x,y \sim \mathrm{NG}(\mu, \Lambda, a, b) \; .
\end{equation}

Then, the joint probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $x$ and $y$ is

\begin{equation} \label{eq:ng-pdf-ng-pdf}
p(x,y) = \sqrt{\frac{|\Lambda|}{(2 \pi)^n}} \frac{b^a}{\Gamma(a)} \cdot y^{a+\frac{n}{2}-1} \exp \left[ -\frac{y}{2} \left( (x-\mu)^\mathrm{T} \Lambda (x-\mu) + 2b \right) \right] \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The probability density of the normal-gamma distribution is defined as ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:ng}) as the product of a multivariate normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mvn}) over $x$ conditional on $y$ and a univariate gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:gam}) over $y$:

\begin{equation} \label{eq:ng-pdf-ng-pdf-w1}
p(x,y) = \mathcal{N}(x; \mu, (y \Lambda)^{-1}) \cdot \mathrm{Gam}(y; a, b)
\end{equation}

With the probability density function of the multivariate normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mvn-pdf}) and the probability density function of the gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-pdf}), this becomes:

\begin{equation} \label{eq:ng-pdf-ng-pdf-s2}
p(x,y) = \sqrt{\frac{|y \Lambda|}{(2 \pi)^n}} \exp \left[ -\frac{1}{2} (x-\mu)^\mathrm{T} (y \Lambda) (x-\mu) \right] \cdot \frac{b^a}{\Gamma(a)} y^{a-1} \exp\left[-by\right] \; .
\end{equation}

Using the relation $\lvert y A \rvert = y^n \lvert A \rvert$ for an $n \times n$ matrix $A$ and rearranging the terms, we have:

\begin{equation} \label{eq:ng-pdf-ng-pdf-qed}
p(x,y) = \sqrt{\frac{|\Lambda|}{(2 \pi)^n}} \frac{b^a}{\Gamma(a)} \cdot y^{a+\frac{n}{2}-1} \exp \left[ -\frac{y}{2} \left( (x-\mu)^\mathrm{T} \Lambda (x-\mu) + 2b \right) \right] \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Koch KR (2007): "Normal-Gamma Distribution"; in: \textit{Introduction to Bayesian Statistics}, ch. 2.5.3, pp. 55-56, eq. 2.212; URL: \url{https://www.springer.com/gp/book/9783540727231}; DOI: 10.1007/978-3-540-72726-2.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P44 | shortcut: ng-pdf | author: JoramSoch | date: 2020-02-07, 20:44.
\vspace{1em}



\subsubsection[\textbf{Kullback-Leibler divergence}]{Kullback-Leibler divergence} \label{sec:ng-kl}
\setcounter{equation}{0}

\textbf{Theorem:} Let $x$ be an $n \times 1$ random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}) and let $y$ be a positive random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}). Assume two normal-gamma distributions ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:ng}) $P$ and $Q$ specifying the joint distribution of $x$ and $y$ as

\begin{equation} \label{eq:ng-kl-NGs}
\begin{split}
P: \; (x,y) &\sim \mathrm{NG}(\mu_1, \Lambda_1^{-1}, a_1, b_1) \\
Q: \; (x,y) &\sim \mathrm{NG}(\mu_2, \Lambda_2^{-1}, a_2, b_2) \; . \\
\end{split}
\end{equation}

Then, the Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) of $P$ from $Q$ is given by

\begin{equation} \label{eq:ng-kl-NG-KL}
\begin{split}
\mathrm{KL}[P\,||\,Q] &= \frac{1}{2} \frac{a_1}{b_1} \left[ (\mu_2 - \mu_1)^T \Lambda_2 (\mu_2 - \mu_1) \right] + \frac{1}{2} \, \mathrm{tr}(\Lambda_2 \Lambda_1^{-1}) - \frac{1}{2} \ln \frac{|\Lambda_2|}{|\Lambda_1|} - \frac{n}{2} \\
&+ a_2 \, \ln \frac{b_1}{b_2} - \ln \frac{\Gamma(a_1)}{\Gamma(a_2)} + (a_1 - a_2) \, \psi(a_1) - (b_1 - b_2) \, \frac{a_1}{b_1} \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Proof:} The probabibility density function of the normal-gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:ng-pdf}) is

\begin{equation} \label{eq:ng-kl-NG-pdf}
p(x,y) = p(x|y) \cdot p(y) = \mathcal{N}(x; \mu, (y \Lambda)^{-1}) \cdot \mathrm{Gam}(y; a, b) \; .
\end{equation}

The Kullback-Leibler divergence of the multivariate normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mvn-kl}) is

\begin{equation} \label{eq:ng-kl-mvn-KL}
\mathrm{KL}[P\,||\,Q] = \frac{1}{2} \left[ (\mu_2 - \mu_1)^T \Sigma_2^{-1} (\mu_2 - \mu_1) + \mathrm{tr}(\Sigma_2^{-1} \Sigma_1) - \ln \frac{|\Sigma_1|}{|\Sigma_2|} - n \right]
\end{equation}

and the Kullback-Leibler divergence of the univariate gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-kl}) is

\begin{equation} \label{eq:ng-kl-gam-KL}
\mathrm{KL}[P\,||\,Q] = a_2 \, \ln \frac{b_1}{b_2} - \ln \frac{\Gamma(a_1)}{\Gamma(a_2)} + (a_1 - a_2) \, \psi(a_1) - (b_1 - b_2) \, \frac{a_1}{b_1}
\end{equation}

where $\Gamma(x)$ is the gamma function and $\psi(x)$ is the digamma function.

\vspace{1em}
The KL divergence for a continuous random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) is given by 

\begin{equation} \label{eq:ng-kl-KL-cont}
\mathrm{KL}[P\,||\,Q] = \int_{\mathcal{Z}} p(z) \, \ln \frac{p(z)}{q(z)} \, \mathrm{d}z
\end{equation}

which, applied to the normal-gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:ng}) over $x$ and $y$, yields

\begin{equation} \label{eq:ng-kl-NG-KL0}
\mathrm{KL}[P\,||\,Q] = \int_{0}^{\infty} \int_{\mathbb{R}^n} p(x,y) \, \ln \frac{p(x,y)}{q(x,y)} \, \mathrm{d}x \, \mathrm{d}y \; .
\end{equation}

Using the law of conditional probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-cond}), this can be evaluated as follows:

\begin{equation} \label{eq:ng-kl-NG-KL1}
\begin{split}
\mathrm{KL}[P\,||\,Q] &= \int_{0}^{\infty} \int_{\mathbb{R}^n} p(x|y) \, p(y) \, \ln \frac{p(x|y) \, p(y)}{q(x|y) \, q(y)} \, \mathrm{d}x \, \mathrm{d}y \\
&= \int_{0}^{\infty} \int_{\mathbb{R}^n} p(x|y)\, p(y) \, \ln \frac{p(x|y)}{q(x|y)} \, \mathrm{d}x \, \mathrm{d}y + \int_{0}^{\infty} \int_{\mathbb{R}^n} p(x|y)\, p(y) \, \ln \frac{p(y)}{q(y)} \, \mathrm{d}x \, \mathrm{d}y \\
&= \int_{0}^{\infty} p(y) \int_{\mathbb{R}^n} p(x|y) \, \ln \frac{p(x|y)}{q(x|y)} \, \mathrm{d}x \, \mathrm{d}y + \int_{0}^{\infty} p(y) \, \ln \frac{p(y)}{q(y)} \int_{\mathbb{R}^n} p(x|y) \, \mathrm{d}x \, \mathrm{d}y \\
&= \left\langle \mathrm{KL}[p(x|y)\,||\,q(x|y)] \right\rangle_{p(y)} + \mathrm{KL}[p(y)\,||\,q(y)] \; .
\end{split}
\end{equation}

In other words, the KL divergence between two normal-gamma distributions over $x$ and $y$ is equal to the sum of a multivariate normal KL divergence regarding $x$ conditional on $y$, expected over $y$, and a univariate gamma KL divergence regarding $y$.

\vspace{1em}
From equations \eqref{eq:ng-kl-NG-pdf} and \eqref{eq:ng-kl-mvn-KL}, the first term becomes

\begin{equation} \label{eq:ng-kl-exp-mvn-KL-s1}
\begin{split}
&\left\langle \mathrm{KL}[p(x|y)\,||\,q(x|y)] \right\rangle_{p(y)} \\
&= \left\langle \frac{1}{2} \left[ (\mu_2 - \mu_1)^T (y \Lambda_2) (\mu_2 - \mu_1) + \mathrm{tr}\left( (y \Lambda_2) (y \Lambda_1)^{-1} \right) - \ln \frac{|(y \Lambda_1)^{-1}|}{|(y \Lambda_2)^{-1}|} - n \right] \right\rangle_{p(y)} \\
&= \left\langle \frac{y}{2} (\mu_2 - \mu_1)^T \Lambda_2 (\mu_2 - \mu_1) + \frac{1}{2} \, \mathrm{tr}(\Lambda_2 \Lambda_1^{-1}) - \frac{1}{2} \ln \frac{|\Lambda_2|}{|\Lambda_1|} - \frac{n}{2} \right\rangle_{p(y)} \\
\end{split}
\end{equation}

and using the relation ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-mean}) $y \sim \mathrm{Gam}(a,b) \Rightarrow \left\langle y \right\rangle = a/b$, we have

\begin{equation} \label{eq:ng-kl-exp-mvn-KL-s2}
\begin{split}
\left\langle \mathrm{KL}[p(x|y)\,||\,q(x|y)] \right\rangle_{p(y)} = \frac{1}{2} \frac{a_1}{b_1} (\mu_2 - \mu_1)^T \Lambda_2 (\mu_2 - \mu_1) + \frac{1}{2} \, \mathrm{tr}(\Lambda_2 \Lambda_1^{-1}) - \frac{1}{2} \ln \frac{|\Lambda_2|}{|\Lambda_1|} - \frac{n}{2} \; .
\end{split}
\end{equation}

By plugging \eqref{eq:ng-kl-exp-mvn-KL-s2} and \eqref{eq:ng-kl-gam-KL} into \eqref{eq:ng-kl-NG-KL1}, one arrives at the KL divergence given by \eqref{eq:ng-kl-NG-KL}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Soch \& Allefeld (2016): "Kullback-Leibler Divergence for the Normal-Gamma Distribution"; in: \textit{arXiv math.ST}, 1611.01437; URL: \url{https://arxiv.org/abs/1611.01437}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P6 | shortcut: ng-kl | author: JoramSoch | date: 2019-12-06, 09:35.
\vspace{1em}



\subsubsection[\textbf{Marginal distributions}]{Marginal distributions} \label{sec:ng-marg}
\setcounter{equation}{0}

\textbf{Theorem:} Let $x$ and $y$ follow a normal-gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:ng}):

\begin{equation} \label{eq:ng-marg-ng}
x,y \sim \mathrm{NG}(\mu, \Lambda, a, b) \; .
\end{equation}

Then, the marginal distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-marg}) of $y$ is a gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:gam})

\begin{equation} \label{eq:ng-marg-ng-marg-y}
y \sim \mathrm{Gam}(a, b)
\end{equation}

and the marginal distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-marg}) of $x$ is a multivariate t-distribution ($\rightarrow$ Definition "mvt")

\begin{equation} \label{eq:ng-marg-ng-marg-x}
x \sim \mathrm{t}\left( \mu, \left(\frac{a}{b} \Lambda \right)^{-1}, 2a \right) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The probability density function of the normal-gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:ng-pdf}) is given by

\begin{equation} \label{eq:ng-marg-ng-pdf}
\begin{split}
p(x,y) &= p(x|y) \cdot p(y) \\
p(x|y) &= \mathcal{N}(x; \mu, (y \Lambda)^{-1}) \\
p(y) &= \mathrm{Gam}(y; a, b) \; .
\end{split}
\end{equation}

\vspace{1em}
Using the law of marginal probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}), the marginal distribution of $y$ can be derived as

\begin{equation} \label{eq:ng-marg-ng-marg-y-qed}
\begin{split}
p(y) &= \int p(x,y) \, \mathrm{d}x \\
&= \int \mathcal{N}(x; \mu, (y \Lambda)^{-1}) \, \mathrm{Gam}(y; a, b) \, \mathrm{d}x \\
&= \mathrm{Gam}(y; a, b) \int \mathcal{N}(x; \mu, (y \Lambda)^{-1}) \, \mathrm{d}x \\
&= \mathrm{Gam}(y; a, b)
\end{split}
\end{equation}

which is the probability density function of the gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-pdf}) with shape parameter $a$ and rate parameter $b$.

\vspace{1em}
Using the law of marginal probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}), the marginal distribution of $x$ can be derived as

\begin{equation} \label{eq:ng-marg-ng-marg-x-qed}
\begin{split}
p(x) &= \int p(x,y) \, \mathrm{d}y \\
&= \int \mathcal{N}(x; \mu, (y \Lambda)^{-1}) \, \mathrm{Gam}(y; a, b) \, \mathrm{d}y \\
&= \int \sqrt{\frac{|y \Lambda|}{(2 \pi)^n}} \, \exp \left[ -\frac{1}{2} (x-\mu)^\mathrm{T} (y \Lambda) (x-\mu) \right] \cdot \frac{b^a}{\Gamma(a)} \, y^{a-1} \exp[-b y] \, \mathrm{d}y \\
&= \int \sqrt{\frac{y^n |\Lambda|}{(2 \pi)^n}} \, \exp \left[ -\frac{1}{2} (x-\mu)^\mathrm{T} (y \Lambda) (x-\mu) \right] \cdot \frac{b^a}{\Gamma(a)} \, y^{a-1} \exp[-b y] \, \mathrm{d}y \\
&= \int \sqrt{\frac{|\Lambda|}{(2 \pi)^n}} \cdot \frac{b^a}{\Gamma(a)} \cdot y^{a+\frac{n}{2}-1} \cdot \exp \left[ -\left( b + \frac{1}{2} (x-\mu)^\mathrm{T} \Lambda (x-\mu) \right) y \right] \mathrm{d}y \\
&= \int \sqrt{\frac{|\Lambda|}{(2 \pi)^n}} \cdot \frac{b^a}{\Gamma(a)} \cdot \frac{\Gamma\left( a+\frac{n}{2} \right)}{\left( b + \frac{1}{2} (x-\mu)^\mathrm{T} \Lambda (x-\mu) \right)^{a+\frac{n}{2}}} \cdot \mathrm{Gam}\left( y; a+\frac{n}{2}, b + \frac{1}{2} (x-\mu)^\mathrm{T} \Lambda (x-\mu) \right) \mathrm{d}y \\
&= \sqrt{\frac{|\Lambda|}{(2 \pi)^n}} \cdot \frac{b^a}{\Gamma(a)} \cdot \frac{\Gamma\left( a+\frac{n}{2} \right)}{\left( b + \frac{1}{2} (x-\mu)^\mathrm{T} \Lambda (x-\mu) \right)^{a+\frac{n}{2}}} \int \mathrm{Gam}\left( y; a+\frac{n}{2}, b + \frac{1}{2} (x-\mu)^\mathrm{T} \Lambda (x-\mu) \right) \mathrm{d}y \\
&= \sqrt{\frac{|\Lambda|}{(2 \pi)^n}} \cdot \frac{b^a}{\Gamma(a)} \cdot \frac{\Gamma\left( a+\frac{n}{2} \right)}{\left( b + \frac{1}{2} (x-\mu)^\mathrm{T} \Lambda (x-\mu) \right)^{a+\frac{n}{2}}} \\
&= \frac{\sqrt{|\Lambda|}}{(2 \pi)^\frac{n}{2}} \cdot \frac{\Gamma\left( \frac{2a+n}{2} \right)}{\Gamma\left( \frac{2a}{2} \right)} \cdot b^a \cdot \left( b + \frac{1}{2} (x-\mu)^\mathrm{T} \Lambda (x-\mu) \right)^{-\left( a+\frac{n}{2} \right)} \\
&= \frac{\sqrt{|\Lambda|}}{\pi^\frac{n}{2}} \cdot \frac{\Gamma\left( \frac{2a+n}{2} \right)}{\Gamma\left( \frac{2a}{2} \right)} \cdot \left( \frac{1}{b} \right)^{-a} \cdot \left( b + \frac{1}{2} (x-\mu)^\mathrm{T} \Lambda (x-\mu) \right)^{-a} \cdot 2^{-\frac{n}{2}} \cdot \left( b + \frac{1}{2} (x-\mu)^\mathrm{T} \Lambda (x-\mu) \right)^{-\frac{n}{2}} \\
&= \frac{\sqrt{|\Lambda|}}{\pi^\frac{n}{2}} \cdot \frac{\Gamma\left( \frac{2a+n}{2} \right)}{\Gamma\left( \frac{2a}{2} \right)} \cdot \left( 1 + \frac{1}{2b} (x-\mu)^\mathrm{T} \Lambda (x-\mu) \right)^{-a} \cdot \left( 2b + (x-\mu)^\mathrm{T} \Lambda (x-\mu) \right)^{-\frac{n}{2}} \\
&= \frac{\sqrt{|\Lambda|}}{\pi^\frac{n}{2}} \cdot \frac{\Gamma\left( \frac{2a+n}{2} \right)}{\Gamma\left( \frac{2a}{2} \right)} \cdot \left( \frac{1}{2a} \right)^{-a} \cdot \left( 2a + (x-\mu)^\mathrm{T} \left( \frac{a}{b}\Lambda \right) (x-\mu) \right)^{-a} \cdot \left( \frac{b}{a} \right)^{-\frac{n}{2}} \cdot \left( 2a + (x-\mu)^\mathrm{T} \left( \frac{a}{b}\Lambda \right) (x-\mu) \right)^{-\frac{n}{2}} \\
&= \frac{\sqrt{\left( \frac{a}{b} \right)^n |\Lambda|}}{(2a)^{-a}\,\pi^\frac{n}{2}} \cdot \frac{\Gamma\left( \frac{2a+n}{2} \right)}{\Gamma\left( \frac{2a}{2} \right)} \cdot \left( 2a + (x-\mu)^\mathrm{T} \left( \frac{a}{b}\Lambda \right) (x-\mu) \right)^{-a} \cdot \left( 2a + (x-\mu)^\mathrm{T} \left( \frac{a}{b}\Lambda \right) (x-\mu) \right)^{-\frac{n}{2}} \\
&= \frac{\sqrt{\left( \frac{a}{b} \right)^n |\Lambda|}}{(2a)^{-a}\,\pi^\frac{n}{2}} \cdot \frac{\Gamma\left( \frac{2a+n}{2} \right)}{\Gamma\left( \frac{2a}{2} \right)} \cdot (2a)^{-a} \cdot \left( 1 + \frac{1}{2a} (x-\mu)^\mathrm{T} \left( \frac{a}{b}\Lambda \right) (x-\mu) \right)^{-a} \cdot (2a)^{-\frac{n}{2}} \cdot \left( 1 + \frac{1}{2a} (x-\mu)^\mathrm{T} \left( \frac{a}{b}\Lambda \right) (x-\mu) \right)^{-\frac{n}{2}} \\
&= \frac{\sqrt{\left( \frac{a}{b} \right)^n |\Lambda|}}{(2a)^\frac{n}{2}\,\pi^\frac{n}{2}} \cdot \frac{\Gamma\left( \frac{2a+n}{2} \right)}{\Gamma\left( \frac{2a}{2} \right)} \cdot \left( 1 + \frac{1}{2a} (x-\mu)^\mathrm{T} \left( \frac{a}{b}\Lambda \right) (x-\mu) \right)^{-\frac{2a+n}{2}} \\
&= \sqrt{\frac{\left| \frac{a}{b}\,\Lambda \right|}{(2a\,\pi)^n}} \cdot \frac{\Gamma\left( \frac{2a+n}{2} \right)}{\Gamma\left( \frac{2a}{2} \right)} \cdot \left( 1 + \frac{1}{2a} (x-\mu)^\mathrm{T} \left( \frac{a}{b}\Lambda \right) (x-\mu) \right)^{-\frac{2a+n}{2}} \\
\end{split}
\end{equation}

which is the probability density function of a multivariate t-distribution ($\rightarrow$ Proof "mvt-pdf") with mean vector $\mu$, shape matrix $\left( \frac{a}{b}\Lambda \right)^{-1}$ and $2a$ degrees of freedom.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P36 | shortcut: ng-marg | author: JoramSoch | date: 2020-01-29, 21:42.
\vspace{1em}



\subsubsection[\textbf{Conditional distributions}]{Conditional distributions} \label{sec:ng-cond}
\setcounter{equation}{0}

\textbf{Theorem:} Let $x$ and $y$ follow a normal-gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:ng}):

\begin{equation} \label{eq:ng-cond-ng}
x,y \sim \mathrm{NG}(\mu, \Lambda, a, b) \; .
\end{equation}

Then,

1) the conditional distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-cond}) of $x$ given $y$ is a multivariate normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mvn})

\begin{equation} \label{eq:ng-cond-ng-cond-x-y}
x|y \sim \mathcal{N}(\mu, (y \Lambda)^{-1}) \; ;
\end{equation}

2) the conditional distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-cond}) of a subset vector $x_1$, given the complement vector $x_2$ and $y$, is also a multivariate normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mvn})

\begin{equation} \label{eq:ng-cond-ng-cond-x1-x2-y}
x_1|x_2,y \sim \mathcal{N}(\mu_{1|2}(y), \Sigma_{1|2}(y))
\end{equation}

with the conditional mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) and covariance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cov})

\begin{equation} \label{eq:ng-cond-ng-cond-x1-x2-y-hyp}
\begin{split}
\mu_{1|2}(y) &= \mu_1 + \Sigma_{12} \Sigma_{22}^{-1} (x_2 - \mu_2) \\
\Sigma_{1|2}(y) &= \Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{12}
\end{split}
\end{equation}

where $\mu_1$, $\mu_2$ and $\Sigma_{11}$, $\Sigma_{12}$, $\Sigma_{22}$, $\Sigma_{21}$ are block-wise components ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mvn-cond}) of $\mu$ and $\Sigma(y) = (y \Lambda)^{-1}$;

3) the conditional distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-cond}) of $y$ given $x$ is a gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:gam})

\begin{equation} \label{eq:ng-cond-ng-cond-y-x}
y|x \sim \mathrm{Gam}\left( a + \frac{n}{2}, b + \frac{1}{2} (x-\mu)^\mathrm{T} \Lambda (x-\mu) \right)
\end{equation}

where $n$ is the dimensionality of $x$.


\vspace{1em}
\textbf{Proof:}

1) This follows from the definition of the normal-gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:ng}):

\begin{equation} \label{eq:ng-cond-ng-pdf}
\begin{split}
p(x,y) &= p(x|y) \cdot p(y) \\
&= \mathcal{N}(x; \mu, (y \Lambda)^{-1}) \cdot \mathrm{Gam}(y; a, b) \; .
\end{split}
\end{equation}

2) This follows from \eqref{eq:ng-cond-ng-cond-x-y} and the conditional distributions of the multivariate normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mvn-cond}):

\begin{equation} \label{eq:ng-cond-mvn-cond}
\begin{split}
x &\sim \mathcal{N}(\mu, \Sigma) \\
\Rightarrow x_1|x_2 &\sim \mathcal{N}(\mu_{1|2}, \Sigma_{1|2}) \\
\mu_{1|2} &= \mu_1 + \Sigma_{12} \Sigma_{22}^{-1} (x_2 - \mu_2) \\
\Sigma_{1|2} &= \Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21} \; .
\end{split}
\end{equation}

3) The conditional density of $y$ given $x$ follows from Bayes' theorem ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:bayes-th}) as

\begin{equation} \label{eq:ng-cond-ng-cond-y-x-s1}
p(y|x) = \frac{p(x|y) \cdot p(y)}{p(x)} \; .
\end{equation}

The conditional distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-cond}) of $x$ given $y$ is a multivariate normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:ng-pdf})

\begin{equation} \label{eq:ng-cond-ng-x-y-pdf}
p(x|y) = \mathcal{N}(x; \mu, (y \Lambda)^{-1}) = \sqrt{\frac{|y \Lambda|}{(2 \pi)^n}} \exp \left[ -\frac{1}{2} (x-\mu)^\mathrm{T} (y \Lambda) (x-\mu) \right] \; ,
\end{equation}

the marginal distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-marg}) of $y$ is a gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:ng-marg})

\begin{equation} \label{eq:ng-cond-ng-y-pdf}
p(y) = \mathrm{Gam}(y; a, b) = \frac{b^a}{\Gamma(a)} y^{a-1} \exp\left[ -by \right]
\end{equation}

and the marginal distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-marg}) of $x$ is a multivariate t-distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:ng-marg})

\begin{equation} \label{eq:ng-cond-ng-x-pdf}
\begin{split}
p(x) &= \mathrm{t}\left( x; \mu, \left(\frac{a}{b} \Lambda \right)^{-1}, 2a \right) \\
&= \sqrt{\frac{\left| \frac{a}{b}\,\Lambda \right|}{(2a\,\pi)^n}} \cdot \frac{\Gamma\left( \frac{2a+n}{2} \right)}{\Gamma\left( \frac{2a}{2} \right)} \cdot \left( 1 + \frac{1}{2a} (x-\mu)^\mathrm{T} \left( \frac{a}{b}\Lambda \right) (x-\mu) \right)^{-\frac{2a+n}{2}} \\
&= \sqrt{\frac{|\Lambda|}{(2 \pi)^n}} \cdot \frac{\Gamma\left( a+\frac{n}{2} \right)}{\Gamma(a)} \cdot b^a \cdot \left( b + \frac{1}{2} (x-\mu)^\mathrm{T} \Lambda (x-\mu) \right)^{-\left( a+\frac{n}{2} \right)} \; .
\end{split}
\end{equation}

Plugging \eqref{eq:ng-cond-ng-x-y-pdf}, \eqref{eq:ng-cond-ng-y-pdf} and \eqref{eq:ng-cond-ng-x-pdf} into \eqref{eq:ng-cond-ng-cond-y-x-s1}, we obtain

\begin{equation} \label{eq:ng-cond-ng-cond-y-x-s2}
\begin{split}
p(y|x) &= \frac{\sqrt{\frac{|y \Lambda|}{(2 \pi)^n}} \exp \left[ -\frac{1}{2} (x-\mu)^\mathrm{T} (y \Lambda) (x-\mu) \right] \cdot \frac{b^a}{\Gamma(a)} y^{a-1} \exp\left[ -by \right]}{\sqrt{\frac{|\Lambda|}{(2 \pi)^n}} \cdot \frac{\Gamma\left( a+\frac{n}{2} \right)}{\Gamma(a)} \cdot b^a \cdot \left( b + \frac{1}{2} (x-\mu)^\mathrm{T} \Lambda (x-\mu) \right)^{-\left( a+\frac{n}{2} \right)}} \\
&= y^{\frac{n}{2}} \cdot \exp \left[ -\frac{1}{2} (x-\mu)^\mathrm{T} (y \Lambda) (x-\mu) \right] \cdot y^{a-1} \cdot \exp\left[ -by \right] \cdot \frac{1}{\Gamma\left( a+\frac{n}{2} \right)} \cdot \left( b + \frac{1}{2} (x-\mu)^\mathrm{T} \Lambda (x-\mu) \right)^{a+\frac{n}{2}} \\
&= \frac{\left( b + \frac{1}{2} (x-\mu)^\mathrm{T} \Lambda (x-\mu) \right)^{a+\frac{n}{2}}}{\Gamma\left( a+\frac{n}{2} \right)} \cdot y^{a+\frac{n}{2}-1} \cdot \exp \left[ -\left( b + \frac{1}{2} (x-\mu)^\mathrm{T} \Lambda (x-\mu) \right) \right]
\end{split}
\end{equation}

which is the probability density function of a gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-pdf}) with shape and rate parameters

\begin{equation} \label{eq:ng-cond-ng-cond-y-x-hyp}
a + \frac{n}{2} \quad \text{and} \quad b + \frac{1}{2} (x-\mu)^\mathrm{T} \Lambda (x-\mu) \; ,
\end{equation}

such that

\begin{equation} \label{eq:ng-cond-ng-cond-y-x-qed}
p(y|x) = \mathrm{Gam}\left( y; a + \frac{n}{2}, b + \frac{1}{2} (x-\mu)^\mathrm{T} \Lambda (x-\mu) \right) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P146 | shortcut: ng-cond | author: JoramSoch | date: 2020-08-05, 06:54.
\vspace{1em}



\subsection{Dirichlet distribution}

\subsubsection[\textit{Definition}]{Definition} \label{sec:dir}
\setcounter{equation}{0}

**Definition**: Let $X$ be a random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}). Then, $X$ is said to follow a Dirichlet distribution with concentration parameters $\alpha = \left[ \alpha_1, \ldots, \alpha_k \right]$

\begin{equation} \label{eq:dir-Dir}
X \sim \mathrm{Dir}(\alpha) \; ,
\end{equation}

if and only if its probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) is given by

\begin{equation} \label{eq:dir-beta-pdf}
\mathrm{Dir}(x; \alpha) = \frac{\Gamma\left( \sum_{i=1}^k \alpha_i \right)}{\prod_{i=1}^k \Gamma(\alpha_i)} \, \prod_{i=1}^k {x_i}^{\alpha_i-1}
\end{equation}

where $\alpha_i > 0$ for all $i = 1, \ldots, k$, and the density is zero, if $x_i \notin [0,1]$ for any $i = 1, \ldots, k$ or $\sum_{i=1}^k x_i \neq 1$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Dirichlet distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-05-10; URL: \url{https://en.wikipedia.org/wiki/Dirichlet_distribution#Probability_density_function}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D54 | shortcut: dir | author: JoramSoch | date: 2020-05-10, 20:36.
\vspace{1em}



\subsubsection[\textbf{Probability density function}]{Probability density function} \label{sec:dir-pdf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random vector ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvec}) following a Dirichlet distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:dir}):

\begin{equation} \label{eq:dir-pdf-Dir}
X \sim \mathrm{Dir}(\alpha) \; .
\end{equation}

Then, the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $X$ is

\begin{equation} \label{eq:dir-pdf-Dir-pdf}
f_X(x) = \frac{\Gamma\left( \sum_{i=1}^k \alpha_i \right)}{\prod_{i=1}^k \Gamma(\alpha_i)} \, \prod_{i=1}^k {x_i}^{\alpha_i-1} \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} This follows directly from the definition of the Dirichlet distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:dir}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P95 | shortcut: dir-pdf | author: JoramSoch | date: 2020-05-05, 21:22.
\vspace{1em}



\pagebreak
\section{Matrix-variate continuous distributions}

\subsection{Matrix-normal distribution}

\subsubsection[\textit{Definition}]{Definition} \label{sec:matn}
\setcounter{equation}{0}

**Definition**: Let $X$ be an $n \times p$ random matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rmat}). Then, $X$ is said to be matrix-normally distributed with mean $M$, covariance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:covmat}) across rows $U$ and covariance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:covmat}) across columns $V$

\begin{equation} \label{eq:matn-matn}
X \sim \mathcal{MN}(M, U, V) \; ,
\end{equation}

if and only if its probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) is given by

\begin{equation} \label{eq:matn-matn-pdf}
\mathcal{MN}(X; M, U, V) = \frac{1}{\sqrt{(2\pi)^{np} |V|^n |U|^p}} \cdot \exp\left[-\frac{1}{2} \mathrm{tr}\left( V^{-1} (X-M)^\mathrm{T} \, U^{-1} (X-M) \right) \right]
\end{equation}

where $M$ is an $n \times p$ real matrix, $U$ is an $n \times n$ positive definite matrix and $V$ is a $p \times p$ positive definite matrix.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Matrix normal distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-01-27; URL: \url{https://en.wikipedia.org/wiki/Matrix_normal_distribution#Definition}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D6 | shortcut: matn | author: JoramSoch | date: 2020-01-27, 14:37.
\vspace{1em}



\subsubsection[\textbf{Probability density function}]{Probability density function} \label{sec:matn-pdf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rmat}) following a matrix-normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:matn}):

\begin{equation} \label{eq:matn-pdf-matn}
X \sim \mathcal{MN}(M, U, V) \; .
\end{equation}

Then, the probability density function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) of $X$ is

\begin{equation} \label{eq:matn-pdf-matn-pdf}
f(X) = \frac{1}{\sqrt{(2\pi)^{np} |V|^n |U|^p}} \cdot \exp\left[-\frac{1}{2} \mathrm{tr}\left( V^{-1} (X-M)^\mathrm{T} \, U^{-1} (X-M) \right) \right] \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} This follows directly from the definition of the matrix-normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:matn}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P70 | shortcut: matn-pdf | author: JoramSoch | date: 2020-03-02, 21:03.
\vspace{1em}



\subsubsection[\textbf{Equivalence to multivariate normal distribution}]{Equivalence to multivariate normal distribution} \label{sec:matn-mvn}
\setcounter{equation}{0}

\textbf{Theorem:} The matrix $X$ is matrix-normally distributed ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:matn})

\begin{equation} \label{eq:matn-mvn-matn}
X \sim \mathcal{MN}(M, U, V) \; ,
\end{equation}

if and only if $\mathrm{vec}(X)$ is multivariate normally distributed ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mvn})

\begin{equation} \label{eq:matn-mvn-mvn}
\mathrm{vec}(X) \sim \mathcal{MN}(\mathrm{vec}(M), V \otimes U)
\end{equation}

where $\mathrm{vec}(X)$ is the vectorization operator and $\otimes$ is the Kronecker product.


\vspace{1em}
\textbf{Proof:} The probability density function of the matrix-normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:matn-pdf}) with $n \times p$ mean $M$, $n \times n$ covariance across rows $U$ and $p \times p$ covariance across columns $V$ is

\begin{equation} \label{eq:matn-mvn-matn-pdf}
\mathcal{MN}(X; M, U, V) = \frac{1}{\sqrt{(2\pi)^{np} |V|^n |U|^p}} \cdot \exp\left[-\frac{1}{2} \mathrm{tr}\left( V^{-1} (X-M)^\mathrm{T} \, U^{-1} (X-M) \right) \right] \; .
\end{equation}

Using the trace property $\mathrm{tr}(ABC) = \mathrm{tr}(BCA)$, we have:

\begin{equation} \label{eq:matn-mvn-matn-mvn-s1}
\mathcal{MN}(X; M, U, V) = \frac{1}{\sqrt{(2\pi)^{np} |V|^n |U|^p}} \cdot \exp\left[-\frac{1}{2} \mathrm{tr}\left( (X-M)^\mathrm{T} \, U^{-1} (X-M) \, V^{-1} \right) \right] \; .
\end{equation}

Using the trace-vectorization relation $\mathrm{tr}(A^\mathrm{T} B) = \mathrm{vec}(A)^\mathrm{T} \, \mathrm{vec}(B)$, we have:

\begin{equation} \label{eq:matn-mvn-matn-mvn-s2}
\mathcal{MN}(X; M, U, V) = \frac{1}{\sqrt{(2\pi)^{np} |V|^n |U|^p}} \cdot \exp\left[-\frac{1}{2} \mathrm{vec}(X-M)^\mathrm{T} \, \mathrm{vec}\left( U^{-1} (X-M) \, V^{-1} \right) \right] \; .
\end{equation}

Using the vectorization-Kronecker relation $\mathrm{vec}(ABC) = \left( C^\mathrm{T} \otimes A \right) \mathrm{vec}(B)$, we have:

\begin{equation} \label{eq:matn-mvn-matn-mvn-s3}
\mathcal{MN}(X; M, U, V) = \frac{1}{\sqrt{(2\pi)^{np} |V|^n |U|^p}} \cdot \exp\left[-\frac{1}{2} \mathrm{vec}(X-M)^\mathrm{T} \, \left( V^{-1} \otimes U^{-1} \right) \mathrm{vec}(X-M) \right] \; .
\end{equation}

Using the Kronecker product property $\left( A^{-1} \otimes B^{-1} \right) = \left( A \otimes B \right)^{-1}$, we have:

\begin{equation} \label{eq:matn-mvn-matn-mvn-s4}
\mathcal{MN}(X; M, U, V) = \frac{1}{\sqrt{(2\pi)^{np} |V|^n |U|^p}} \cdot \exp\left[-\frac{1}{2} \mathrm{vec}(X-M)^\mathrm{T} \, \left( V \otimes U \right)^{-1} \mathrm{vec}(X-M) \right] \; .
\end{equation}

Using the vectorization property $\mathrm{vec}(A+B) = \mathrm{vec}(A) + \mathrm{vec}(B)$, we have:

\begin{equation} \label{eq:matn-mvn-matn-mvn-s5}
\mathcal{MN}(X; M, U, V) = \frac{1}{\sqrt{(2\pi)^{np} |V|^n |U|^p}} \cdot \exp\left[-\frac{1}{2} \left[ \mathrm{vec}(X) - \mathrm{vec}(M) \right]^\mathrm{T} \, \left( V \otimes U \right)^{-1} \left[ \mathrm{vec}(X) - \mathrm{vec}(M) \right] \right] \; .
\end{equation}

Using the Kronecker-determinant relation $\lvert A \otimes B \rvert = \lvert A \rvert^m \lvert B \rvert^n$, we have:

\begin{equation} \label{eq:matn-mvn-matn-mvn-s6}
\mathcal{MN}(X; M, U, V) = \frac{1}{\sqrt{(2\pi)^{np} |V \otimes U|}} \cdot \exp\left[-\frac{1}{2} \left[ \mathrm{vec}(X) - \mathrm{vec}(M) \right]^\mathrm{T} \, \left( V \otimes U \right)^{-1} \left[ \mathrm{vec}(X) - \mathrm{vec}(M) \right] \right] \; .
\end{equation}

This is the probability density function of the multivariate normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mvn-pdf}) with the $np \times 1$ mean vector $\mathrm{vec}(M)$ and the $np \times np$ covariance matrix $V \otimes U$:

\begin{equation} \label{eq:matn-mvn-matn-mvn}
\mathcal{MN}(X; M, U, V) = \mathcal{N}(\mathrm{vec}(X); \mathrm{vec}(M), V \otimes U) \; .
\end{equation}

By showing that the probability density functions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}) are identical, it is proven that the associated probability distributions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist}) are equivalent.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Matrix normal distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-01-20; URL: \url{https://en.wikipedia.org/wiki/Matrix_normal_distribution#Proof}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P26 | shortcut: matn-mvn | author: JoramSoch | date: 2020-01-20, 21:09.
\vspace{1em}



\subsubsection[\textbf{Transposition}]{Transposition} \label{sec:matn-trans}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be a random matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rmat}) following a matrix-normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:matn}):

\begin{equation} \label{eq:matn-trans-matn}
X \sim \mathcal{MN}(M, U, V) \; .
\end{equation}

Then, the transpose of $X$ also has a matrix-normal distribution:

\begin{equation} \label{eq:matn-trans-matn-trans}
X^\mathrm{T} \sim \mathcal{MN}(M^\mathrm{T}, V, U) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The probability density function of the matrix-normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:matn-pdf}) is:

\begin{equation} \label{eq:matn-trans-matn-pdf-X}
f(X) = \mathcal{MN}(X; M, U, V) = \frac{1}{\sqrt{(2\pi)^{np} |V|^n |U|^p}} \cdot \exp\left[-\frac{1}{2} \mathrm{tr}\left( V^{-1} (X-M)^\mathrm{T} \, U^{-1} (X-M) \right) \right] \; .
\end{equation}

Define $Y = X^\mathrm{T}$. Then, $X = Y^\mathrm{T}$ and we can substitute:

\begin{equation} \label{eq:matn-trans-matn-pdf-Y-s1}
f(Y) = \frac{1}{\sqrt{(2\pi)^{np} |V|^n |U|^p}} \cdot \exp\left[-\frac{1}{2} \mathrm{tr}\left( V^{-1} (Y^\mathrm{T}-M)^\mathrm{T} \, U^{-1} (Y^\mathrm{T}-M) \right) \right] \; .
\end{equation}

Using $(A+B)^\mathrm{T} = (A^\mathrm{T} + B^\mathrm{T})$, we have:

\begin{equation} \label{eq:matn-trans-matn-pdf-Y-s2}
f(Y) = \frac{1}{\sqrt{(2\pi)^{np} |V|^n |U|^p}} \cdot \exp\left[-\frac{1}{2} \mathrm{tr}\left( V^{-1} (Y-M^\mathrm{T}) \, U^{-1} (Y-M^\mathrm{T})^\mathrm{T} \right) \right] \; .
\end{equation}

Using $\mathrm{tr}(ABC) = \mathrm{tr}(CAB)$, we obtain

\begin{equation} \label{eq:matn-trans-matn-pdf-Y-s3}
f(Y) = \frac{1}{\sqrt{(2\pi)^{np} |V|^n |U|^p}} \cdot \exp\left[-\frac{1}{2} \mathrm{tr}\left( U^{-1} (Y-M^\mathrm{T})^\mathrm{T} \, V^{-1} (Y-M^\mathrm{T}) \right) \right]
\end{equation}

which is the probability density function of a matrix-normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:matn-pdf}) with mean $M^T$, covariance across rows $V$ and covariance across columns $U$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P144 | shortcut: matn-trans | author: JoramSoch | date: 2020-08-03, 22:21.
\vspace{1em}



\subsubsection[\textbf{Linear transformation}]{Linear transformation} \label{sec:matn-ltt}
\setcounter{equation}{0}

\textbf{Theorem:} Let $X$ be an $n \times p$ random matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rmat}) following a matrix-normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:matn}):

\begin{equation} \label{eq:matn-ltt-matn}
X \sim \mathcal{MN}(M, U, V) \; .
\end{equation}

Then, a linear transformation of $X$ is also matrix-normally distributed

\begin{equation} \label{eq:matn-ltt-matn-trans}
Y = AXB + C \sim \mathcal{MN}(AMB+C, AUA^\mathrm{T}, B^\mathrm{T}VB)
\end{equation}

where $A$ us ab $r \times n$ matrix of full rank $r \leq b$ and $B$ is a $p \times s$ matrix of full rank $s \leq p$ and $C$ is an $r \times s$ matrix.


\vspace{1em}
\textbf{Proof:} The matrix-normal distribution is equivalent to the multivariate normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:matn-mvn}),

\begin{equation} \label{eq:matn-ltt-matn-mvn}
X \sim \mathcal{MN}(M, U, V) \quad \Leftrightarrow \quad \mathrm{vec}(X) \sim \mathcal{N}(\mathrm{vec}(M), V \otimes U) \; ,
\end{equation}

and the linear transformation theorem for the multivariate normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mvn-ltt}) states:

\begin{equation} \label{eq:matn-ltt-mvn-ltt}
x \sim \mathcal{N}(\mu, \Sigma) \quad \Rightarrow \quad y = Ax + b \sim \mathcal{N}(A\mu + b, A \Sigma A^\mathrm{T}) \; .
\end{equation}

The vectorization of $Y = AXB + C$ is

\begin{equation} \label{eq:matn-ltt-vec-Y-s1}
\begin{split}
\mathrm{vec}(Y) &= \mathrm{vec}(AXB + C) \\
&= \mathrm{vec}(AXB) + \mathrm{vec}(C) \\
&= (B^\mathrm{T} \otimes A)\mathrm{vec}(X) + \mathrm{vec}(C) \; .
\end{split}
\end{equation}

Using \eqref{eq:matn-ltt-matn-mvn} and \eqref{eq:matn-ltt-mvn-ltt}, we have

\begin{equation} \label{eq:matn-ltt-vec-Y-s2}
\begin{split}
\mathrm{vec}(Y) &\sim \mathcal{N}((B^\mathrm{T} \otimes A) \mathrm{vec}(M) + \mathrm{vec}(C), (B^\mathrm{T} \otimes A) (V \otimes U) (B^\mathrm{T} \otimes A)^\mathrm{T}) \\
&= \mathcal{N}(\mathrm{vec}(AMB) + \mathrm{vec}(C), (B^\mathrm{T}V \otimes AU) (B^\mathrm{T} \otimes A)^\mathrm{T}) \\
&= \mathcal{N}(\mathrm{vec}(AMB + C), B^\mathrm{T}VB \otimes AUA^\mathrm{T}) \; .
\end{split}
\end{equation}

Using \eqref{eq:matn-ltt-matn-mvn}, we finally have:

\begin{equation} \label{eq:matn-ltt-matn-ltt-qed}
Y \sim \mathcal{MN}(AMB + C, AUA^\mathrm{T} ,B^\mathrm{T}VB) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P145 | shortcut: matn-ltt | author: JoramSoch | date: 2020-08-03, 22:24.
\vspace{1em}



\subsection{Wishart distribution}

\subsubsection[\textit{Definition}]{Definition} \label{sec:wish}
\setcounter{equation}{0}

\textbf{Definition:} Let $X$ be an $n \times p$ matrix following a matrix-normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:matn}) with mean zero, independence across rows and covariance across columns $V$:

\begin{equation} \label{eq:wish-matn}
X \sim \mathcal{MN}(0, I_n, V) \; .
\end{equation}

Define the scatter matrix $S$ as the product of the transpose of $X$ with itself:

\begin{equation} \label{eq:wish-scat-mat}
S = X^T X = \sum_{i=1}^n x_i^\mathrm{T} x_i \; .
\end{equation}

Then, the matrix $S$ is said to follow a Wishart distribution with scale matrix $V$ and degrees of freedom $n$

\begin{equation} \label{eq:wish-wish}
S \sim \mathcal{W}(V, n)
\end{equation}

where $n > p - 1$ and $V$ is a positive definite symmetric covariance matrix.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Wishart distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-03-22; URL: \url{https://en.wikipedia.org/wiki/Wishart_distribution#Definition}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D43 | shortcut: wish | author: JoramSoch | date: 2020-03-22, 17:15.
\vspace{1em}





% Chapter 3 %
\chapter{Statistical Models} \label{sec:Statistical Models} \newpage

\pagebreak
\section{Univariate normal data}

\subsection{Multiple linear regression}

\subsubsection[\textit{Definition}]{Definition} \label{sec:mlr}
\setcounter{equation}{0}

\textbf{Definition:} Let $y$ be an $n \times 1$ vector and let $X$ be an $n \times p$ matrix.

Then, a statement asserting a linear combination of $X$ into $y$

\begin{equation} \label{eq:mlr-mlr-model}
y = X\beta + \varepsilon \; ,
\end{equation}

together with a statement asserting a normal distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mvn}) for $\varepsilon$

\begin{equation} \label{eq:mlr-mlr-noise}
\varepsilon \sim \mathcal{N}(0, \sigma^2 V)
\end{equation}

is called a univariate linear regression model or simply, "multiple linear regression".

\begin{itemize}

\item $y$ is called "measured data", "dependent variable" or "measurements";

\item $X$ is called "design matrix", "set of independent variables" or "predictors";

\item $V$ is called "covariance matrix" or "covariance structure";

\item $\beta$ are called "regression coefficients" or "weights";

\item $\varepsilon$ is called "noise", "errors" or "error terms";

\item $\sigma^2$ is called "noise variance" or "error variance";

\item $n$ is the number of observations;

\item $p$ is the number of predictors.

\end{itemize}

Alternatively, the linear combination may also be written as

\begin{equation} \label{eq:mlr-mlr-model-sum}
y = \sum_{i=1}^{p} \beta_i x_i + \varepsilon
\end{equation}

or, when the model includes an intercept term, as

\begin{equation} \label{eq:mlr-mlr-model-sum-base}
y = \beta_0 + \sum_{i=1}^{p} \beta_i x_i + \varepsilon
\end{equation}

which is equivalent to adding a constant regressor $x_0 = 1_n$ to the design matrix $X$.

When the covariance structure $V$ is equal to the $n \times n$ identity matrix, this is called multiple linear regression with independent and identically distributed (i.i.d.) observations:

\begin{equation} \label{eq:mlr-mlr-noise-iid}
V = I_n \quad \Rightarrow \quad \varepsilon \sim \mathcal{N}(0, \sigma^2 I_n) \quad \Rightarrow \quad \varepsilon_i \overset{\text{i.i.d.}}{\sim} \mathcal{N}(0, \sigma^2) \; .
\end{equation}

Otherwise, it is called multiple linear regression with correlated observations.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Linear regression"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-03-21; URL: \url{https://en.wikipedia.org/wiki/Linear_regression#Simple_and_multiple_linear_regression}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D36 | shortcut: mlr | author: JoramSoch | date: 2020-03-21, 20:09.
\vspace{1em}



\subsubsection[\textbf{Ordinary least squares}]{Ordinary least squares} \label{sec:mlr-ols}
\setcounter{equation}{0}

\textbf{Theorem:} Given a linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}) with independent observations

\begin{equation} \label{eq:mlr-ols-MLR}
y = X\beta + \varepsilon, \; \varepsilon_i \overset{\mathrm{i.i.d.}}{\sim} \mathcal{N}(0, \sigma^2) \; ,
\end{equation}

the parameters minimizing the residual sum of squares ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:rss}) are given by

\begin{equation} \label{eq:mlr-ols-OLS}
\hat{\beta} = (X^\mathrm{T} X)^{-1} X^\mathrm{T} y \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} Let $\hat{\beta}$ be the ordinary least squares (OLS) solution and let $\hat{\varepsilon} = y - X\hat{\beta}$ be the resulting vector of residuals. Then, this vector must be orthogonal to the design matrix,

\begin{equation} \label{eq:mlr-ols-X-e-orth}
X^\mathrm{T} \hat{\varepsilon} = 0 \; ,
\end{equation}

because if it wasn't, there would be another solution $\tilde{\beta}$ giving another vector $\tilde{\varepsilon}$ with a smaller residual sum of squares. From \eqref{eq:mlr-ols-X-e-orth}, the OLS formula can be directly derived:

\begin{equation} \label{eq:mlr-ols-OLS-qed}
\begin{split}
X^\mathrm{T} \hat{\varepsilon} &= 0 \\
X^\mathrm{T} \left( y - X\hat{\beta} \right) &= 0 \\
X^\mathrm{T} y - X^\mathrm{T} X\hat{\beta} &= 0 \\
X^\mathrm{T} X\hat{\beta} &= X^\mathrm{T} y \\
\hat{\beta} &= (X^\mathrm{T} X)^{-1} X^\mathrm{T} y \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Stephan, Klaas Enno (2010): "The General Linear Model (GLM)"; in: \textit{Methods and models for fMRI data analysis in neuroeconomics}, Lecture 3, Slides 10/11; URL: \url{http://www.socialbehavior.uzh.ch/teaching/methodsspring10.html}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P2 | shortcut: mlr-ols | author: JoramSoch | date: 2019-09-27, 07:18.
\vspace{1em}



\subsubsection[\textbf{Ordinary least squares}]{Ordinary least squares} \label{sec:mlr-ols2}
\setcounter{equation}{0}

\textbf{Theorem:} Given a linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}) with independent observations

\begin{equation} \label{eq:mlr-ols2-MLR}
y = X\beta + \varepsilon, \; \varepsilon_i \overset{\mathrm{i.i.d.}}{\sim} \mathcal{N}(0, \sigma^2) \; ,
\end{equation}

the parameters minimizing the residual sum of squares ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:rss}) are given by

\begin{equation} \label{eq:mlr-ols2-OLS}
\hat{\beta} = (X^\mathrm{T} X)^{-1} X^\mathrm{T} y \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The residual sum of squares ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:rss}) is defined as

\begin{equation} \label{eq:mlr-ols2-RSS}
\mathrm{RSS}(\beta) = \sum_{i=1}^n \varepsilon_i = \varepsilon^\mathrm{T} \varepsilon = (y-X\beta)^\mathrm{T} (y-X\beta)
\end{equation}

which can be developed into

\begin{equation} \label{eq:mlr-ols2-RSS-dev}
\begin{split}
\mathrm{RSS}(\beta) &= y^\mathrm{T} y - y^\mathrm{T} X \beta - \beta^\mathrm{T} X^\mathrm{T} y + \beta^\mathrm{T} X^\mathrm{T} X \beta \\
&= y^\mathrm{T} y - 2 \beta^\mathrm{T} X^\mathrm{T} y + \beta^\mathrm{T} X^\mathrm{T} X \beta \; .
\end{split}
\end{equation}

The derivative of $\mathrm{RSS}(\beta)$ with respect to $\beta$ is

\begin{equation} \label{eq:mlr-ols2-RSS-der}
\frac{\mathrm{d}\mathrm{RSS}(\beta)}{\mathrm{d}\beta} = - 2 X^\mathrm{T} y + 2 X^\mathrm{T} X \beta
\end{equation}

and setting this deriative to zero, we obtain:

\begin{equation} \label{eq:mlr-ols2-OLS-qed}
\begin{split}
\frac{\mathrm{d}\mathrm{RSS}(\hat{\beta})}{\mathrm{d}\beta} &= 0 \\
0 &= - 2 X^\mathrm{T} y + 2 X^\mathrm{T} X \hat{\beta} \\
X^\mathrm{T} X \hat{\beta} &= X^\mathrm{T} y \\
\hat{\beta} &= (X^\mathrm{T} X)^{-1} X^\mathrm{T} y \; .
\end{split}
\end{equation}

Since the quadratic form $y^\mathrm{T} y$ in \eqref{eq:mlr-ols2-RSS-dev} is positive, $\hat{\beta}$ minimizes $\mathrm{RSS}(\beta)$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Proofs involving ordinary least squares"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-02-03; URL: \url{https://en.wikipedia.org/wiki/Proofs_involving_ordinary_least_squares#Least_squares_estimator_for_%CE%B2}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P40 | shortcut: mlr-ols2 | author: JoramSoch | date: 2020-02-03, 18:43.
\vspace{1em}



\subsubsection[\textit{Total sum of squares}]{Total sum of squares} \label{sec:tss}
\setcounter{equation}{0}

\textbf{Definition:} Let there be a multiple linear regression with independent observations ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}) using measured data $y$ and design matrix $X$:

\begin{equation} \label{eq:tss-mlr}
y = X\beta + \varepsilon, \; \varepsilon_i \overset{\mathrm{i.i.d.}}{\sim} \mathcal{N}(0, \sigma^2) \; .
\end{equation}

Then, the total sum of squares (TSS) is defined as the sum of squared deviations of the measured signal from the average signal:

\begin{equation} \label{eq:tss-tss}
\mathrm{TSS} = \sum_{i=1}^n (y_i - \bar{y})^2 \quad \text{where} \quad \bar{y} = \frac{1}{n} \sum_{i=1}^n y_i \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Total sum of squares"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-03-21; URL: \url{https://en.wikipedia.org/wiki/Total_sum_of_squares}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D37 | shortcut: tss | author: JoramSoch | date: 2020-03-21, 21:44.
\vspace{1em}



\subsubsection[\textit{Explained sum of squares}]{Explained sum of squares} \label{sec:ess}
\setcounter{equation}{0}

\textbf{Definition:} Let there be a multiple linear regression with independent observations ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}) using measured data $y$ and design matrix $X$:

\begin{equation} \label{eq:ess-mlr}
y = X\beta + \varepsilon, \; \varepsilon_i \overset{\mathrm{i.i.d.}}{\sim} \mathcal{N}(0, \sigma^2) \; .
\end{equation}

Then, the explained sum of squares (ESS) is defined as the sum of squared deviations of the fitted signal from the average signal:

\begin{equation} \label{eq:ess-ess}
\mathrm{ESS} = \sum_{i=1}^n (\hat{y}_i - \bar{y})^2 \quad \text{where} \quad \hat{y} = X \hat{\beta} \quad \text{and} \quad \bar{y} = \frac{1}{n} \sum_{i=1}^n y_i
\end{equation}

with estimated regression coefficients $\hat{\beta}$, e.g. obtained via ordinary least squares ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mlr-ols}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Explained sum of squares"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-03-21; URL: \url{https://en.wikipedia.org/wiki/Explained_sum_of_squares}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D38 | shortcut: ess | author: JoramSoch | date: 2020-03-21, 21:57.
\vspace{1em}



\subsubsection[\textit{Residual sum of squares}]{Residual sum of squares} \label{sec:rss}
\setcounter{equation}{0}

\textbf{Definition:} Let there be a multiple linear regression with independent observations ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}) using measured data $y$ and design matrix $X$:

\begin{equation} \label{eq:rss-mlr}
y = X\beta + \varepsilon, \; \varepsilon_i \overset{\mathrm{i.i.d.}}{\sim} \mathcal{N}(0, \sigma^2) \; .
\end{equation}

Then, the residual sum of squares (RSS) is defined as the sum of squared deviations of the measured signal from the fitted signal:

\begin{equation} \label{eq:rss-rss}
\mathrm{RSS} = \sum_{i=1}^n (y_i - \hat{y}_i)^2 \quad \text{where} \quad \hat{y} = X \hat{\beta}
\end{equation}

with estimated regression coefficients $\hat{\beta}$, e.g. obtained via ordinary least squares ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mlr-ols}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Residual sum of squares"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-03-21; URL: \url{https://en.wikipedia.org/wiki/Residual_sum_of_squares}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D39 | shortcut: rss | author: JoramSoch | date: 2020-03-21, 22:03.
\vspace{1em}



\subsubsection[\textbf{Total, explained and residual sum of squares}]{Total, explained and residual sum of squares} \label{sec:mlr-pss}
\setcounter{equation}{0}

\textbf{Theorem:} Assume a linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}) with independent observations

\begin{equation} \label{eq:mlr-pss-mlr}
y = X\beta + \varepsilon, \; \varepsilon_i \overset{\mathrm{i.i.d.}}{\sim} \mathcal{N}(0, \sigma^2) \; ,
\end{equation}

and let $X$ contain a constant regressor $1_n$ modelling the intercept term. Then, it holds that

\begin{equation} \label{eq:mlr-pss-pss}
\mathrm{TSS} = \mathrm{ESS} + \mathrm{RSS}
\end{equation}

where $\mathrm{TSS}$ is the total sum of squares ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:tss}), $\mathrm{ESS}$ is the explained sum of squares ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:ess}) and $\mathrm{RSS}$ is the residual sum of squares ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:rss}).


\vspace{1em}
\textbf{Proof:} The total sum of squares ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:tss}) is given by

\begin{equation} \label{eq:mlr-pss-TSS}
\mathrm{TSS} = \sum_{i=1}^{n} (y_i - \bar{y})^2
\end{equation}

where $\bar{y}$ is the mean across all $y_i$. The $\mathrm{TSS}$ can be rewritten as

\begin{equation} \label{eq:mlr-pss-TSS-s1}
\begin{split}
\mathrm{TSS} &= \sum_{i=1}^{n} (y_i - \bar{y} + \hat{y}_i - \hat{y}_i)^2 \\
&= \sum_{i=1}^{n} \left( (\hat{y}_i - \bar{y}) + (y_i - \hat{y}_i) \right)^2 \\
&= \sum_{i=1}^{n} \left( (\hat{y}_i - \bar{y}) + \hat{\varepsilon}_i \right)^2 \\
&= \sum_{i=1}^{n} \left( (\hat{y}_i - \bar{y})^2 + 2 \, \hat{\varepsilon}_i (\hat{y}_i - \bar{y}) + \hat{\varepsilon}_i^2 \right) \\
&= \sum_{i=1}^{n} (\hat{y}_i - \bar{y})^2 + \sum_{i=1}^{n} \hat{\varepsilon}_i^2 + 2 \sum_{i=1}^{n} \hat{\varepsilon}_i (\hat{y}_i - \bar{y}) \\
&= \sum_{i=1}^{n} (\hat{y}_i - \bar{y})^2 + \sum_{i=1}^{n} \hat{\varepsilon}_i^2 + 2 \sum_{i=1}^{n} \hat{\varepsilon}_i (x_i \hat{\beta} - \bar{y}) \\
&= \sum_{i=1}^{n} (\hat{y}_i - \bar{y})^2 + \sum_{i=1}^{n} \hat{\varepsilon}_i^2 + 2 \sum_{i=1}^{n} \hat{\varepsilon}_i \left( \sum_{j=1}^{p} x_{ij} \hat{\beta}_j \right) - 2 \sum_{i=1}^{n} \hat{\varepsilon}_i \, \bar{y} \\
&= \sum_{i=1}^{n} (\hat{y}_i - \bar{y})^2 + \sum_{i=1}^{n} \hat{\varepsilon}_i^2 + 2 \sum_{j=1}^{p} \hat{\beta}_j \sum_{i=1}^{n} \hat{\varepsilon}_i x_{ij} - 2 \bar{y} \sum_{i=1}^{n} \hat{\varepsilon}_i \\
\end{split}
\end{equation}

The fact that the design matrix includes a constant regressor ensures that

\begin{equation} \label{eq:mlr-pss-e-est-sum}
\sum_{i=1}^{n} \hat{\varepsilon}_i = \hat{\varepsilon}^\mathrm{T} 1_n = 0
\end{equation}

and because the residuals are orthogonal to the design matrix ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mlr-ols}), we have

\begin{equation} \label{eq:mlr-pss-X-e-orth}
\sum_{i=1}^{n} \hat{\varepsilon}_i x_{ij} = \hat{\varepsilon}^\mathrm{T} x_j = 0 \; .
\end{equation}

Applying \eqref{eq:mlr-pss-e-est-sum} and \eqref{eq:mlr-pss-X-e-orth} to \eqref{eq:mlr-pss-TSS-s1}, this becomes

\begin{equation} \label{eq:mlr-pss-TSS-s2}
\mathrm{TSS} = \sum_{i=1}^{n} (\hat{y}_i - \bar{y})^2 + \sum_{i=1}^{n} \hat{\varepsilon}_i^2
\end{equation}

and, with the definitions of explained ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:ess}) and residual sum of squares ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:rss}), it is

\begin{equation} \label{eq:mlr-pss-TSS-s3}
\mathrm{TSS} = \mathrm{ESS} + \mathrm{RSS} \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Partition of sums of squares"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-03-09; URL: \url{https://en.wikipedia.org/wiki/Partition_of_sums_of_squares#Partitioning_the_sum_of_squares_in_linear_regression}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P76 | shortcut: mlr-pss | author: JoramSoch | date: 2020-03-09, 22:18.
\vspace{1em}



\subsubsection[\textit{Estimation matrix}]{Estimation matrix} \label{sec:emat}
\setcounter{equation}{0}

\textbf{Definition:} In multiple linear regression ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}), the estimation matrix is the matrix $E$ that results in ordinary least squares ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mlr-ols}) or weighted least squares ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mlr-wls}) parameter estimates when right-multiplied with the measured data:

\begin{equation} \label{eq:emat-em}
Ey = \hat{\beta} \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D81 | shortcut: emat | author: JoramSoch | date: 2020-07-22, 05:17.
\vspace{1em}



\subsubsection[\textit{Projection matrix}]{Projection matrix} \label{sec:pmat}
\setcounter{equation}{0}

\textbf{Definition:} In multiple linear regression ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}), the projection matrix is the matrix $P$ that results in the fitted signal explained by estimated parameters ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:emat}) when right-multiplied with the measured data:

\begin{equation} \label{eq:pmat-pm}
Py = \hat{y} = X \hat{\beta} \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Projection matrix"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-07-22; URL: \url{https://en.wikipedia.org/wiki/Projection_matrix#Overview}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D82 | shortcut: pmat | author: JoramSoch | date: 2020-07-22, 05:25.
\vspace{1em}



\subsubsection[\textit{Residual-forming matrix}]{Residual-forming matrix} \label{sec:rfmat}
\setcounter{equation}{0}

\textbf{Definition:} In multiple linear regression ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}), the residual-forming matrix is the matrix $R$ that results in the vector of residuals left over by estimated parameters ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:emat}) when right-multiplied with the measured data:

\begin{equation} \label{eq:rfmat-pm}
Ry = \hat{\varepsilon} = y - \hat{y} \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Projection matrix"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-07-22; URL: \url{https://en.wikipedia.org/wiki/Projection_matrix#Properties}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D83 | shortcut: rfmat | author: JoramSoch | date: 2020-07-22, 05:35.
\vspace{1em}



\subsubsection[\textbf{Estimation, projection and residual-forming matrix}]{Estimation, projection and residual-forming matrix} \label{sec:mlr-mat}
\setcounter{equation}{0}

\textbf{Theorem:} Assume a linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}) with independent observations

\begin{equation} \label{eq:mlr-mat-mlr}
y = X\beta + \varepsilon, \; \varepsilon_i \overset{\mathrm{i.i.d.}}{\sim} \mathcal{N}(0, \sigma^2)
\end{equation}

and consider estimation using ordinary least squares ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mlr-ols}). Then, the estimated parameters, fitted signal and residuals are given by

\begin{equation} \label{eq:mlr-mat-mlr-est}
\begin{split}
\hat{\beta} &= E y \\
\hat{y} &= P y \\
\hat{\varepsilon} &= R y
\end{split}
\end{equation}

where 

\begin{equation} \label{eq:mlr-mat-mlr-mat}
\begin{split}
E &= (X^\mathrm{T} X)^{-1} X^\mathrm{T} \\
P &= X (X^\mathrm{T} X)^{-1} X^\mathrm{T} \\
R &= I_n - X (X^\mathrm{T} X)^{-1} X^\mathrm{T}
\end{split}
\end{equation}

are the estimation matrix ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:emat}), projection matrix ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:pmat}) and residual-forming matrix ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:rfmat}) and $n$ is the number of observations.


\vspace{1em}
\textbf{Proof:}

1) Ordinary least squares parameter estimates of $\beta$ are defined as minimizing the residual sum of squares ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:rss})

\begin{equation} \label{eq:mlr-mat-ols}
\hat{\beta} = \operatorname*{arg\,min}_{\beta} \left[ (y-X\beta)^\mathrm{T} (y-X\beta) \right]
\end{equation}

and the solution to this ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mlr-ols}) is given by

\begin{equation} \label{eq:mlr-mat-b-est-qed}
\begin{split}
\hat{\beta} &= (X^\mathrm{T} X)^{-1} X^\mathrm{T} y \\
&\overset{\eqref{eq:mlr-mat-mlr-mat}}{=} E y \; .
\end{split}
\end{equation}

\vspace{1em}
2) The fitted signal is given by multiplying the design matrix with the estimated regression coefficients

\begin{equation} \label{eq:mlr-mat-y-est}
\hat{y} = X\hat{\beta}
\end{equation}

and using \eqref{eq:mlr-mat-b-est-qed}, this becomes

\begin{equation} \label{eq:mlr-mat-y-est-qed}
\begin{split}
\hat{y} &= X (X^\mathrm{T} X)^{-1} X^\mathrm{T} y \\
&\overset{\eqref{eq:mlr-mat-mlr-mat}}{=} P y \; .
\end{split}
\end{equation}

\vspace{1em}
3) The residuals of the model are calculated by subtracting the fitted signal from the measured signal

\begin{equation} \label{eq:mlr-mat-e-est}
\hat{\varepsilon} = y - \hat{y}
\end{equation}

and using \eqref{eq:mlr-mat-y-est-qed}, this becomes

\begin{equation} \label{eq:mlr-mat-e-est-qed}
\begin{split}
\hat{\varepsilon} &= y - X (X^\mathrm{T} X)^{-1} X^\mathrm{T} y \\
&= (I_n - X (X^\mathrm{T} X)^{-1} X^\mathrm{T}) y \\
&\overset{\eqref{eq:mlr-mat-mlr-mat}}{=} R y \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Stephan, Klaas Enno (2010): "The General Linear Model (GLM)"; in: \textit{Methods and models for fMRI data analysis in neuroeconomics}, Lecture 3, Slide 10; URL: \url{http://www.socialbehavior.uzh.ch/teaching/methodsspring10.html}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P75 | shortcut: mlr-mat | author: JoramSoch | date: 2020-03-09, 21:18.
\vspace{1em}



\subsubsection[\textbf{Idempotence of projection and residual-forming matrix}]{Idempotence of projection and residual-forming matrix} \label{sec:mlr-idem}
\setcounter{equation}{0}

\textbf{Theorem:} The projection matrix ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:pmat}) and the residual-forming matrix ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:rfmat}) are idempotent:

\begin{equation} \label{eq:mlr-idem-P^2-R^2}
\begin{split}
P^2 &= P \\
R^2 &= R \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Proof:}

1) The projection matrix for ordinary least squares is given by ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mlr-mat})

\begin{equation} \label{eq:mlr-idem-P}
P = X (X^\mathrm{T} X)^{-1} X^\mathrm{T} \; ,
\end{equation}

such that

\begin{equation} \label{eq:mlr-idem-P^2}
\begin{split}
P^2 &= X (X^\mathrm{T} X)^{-1} X^\mathrm{T} X (X^\mathrm{T} X)^{-1} X^\mathrm{T} \\
&= X (X^\mathrm{T} X)^{-1} X^\mathrm{T} \\
&\overset{\eqref{eq:mlr-idem-P}}{=} P \; .
\end{split}
\end{equation}

\vspace{1em}
2) The residual-forming matrix for ordinary least squares is given by ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mlr-mat})

\begin{equation} \label{eq:mlr-idem-R}
R = I_n - X (X^\mathrm{T} X)^{-1} X^\mathrm{T} = I_n - P \; ,
\end{equation}

such that

\begin{equation} \label{eq:mlr-idem-R^2}
\begin{split}
R^2 &= (I_n - P) (I_n - P) \\
&= I_n - P - P + P^2 \\
&\overset{\eqref{eq:mlr-idem-P^2}}{=} I_n - 2 P + P \\
&= I_n - P \\
&\overset{\eqref{eq:mlr-idem-R}}{=} R \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Projection matrix"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-07-22; URL: \url{https://en.wikipedia.org/wiki/Projection_matrix#Properties}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P135 | shortcut: mlr-idem | author: JoramSoch | date: 2020-07-22, 06:28.
\vspace{1em}



\subsubsection[\textbf{Weighted least squares}]{Weighted least squares} \label{sec:mlr-wls}
\setcounter{equation}{0}

\textbf{Theorem:} Given a linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}) with correlated observations

\begin{equation} \label{eq:mlr-wls-MLR}
y = X\beta + \varepsilon, \; \varepsilon \sim \mathcal{N}(0, \sigma^2 V) \; ,
\end{equation}

the parameters minimizing the weighted residual sum of squares ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:rss}) are given by

\begin{equation} \label{eq:mlr-wls-WLS}
\hat{\beta} = (X^\mathrm{T} V^{-1} X)^{-1} X^\mathrm{T} V^{-1} y \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} Let there be an $n \times n$ square matrix $W$, such that

\begin{equation} \label{eq:mlr-wls-W-def}
W V W^\mathrm{T} = I_n \; .
\end{equation}

Since $V$ is a covariance matrix and thus symmetric, $W$ is also symmetric and can be expressed as the matrix square root of the inverse of $V$:

\begin{equation} \label{eq:mlr-wls-W-V}
W V W = I_n \quad \Leftrightarrow \quad V = W^{-1} W^{-1} \quad \Leftrightarrow \quad V^{-1} = W W \quad \Leftrightarrow \quad W = V^{-1/2} \; .
\end{equation}

Left-multiplying the linear regression equation \eqref{eq:mlr-wls-MLR} with $W$, the linear transformation theorem ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mvn-ltt}) implies that

\begin{equation} \label{eq:mlr-wls-MLR-W}
Wy = WX\beta + W\varepsilon, \; W\varepsilon \sim \mathcal{N}(0, \sigma^2 W V W^T) \; .
\end{equation}

Applying \eqref{eq:mlr-wls-W-def}, we see that \eqref{eq:mlr-wls-MLR-W} is actually a linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}) with independent observations

\begin{equation} \label{eq:mlr-wls-MLR-W-dev}
\tilde{y} = \tilde{X}\beta + \tilde{\varepsilon}, \; \tilde{\varepsilon} \sim \mathcal{N}(0, \sigma^2 I_n)
\end{equation}

where $\tilde{y} = Wy$, $\tilde{X} = WX$ and $\tilde{\varepsilon} = W\varepsilon$, such that we can apply the ordinary least squares solution ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mlr-ols}) giving

\begin{equation} \label{eq:mlr-wls-WLS-qed}
\begin{split}
\hat{\beta} &= (\tilde{X}^\mathrm{T} \tilde{X})^{-1} \tilde{X}^\mathrm{T} \tilde{y} \\
&= \left( (WX)^\mathrm{T} WX \right)^{-1} (WX)^\mathrm{T} Wy \\
&= \left( X^\mathrm{T} W^\mathrm{T} W X \right)^{-1} X^\mathrm{T} W^\mathrm{T} W y \\
&= \left( X^\mathrm{T} W W X \right)^{-1} X^\mathrm{T} W W y \\
&\overset{\eqref{eq:mlr-wls-W-V}}{=} \left( X^\mathrm{T} V^{-1} X \right)^{-1} X^\mathrm{T} V^{-1} y
\end{split}
\end{equation}

which corresponds to the weighted least squares solution \eqref{eq:mlr-wls-WLS}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Stephan, Klaas Enno (2010): "The General Linear Model (GLM)"; in: \textit{Methods and models for fMRI data analysis in neuroeconomics}, Lecture 3, Slides 20/23; URL: \url{http://www.socialbehavior.uzh.ch/teaching/methodsspring10.html}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P77 | shortcut: mlr-wls | author: JoramSoch | date: 2020-03-11, 11:22.
\vspace{1em}



\subsubsection[\textbf{Weighted least squares}]{Weighted least squares} \label{sec:mlr-wls2}
\setcounter{equation}{0}

\textbf{Theorem:} Given a linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}) with correlated observations

\begin{equation} \label{eq:mlr-wls2-MLR}
y = X\beta + \varepsilon, \; \varepsilon \sim \mathcal{N}(0, \sigma^2 V) \; ,
\end{equation}

the parameters minimizing the weighted residual sum of squares ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:rss}) are given by

\begin{equation} \label{eq:mlr-wls2-WLS}
\hat{\beta} = (X^\mathrm{T} V^{-1} X)^{-1} X^\mathrm{T} V^{-1} y \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} Let there be an $n \times n$ square matrix $W$, such that

\begin{equation} \label{eq:mlr-wls2-W-def}
W V W^\mathrm{T} = I_n \; .
\end{equation}

Since $V$ is a covariance matrix and thus symmetric, $W$ is also symmetric and can be expressed the matrix square root of the inverse of $V$:

\begin{equation} \label{eq:mlr-wls2-W-V}
W V W = I_n \quad \Leftrightarrow \quad V = W^{-1} W^{-1} \quad \Leftrightarrow \quad V^{-1} = W W \quad \Leftrightarrow \quad W = V^{-1/2} \; .
\end{equation}

Left-multiplying the linear regression equation \eqref{eq:mlr-wls2-MLR} with $W$, the linear transformation theorem ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mvn-ltt}) implies that

\begin{equation} \label{eq:mlr-wls2-MLR-W}
Wy = WX\beta + W\varepsilon, \; W\varepsilon \sim \mathcal{N}(0, \sigma^2 W V W^T) \; .
\end{equation}

Applying \eqref{eq:mlr-wls2-W-def}, we see that \eqref{eq:mlr-wls2-MLR-W} is actually a linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}) with independent observations

\begin{equation} \label{eq:mlr-wls2-MLR-W-dev}
Wy = WX\beta + W\varepsilon, \; W\varepsilon \sim \mathcal{N}(0, \sigma^2 I_n) \; .
\end{equation}

With this, we can express the weighted residual sum of squares ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:rss}) as

\begin{equation} \label{eq:mlr-wls2-wRSS}
\mathrm{wRSS}(\beta) = \sum_{i=1}^n (W \varepsilon)_i = (W \varepsilon)^\mathrm{T} (W \varepsilon) = (Wy-WX\beta)^\mathrm{T} (Wy-WX\beta)
\end{equation}

which can be developed into

\begin{equation} \label{eq:mlr-wls2-wRSS-dev}
\begin{split}
\mathrm{wRSS}(\beta) &= y^\mathrm{T} W^\mathrm{T} W y - y^\mathrm{T} W^\mathrm{T} W X \beta - \beta^\mathrm{T} X^\mathrm{T} W^\mathrm{T} W y + \beta^\mathrm{T} X^\mathrm{T} W^\mathrm{T} W X \beta \\
&= y^\mathrm{T} W W y - 2 \beta^\mathrm{T} X^\mathrm{T} W W y + \beta^\mathrm{T} X^\mathrm{T} W W X \beta \\
&\overset{\eqref{eq:mlr-wls2-W-V}}{=} y^\mathrm{T} V^{-1} y - 2 \beta^\mathrm{T} X^\mathrm{T} V^{-1} y + \beta^\mathrm{T} X^\mathrm{T} V^{-1} X \beta \; .
\end{split}
\end{equation}

The derivative of $\mathrm{wRSS}(\beta)$ with respect to $\beta$ is

\begin{equation} \label{eq:mlr-wls2-wRSS-der}
\frac{\mathrm{d}\mathrm{wRSS}(\beta)}{\mathrm{d}\beta} = - 2 X^\mathrm{T} V^{-1} y + 2 X^\mathrm{T} V^{-1} X \beta
\end{equation}

and setting this deriative to zero, we obtain:

\begin{equation} \label{eq:mlr-wls2-WLS-qed}
\begin{split}
\frac{\mathrm{d}\mathrm{wRSS}(\hat{\beta})}{\mathrm{d}\beta} &= 0 \\
0 &= - 2 X^\mathrm{T} V^{-1} y + 2 X^\mathrm{T} V^{-1} X \hat{\beta} \\
X^\mathrm{T} V^{-1} X \hat{\beta} &= X^\mathrm{T} V^{-1} y \\
\hat{\beta} &= (X^\mathrm{T} V^{-1} X)^{-1} X^\mathrm{T} V^{-1} y \; .
\end{split}
\end{equation}

Since the quadratic form $y^\mathrm{T} V^{-1} y$ in \eqref{eq:mlr-wls2-wRSS-dev} is positive, $\hat{\beta}$ minimizes $\mathrm{wRSS}(\beta)$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P136 | shortcut: mlr-wls2 | author: JoramSoch | date: 2020-07-22, 06:48.
\vspace{1em}



\subsubsection[\textbf{Maximum likelihood estimation}]{Maximum likelihood estimation} \label{sec:mlr-mle}
\setcounter{equation}{0}

\textbf{Theorem:} Given a linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}) with correlated observations

\begin{equation} \label{eq:mlr-mle-MLR}
y = X\beta + \varepsilon, \; \varepsilon \sim \mathcal{N}(0, \sigma^2 V) \; ,
\end{equation}

the maximum likelihood estimates ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mle}) of $\beta$ and $\sigma^2$ are given  by

\begin{equation} \label{eq:mlr-mle-MLE-MLE}
\begin{split}
\hat{\beta} &= (X^\mathrm{T} V^{-1} X)^{-1} X^\mathrm{T} V^{-1} y \\
\hat{\sigma}^2 &= \frac{1}{n} (y-X\hat{\beta})^\mathrm{T} (y-X\hat{\beta}) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Proof:} With the probability density function of the multivariate normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mvn-pdf}), the linear regression equation \eqref{eq:mlr-mle-MLR} implies the following likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf})

\begin{equation} \label{eq:mlr-mle-MLR-LF}
\begin{split}
p(y|\beta,\sigma^2) &= \mathcal{N}(y; X\beta, \sigma^2 V) \\
&= \sqrt{\frac{1}{(2\pi)^n |\sigma^2 V|}} \cdot \exp\left[ -\frac{1}{2} (y - X\beta)^\mathrm{T} (\sigma^2 V)^{-1} (y - X\beta) \right]
\end{split}
\end{equation}

and, using $\lvert \sigma^2 V \rvert = (\sigma^2)^n \lvert V \rvert$, the log-likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:llf})

\begin{equation} \label{eq:mlr-mle-MLR-LL1}
\begin{split}
\mathrm{LL}(\beta,\sigma^2) = &\log p(y|\beta,\sigma^2) \\
= &- \frac{n}{2} \log(2\pi) - \frac{n}{2} \log (\sigma^2) - \frac{1}{2} \log |V| \\
&- \frac{1}{2 \sigma^2} (y - X\beta)^\mathrm{T} V^{-1} (y - X\beta) \; .
\end{split}
\end{equation}

Substituting the precision matrix $P = V^{-1}$ into \eqref{eq:mlr-mle-MLR-LL1} to ease notation, we have:

\begin{equation} \label{eq:mlr-mle-MLR-LL2}
\begin{split}
\mathrm{LL}(\beta,\sigma^2) = &- \frac{n}{2} \log(2\pi) - \frac{n}{2} \log(\sigma^2) - \frac{1}{2} \log(|V|) \\
&- \frac{1}{2 \sigma^2} \left( y^\mathrm{T} P y - 2 \beta^\mathrm{T} X^\mathrm{T} P y + \beta^\mathrm{T} X^\mathrm{T} P X \beta \right) \; .
\end{split}
\end{equation}

\vspace{1em}
The derivative of the log-likelihood function \eqref{eq:mlr-mle-MLR-LL2} with respect to $\beta$ is

\begin{equation} \label{eq:mlr-mle-dLL-dbeta}
\begin{split}
\frac{\mathrm{d}\mathrm{LL}(\beta,\sigma^2)}{\mathrm{d}\beta} &= \frac{\mathrm{d}}{\mathrm{d}\beta} \left( - \frac{1}{2 \sigma^2} \left( y^\mathrm{T} P y - 2 \beta^\mathrm{T} X^\mathrm{T} P y + \beta^\mathrm{T} X^\mathrm{T} P X \beta \right) \right) \\
&= \frac{1}{2 \sigma^2} \, \frac{\mathrm{d}}{\mathrm{d}\beta} \left( 2 \beta^\mathrm{T} X^\mathrm{T} P y - \beta^\mathrm{T} X^\mathrm{T} P X \beta \right) \\
&= \frac{1}{2 \sigma^2} \left( 2 X^\mathrm{T} P y - 2 X^\mathrm{T} P X \beta \right) \\
&= \frac{1}{\sigma^2} \left( X^\mathrm{T} P y - X^\mathrm{T} P X \beta \right)
\end{split}
\end{equation}

and setting this derivative to zero gives the MLE for $\beta$:

\begin{equation} \label{eq:mlr-mle-beta-MLE}
\begin{split}
\frac{\mathrm{d}\mathrm{LL}(\hat{\beta},\sigma^2)}{\mathrm{d}\beta} &= 0 \\
0 &= \frac{1}{\sigma^2} \left( X^\mathrm{T} P y - X^\mathrm{T} P X \hat{\beta} \right) \\
0 &= X^\mathrm{T} P y - X^\mathrm{T} P X \hat{\beta} \\
X^\mathrm{T} P X \hat{\beta} &= X^\mathrm{T} P y \\
\hat{\beta} &= \left( X^\mathrm{T} P X \right)^{-1} X^\mathrm{T} P y
\end{split}
\end{equation}

\vspace{1em}
The derivative of the log-likelihood function \eqref{eq:mlr-mle-MLR-LL1} at $\hat{\beta}$ with respect to $\sigma^2$ is

\begin{equation} \label{eq:mlr-mle-dLL-ds2}
\begin{split}
\frac{\mathrm{d}\mathrm{LL}(\hat{\beta},\sigma^2)}{\mathrm{d}\sigma^2} &= \frac{\mathrm{d}}{\mathrm{d}\sigma^2} \left( - \frac{n}{2} \log (\sigma^2) - \frac{1}{2 \sigma^2} (y - X\hat{\beta})^\mathrm{T} V^{-1} (y - X\hat{\beta}) \right) \\
&= - \frac{n}{2} \, \frac{1}{\sigma^2} + \frac{1}{2 (\sigma^2)^2} (y - X\hat{\beta})^\mathrm{T} V^{-1} (y - X\hat{\beta}) \\
&= - \frac{n}{2 \sigma^2} + \frac{1}{2 (\sigma^2)^2} (y - X\hat{\beta})^\mathrm{T} V^{-1} (y - X\hat{\beta})
\end{split}
\end{equation}

and setting this derivative to zero gives the MLE for $\sigma^2$:

\begin{equation} \label{eq:mlr-mle-s2-MLE}
\begin{split}
\frac{\mathrm{d}\mathrm{LL}(\hat{\beta},\hat{\sigma}^2)}{\mathrm{d}\sigma^2} &= 0 \\
0 &= - \frac{n}{2 \hat{\sigma}^2} + \frac{1}{2 (\hat{\sigma}^2)^2} (y - X\hat{\beta})^\mathrm{T} V^{-1} (y - X\hat{\beta}) \\
\frac{n}{2 \hat{\sigma}^2} &= \frac{1}{2 (\hat{\sigma}^2)^2} (y - X\hat{\beta})^\mathrm{T} V^{-1} (y - X\hat{\beta}) \\
\frac{2 (\hat{\sigma}^2)^2}{n} \cdot \frac{n}{2 \hat{\sigma}^2} &= \frac{2 (\hat{\sigma}^2)^2}{n} \cdot \frac{1}{2 (\hat{\sigma}^2)^2} (y - X\hat{\beta})^\mathrm{T} V^{-1} (y - X\hat{\beta}) \\
\hat{\sigma}^2 &= \frac{1}{n} (y - X\hat{\beta})^\mathrm{T} V^{-1} (y - X\hat{\beta})
\end{split}
\end{equation}

\vspace{1em}
Together, \eqref{eq:mlr-mle-beta-MLE} and \eqref{eq:mlr-mle-s2-MLE} constitute the MLE for multiple linear regression.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P78 | shortcut: mlr-mle | author: JoramSoch | date: 2020-03-11, 12:27.
\vspace{1em}



\subsection{Bayesian linear regression}

\subsubsection[\textbf{Conjugate prior distribution}]{Conjugate prior distribution} \label{sec:blr-prior}
\setcounter{equation}{0}

\textbf{Theorem:} Let

\begin{equation} \label{eq:blr-prior-GLM}
y = X \beta + \varepsilon, \; \varepsilon \sim \mathcal{N}(0, \sigma^2 V)
\end{equation}

be a linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}) with measured $n \times 1$ data vector $y$, known $n \times p$ design matrix $X$, known $n \times n$ covariance structure $V$ and unknown $p \times 1$ regression coefficients $\beta$ and noise variance $\sigma^2$.

Then, the conjugate prior ($\rightarrow$ Definition "prior-conj") for this model is a normal-gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:ng})

\begin{equation} \label{eq:blr-prior-GLM-NG-prior}
p(\beta,\tau) = \mathcal{N}(\beta; \mu_0, (\tau \Lambda_0)^{-1}) \cdot \mathrm{Gam}(\tau; a_0, b_0)
\end{equation}

where $\tau = 1/\sigma^2$ is the inverse noise variance or noise precision.


\vspace{1em}
\textbf{Proof:} By definition, a conjugate prior ($\rightarrow$ Definition "prior-conj") is a prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) that, when combined with the likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}), leads to a posterior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) that belongs to the same family of probability distributions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist}). This is fulfilled when the prior density and the likelihood function are proportional to the model parameters in the same way, i.e. the model parameters appear in the same functional form in both.

Equation \eqref{eq:blr-prior-GLM} implies the following likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf})

\begin{equation} \label{eq:blr-prior-GLM-LF-class}
p(y|\beta,\sigma^2) = \mathcal{N}(y; X \beta, \sigma^2 V) = \sqrt{\frac{1}{(2 \pi)^n |\sigma^2 V|}} \, \exp\left[ -\frac{1}{2 \sigma^2} (y-X\beta)^\mathrm{T} V^{-1} (y-X\beta) \right]
\end{equation}

which, for mathematical convenience, can also be parametrized as

\begin{equation} \label{eq:blr-prior-GLM-LF-Bayes}
p(y|\beta,\tau) = \mathcal{N}(y; X \beta, (\tau P)^{-1}) = \sqrt{\frac{|\tau P|}{(2 \pi)^n}} \, \exp\left[ -\frac{\tau}{2} (y-X\beta)^\mathrm{T} P (y-X\beta) \right]
\end{equation}

using the noise precision $\tau = 1/\sigma^2$ and the $n \times n$ precision matrix $P = V^{-1}$.

\vspace{1em}
Seperating constant and variable terms, we have:

\begin{equation} \label{eq:blr-prior-GLM-LF-s1}
p(y|\beta,\tau) = \sqrt{\frac{|P|}{(2 \pi)^n}} \cdot \tau^{n/2} \cdot \exp\left[ -\frac{\tau}{2} (y-X\beta)^\mathrm{T} P (y-X\beta) \right] \; .
\end{equation}

Expanding the product in the exponent, we have:

\begin{equation} \label{eq:blr-prior-GLM-LF-s2}
p(y|\beta,\tau) = \sqrt{\frac{|P|}{(2 \pi)^n}} \cdot \tau^{n/2} \cdot \exp\left[ -\frac{\tau}{2} \left( y^\mathrm{T} P y - y^\mathrm{T} P X \beta - \beta^\mathrm{T} X^\mathrm{T} P y + \beta^\mathrm{T} X^\mathrm{T} P X \beta \right) \right] \; .
\end{equation}

Completing the square over $\beta$, finally gives

\begin{equation} \label{eq:blr-prior-GLM-LF-s3}
p(y|\beta,\tau) = \sqrt{\frac{|P|}{(2 \pi)^n}} \cdot \tau^{n/2} \cdot \exp\left[ -\frac{\tau}{2} \left( (\beta - \tilde{X}y)^\mathrm{T} X^\mathrm{T} P X (\beta - \tilde{X}y) - y^\mathrm{T} Q y + y^\mathrm{T} P y \right) \right]
\end{equation}

where $\tilde{X} = \left( X^\mathrm{T} P X \right)^{-1} X^\mathrm{T} P$ and $Q = \tilde{X}^\mathrm{T} \left( X^\mathrm{T} P X \right) \tilde{X}$.

\vspace{1em}
In other words, the likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) is proportional to a power of $\tau$ times an exponential of $\tau$ and an exponential of a squared form of $\beta$, weighted by $\tau$:

\begin{equation} \label{eq:blr-prior-GLM-LF-s4}
p(y|\beta,\tau) \propto \tau^{n/2} \cdot \exp\left[ -\frac{\tau}{2} \left( y^\mathrm{T} P y - y^\mathrm{T} Q y \right) \right] \cdot \exp\left[ -\frac{\tau}{2} (\beta - \tilde{X}y)^\mathrm{T} X^\mathrm{T} P X (\beta - \tilde{X}y) \right] \; .
\end{equation}

The same is true for a normal gamma distribution over $\beta$ and $\tau$

\begin{equation} \label{eq:blr-prior-BLR-prior-s1}
p(\beta,\tau) = \mathcal{N}(\beta; \mu_0, (\tau \Lambda_0)^{-1}) \cdot \mathrm{Gam}(\tau; a_0, b_0)
\end{equation}

the probability density function of which ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:ng-pdf})

\begin{equation} \label{eq:blr-prior-BLR-prior-s2}
p(\beta,\tau) = \sqrt{\frac{|\tau \Lambda_0|}{(2 \pi)^p}} \exp\left[ -\frac{\tau}{2} (\beta-\mu_0)^\mathrm{T} \Lambda_0 (\beta-\mu_0) \right] \cdot \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \, \tau^{a_0-1} \exp[-b_0 \tau]
\end{equation}

exhibits the same proportionality

\begin{equation} \label{eq:blr-prior-BLR-prior-s3}
p(\beta,\tau) \propto \tau^{a_0+p/2-1} \cdot \exp[-\tau b_0] \cdot \exp\left[ -\frac{\tau}{2} (\beta-\mu_0)^\mathrm{T} \Lambda_0 (\beta-\mu_0) \right]
\end{equation}

and is therefore conjugate relative to the likelihood.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Bishop CM (2006): "Bayesian linear regression"; in: \textit{Pattern Recognition for Machine Learning}, pp. 152-161, ex. 3.12, eq. 3.112; URL: \url{https://www.springer.com/gp/book/9780387310732}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P9 | shortcut: blr-prior | author: JoramSoch | date: 2020-01-03, 15:26.
\vspace{1em}



\subsubsection[\textbf{Posterior distribution}]{Posterior distribution} \label{sec:blr-post}
\setcounter{equation}{0}

\textbf{Theorem:} Let

\begin{equation} \label{eq:blr-post-GLM}
y = X \beta + \varepsilon, \; \varepsilon \sim \mathcal{N}(0, \sigma^2 V)
\end{equation}

be a linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}) with measured $n \times 1$ data vector $y$, known $n \times p$ design matrix $X$, known $n \times n$ covariance structure ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:covmat}) $V$ and unknown $p \times 1$ regression coefficients $\beta$ and noise variance $\sigma^2$.  Moreover, assume a normal-gamma prior distribution ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:blr-prior}) over the model parameters $\beta$ and $\tau = 1/\sigma^2$:

\begin{equation} \label{eq:blr-post-GLM-NG-prior}
p(\beta,\tau) = \mathcal{N}(\beta; \mu_0, (\tau \Lambda_0)^{-1}) \cdot \mathrm{Gam}(\tau; a_0, b_0) \; .
\end{equation}

Then, the posterior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) is also a normal-gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:ng})

\begin{equation} \label{eq:blr-post-GLM-NG-post}
p(\beta,\tau|y) = \mathcal{N}(\beta; \mu_n, (\tau \Lambda_n)^{-1}) \cdot \mathrm{Gam}(\tau; a_n, b_n)
\end{equation}

and the posterior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) are given by

\begin{equation} \label{eq:blr-post-GLM-NG-post-par}
\begin{split}
\mu_n &= \Lambda_n^{-1} (X^\mathrm{T} P y + \Lambda_0 \mu_0) \\
\Lambda_n &= X^\mathrm{T} P X + \Lambda_0 \\
a_n &= a_0 + \frac{n}{2} \\
b_n &= b_0 + \frac{1}{2} (y^\mathrm{T} P y + \mu_0^\mathrm{T} \Lambda_0 \mu_0 - \mu_n^\mathrm{T} \Lambda_n \mu_n) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Proof:} According to Bayes' theorem ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:bayes-th}), the posterior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) is given by

\begin{equation} \label{eq:blr-post-GLM-NG-BT}
p(\beta,\tau|y) = \frac{p(y|\beta,\tau) \, p(\beta,\tau)}{p(y)} \; .
\end{equation}

Since $p(y)$ is just a normalization factor, the posterior is proportional ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:post-jl}) to the numerator:

\begin{equation} \label{eq:blr-post-GLM-NG-post-JL}
p(\beta,\tau|y) \propto p(y|\beta,\tau) \, p(\beta,\tau) = p(y,\beta,\tau) \; .
\end{equation}

Equation \eqref{eq:blr-post-GLM} implies the following likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf})

\begin{equation} \label{eq:blr-post-GLM-LF-class}
p(y|\beta,\sigma^2) = \mathcal{N}(y; X \beta, \sigma^2 V) = \sqrt{\frac{1}{(2 \pi)^n |\sigma^2 V|}} \, \exp\left[ -\frac{1}{2 \sigma^2} (y-X\beta)^\mathrm{T} V^{-1} (y-X\beta) \right]
\end{equation}

which, for mathematical convenience, can also be parametrized as

\begin{equation} \label{eq:blr-post-GLM-LF-Bayes}
p(y|\beta,\tau) = \mathcal{N}(y; X \beta, (\tau P)^{-1}) = \sqrt{\frac{|\tau P|}{(2 \pi)^n}} \, \exp\left[ -\frac{\tau}{2} (y-X\beta)^\mathrm{T} P (y-X\beta) \right]
\end{equation}

using the noise precision $\tau = 1/\sigma^2$ and the $n \times n$ precision matrix ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:precmat}) $P = V^{-1}$.

\vspace{1em}
Combining the likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) \eqref{eq:blr-post-GLM-LF-Bayes} with the prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) \eqref{eq:blr-post-GLM-NG-prior}, the joint likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:jl}) of the model is given by

\begin{equation} \label{eq:blr-post-GLM-NG-JL-s1}
\begin{split}
p(y,\beta,\tau) = \; & p(y|\beta,\tau) \, p(\beta,\tau) \\
= \; & \sqrt{\frac{|\tau P|}{(2 \pi)^n}} \, \exp\left[ -\frac{\tau}{2} (y-X\beta)^\mathrm{T} P (y-X\beta) \right] \cdot \\
& \sqrt{\frac{|\tau \Lambda_0|}{(2 \pi)^p}} \, \exp\left[ -\frac{\tau}{2} (\beta-\mu_0)^\mathrm{T} \Lambda_0 (\beta-\mu_0) \right] \cdot \\
& \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \, \tau^{a_0-1} \exp[-b_0 \tau] \; .
\end{split}
\end{equation}

Collecting identical variables gives:

\begin{equation} \label{eq:blr-post-GLM-NG-JL-s2}
\begin{split}
p(y,\beta,\tau) = \; & \sqrt{\frac{\tau^{n+p}}{(2 \pi)^{n+p}} |P| |\Lambda_0|} \, \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \, \tau^{a_0-1} \exp[-b_0 \tau] \cdot \\
& \exp\left[ -\frac{\tau}{2} \left( (y-X\beta)^\mathrm{T} P (y-X\beta) + (\beta-\mu_0)^\mathrm{T} \Lambda_0 (\beta-\mu_0) \right) \right] \; .
\end{split}
\end{equation}

Expanding the products in the exponent gives:

\begin{equation} \label{eq:blr-post-GLM-NG-JL-s3}
\begin{split}
p(y,\beta,\tau) = \; & \sqrt{\frac{\tau^{n+p}}{(2 \pi)^{n+p}} |P| |\Lambda_0|} \, \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \, \tau^{a_0-1} \exp[-b_0 \tau] \cdot \\
& \exp\left[ -\frac{\tau}{2} \left( y^\mathrm{T} P y - y^\mathrm{T} P X \beta - \beta^\mathrm{T} X^\mathrm{T} P y + \beta^\mathrm{T} X^\mathrm{T} P X \beta + \right. \right. \\
& \hphantom{\exp \left[ -\frac{\tau}{2} \right.} \; \left. \left. \beta^\mathrm{T} \Lambda_0 \beta - \beta^\mathrm{T} \Lambda_0 \mu_0 - \mu_0^\mathrm{T} \Lambda_0 \beta + \mu_0^\mathrm{T} \Lambda_0 \mu_0 \right) \right] \; .
\end{split}
\end{equation}

Completing the square over $\beta$, we finally have

\begin{equation} \label{eq:blr-post-GLM-NG-JL-s4}
\begin{split}
p(y,\beta,\tau) = \; & \sqrt{\frac{\tau^{n+p}}{(2 \pi)^{n+p}} |P| |\Lambda_0|} \, \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \, \tau^{a_0-1} \exp[-b_0 \tau] \cdot \\
& \exp\left[ -\frac{\tau}{2} \left( (\beta-\mu_n)^\mathrm{T} \Lambda_n (\beta-\mu_n) + (y^\mathrm{T} P y + \mu_0^\mathrm{T} \Lambda_0 \mu_0 - \mu_n^\mathrm{T} \Lambda_n \mu_n) \right) \right]
\end{split}
\end{equation}

with the posterior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post})

\begin{equation} \label{eq:blr-post-GLM-NG-post-beta-par}
\begin{split}
\mu_n &= \Lambda_n^{-1} (X^\mathrm{T} P y + \Lambda_0 \mu_0) \\
\Lambda_n &= X^\mathrm{T} P X + \Lambda_0 \; .
\end{split}
\end{equation}

Ergo, the joint likelihood is proportional to

\begin{equation} \label{eq:blr-post-GLM-NG-JL-s5}
p(y,\beta,\tau) \propto \tau^{p/2} \cdot \exp\left[ -\frac{\tau}{2} (\beta-\mu_n)^\mathrm{T} \Lambda_n (\beta-\mu_n) \right] \cdot \tau^{a_n-1} \cdot \exp\left[ -b_n \tau \right]
\end{equation}

with the posterior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post})

\begin{equation} \label{eq:blr-post-GLM-NG-post-tau-par}
\begin{split}
a_n &= a_0 + \frac{n}{2} \\
b_n &= b_0 + \frac{1}{2} (y^\mathrm{T} P y + \mu_0^\mathrm{T} \Lambda_0 \mu_0 - \mu_n^\mathrm{T} \Lambda_n \mu_n) \; .
\end{split}
\end{equation}

From the term in \eqref{eq:blr-post-GLM-NG-JL-s5}, we can isolate the posterior distribution over $\beta$ given $\tau$:

\begin{equation} \label{eq:blr-post-GLM-NG-post-beta}
p(\beta|\tau,y) = \mathcal{N}(\beta; \mu_n, (\tau \Lambda_n)^{-1}) \; .
\end{equation}

From the remaining term, we can isolate the posterior distribution over $\tau$:

\begin{equation} \label{eq:blr-post-GLM-NG-post-tau}
p(\tau|y) = \mathrm{Gam}(\tau; a_n, b_n) \; .
\end{equation}

Together, \eqref{eq:blr-post-GLM-NG-post-beta} and \eqref{eq:blr-post-GLM-NG-post-tau} constitute the joint ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-joint}) posterior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) of $\beta$ and $\tau$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Bishop CM (2006): "Bayesian linear regression"; in: \textit{Pattern Recognition for Machine Learning}, pp. 152-161, ex. 3.12, eq. 3.113; URL: \url{https://www.springer.com/gp/book/9780387310732}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P10 | shortcut: blr-post | author: JoramSoch | date: 2020-01-03, 17:53.
\vspace{1em}



\subsubsection[\textbf{Log model evidence}]{Log model evidence} \label{sec:blr-lme}
\setcounter{equation}{0}

\textbf{Theorem:} Let

\begin{equation} \label{eq:blr-lme-GLM}
m: \; y = X \beta + \varepsilon, \; \varepsilon \sim \mathcal{N}(0, \sigma^2 V)
\end{equation}

be a linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}) with measured $n \times 1$ data vector $y$, known $n \times p$ design matrix $X$, known $n \times n$ covariance structure $V$ and unknown $p \times 1$ regression coefficients $\beta$ and noise variance $\sigma^2$.  Moreover, assume a normal-gamma prior distribution ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:blr-prior}) over the model parameters $\beta$ and $\tau = 1/\sigma^2$:

\begin{equation} \label{eq:blr-lme-GLM-NG-prior}
p(\beta,\tau) = \mathcal{N}(\beta; \mu_0, (\tau \Lambda_0)^{-1}) \cdot \mathrm{Gam}(\tau; a_0, b_0) \; .
\end{equation}

Then, the log model evidence ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme}) for this model is

\begin{equation} \label{eq:blr-lme-GLM-NG-LME}
\begin{split}
\log p(y|m) = \frac{1}{2} & \log |P| - \frac{n}{2} \log (2 \pi)  + \frac{1}{2} \log |\Lambda_0| - \frac{1}{2} \log |\Lambda_n| + \\
& \log \Gamma(a_n) - \log \Gamma(a_0) + a_0 \log b_0 - a_n \log b_n
\end{split}
\end{equation}

where the posterior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) are given by

\begin{equation} \label{eq:blr-lme-GLM-NG-post-par}
\begin{split}
\mu_n &= \Lambda_n^{-1} (X^\mathrm{T} P y + \Lambda_0 \mu_0) \\
\Lambda_n &= X^\mathrm{T} P X + \Lambda_0 \\
a_n &= a_0 + \frac{n}{2} \\
b_n &= b_0 + \frac{1}{2} (y^\mathrm{T} P y + \mu_0^\mathrm{T} \Lambda_0 \mu_0 - \mu_n^\mathrm{T} \Lambda_n \mu_n) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Proof:} According to the law of marginal probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}), the model evidence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ml}) for this model is:

\begin{equation} \label{eq:blr-lme-GLM-NG-ME-s1}
p(y|m) = \iint p(y|\beta,\tau) \, p(\beta,\tau) \, \mathrm{d}\beta \, \mathrm{d}\tau \; .
\end{equation}

According to the law of conditional probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-cond}), the integrand is equivalent to the joint likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:jl}):

\begin{equation} \label{eq:blr-lme-GLM-NG-ME-s2}
p(y|m) = \iint p(y,\beta,\tau) \, \mathrm{d}\beta \, \mathrm{d}\tau \; .
\end{equation}

Equation \eqref{eq:blr-lme-GLM} implies the following likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf})

\begin{equation} \label{eq:blr-lme-GLM-LF-class}
p(y|\beta,\sigma^2) = \mathcal{N}(y; X \beta, \sigma^2 V) = \sqrt{\frac{1}{(2 \pi)^n |\sigma^2 V|}} \, \exp\left[ -\frac{1}{2 \sigma^2} (y-X\beta)^\mathrm{T} V^{-1} (y-X\beta) \right]
\end{equation}

which, for mathematical convenience, can also be parametrized as

\begin{equation} \label{eq:blr-lme-GLM-LF-Bayes}
p(y|\beta,\tau) = \mathcal{N}(y; X \beta, (\tau P)^{-1}) = \sqrt{\frac{|\tau P|}{(2 \pi)^n}} \, \exp\left[ -\frac{\tau}{2} (y-X\beta)^\mathrm{T} P (y-X\beta) \right]
\end{equation}

using the noise precision $\tau = 1/\sigma^2$ and the $n \times n$ precision matrix $P = V^{-1}$.

\vspace{1em}
When deriving the posterior distribution ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:blr-post}) $p(\beta,\tau|y)$, the joint likelihood $p(y,\beta,\tau)$ is obtained as

\begin{equation} \label{eq:blr-lme-GLM-NG-LME-s1}
\begin{split}
p(y,\beta,\tau) = \; & \sqrt{\frac{\tau^n |P|}{(2 \pi)^n}} \, \sqrt{\frac{\tau^p |\Lambda_0|}{(2 \pi)^p}} \, \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \, \tau^{a_0-1} \exp[-b_0 \tau] \cdot \\
& \exp\left[ -\frac{\tau}{2} \left( (\beta-\mu_n)^T \Lambda_n (\beta-\mu_n) + (y^T P y + \mu_0^T \Lambda_0 \mu_0 - \mu_n^T \Lambda_n \mu_n) \right) \right] \; .
\end{split}
\end{equation}

Using the probability density function of the multivariate normal distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mvn-pdf}), we can rewrite this as

\begin{equation} \label{eq:blr-lme-GLM-NG-LME-s2}
\begin{split}
p(y,\beta,\tau) = \; & \sqrt{\frac{\tau^n |P|}{(2 \pi)^n}} \, \sqrt{\frac{\tau^p |\Lambda_0|}{(2 \pi)^p}} \, \sqrt{\frac{(2 \pi)^p}{\tau^p |\Lambda_n|}} \, \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \, \tau^{a_0-1} \exp[-b_0 \tau] \cdot \\
& \mathcal{N}(\beta; \mu_n, (\tau \Lambda_n)^{-1}) \, \exp\left[ -\frac{\tau}{2} (y^T P y + \mu_0^T \Lambda_0 \mu_0 - \mu_n^T \Lambda_n \mu_n) \right] \; .
\end{split}
\end{equation}

Now, $\beta$ can be integrated out easily:

\begin{equation} \label{eq:blr-lme-GLM-NG-LME-s3}
\begin{split}
\int p(y,\beta,\tau) \, \mathrm{d}\beta = \; & \sqrt{\frac{\tau^n |P|}{(2 \pi)^n}} \, \sqrt{\frac{|\Lambda_0|}{|\Lambda_n|}} \, \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \, \tau^{a_0-1} \exp[-b_0 \tau] \cdot \\
& \exp\left[ -\frac{\tau}{2} (y^T P y + \mu_0^T \Lambda_0 \mu_0 - \mu_n^T \Lambda_n \mu_n) \right] \; .
\end{split}
\end{equation}

Using the probability density function of the gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-pdf}), we can rewrite this as

\begin{equation}\label{eq:blr-lme-GLM-NG-LME-s4}
\int p(y,\beta,\tau) \, \mathrm{d}\beta = \; \sqrt{\frac{|P|}{(2 \pi)^n}} \, \sqrt{\frac{|\Lambda_0|}{|\Lambda_n|}} \, \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \, \frac{\Gamma(a_n)}{ {b_n}^{a_n}} \, \mathrm{Gam}(\tau; a_n, b_n) \; .
\end{equation}

Finally, $\tau$ can also be integrated out:

\begin{equation} \label{eq:blr-lme-GLM-NG-LME-s5}
\iint p(y,\beta,\tau) \, \mathrm{d}\beta \, \mathrm{d}\tau = \; \sqrt{\frac{|P|}{(2 \pi)^n}} \, \sqrt{\frac{|\Lambda_0|}{|\Lambda_n|}} \, \frac{\Gamma(a_n)}{\Gamma(a_0)} \, \frac{ {b_0}^{a_0}}{ {b_n}^{a_n}} = p(y|m) \; .
\end{equation}

Thus, the log model evidence ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme}) of this model is given by

\begin{equation} \label{eq:blr-lme-GLM-NG-LME-s6}
\begin{split}
\log p(y|m) = \frac{1}{2} & \log |P| - \frac{n}{2} \log (2 \pi)  + \frac{1}{2} \log |\Lambda_0| - \frac{1}{2} \log |\Lambda_n| + \\
& \log \Gamma(a_n) - \log \Gamma(a_0) + a_0 \log b_0 - a_n \log b_n \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Bishop CM (2006): "Bayesian linear regression"; in: \textit{Pattern Recognition for Machine Learning}, pp. 152-161, ex. 3.23, eq. 3.118; URL: \url{https://www.springer.com/gp/book/9780387310732}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P11 | shortcut: blr-lme | author: JoramSoch | date: 2020-01-03, 22:05.
\vspace{1em}



\subsubsection[\textbf{Posterior probability of alternative hypothesis}]{Posterior probability of alternative hypothesis} \label{sec:blr-pp}
\setcounter{equation}{0}

\textbf{Theorem:} Let there be a linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}) with normally distributed ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mvn}) errors:

\begin{equation} \label{eq:blr-pp-GLM}
y = X \beta + \varepsilon, \; \varepsilon \sim \mathcal{N}(0, \sigma^2 V)
\end{equation}

and assume a normal-gamma ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:ng}) prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) over the model parameters $\beta$ and $\tau = 1/\sigma^2$:

\begin{equation} \label{eq:blr-pp-GLM-NG-prior}
p(\beta,\tau) = \mathcal{N}(\beta; \mu_0, (\tau \Lambda_0)^{-1}) \cdot \mathrm{Gam}(\tau; a_0, b_0) \; .
\end{equation}

Then, the posterior ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob}) of the alternative hypothesis ($\rightarrow$ Definition "h1")

\begin{equation} \label{eq:blr-pp-GLM-H1}
\mathrm{H}_1: \, c^\mathrm{T} \beta > 0
\end{equation}

is given by

\begin{equation} \label{eq:blr-pp-GLM-NG-PP}
\mathrm{Pr}\left( \mathrm{H}_1 | y \right) = 1 - \mathrm{T}\left( -\frac{c^\mathrm{T} \mu}{\sqrt{c^\mathrm{T} \Sigma c}}; \nu \right)
\end{equation}

where $c$ is a $p \times 1$ contrast vector ($\rightarrow$ Definition "con"), $\mathrm{T}(x; \nu)$ is the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) of the t-distribution ($\rightarrow$ Definition "t") with $\nu$ degrees of freedom ($\rightarrow$ Definition "dof") and $\mu$, $\Sigma$ and $\nu$ can be obtained from the posterior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) of Bayesian linear regression.


\vspace{1em}
\textbf{Proof:} The posterior distribution for Bayesian linear regression ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:blr-post}) is given by a normal-gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:ng}) over $\beta$ and $\tau = 1/\sigma^2$

\begin{equation} \label{eq:blr-pp-GLM-NG-post}
p(\beta,\tau|y) = \mathcal{N}(\beta; \mu_n, (\tau \Lambda_n)^{-1}) \cdot \mathrm{Gam}(\tau; a_n, b_n)
\end{equation}

with the posterior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post})

\begin{equation} \label{eq:blr-pp-GLM-NG-post-par}
\begin{split}
\mu_n &= \Lambda_n^{-1} (X^\mathrm{T} P y + \Lambda_0 \mu_0) \\
\Lambda_n &= X^\mathrm{T} P X + \Lambda_0 \\
a_n &= a_0 + \frac{n}{2} \\
b_n &= b_0 + \frac{1}{2} (y^\mathrm{T} P y + \mu_0^\mathrm{T} \Lambda_0 \mu_0 - \mu_n^\mathrm{T} \Lambda_n \mu_n) \; .
\end{split}
\end{equation}

The marginal distribution of a normal-gamma distribution is a multivariate t-distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:ng-marg}), such that the marginal ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-marg}) posterior ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) distribution of $\beta$ is

\begin{equation} \label{eq:blr-pp-GLM-NG-post-beta}
p(\beta|y) = \mathrm{t}(\beta; \mu, \Sigma, \nu)
\end{equation}

with the posterior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post})

\begin{equation} \label{eq:blr-pp-GLM-NG-post-par-beta}
\begin{split}
\mu &= \mu_n \\
\Sigma &= \left( \frac{a_n}{b_n} \Lambda_n \right)^{-1} \\
\nu &= 2 \, a_n \; .
\end{split}
\end{equation}

Define the quantity $\gamma = c^\mathrm{T} \beta$. According to the linear transformation theorem for the multivariate t-distribution ($\rightarrow$ Proof "mvt-ltt"), $\gamma$ also follows a multivariate t-distribution ($\rightarrow$ Definition "mvt"):

\begin{equation} \label{eq:blr-pp-GLM-NG-post-gamma}
p(\gamma|y) = \mathrm{t}(\gamma; c^\mathrm{T} \mu, c^\mathrm{T} \Sigma \, c, \nu) \; .
\end{equation}

Because $c^\mathrm{T}$ is a $1 \times p$ vector, $\gamma$ is a scalar and actually has a non-central scaled t-distribution ($\rightarrow$ Definition "ncst"). Therefore, the posterior probability of $H_1$ can be calculated using a one-dimensional integral:

\begin{equation} \label{eq:blr-pp-GLM-NG-post-prob-H0-s1}
\begin{split}
\mathrm{Pr}\left( \mathrm{H}_1 | y \right) &= p(\gamma > 0|y) \\
&= \int_{0}^{+\infty} p(\gamma|y) \, \mathrm{d}\gamma \\
&= 1 - \int_{-\infty}^{0} p(\gamma|y) \, \mathrm{d}\gamma \\
&= 1 - \mathrm{T}_\mathrm{ncst}(0; c^\mathrm{T} \mu, c^\mathrm{T} \Sigma \, c, \nu) \; .
\end{split}
\end{equation}

Using the relation between non-central scaled t-distribution and standard t-distribution ($\rightarrow$ Proof "ncst-t"), we can finally write:

\begin{equation} \label{eq:blr-pp-GLM-NG-post-prob-H0-s2}
\begin{split}
\mathrm{Pr}\left( \mathrm{H}_1 | y \right) &= 1 - \mathrm{T}\left( \frac{(0 - c^\mathrm{T} \mu)}{\sqrt{c^\mathrm{T} \Sigma c}}; \nu \right) \\
&= 1 - \mathrm{T}\left( -\frac{c^\mathrm{T} \mu}{\sqrt{c^\mathrm{T} \Sigma c}}; \nu \right) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Koch, Karl-Rudolf (2007): "Multivariate t-distribution"; in: \textit{Introduction to Bayesian Statistics}, Springer, Berlin/Heidelberg, 2007, eqs. 2.235, 2.236, 2.213, 2.210, 2.188; URL: \url{https://www.springer.com/de/book/9783540727231}; DOI: 10.1007/978-3-540-72726-2.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P133 | shortcut: blr-pp | author: JoramSoch | date: 2020-07-17, 17:03.
\vspace{1em}



\subsubsection[\textbf{Posterior credibility region excluding null hypothesis}]{Posterior credibility region excluding null hypothesis} \label{sec:blr-pcr}
\setcounter{equation}{0}

\textbf{Theorem:} Let there be a linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}) with normally distributed ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mvn}) errors:

\begin{equation} \label{eq:blr-pcr-GLM}
y = X \beta + \varepsilon, \; \varepsilon \sim \mathcal{N}(0, \sigma^2 V)
\end{equation}

and assume a normal-gamma ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:ng}) prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) over the model parameters $\beta$ and $\tau = 1/\sigma^2$:

\begin{equation} \label{eq:blr-pcr-GLM-NG-prior}
p(\beta,\tau) = \mathcal{N}(\beta; \mu_0, (\tau \Lambda_0)^{-1}) \cdot \mathrm{Gam}(\tau; a_0, b_0) \; .
\end{equation}

Then, the largest posterior ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) credibility region ($\rightarrow$ Definition "cr") that does not contain the omnibus null hypothesis ($\rightarrow$ Definition "h0")

\begin{equation} \label{eq:blr-pcr-GLM-H0}
\mathrm{H}_0: \, C^\mathrm{T} \beta = 0
\end{equation}

is given by the credibility level ($\rightarrow$ Definition "cr")

\begin{equation} \label{eq:blr-pcr-GLM-NG-PCR}
(1-\alpha) = \mathrm{F}\left( \left[ \mu^\mathrm{T} C (C^\mathrm{T} \Sigma \, C)^{-1} C^\mathrm{T} \mu \right]/q; q, \nu \right)
\end{equation}

where $C$ is a $p \times q$ contrast matrix ($\rightarrow$ Definition "con"), $\mathrm{F}(x; v, w)$ is the cumulative distribution function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:cdf}) of the F-distribution ($\rightarrow$ Definition "f") with $v$ numerator degrees of freedom ($\rightarrow$ Definition "dof") $w$ denominator degrees of freedom ($\rightarrow$ Definition "dof") and $\mu$, $\Sigma$ and $\nu$ can be obtained from the posterior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) of Bayesian linear regression.


\vspace{1em}
\textbf{Proof:} The posterior distribution for Bayesian linear regression ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:blr-post}) is given by a normal-gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:ng}) over $\beta$ and $\tau = 1/\sigma^2$

\begin{equation} \label{eq:blr-pcr-GLM-NG-post}
p(\beta,\tau|y) = \mathcal{N}(\beta; \mu_n, (\tau \Lambda_n)^{-1}) \cdot \mathrm{Gam}(\tau; a_n, b_n)
\end{equation}

with the posterior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post})

\begin{equation} \label{eq:blr-pcr-GLM-NG-post-par}
\begin{split}
\mu_n &= \Lambda_n^{-1} (X^\mathrm{T} P y + \Lambda_0 \mu_0) \\
\Lambda_n &= X^\mathrm{T} P X + \Lambda_0 \\
a_n &= a_0 + \frac{n}{2} \\
b_n &= b_0 + \frac{1}{2} (y^\mathrm{T} P y + \mu_0^\mathrm{T} \Lambda_0 \mu_0 - \mu_n^\mathrm{T} \Lambda_n \mu_n) \; .
\end{split}
\end{equation}

The marginal distribution of a normal-gamma distribution is a multivariate t-distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:ng-marg}), such that the marginal ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-marg}) posterior ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) distribution of $\beta$ is

\begin{equation} \label{eq:blr-pcr-GLM-NG-post-beta}
p(\beta|y) = \mathrm{t}(\beta; \mu, \Sigma, \nu)
\end{equation}

with the posterior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post})

\begin{equation} \label{eq:blr-pcr-GLM-NG-post-par-beta}
\begin{split}
\mu &= \mu_n \\
\Sigma &= \left( \frac{a_n}{b_n} \Lambda_n \right)^{-1} \\
\nu &= 2 \, a_n \; .
\end{split}
\end{equation}

Define the quantity $\gamma = C^\mathrm{T} \beta$. According to the linear transformation theorem for the multivariate t-distribution ($\rightarrow$ Proof "mvt-ltt"), $\gamma$ also follows a multivariate t-distribution ($\rightarrow$ Definition "mvt"):

\begin{equation} \label{eq:blr-pcr-GLM-NG-post-gamma}
p(\gamma|y) = \mathrm{t}(\gamma; C^\mathrm{T} \mu, C^\mathrm{T} \Sigma \, C, \nu) \; .
\end{equation}

Because $C^\mathrm{T}$ is a $q \times p$ matrix, $\gamma$ is a $q \times 1$ vector. The quadratic form of a multivariate t-distributed random variable has an F-distribution ($\rightarrow$ Proof "mvt-f"), such that we can write:

\begin{equation} \label{eq:blr-pcr-GLM-NG-post-qf}
\mathrm{QF}(\gamma) = (\gamma - C^\mathrm{T} \mu)^\mathrm{T} (C^\mathrm{T} \Sigma \, C)^{-1} (\gamma - C^\mathrm{T} \mu) /q \, \sim \mathrm{F}(q,\nu) \; .
\end{equation}

Therefore, the largest posterior credibility region for $\gamma$ which does not contain $\gamma = 0_q$ (i.e. only touches this origin point) can be obtained by plugging $\mathrm{QF}(0)$ into the cumulative distribution function of the F-distribution:

\begin{equation} \label{eq:blr-pcr-GLM-NG-post-cred-reg-not-H0}
\begin{split}
(1-\alpha) &= \mathrm{F}\left( \mathrm{QF}(0); q, \nu \right) \\
&= \mathrm{F}\left( \left[ \mu^\mathrm{T} C (C^\mathrm{T} \Sigma \, C)^{-1} C^\mathrm{T} \mu \right]/q; q, \nu \right) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Koch, Karl-Rudolf (2007): "Multivariate t-distribution"; in: \textit{Introduction to Bayesian Statistics}, Springer, Berlin/Heidelberg, 2007, eqs. 2.235, 2.236, 2.213, 2.210, 2.211, 2.183; URL: \url{https://www.springer.com/de/book/9783540727231}; DOI: 10.1007/978-3-540-72726-2.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P134 | shortcut: blr-pcr | author: JoramSoch | date: 2020-07-17, 17:41.
\vspace{1em}



\pagebreak
\section{Multivariate normal data}

\subsection{General linear model}

\subsubsection[\textit{Definition}]{Definition} \label{sec:glm}
\setcounter{equation}{0}

\textbf{Definition:} Let $Y$ be an $n \times v$ matrix and let $X$ be an $n \times p$ matrix. Then, a statement asserting a linear mapping from $X$ to $Y$ with parameters $B$ and matrix-normally distributed ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:matn}) errors $E$

\begin{equation} \label{eq:glm-glm}
Y = X B + E, \; E \sim \mathcal{MN}(0, V, \Sigma)
\end{equation}

is called a multivariate linear regression model or simply, "general linear model".

\begin{itemize}

\item $Y$ is called "data matrix", "set of dependent variables" or "measurements";

\item $X$ is called "design matrix", "set of independent variables" or "predictors";

\item $B$ are called "regression coefficients" or "weights";

\item $E$ is called "noise matrix" or "error terms";

\item $V$ is called "covariance across rows";

\item $\Sigma$ is called "covariance across columns";

\item $n$ is the number of observations;

\item $v$ is the number of measurements;

\item $p$ is the number of predictors.

\end{itemize}

When rows of $Y$ correspond to units of time, e.g. subsequent measurements, $V$ is called "temporal covariance". When columns of $Y$ correspond to units of space, e.g. measurement channels, $\Sigma$ is called "spatial covariance".

When the covariance matrix $V$ is a scalar multiple of the $n \times n$ identity matrix, this is called a general linear model with independent and identically distributed (i.i.d.) observations:

\begin{equation} \label{eq:glm-glm-iid}
V = \lambda I_n \quad \Rightarrow \quad E \sim \mathcal{MN}(0, \lambda I_n, \Sigma) \quad \Rightarrow \quad \varepsilon_i \overset{\text{i.i.d.}}{\sim} \mathcal{N}(0, \lambda \Sigma) \; .
\end{equation}

Otherwise, it is called a general linear model with correlated observations.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "General linear model"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-03-21; URL: \url{https://en.wikipedia.org/wiki/General_linear_model}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D40 | shortcut: glm | author: JoramSoch | date: 2020-03-21, 22:24.
\vspace{1em}



\subsubsection[\textbf{Ordinary least squares}]{Ordinary least squares} \label{sec:glm-ols}
\setcounter{equation}{0}

\textbf{Theorem:} Given a general linear model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:glm}) with independent observations

\begin{equation} \label{eq:glm-ols-GLM}
Y = X B + E, \; E \sim \mathcal{MN}(0, \sigma^2 I_n, \Sigma) \; ,
\end{equation}

the ordinary least squares ($\rightarrow$ Definition "ols") parameters estimates are given by

\begin{equation} \label{eq:glm-ols-OLS}
\hat{B} = (X^\mathrm{T} X)^{-1} X^\mathrm{T} Y \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} Let $\hat{B}$ be the ordinary least squares ($\rightarrow$ Definition "ols") (OLS) solution and let $\hat{E} = Y - X\hat{B}$ be the resulting matrix of residuals. According to the exogeneity assumption of OLS, the errors have conditional mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) zero

\begin{equation} \label{eq:glm-ols-OLS-exo}
\mathrm{E}(E|X) = 0 \; ,
\end{equation}

a direct consequence of which is that the regressors are uncorrelated with the errors

\begin{equation} \label{eq:glm-ols-OLS-uncorr}
\mathrm{E}(X^\mathrm{T} E) = 0 \; ,
\end{equation}

which, in the finite sample, means that the residual matrix must be orthogonal to the design matrix:

\begin{equation} \label{eq:glm-ols-X-E-orth}
X^\mathrm{T} \hat{E} = 0 \; .
\end{equation}

From \eqref{eq:glm-ols-X-E-orth}, the OLS formula can be directly derived:

\begin{equation} \label{eq:glm-ols-OLS-qed}
\begin{split}
X^\mathrm{T} \hat{E} &= 0 \\
X^\mathrm{T} \left( Y - X\hat{B} \right) &= 0 \\
X^\mathrm{T} Y - X^\mathrm{T} X\hat{B} &= 0 \\
X^\mathrm{T} X\hat{B} &= X^\mathrm{T} Y \\
\hat{B} &= (X^\mathrm{T} X)^{-1} X^\mathrm{T} Y \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P106 | shortcut: glm-ols | author: JoramSoch | date: 2020-05-19, 06:02.
\vspace{1em}



\subsubsection[\textbf{Weighted least squares}]{Weighted least squares} \label{sec:glm-wls}
\setcounter{equation}{0}

\textbf{Theorem:} Given a general linear model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:glm}) with correlated observations

\begin{equation} \label{eq:glm-wls-GLM}
Y = X B + E, \; E \sim \mathcal{MN}(0, V, \Sigma) \; ,
\end{equation}

the weighted least sqaures ($\rightarrow$ Definition "wls") parameter estimates are given by

\begin{equation} \label{eq:glm-wls-WLS}
\hat{B} = (X^\mathrm{T} V^{-1} X)^{-1} X^\mathrm{T} V^{-1} Y \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} Let there be an $n \times n$ square matrix $W$, such that

\begin{equation} \label{eq:glm-wls-W-def}
W V W^\mathrm{T} = I_n \; .
\end{equation}

Since $V$ is a covariance matrix and thus symmetric, $W$ is also symmetric and can be expressed as the matrix square root of the inverse of $V$:

\begin{equation} \label{eq:glm-wls-W-V}
W W = V^{-1} \quad \Leftrightarrow \quad W = V^{-1/2} \; .
\end{equation}

Left-multiplying the linear regression equation \eqref{eq:glm-wls-GLM} with $W$, the linear transformation theorem ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:matn-ltt}) implies that

\begin{equation} \label{eq:glm-wls-GLM-W}
WY = WXB + WE, \; WE \sim \mathcal{MN}(0, W V W^\mathrm{T}, \Sigma) \; .
\end{equation}

Applying \eqref{eq:glm-wls-W-def}, we see that \eqref{eq:glm-wls-GLM-W} is actually a general linear model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:glm}) with independent observations

\begin{equation} \label{eq:glm-wls-GLM-W-dev}
\tilde{Y} = \tilde{X}B + \tilde{E}, \; \tilde{E} \sim \mathcal{N}(0, I_n, \Sigma)
\end{equation}

where $\tilde{Y} = WY$, $\tilde{X} = WX$ and $\tilde{E} = WE$, such that we can apply the ordinary least squares solution ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:glm-ols}) giving

\begin{equation} \label{eq:glm-wls-WLS-qed}
\begin{split}
\hat{B} &= (\tilde{X}^\mathrm{T} \tilde{X})^{-1} \tilde{X}^\mathrm{T} \tilde{Y} \\
&= \left( (WX)^\mathrm{T} WX \right)^{-1} (WX)^\mathrm{T} WY \\
&= \left( X^\mathrm{T} W^\mathrm{T} W X \right)^{-1} X^\mathrm{T} W^\mathrm{T} W Y \\
&= \left( X^\mathrm{T} W W X \right)^{-1} X^\mathrm{T} W W Y \\
&\overset{\eqref{eq:glm-wls-W-V}}{=} \left( X^\mathrm{T} V^{-1} X \right)^{-1} X^\mathrm{T} V^{-1} Y
\end{split}
\end{equation}

which corresponds to the weighted least squares solution \eqref{eq:glm-wls-WLS}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P107 | shortcut: glm-wls | author: JoramSoch | date: 2020-05-19, 06:27.
\vspace{1em}



\subsubsection[\textbf{Maximum likelihood estimation}]{Maximum likelihood estimation} \label{sec:glm-mle}
\setcounter{equation}{0}

\textbf{Theorem:} Given a general linear model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:glm}) with matrix-normally distributed ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:matn}) errors

\begin{equation} \label{eq:glm-mle-GLM}
Y = X B + E, \; E \sim \mathcal{MN}(0, V, \Sigma) \; ,
\end{equation}

maximum likelihood estimates ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mle}) for the unknown parameters $B$ and $\Sigma$ are given by

\begin{equation} \label{eq:glm-mle-GLM-MLE}
\begin{split}
\hat{B} &= (X^\mathrm{T} V^{-1} X)^{-1} X^\mathrm{T} V^{-1} Y \\
\hat{\Sigma} &= \frac{1}{n} (Y - X\hat{B})^\mathrm{T} V^{-1} (Y - X\hat{B}) \; . \\
\end{split}
\end{equation}


\vspace{1em}
\textbf{Proof:} In \eqref{eq:glm-mle-GLM}, $Y$ is an $n \times v$ matrix of measurements ($n$ observations, $v$ dependent variables), $X$ is an $n \times p$ design matrix ($n$ observations, $p$ independent variables) and $V$ is an $n \times n$ covariance matrix across observations. This multivariate GLM implies the following likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf})

\begin{equation} \label{eq:glm-mle-GLM-LF}
\begin{split}
p(Y|B,\Sigma) &= \mathcal{MN}(Y; XB, V, \Sigma) \\
&= \sqrt{\frac{1}{(2\pi)^{nv} |\Sigma|^n |V|^v}} \cdot \exp\left[ -\frac{1}{2} \, \mathrm{tr}\left( \Sigma^{-1} (Y - XB)^\mathrm{T} V^{-1} (Y - XB) \right)  \right] \\
\end{split}
\end{equation}

and the log-likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:llf})

\begin{equation} \label{eq:glm-mle-GLM-LL1}
\begin{split}
\mathrm{LL}(B,\Sigma) = &\log p(Y|B,\Sigma) \\
= &- \frac{nv}{2} \log(2\pi) - \frac{n}{2} \log |\Sigma| - \frac{v}{2} \log |V| \\
&- \frac{1}{2} \, \mathrm{tr}\left[ \Sigma^{-1} (Y - XB)^\mathrm{T} V^{-1} (Y - XB) \right] \; .\\
\end{split}
\end{equation}

Substituting $V^{-1}$ by the precision matrix $P$ to ease notation, we have:

\begin{equation} \label{eq:glm-mle-GLM-LL2}
\begin{split}
\mathrm{LL}(B,\Sigma) = &- \frac{nv}{2} \log(2\pi) - \frac{n}{2} \log(|\Sigma|) - \frac{v}{2} \log(|V|) \\
&- \frac{1}{2} \, \mathrm{tr}\left[ \Sigma^{-1} \left( Y^\mathrm{T} P Y - Y^\mathrm{T} P X B - B^\mathrm{T} X^\mathrm{T} P Y + B^\mathrm{T} X^\mathrm{T} P X B \right) \right] \; .\\
\end{split}
\end{equation}

\vspace{1em}
The derivative of the log-likelihood function \eqref{eq:glm-mle-GLM-LL2} with respect to $B$ is

\begin{equation} \label{eq:glm-mle-dLL-dB}
\begin{split}
\frac{\mathrm{d}\mathrm{LL}(B,\Sigma)}{\mathrm{d}B} &= \frac{\mathrm{d}}{\mathrm{d}B} \left( - \frac{1}{2} \, \mathrm{tr}\left[ \Sigma^{-1} \left( Y^\mathrm{T} P Y - Y^\mathrm{T} P X B - B^\mathrm{T} X^\mathrm{T} P Y + B^\mathrm{T} X^\mathrm{T} P X B \right) \right] \right) \\
&= \frac{\mathrm{d}}{\mathrm{d}B} \left( -\frac{1}{2} \, \mathrm{tr}\left[ -2 \Sigma^{-1} Y^\mathrm{T} P X B \right] \right) + \frac{\mathrm{d}}{\mathrm{d}B} \left( -\frac{1}{2} \, \mathrm{tr}\left[ \Sigma^{-1} B^\mathrm{T} X^\mathrm{T} P X B \right] \right) \\
&= - \frac{1}{2} \left( -2 X^\mathrm{T} P Y \Sigma^{-1} \right) - \frac{1}{2} \left( X^\mathrm{T} P X B \Sigma^{-1} + (X^\mathrm{T} P X)^\mathrm{T} B (\Sigma^{-1})^\mathrm{T} \right) \\
&= X^\mathrm{T} P Y \Sigma^{-1} - X^\mathrm{T} P X B \Sigma^{-1} \\
\end{split}
\end{equation}

and setting this derivative to zero gives the MLE for $B$:

\begin{equation} \label{eq:glm-mle-B-MLE}
\begin{split}
\frac{\mathrm{d}\mathrm{LL}(\hat{B},\Sigma)}{\mathrm{d}B} &= 0 \\
0 &= X^\mathrm{T} P Y \Sigma^{-1} - X^\mathrm{T} P X \hat{B} \Sigma^{-1} \\
0 &= X^\mathrm{T} P Y - X^\mathrm{T} P X \hat{B} \\
X^\mathrm{T} P X \hat{B} &= X^\mathrm{T} P Y \\
\hat{B} &= \left( X^\mathrm{T} P X \right)^{-1} X^\mathrm{T} P Y \\
\end{split}
\end{equation}

\vspace{1em}
The derivative of the log-likelihood function \eqref{eq:glm-mle-GLM-LL1} at $\hat{B}$ with respect to $\Sigma$ is

\begin{equation} \label{eq:glm-mle-dLL-dS}
\begin{split}
\frac{\mathrm{d}\mathrm{LL}(\hat{B},\Sigma)}{\mathrm{d}\Sigma} &= \frac{\mathrm{d}}{\mathrm{d}\Sigma} \left( - \frac{n}{2} \log |\Sigma| - \frac{1}{2} \, \mathrm{tr}\left[ \Sigma^{-1} (Y - X\hat{B})^\mathrm{T} V^{-1} (Y - X\hat{B}) \right] \right) \\
&= - \frac{n}{2} \left( \Sigma^{-1} \right)^\mathrm{T} + \frac{1}{2} \left( \Sigma^{-1} (Y - X\hat{B})^\mathrm{T} V^{-1} (Y - X\hat{B}) \, \Sigma^{-1} \right)^\mathrm{T} \\
&= - \frac{n}{2} \, \Sigma^{-1} + \frac{1}{2} \, \Sigma^{-1} (Y - X\hat{B})^\mathrm{T} V^{-1} (Y - X\hat{B}) \, \Sigma^{-1} \\
\end{split}
\end{equation}

and setting this derivative to zero gives the MLE for $\Sigma$:

\begin{equation} \label{eq:glm-mle-S-MLE}
\begin{split}
\frac{\mathrm{d}\mathrm{LL}(\hat{B},\hat{\Sigma})}{\mathrm{d}\Sigma} &= 0 \\
0 &= - \frac{n}{2} \, \hat{\Sigma}^{-1} + \frac{1}{2} \, \hat{\Sigma}^{-1} (Y - X\hat{B})^\mathrm{T} V^{-1} (Y - X\hat{B}) \, \hat{\Sigma}^{-1} \\
\frac{n}{2} \, \hat{\Sigma}^{-1} &= \frac{1}{2} \, \hat{\Sigma}^{-1} (Y - X\hat{B})^\mathrm{T} V^{-1} (Y - X\hat{B}) \, \hat{\Sigma}^{-1} \\
\hat{\Sigma}^{-1} &= \frac{1}{n} \, \hat{\Sigma}^{-1} (Y - X\hat{B})^\mathrm{T} V^{-1} (Y - X\hat{B}) \, \hat{\Sigma}^{-1} \\
I_v &= \frac{1}{n} \, (Y - X\hat{B})^\mathrm{T} V^{-1} (Y - X\hat{B}) \, \hat{\Sigma}^{-1} \\
\hat{\Sigma} &= \frac{1}{n} \, (Y - X\hat{B})^\mathrm{T} V^{-1} (Y - X\hat{B}) \\
\end{split}
\end{equation}

\vspace{1em}
Together, \eqref{eq:glm-mle-B-MLE} and \eqref{eq:glm-mle-S-MLE} constitute the MLE for the GLM.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P7 | shortcut: glm-mle | author: JoramSoch | date: 2019-12-06, 10:40.
\vspace{1em}



\pagebreak
\section{Poisson data}

\subsection{Poisson-distributed data}

\subsubsection[\textit{Definition}]{Definition} \label{sec:poiss-data}
\setcounter{equation}{0}

\textbf{Definition:} Poisson-distributed data are defined as a set of observed counts $y = \left\lbrace y_1, \ldots, y_n \right\rbrace$, independent and identically distributed according to a Poisson distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:poiss}) with rate $\lambda$:

\begin{equation} \label{eq:poiss-data-Poiss}
y_i \sim \mathrm{Poiss}(\lambda), \quad i = 1, \ldots, n \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Poisson distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-03-22; URL: \url{https://en.wikipedia.org/wiki/Poisson_distribution#Parameter_estimation}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D41 | shortcut: poiss-data | author: JoramSoch | date: 2020-03-22, 22:50.
\vspace{1em}



\subsubsection[\textbf{Maximum likelihood estimation}]{Maximum likelihood estimation} \label{sec:poiss-mle}
\setcounter{equation}{0}

\textbf{Theorem:} Let there be a Poisson-distributed data ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:poiss-data}) set $y = \left\lbrace y_1, \ldots, y_n \right\rbrace$:

\begin{equation} \label{eq:poiss-mle-Poiss}
y_i \sim \mathrm{Poiss}(\lambda), \quad i = 1, \ldots, n \; .
\end{equation}

Then, the maximum likelihood estimate ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mle}) for the rate parameter $\lambda$ is given by

\begin{equation} \label{eq:poiss-mle-Poiss-MLE}
\hat{\lambda} = \bar{y}
\end{equation}

where $\bar{y}$ is the sample mean ($\rightarrow$ Proof "mean-sample")

\begin{equation} \label{eq:poiss-mle-y-mean}
\bar{y} = \frac{1}{n} \sum_{i=1}^n y_i \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) for each observation is given by the probability mass function of the Poisson distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:poiss-pmf})

\begin{equation} \label{eq:poiss-mle-Poiss-yi}
p(y_i|\lambda) = \mathrm{Poiss}(y_i; \lambda) = \frac{\lambda^{y_i} \cdot \exp(-\lambda)}{y_i !}
\end{equation}

and because observations are independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}), the likelihood function for all observations is the product of the individual ones:

\begin{equation} \label{eq:poiss-mle-Poiss-LF}
p(y|\lambda) = \prod_{i=1}^n p(y_i|\lambda) = \prod_{i=1}^n \frac{\lambda^{y_i} \cdot \exp(-\lambda)}{y_i !} \; .
\end{equation}

Thus, the log-likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:llf}) is

\begin{equation} \label{eq:poiss-mle-Poiss-LL}
\mathrm{LL}(\lambda) = \log p(y|\lambda) = \log \left[ \prod_{i=1}^n \frac{\lambda^{y_i} \cdot \exp(-\lambda)}{y_i !} \right]
\end{equation}

which can be developed into

\begin{equation} \label{eq:poiss-mle-Poiss-LL-der}
\begin{split}
\mathrm{LL}(\lambda) &= \sum_{i=1}^n \log \left[ \frac{\lambda^{y_i} \cdot \exp(-\lambda)}{y_i !} \right] \\
&= \sum_{i=1}^n \left[ y_i \cdot \log(\lambda) - \lambda - \log(y_i !) \right] \\
&= - \sum_{i=1}^n \lambda + \sum_{i=1}^n y_i \cdot \log(\lambda) - \sum_{i=1}^n \log(y_i !) \\
&= - n \lambda + \log(\lambda) \sum_{i=1}^n y_i - \sum_{i=1}^n \log(y_i !) \\
\end{split}
\end{equation}

The derivatives of the log-likelihood with respect to $\lambda$ are

\begin{equation} \label{eq:poiss-mle-Poiss-dLLdl-d2LLdl2}
\begin{split}
\frac{\mathrm{d}\mathrm{LL}(\lambda)}{\mathrm{d}\lambda} &= \frac{1}{\lambda} \sum_{i=1}^n y_i - n \\
\frac{\mathrm{d}^2\mathrm{LL}(\lambda)}{\mathrm{d}\lambda^2} &= -\frac{1}{\lambda^2} \sum_{i=1}^n y_i \; . \\
\end{split}
\end{equation}

Setting the first derivative to zero, we obtain:

\begin{equation} \label{eq:poiss-mle-Poiss-dLLdl}
\begin{split}
\frac{\mathrm{d}\mathrm{LL}(\hat{\lambda})}{\mathrm{d}\lambda} &= 0 \\
0 &= \frac{1}{\hat{\lambda}} \sum_{i=1}^n y_i - n \\
\hat{\lambda} &= \frac{1}{n} \sum_{i=1}^n y_i = \bar{y} \; .
\end{split}
\end{equation}

Plugging this value into the second deriative, we confirm:

\begin{equation} \label{eq:poiss-mle-Poiss-d2LLdl2}
\begin{split}
\frac{\mathrm{d}^2\mathrm{LL}(\hat{\lambda})}{\mathrm{d}\lambda^2} &= -\frac{1}{\bar{y}^2} \sum_{i=1}^n y_i \\
&= -\frac{n \cdot \bar{y}}{\bar{y}^2} \\
&= -\frac{n}{\bar{y}} < 0 \; .
\end{split}
\end{equation}

This demonstrates that the estimate $\hat{\lambda} = \bar{y}$ maximizes the likelihood $p(y \vert \lambda)$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P27 | shortcut: poiss-mle | author: JoramSoch | date: 2020-01-20, 21:53.
\vspace{1em}



\subsection{Poisson distribution with exposure values}

\subsubsection[\textit{Definition}]{Definition} \label{sec:poissexp}
\setcounter{equation}{0}

\textbf{Definition:} A Poisson distribution with exposure values is defined as a set of observed counts $y = \left\lbrace y_1, \ldots, y_n \right\rbrace$, independently distributed according to a Poisson distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:poiss}) with common rate $\lambda$ and a set of concurrent exposures $x = \left\lbrace x_1, \ldots, x_n \right\rbrace$:

\begin{equation} \label{eq:poissexp-Poiss-exp}
y_i \sim \mathrm{Poiss}(\lambda x_i), \quad i = 1, \ldots, n \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Gelman A, Carlin JB, Stern HS, Dunson DB, Vehtari A, Rubin DB (2014): "Other standard single-parameter models"; in: \textit{Bayesian Data Analysis}, 3rd edition, ch. 2.6, p. 45, eq. 2.14; URL: \url{http://www.stat.columbia.edu/~gelman/book/}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D42 | shortcut: poissexp | author: JoramSoch | date: 2020-03-22, 22:57.
\vspace{1em}



\subsubsection[\textbf{Conjugate prior distribution}]{Conjugate prior distribution} \label{sec:poissexp-prior}
\setcounter{equation}{0}

\textbf{Theorem:} Consider data $y = \left\lbrace y_1, \ldots, y_n \right\rbrace$ following a Poisson distribution with exposure values ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:poissexp}):

\begin{equation} \label{eq:poissexp-prior-Poiss-exp}
y_i \sim \mathrm{Poiss}(\lambda x_i), \quad i = 1, \ldots, n \; .
\end{equation}

Then, the conjugate prior ($\rightarrow$ Definition "prior-conj") for the model parameter $\lambda$ is a gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:gam}):

\begin{equation} \label{eq:poissexp-prior-Poiss-exp-prior}
p(\lambda) = \mathrm{Gam}(\lambda; a_0, b_0) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} With the probability mass function of the Poisson distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:poiss-pmf}), the likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) for each observation implied by \eqref{eq:poissexp-prior-Poiss-exp} is given by

\begin{equation} \label{eq:poissexp-prior-Poiss-exp-LF-s1}
p(y_i|\lambda) = \mathrm{Poiss}(y_i; \lambda x_i) = \frac{(\lambda x_i)^{y_i} \cdot \exp\left[-\lambda x_i\right]}{y_i !}
\end{equation}

and because observations are independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}), the likelihood function for all observations is the product of the individual ones:

\begin{equation} \label{eq:poissexp-prior-Poiss-exp-LF-s2}
p(y|\lambda) = \prod_{i=1}^n p(y_i|\lambda) = \prod_{i=1}^n \frac{(\lambda x_i)^{y_i} \cdot \exp\left[-\lambda x_i\right]}{y_i !} \; .
\end{equation}

Resolving the product in the likelihood function, we have

\begin{equation} \label{eq:poissexp-prior-Poiss-exp-LF-s3}
\begin{split}
p(y|\lambda) &= \prod_{i=1}^n \frac{ {x_i}^{y_i}}{y_i !} \cdot \prod_{i=1}^n \lambda^{y_i} \cdot \prod_{i=1}^n \exp\left[-\lambda x_i\right] \\
&= \prod_{i=1}^n \left(\frac{ {x_i}^{y_i}}{y_i !}\right) \cdot \lambda^{\sum_{i=1}^n y_i} \cdot \exp\left[-\lambda \sum_{i=1}^n x_i\right] \\
&= \prod_{i=1}^n \left(\frac{ {x_i}^{y_i}}{y_i !}\right) \cdot \lambda^{n \bar{y}} \cdot \exp\left[-n \bar{x} \lambda\right]
\end{split}
\end{equation}

where $\bar{y}$ and $\bar{x}$ are the means ($\rightarrow$ Proof "mean-sample") of $y$ and $x$ respectively:

\begin{equation} \label{eq:poissexp-prior-xy-mean}
\begin{split}
\bar{y} &= \frac{1}{n} \sum_{i=1}^n y_i \\
\bar{x} &= \frac{1}{n} \sum_{i=1}^n x_i \; .
\end{split}
\end{equation}

In other words, the likelihood function is proportional to a power of $\lambda$ times an exponential of $\lambda$:

\begin{equation} \label{eq:poissexp-prior-Poiss-exp-LF-prop}
p(y|\lambda) \propto \lambda^{n \bar{y}} \cdot \exp\left[-n \bar{x} \lambda\right] \; .
\end{equation}

The same is true for a gamma distribution over $\lambda$

\begin{equation} \label{eq:poissexp-prior-Poiss-exp-prior-s1}
p(\lambda) = \mathrm{Gam}(\lambda; a_0, b_0)
\end{equation}

the probability density function of which ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-pdf})

\begin{equation} \label{eq:poissexp-prior-Poiss-exp-prior-s2}
p(\lambda) = \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \lambda^{a_0-1} \exp[-b_0 \lambda]
\end{equation}

exhibits the same proportionality

\begin{equation} \label{eq:poissexp-prior-Poiss-exp-prior-s3}
p(\lambda) \propto \lambda^{a_0-1} \cdot \exp[-b_0 \lambda]
\end{equation}

and is therefore conjugate relative to the likelihood.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Gelman A, Carlin JB, Stern HS, Dunson DB, Vehtari A, Rubin DB (2014): "Other standard single-parameter models"; in: \textit{Bayesian Data Analysis}, 3rd edition, ch. 2.6, p. 45, eq. 2.14ff.; URL: \url{http://www.stat.columbia.edu/~gelman/book/}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P41 | shortcut: poissexp-prior | author: JoramSoch | date: 2020-02-04, 14:11.
\vspace{1em}



\subsubsection[\textbf{Posterior distribution}]{Posterior distribution} \label{sec:poissexp-post}
\setcounter{equation}{0}

\textbf{Theorem:} Consider data $y = \left\lbrace y_1, \ldots, y_n \right\rbrace$ following a Poisson distribution with exposure values ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:poissexp}):

\begin{equation} \label{eq:poissexp-post-Poiss-exp}
y_i \sim \mathrm{Poiss}(\lambda x_i), \quad i = 1, \ldots, n \; .
\end{equation}

Moreover, assume a gamma prior distribution ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:poissexp-prior}) over the model parameter $\lambda$:

\begin{equation} \label{eq:poissexp-post-Poiss-exp-prior}
p(\lambda) = \mathrm{Gam}(\lambda; a_0, b_0) \; .
\end{equation}

Then, the posterior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) is also a gamma distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:gam})

\begin{equation} \label{eq:poissexp-post-Poiss-exp-post}
p(\lambda|y) = \mathrm{Gam}(\lambda; a_n, b_n)
\end{equation}

and the posterior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) are given by

\begin{equation} \label{eq:poissexp-post-Poiss-exp-post-par}
\begin{split}
a_n &= a_0 + n \bar{y} \\
a_n &= a_0 + n \bar{x} \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Proof:} With the probability mass function of the Poisson distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:poiss-pmf}), the likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) for each observation implied by \eqref{eq:poissexp-post-Poiss-exp} is given by

\begin{equation} \label{eq:poissexp-post-Poiss-exp-LF-s1}
p(y_i|\lambda) = \mathrm{Poiss}(y_i; \lambda x_i) = \frac{(\lambda x_i)^{y_i} \cdot \exp\left[-\lambda x_i\right]}{y_i !}
\end{equation}

and because observations are independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}), the likelihood function for all observations is the product of the individual ones:

\begin{equation} \label{eq:poissexp-post-Poiss-exp-LF-s2}
p(y|\lambda) = \prod_{i=1}^n p(y_i|\lambda) = \prod_{i=1}^n \frac{(\lambda x_i)^{y_i} \cdot \exp\left[-\lambda x_i\right]}{y_i !} \; .
\end{equation}

Combining the likelihood function \eqref{eq:poissexp-post-Poiss-exp-LF-s2} with the prior distribution \eqref{eq:poissexp-post-Poiss-exp-prior}, the joint likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:jl}) of the model is given by

\begin{equation} \label{eq:poissexp-post-Poiss-exp-JL-s1}
\begin{split}
p(y,\lambda) &= p(y|\lambda) \, p(\lambda) \\
&= \prod_{i=1}^n \frac{(\lambda x_i)^{y_i} \cdot \exp\left[-\lambda x_i\right]}{y_i !} \cdot \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \lambda^{a_0-1} \exp[-b_0 \lambda] \; .
\end{split}
\end{equation}

Resolving the product in the joint likelihood, we have

\begin{equation} \label{eq:poissexp-post-Poiss-JL-s2}
\begin{split}
p(y,\lambda) &= \prod_{i=1}^n \frac{ {x_i}^{y_i}}{y_i !} \prod_{i=1}^n \lambda^{y_i} \prod_{i=1}^n \exp\left[-\lambda x_i\right] \cdot \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \lambda^{a_0-1} \exp[-b_0 \lambda] \\
&= \prod_{i=1}^n \left(\frac{ {x_i}^{y_i}}{y_i !}\right) \lambda^{\sum_{i=1}^n y_i} \exp\left[-\lambda \sum_{i=1}^n x_i\right] \cdot \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \lambda^{a_0-1} \exp[-b_0 \lambda] \\
&= \prod_{i=1}^n \left(\frac{ {x_i}^{y_i}}{y_i !}\right) \lambda^{n \bar{y}} \exp\left[-n \bar{x} \lambda\right] \cdot \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \lambda^{a_0-1} \exp[-b_0 \lambda] \\
&= \prod_{i=1}^n \left(\frac{ {x_i}^{y_i}}{y_i !}\right) \frac{ {b_0}^{a_0}}{\Gamma(a_0)}  \cdot \lambda^{a_0 + n \bar{y} - 1} \cdot \exp\left[-(b_0 + n \bar{x}) \lambda\right] \\
\end{split}
\end{equation}

where $\bar{y}$ and $\bar{x}$ are the means ($\rightarrow$ Proof "mean-sample") of $y$ and $x$ respectively:

\begin{equation} \label{eq:poissexp-post-xy-mean}
\begin{split}
\bar{y} &= \frac{1}{n} \sum_{i=1}^n y_i \\
\bar{x} &= \frac{1}{n} \sum_{i=1}^n x_i \; .
\end{split}
\end{equation}

Note that the posterior distribution is proportional to the joint likelihood ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:post-jl}):

\begin{equation} \label{eq:poissexp-post-Poiss-exp-post-s1}
p(\lambda|y) \propto p(y,\lambda) \; .
\end{equation}

Setting $a_n = a_0 + n \bar{y}$ and $b_n = b_0 + n \bar{x}$, the posterior distribution is therefore proportional to

\begin{equation} \label{eq:poissexp-post-Poiss-exp-post-s2}
p(\lambda|y) \propto \lambda^{a_n-1} \cdot \exp\left[-b_n \lambda\right]
\end{equation}

which, when normalized to one, results in the probability density function of the gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-pdf}):

\begin{equation} \label{eq:poissexp-post-Poiss-exp-post-s3}
p(\lambda|y) = \frac{ {b_n}^{a_n}}{\Gamma(a_0)} \lambda^{a_n-1} \exp\left[-b_n \lambda\right] = \mathrm{Gam}(\lambda; a_n, b_n) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Gelman A, Carlin JB, Stern HS, Dunson DB, Vehtari A, Rubin DB (2014): "Other standard single-parameter models"; in: \textit{Bayesian Data Analysis}, 3rd edition, ch. 2.6, p. 45, eq. 2.15; URL: \url{http://www.stat.columbia.edu/~gelman/book/}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P42 | shortcut: poissexp-post | author: JoramSoch | date: 2020-02-04, 14:42.
\vspace{1em}



\subsubsection[\textbf{Log model evidence}]{Log model evidence} \label{sec:poissexp-lme}
\setcounter{equation}{0}

\textbf{Theorem:} Consider data $y = \left\lbrace y_1, \ldots, y_n \right\rbrace$ following a Poisson distribution with exposure values ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:poissexp}):

\begin{equation} \label{eq:poissexp-lme-Poiss-exp}
y_i \sim \mathrm{Poiss}(\lambda x_i), \quad i = 1, \ldots, n \; .
\end{equation}

Moreover, assume a gamma prior distribution ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:poissexp-prior}) over the model parameter $\lambda$:

\begin{equation} \label{eq:poissexp-lme-Poiss-exp-prior}
p(\lambda) = \mathrm{Gam}(\lambda; a_0, b_0) \; .
\end{equation}

Then, the log model evidence ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme}) for this model is

\begin{equation} \label{eq:poissexp-lme-Poiss-exp-LME}
\begin{split}
\log p(y|m) = &\sum_{i=1}^n y_i \log(x_i) - \sum_{i=1}^n \log y_i ! + \\ 
&\log \Gamma(a_n) - \log \Gamma(a_0) + a_0 \log b_0 - a_n \log b_n \; .
\end{split}
\end{equation}

where the posterior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) are given by

\begin{equation} \label{eq:poissexp-lme-Poiss-exp-post-par}
\begin{split}
a_n &= a_0 + n \bar{y} \\
a_n &= a_0 + n \bar{x} \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Proof:} With the probability mass function of the Poisson distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:poiss-pmf}), the likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) for each observation implied by \eqref{eq:poissexp-lme-Poiss-exp} is given by

\begin{equation} \label{eq:poissexp-lme-Poiss-exp-LF-s1}
p(y_i|\lambda) = \mathrm{Poiss}(y_i; \lambda x_i) = \frac{(\lambda x_i)^{y_i} \cdot \exp\left[-\lambda x_i\right]}{y_i !}
\end{equation}

and because observations are independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}), the likelihood function for all observations is the product of the individual ones:

\begin{equation} \label{eq:poissexp-lme-Poiss-exp-LF-s2}
p(y|\lambda) = \prod_{i=1}^n p(y_i|\lambda) = \prod_{i=1}^n \frac{(\lambda x_i)^{y_i} \cdot \exp\left[-\lambda x_i\right]}{y_i !} \; .
\end{equation}

Combining the likelihood function \eqref{eq:poissexp-lme-Poiss-exp-LF-s2} with the prior distribution \eqref{eq:poissexp-lme-Poiss-exp-prior}, the joint likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:jl}) of the model is given by

\begin{equation} \label{eq:poissexp-lme-Poiss-exp-JL-s1}
\begin{split}
p(y,\lambda) &= p(y|\lambda) \, p(\lambda) \\
&= \prod_{i=1}^n \frac{(\lambda x_i)^{y_i} \cdot \exp\left[-\lambda x_i\right]}{y_i !} \cdot \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \lambda^{a_0-1} \exp[-b_0 \lambda] \; .
\end{split}
\end{equation}

Resolving the product in the joint likelihood, we have

\begin{equation} \label{eq:poissexp-lme-Poiss-exp-JL-s2}
\begin{split}
p(y,\lambda) &= \prod_{i=1}^n \frac{ {x_i}^{y_i}}{y_i !} \prod_{i=1}^n \lambda^{y_i} \prod_{i=1}^n \exp\left[-\lambda x_i\right] \cdot \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \lambda^{a_0-1} \exp[-b_0 \lambda] \\
&= \prod_{i=1}^n \left(\frac{ {x_i}^{y_i}}{y_i !}\right) \lambda^{\sum_{i=1}^n y_i} \exp\left[-\lambda \sum_{i=1}^n x_i\right] \cdot \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \lambda^{a_0-1} \exp[-b_0 \lambda] \\
&= \prod_{i=1}^n \left(\frac{ {x_i}^{y_i}}{y_i !}\right) \lambda^{n \bar{y}} \exp\left[-n \bar{x} \lambda\right] \cdot \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \lambda^{a_0-1} \exp[-b_0 \lambda] \\
&= \prod_{i=1}^n \left(\frac{ {x_i}^{y_i}}{y_i !}\right) \frac{ {b_0}^{a_0}}{\Gamma(a_0)}  \cdot \lambda^{a_0 + n \bar{y} - 1} \cdot \exp\left[-(b_0 + n \bar{x}) \lambda\right] \\
\end{split}
\end{equation}

where $\bar{y}$ and $\bar{x}$ are the means ($\rightarrow$ Proof "mean-sample") of $y$ and $x$ respectively:

\begin{equation} \label{eq:poissexp-lme-xy-mean}
\begin{split}
\bar{y} &= \frac{1}{n} \sum_{i=1}^n y_i \\
\bar{x} &= \frac{1}{n} \sum_{i=1}^n x_i \; .
\end{split}
\end{equation}

Note that the model evidence is the marginal density of the joint likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ml}):

\begin{equation} \label{eq:poissexp-lme-Poiss-exp-ME}
p(y) = \int p(y,\lambda) \, \mathrm{d}\lambda \; .
\end{equation}

Setting $a_n = a_0 + n \bar{y}$ and $b_n = b_0 + n \bar{x}$, the joint likelihood can also be written as

\begin{equation} \label{eq:poissexp-lme-Poiss-exp-JL-s3}
p(y,\lambda) = \prod_{i=1}^n \left(\frac{ {x_i}^{y_i}}{y_i !}\right) \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \frac{\Gamma(a_n)}{ {b_n}^{a_n}} \cdot \frac{ {b_n}^{a_n}}{\Gamma(a_n)} \lambda^{a_n-1} \exp\left[-b_n \lambda\right] \; .
\end{equation}

Using the probability density function of the gamma distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:gam-pdf}), $\lambda$ can now be integrated out easily

\begin{equation} \label{eq:poissexp-lme-Poiss-exp-ME-qed}
\begin{split}
\mathrm{p}(y) &= \int \prod_{i=1}^n \left(\frac{ {x_i}^{y_i}}{y_i !}\right) \frac{ {b_0}^{a_0}}{\Gamma(a_0)} \frac{\Gamma(a_n)}{ {b_n}^{a_n}} \cdot \frac{ {b_n}^{a_n}}{\Gamma(a_n)} \lambda^{a_n-1} \exp\left[-b_n \lambda\right] \, \mathrm{d}\lambda \\
&= \prod_{i=1}^n \left(\frac{ {x_i}^{y_i}}{y_i !}\right) \frac{\Gamma(a_n)}{\Gamma(a_0)} \frac{ {b_0}^{a_0}}{ {b_n}^{a_n}} \int \mathrm{Gam}(\lambda; a_n, b_n) \, \mathrm{d}\lambda \\
&= \prod_{i=1}^n \left(\frac{ {x_i}^{y_i}}{y_i !}\right) \frac{\Gamma(a_n)}{\Gamma(a_0)} \frac{ {b_0}^{a_0}}{ {b_n}^{a_n}} \; ,
\end{split}
\end{equation}

such that the log model evidence ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme}) is shown to be

\begin{equation} \label{eq:poissexp-lme-Poiss-exp-LME-qed}
\begin{split}
\log p(y|m) = &\sum_{i=1}^n y_i \log(x_i) - \sum_{i=1}^n \log y_i ! + \\ 
&\log \Gamma(a_n) - \log \Gamma(a_0) + a_0 \log b_0 - a_n \log b_n \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P43 | shortcut: poissexp-lme | author: JoramSoch | date: 2020-02-04, 15:12.
\vspace{1em}



\pagebreak
\section{Probability data}

\subsection{Beta-distributed data}

\subsubsection[\textit{Definition}]{Definition} \label{sec:beta-data}
\setcounter{equation}{0}

\textbf{Definition:} Beta-distributed data are defined as a set of proportions $y = \left\lbrace y_1, \ldots, y_n \right\rbrace$ with $y_i \in [0,1], \; i = 1,\ldots,n$, independent and identically distributed according to a Beta distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:beta}) with shapes $\alpha$ and $\beta$:

\begin{equation} \label{eq:beta-data-beta-data}
y_i \sim \mathrm{Bet}(\alpha,\beta), \quad i = 1, \ldots, n \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D77 | shortcut: beta-data | author: JoramSoch | date: 2020-06-28, 21:16.
\vspace{1em}



\subsubsection[\textbf{Method of moments}]{Method of moments} \label{sec:beta-mom}
\setcounter{equation}{0}

\textbf{Theorem:} Let $y = \left\lbrace y_1, \ldots, y_n \right\rbrace$ be a set of observed counts independent and identically distributed ($\rightarrow$ Definition "iid") according to a beta distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:beta}) with shapes $\alpha$ and $\beta$:

\begin{equation} \label{eq:beta-mom-Beta}
y_i \sim \mathrm{Bet}(\alpha,\beta), \quad i = 1, \ldots, n \; .
\end{equation}

Then, the method-of-moments estimates ($\rightarrow$ Definition "mome") for the shape parameters $\alpha$ and $\beta$ are given by

\begin{equation} \label{eq:beta-mom-Beta-MoM}
\begin{split}
\hat{\alpha} &= \bar{y} \left( \frac{\bar{y} (1-\bar{y})}{\bar{v}} - 1  \right) \\
\hat{\beta} &= (1-\bar{y}) \left( \frac{\bar{y} (1-\bar{y})}{\bar{v}} - 1  \right)
\end{split}
\end{equation}

where $\bar{y}$ is the sample mean ($\rightarrow$ Proof "mean-sample") and $\bar{v}$ is the unbiased sample variance ($\rightarrow$ Proof \ref{sec:Model Selection}/\ref{sec:resvar-unb}):

\begin{equation} \label{eq:beta-mom-y-mean-var}
\begin{split}
\bar{y} &= \frac{1}{n} \sum_{i=1}^n y_i \\
\bar{v} &= \frac{1}{n-1} \sum_{i=1}^n (y_i - \bar{y})^2 \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Proof:} Mean ($\rightarrow$ Proof "beta-mean") and variance ($\rightarrow$ Proof "beta-var") of the beta distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:beta}) in terms of the parameters $\alpha$ and $\beta$ are given by

\begin{equation} \label{eq:beta-mom-Beta-E-Var}
\begin{split}
\mathrm{E}(X) &= \frac{\alpha}{\alpha+\beta} \\
\mathrm{Var}(X) &= \frac{\alpha\beta}{(\alpha+\beta)^2 (\alpha+\beta+1)} \; .
\end{split}
\end{equation}

Thus, matching the moments ($\rightarrow$ Definition "mome") requires us to solve the following equation system for $\alpha$ and $\beta$:

\begin{equation} \label{eq:beta-mom-Beta-mean-var}
\begin{split}
\bar{y} &= \frac{\alpha}{\alpha+\beta} \\
\bar{v} &= \frac{\alpha\beta}{(\alpha+\beta)^2 (\alpha+\beta+1)} \; .
\end{split}
\end{equation}

From the first equation, we can deduce:

\begin{equation} \label{eq:beta-mom-beta-as-alpha}
\begin{split}
\bar{y}(\alpha+\beta) &= \alpha \\
\alpha \bar{y} + \beta \bar{y} &= \alpha \\
\beta \bar{y} &= \alpha - \alpha \bar{y} \\
\beta &= \frac{\alpha}{\bar{y}} - \alpha \\
\beta &= \alpha \left( \frac{1}{\bar{y}} - 1 \right) \; .
\end{split}
\end{equation}

If we define $q = 1/\bar{y} - 1$ and plug \eqref{eq:beta-mom-beta-as-alpha} into the second equation, we have:

\begin{equation} \label{eq:beta-mom-alpha-as-q}
\begin{split}
\bar{v} &= \frac{\alpha \cdot \alpha q}{(\alpha + \alpha q)^2 (\alpha + \alpha q + 1)} \\
&= \frac{\alpha^2 q}{(\alpha (1+q))^2 (\alpha (1+q) + 1)} \\
&= \frac{q}{(1+q)^2 (\alpha (1+q) + 1)} \\
&= \frac{q}{\alpha (1+q)^3 + (1+q)^2} \\
q &= \bar{v} \left[ \alpha (1+q)^3 + (1+q)^2 \right] \; .
\end{split}
\end{equation}

Noting that $1+q = 1/\bar{y}$ and $q = (1-\bar{y})/\bar{y}$, one obtains for $\alpha$:

\begin{equation} \label{eq:beta-mom-Beta-MoM-alpha}
\begin{split}
\frac{1-\bar{y}}{\bar{y}} &= \bar{v} \left[ \frac{\alpha}{\bar{y}^3} + \frac{1}{\bar{y}^2} \right] \\
\frac{1-\bar{y}}{\bar{y} \, \bar{v}} &= \frac{\alpha}{\bar{y}^3} + \frac{1}{\bar{y}^2} \\
\frac{\bar{y}^3(1-\bar{y})}{\bar{y} \, \bar{v}} &= \alpha + \bar{y} \\
\alpha &= \frac{\bar{y}^2(1-\bar{y})}{\bar{v}} - \bar{y} \\
&= \bar{y} \left( \frac{\bar{y} (1-\bar{y})}{\bar{v}} - 1 \right) \; .
\end{split}
\end{equation}

Plugging this into equation \eqref{eq:beta-mom-beta-as-alpha}, one obtains for $\beta$:

\begin{equation} \label{eq:beta-mom-Beta-MoM-beta}
\begin{split}
\beta &= \bar{y} \left( \frac{\bar{y} (1-\bar{y})}{\bar{v}} - 1 \right) \cdot \left( \frac{1-\bar{y}}{\bar{y}} \right) \\
&= (1-\bar{y}) \left( \frac{\bar{y} (1-\bar{y})}{\bar{v}} - 1 \right) \; .
\end{split}
\end{equation}

Together, \eqref{eq:beta-mom-Beta-MoM-alpha} and \eqref{eq:beta-mom-Beta-MoM-beta} constitute the method-of-moment estimates of $\alpha$ and $\beta$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Beta distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-01-20; URL: \url{https://en.wikipedia.org/wiki/Beta_distribution#Method_of_moments}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P28 | shortcut: beta-mom | author: JoramSoch | date: 2020-01-22, 02:53.
\vspace{1em}



\subsection{Logistic regression}

\subsubsection[\textit{Definition}]{Definition} \label{sec:logreg}
\setcounter{equation}{0}

\textbf{Definition:} A logistic regression model is given by a set of binary observations $y_i \in \left\lbrace 0, 1 \right\rbrace, i = 1,\ldots,n$, a set of predictors $x_j \in \mathbb{R}^n, j = 1,\ldots,p$, a base $b$ and the assumption that the log-odds are a linear combination of the predictors:

\begin{equation} \label{eq:logreg-logreg}
l_i = x_i \beta + \varepsilon_i, \; i = 1,\ldots,n
\end{equation}

where $l_i$ are the log-odds that $y_i = 1$

\begin{equation} \label{eq:logreg-logodds}
l_i = \log_b \frac{\mathrm{Pr}(y_i = 1)}{\mathrm{Pr}(y_i = 0)}
\end{equation}

and $x_i$ is the $i$-th row of the $n \times p$ matrix

\begin{equation} \label{eq:logreg-X}
X = \left[ x_1, \ldots, x_p \right] \; .
\end{equation}

Within this model,

\begin{itemize}

\item $y$ are called "categorical observations" or "dependent variable";

\item $X$ is called "design matrix" or "set of independent variables";

\item $\beta$ are called "regression coefficients" or "weights";

\item $\varepsilon_i$ is called "noise" or "error term";

\item $n$ is the number of observations;

\item $p$ is the number of predictors.

\end{itemize}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Logistic regression"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-06-28; URL: \url{https://en.wikipedia.org/wiki/Logistic_regression#Logistic_model}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D76 | shortcut: logreg | author: JoramSoch | date: 2020-06-28, 20:51.
\vspace{1em}



\subsubsection[\textbf{Probability and log-odds}]{Probability and log-odds} \label{sec:logreg-pnlo}
\setcounter{equation}{0}

\textbf{Theorem:} Assume a logistic regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:logreg})

\begin{equation} \label{eq:logreg-pnlo-logreg}
l_i = x_i \beta + \varepsilon_i, \; i = 1,\ldots,n
\end{equation}

where $x_i$ are the predictors corresponding to the $i$-th observation $y_i$ and $l_i$ are the log-odds that $y_i = 1$.

Then, the log-odds in favor of $y_i = 1$ against $y_i = 0$ can also be expressed as

\begin{equation} \label{eq:logreg-pnlo-lodds}
l_i = \log_b \frac{p(x_i|y_i=1) \, p(y_i=1)}{p(x_i|y_i=0) \, p(y_i=0)}
\end{equation}

where $p(x_i \vert y_i)$ is a likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) consistent with \eqref{eq:logreg-pnlo-logreg}, $p(y_i)$ are prior probabilities ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) for $y_i = 1$ and $y_i = 0$ and where $b$ is the base used to form the log-odds $l_i$.


\vspace{1em}
\textbf{Proof:} Using Bayes' theorem ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:bayes-th}) and the law of marginal probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}), the posterior probabilities ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) for $y_i = 1$ and $y_i = 0$ are given by

\begin{equation} \label{eq:logreg-pnlo-prob}
\begin{split}
p(y_i=1|x_i) &= \frac{p(x_i|y_i=1) \, p(y_i=1)}{p(x_i|y_i=1) \, p(y_i=1) + p(x_i|y_i=0) \, p(y_i=0)} \\
p(y_i=0|x_i) &= \frac{p(x_i|y_i=0) \, p(y_i=0)}{p(x_i|y_i=1) \, p(y_i=1) + p(x_i|y_i=0) \, p(y_i=0)} \; .
\end{split}
\end{equation}

Calculating the log-odds from the posterior probabilties, we have

\begin{equation} \label{eq:logreg-pnlo-lodds-qed}
\begin{split}
l_i &= \log_b \frac{p(y_i=1|x_i)}{p(y_i=0|x_i)} \\
&= \log_b \frac{p(x_i|y_i=1) \, p(y_i=1)}{p(x_i|y_i=0) \, p(y_i=0)} \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Bishop, Christopher M. (2006): "Linear Models for Classification"; in: \textit{Pattern Recognition for Machine Learning}, ch. 4, p. 197, eq. 4.58; URL: \url{http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P105 | shortcut: logreg-pnlo | author: JoramSoch | date: 2020-05-19, 05:08.
\vspace{1em}



\subsubsection[\textbf{Log-odds and probability}]{Log-odds and probability} \label{sec:logreg-lonp}
\setcounter{equation}{0}

\textbf{Theorem:} Assume a logistic regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:logreg})

\begin{equation} \label{eq:logreg-lonp-logreg}
l_i = x_i \beta + \varepsilon_i, \; i = 1,\ldots,n
\end{equation}

where $x_i$ are the predictors corresponding to the $i$-th observation $y_i$ and $l_i$ are the log-odds that $y_i = 1$.

Then, the probability that $y_i = 1$ is given by

\begin{equation} \label{eq:logreg-lonp-prob}
\mathrm{Pr}(y_i = 1) = \frac{1}{1 + b^{-(x_i \beta + \varepsilon_i)}}
\end{equation}

where $b$ is the base used to form the log-odds $l_i$.


\vspace{1em}
\textbf{Proof:} Let us denote $\mathrm{Pr}(y_i = 1)$ as $p_i$. Then, the log-odds are

\begin{equation} \label{eq:logreg-lonp-lodds}
l_i = \log_b \frac{p_i}{1-p_i}
\end{equation}

and using \eqref{eq:logreg-lonp-logreg}, we have

\begin{equation} \label{eq:logreg-lonp-prob-qed}
\begin{split}
\log_b \frac{p_i}{1-p_i} &= x_i \beta + \varepsilon_i \\
\frac{p_i}{1-p_i} &= b^{x_i \beta + \varepsilon_i} \\
p_i &= \left( b^{x_i \beta + \varepsilon_i} \right) (1-p_i) \\
p_i \left( 1 + b^{x_i \beta + \varepsilon_i} \right) &= b^{x_i \beta + \varepsilon_i} \\
p_i &= \frac{b^{x_i \beta + \varepsilon_i}}{1 + b^{x_i \beta + \varepsilon_i}} \\
p_i &= \frac{b^{x_i \beta + \varepsilon_i}}{b^{x_i \beta + \varepsilon_i} \left( 1 + b^{-(x_i \beta + \varepsilon_i)} \right)} \\
p_i &= \frac{1}{1 + b^{-(x_i \beta + \varepsilon_i)}}
\end{split}
\end{equation}

which proves the identity given by \eqref{eq:logreg-lonp-prob}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Logistic regression"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-03-03; URL: \url{https://en.wikipedia.org/wiki/Logistic_regression#Logistic_model}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P72 | shortcut: logreg-lonp | author: JoramSoch | date: 2020-03-03, 12:01.
\vspace{1em}



\pagebreak
\section{Categorical data}

\subsection{Binomial observations}

\subsubsection[\textit{Definition}]{Definition} \label{sec:bin-data}
\setcounter{equation}{0}

\textbf{Definition:} An ordered pair $(n,y)$ with $n \in \mathbb{N}$ and $y \in \mathbb{N}_0$, where $y$ is the number of successes in $n$ trials, consititutes a set of binomial observations.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D78 | shortcut: bin-data | author: JoramSoch | date: 2020-07-07, 07:04.
\vspace{1em}



\subsubsection[\textbf{Conjugate prior distribution}]{Conjugate prior distribution} \label{sec:bin-prior}
\setcounter{equation}{0}

\textbf{Theorem:} Let $y$ be the number of successes resulting from $n$ independent trials with unknown success probability $p$, such that $y$ follows a binomial distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:bin}):

\begin{equation} \label{eq:bin-prior-Bin}
y \sim \mathrm{Bin}(n,p) \; .
\end{equation}

Then, the conjugate prior ($\rightarrow$ Definition "prior-conj") for the model parameter $p$ is a beta distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:beta}):

\begin{equation} \label{eq:bin-prior-Beta}
\mathrm{p}(p) = \mathrm{Bet}(p; \alpha_0, \beta_0) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} With the probability mass function of the binomial distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:bin-pmf}), the likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) implied by \eqref{eq:bin-prior-Bin} is given by

\begin{equation} \label{eq:bin-prior-Bin-LF}
\mathrm{p}(y|p) = {n \choose y} \, p^y \, (1-p)^{n-y} \; .
\end{equation}

In other words, the likelihood function is proportional to a power of $p$ times a power of $(1-p)$:

\begin{equation} \label{eq:bin-prior-Bin-LF-prop}
\mathrm{p}(y|p) \propto p^y \, (1-p)^{n-y} \; .
\end{equation}

The same is true for a beta distribution over $p$

\begin{equation} \label{eq:bin-prior-Bin-prior-s1}
\mathrm{p}(p) = \mathrm{Bet}(p; \alpha_0, \beta_0)
\end{equation}

the probability density function of which ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:beta-pdf})

\begin{equation} \label{eq:bin-prior-Bin-prior-s2}
\mathrm{p}(p) = \frac{1}{B(\alpha_0,\beta_0)} \, p^{\alpha_0-1} \, (1-p)^{\beta_0-1}
\end{equation}

exhibits the same proportionality

\begin{equation} \label{eq:bin-prior-Bin-prior-s3}
\mathrm{p}(p) \propto p^{\alpha_0-1} \, (1-p)^{\beta_0-1}
\end{equation}

and is therefore conjugate relative to the likelihood.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Binomial distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-01-23; URL: \url{https://en.wikipedia.org/wiki/Binomial_distribution#Estimation_of_parameters}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P29 | shortcut: bin-prior | author: JoramSoch | date: 2020-01-23, 23:38.
\vspace{1em}



\subsubsection[\textbf{Posterior distribution}]{Posterior distribution} \label{sec:bin-post}
\setcounter{equation}{0}

\textbf{Theorem:} Let $y$ be the number of successes resulting from $n$ independent trials with unknown success probability $p$, such that $y$ follows a binomial distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:bin}):

\begin{equation} \label{eq:bin-post-Bin}
y \sim \mathrm{Bin}(n,p) \; .
\end{equation}

Moreover, assume a beta prior distribution ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:bin-prior}) over the model parameter $p$:

\begin{equation} \label{eq:bin-post-Bin-prior}
\mathrm{p}(p) = \mathrm{Bet}(p; \alpha_0, \beta_0) \; .
\end{equation}

Then, the posterior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) is also a beta distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:beta})

\begin{equation} \label{eq:bin-post-Bin-post}
\mathrm{p}(p|y) = \mathrm{Bet}(p; \alpha_n, \beta_n) \; .
\end{equation}

and the posterior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) are given by

\begin{equation} \label{eq:bin-post-Bin-post-par}
\begin{split}
\alpha_n &= \alpha_0 + y \\
\beta_n &= \beta_0 + (n-y) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Proof:} With the probability mass function of the binomial distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:bin-pmf}), the likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) implied by \eqref{eq:bin-post-Bin} is given by

\begin{equation} \label{eq:bin-post-Bin-LF}
\mathrm{p}(y|p) = {n \choose y} \, p^y \, (1-p)^{n-y} \; .
\end{equation}

Combining the likelihood function \eqref{eq:bin-post-Bin-LF} with the prior distribution \eqref{eq:bin-post-Bin-prior}, the joint likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:jl}) of the model is given by

\begin{equation} \label{eq:bin-post-Bin-JL}
\begin{split}
\mathrm{p}(y,p) &= \mathrm{p}(y|p) \, \mathrm{p}(p) \\
&= {n \choose y} \, p^y \, (1-p)^{n-y} \cdot frac{1}{B(\alpha_0,\beta_0)} \, p^{\alpha_0-1} \, (1-p)^{\beta_0-1} \\
&= \frac{1}{B(\alpha_0,\beta_0)} {n \choose y} \, p^{\alpha_0+y-1} \, (1-p)^{\beta_0+(n-y)-1} \; .
\end{split}
\end{equation}

Note that the posterior distribution is proportional to the joint likelihood ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:post-jl}):

\begin{equation} \label{eq:bin-post-Bin-post-s1}
\mathrm{p}(p|y) \propto \mathrm{p}(y,p) \; .
\end{equation}

Setting $\alpha_n = \alpha_0 + y$ and $\beta_n = \beta_0 + (n-y)$, the posterior distribution is therefore proportional to

\begin{equation} \label{eq:bin-post-Bin-post-s2}
\mathrm{p}(p|y) \propto p^{\alpha_n-1} \, (1-p)^{\beta_n-1}
\end{equation}

which, when normalized to one, results in the probability density function of the beta distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:beta-pdf}):

\begin{equation} \label{eq:bin-post-Bin-post-qed}
\mathrm{p}(p|y) = \frac{1}{B(\alpha_n,\beta_n)} \, p^{\alpha_n-1} \, (1-p)^{\beta_n-1} = \mathrm{Bet}(p; \alpha_n, \beta_n) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Binomial distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-01-23; URL: \url{https://en.wikipedia.org/wiki/Binomial_distribution#Estimation_of_parameters}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P30 | shortcut: bin-post | author: JoramSoch | date: 2020-01-24, 00:20.
\vspace{1em}



\subsubsection[\textbf{Log model evidence}]{Log model evidence} \label{sec:bin-lme}
\setcounter{equation}{0}

\textbf{Theorem:} Let $y$ be the number of successes resulting from $n$ independent trials with unknown success probability $p$, such that $y$ follows a binomial distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:bin}):

\begin{equation} \label{eq:bin-lme-Bin}
y \sim \mathrm{Bin}(n,p) \; .
\end{equation}

Moreover, assume a beta prior distribution ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:bin-prior}) over the model parameter $p$:

\begin{equation} \label{eq:bin-lme-Bin-prior}
\mathrm{p}(p) = \mathrm{Bet}(p; \alpha_0, \beta_0) \; .
\end{equation}

Then, the log model evidence ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme}) for this model is

\begin{equation} \label{eq:bin-lme-Bin-LME}
\begin{split}
\log \mathrm{p}(y|m) = \log \Gamma(n+1) &- \log \Gamma(k+1) - \log \Gamma(n-k+1) \\
&+ \log B(\alpha_n,\beta_n) - \log B(\alpha_0,\beta_0) \; .
\end{split}
\end{equation}

where the posterior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) are given by

\begin{equation} \label{eq:bin-lme-Bin-post-par}
\begin{split}
\alpha_n &= \alpha_0 + y \\
\beta_n &= \beta_0 + (n-y) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Proof:} With the probability mass function of the binomial distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:bin-pmf}), the likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) implied by \eqref{eq:bin-lme-Bin} is given by

\begin{equation} \label{eq:bin-lme-Bin-LF}
\mathrm{p}(y|p) = {n \choose y} \, p^y \, (1-p)^{n-y} \; .
\end{equation}

Combining the likelihood function \eqref{eq:bin-lme-Bin-LF} with the prior distribution \eqref{eq:bin-lme-Bin-prior}, the joint likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:jl}) of the model is given by

\begin{equation} \label{eq:bin-lme-Bin-JL-s1}
\begin{split}
\mathrm{p}(y,p) &= \mathrm{p}(y|p) \, \mathrm{p}(p) \\
&= {n \choose y} \, p^y \, (1-p)^{n-y} \cdot frac{1}{B(\alpha_0,\beta_0)} \, p^{\alpha_0-1} \, (1-p)^{\beta_0-1} \\
&= {n \choose y} \, \frac{1}{B(\alpha_0,\beta_0)} \, p^{\alpha_0+y-1} \, (1-p)^{\beta_0+(n-y)-1} \; .
\end{split}
\end{equation}

Note that the model evidence is the marginal density of the joint likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ml}):

\begin{equation} \label{eq:bin-lme-Bin-ME-s1}
\mathrm{p}(y) = \int \mathrm{p}(y,p) \, \mathrm{d}p \; .
\end{equation}

Setting $\alpha_n = \alpha_0 + y$ and $\beta_n = \beta_0 + (n-y)$, the joint likelihood can also be written as

\begin{equation} \label{eq:bin-lme-Bin-JL-s2}
\mathrm{p}(y,p) = {n \choose y} \, \frac{1}{B(\alpha_0,\beta_0)} \, \frac{B(\alpha_n,\beta_n)}{1} \, \frac{1}{B(\alpha_n,\beta_n)} \, p^{\alpha_n-1} \, (1-p)^{\beta_n-1} \; .
\end{equation}

Using the probability density function of the beta distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:beta-pdf}), $p$ can now be integrated out easily

\begin{equation} \label{eq:bin-lme-Bin-ME-s2}
\begin{split}
\mathrm{p}(y) &= \int {n \choose y} \, \frac{1}{B(\alpha_0,\beta_0)} \, \frac{B(\alpha_n,\beta_n)}{1} \, \frac{1}{B(\alpha_n,\beta_n)} \, p^{\alpha_n-1} \, (1-p)^{\beta_n-1} \, \mathrm{d}p \\
&= {n \choose y} \, \frac{B(\alpha_n,\beta_n)}{B(\alpha_0,\beta_0)} \int \mathrm{Bet}(p; \alpha_n, \beta_n) \, \mathrm{d}p \\
&= {n \choose y} \, \frac{B(\alpha_n,\beta_n)}{B(\alpha_0,\beta_0)} \; ,
\end{split}
\end{equation}

such that the log model evidence ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme}) (LME) is shown to be

\begin{equation} \label{eq:bin-lme-Bin-LME-s1}
\log \mathrm{p}(y|m) = \log {n \choose y} + \log B(\alpha_n,\beta_n) - \log B(\alpha_0,\beta_0) \; .
\end{equation}

With the definition of the binomial coefficient

\begin{equation} \label{eq:bin-lme-bin-coeff}
{n \choose k} = \frac{n!}{k! \, (n-k)!}
\end{equation}

and the definition of the gamma function

\begin{equation} \label{eq:bin-lme-gam-fct}
\Gamma(n) = (n-1)! \; ,
\end{equation}

the LME finally becomes

\begin{equation} \label{eq:bin-lme-Bin-LME-s2}
\begin{split}
\log \mathrm{p}(y|m) = \log \Gamma(n+1) &- \log \Gamma(k+1) - \log \Gamma(n-k+1) \\
&+ \log B(\alpha_n,\beta_n) - \log B(\alpha_0,\beta_0) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Beta-binomial distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-01-24; URL: \url{https://en.wikipedia.org/wiki/Beta-binomial_distribution#Motivation_and_derivation}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P31 | shortcut: bin-lme | author: JoramSoch | date: 2020-01-24, 00:44.
\vspace{1em}



\subsection{Multinomial observations}

\subsubsection[\textit{Definition}]{Definition} \label{sec:mult-data}
\setcounter{equation}{0}

\textbf{Definition:} An ordered pair $(n,y)$ with $n \in \mathbb{N}$ and $y = \left[ y_1, \ldots, y_k \right] \in \mathbb{N}_0^{1 \times k}$, where $y_i$ is the number of observations for the $i$-th out of $k$ categories obtained in $n$ trials, $i = 1, \ldots, k$, consititutes a set of multinomial observations.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D79 | shortcut: mult-data | author: JoramSoch | date: 2020-07-07, 07:12.
\vspace{1em}



\subsubsection[\textbf{Conjugate prior distribution}]{Conjugate prior distribution} \label{sec:mult-prior}
\setcounter{equation}{0}

\textbf{Theorem:} Let $y = [y_1, \ldots, y_k]$ be the number of observations in $k$ categories resulting from $n$ independent trials with unknown category probabilities $p = [p_1, \ldots, p_k]$, such that $y$ follows a multinomial distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mult}):

\begin{equation} \label{eq:mult-prior-Mult}
y \sim \mathrm{Mult}(n,p) \; .
\end{equation}

Then, the conjugate prior ($\rightarrow$ Definition "prior-conj") for the model parameter $p$ is a Dirichlet distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:dir}):

\begin{equation} \label{eq:mult-prior-Dir}
\mathrm{p}(p) = \mathrm{Dir}(p; \alpha_0) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} With the probability mass function of the multinomial distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mult-pmf}), the likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) implied by \eqref{eq:mult-prior-Mult} is given by

\begin{equation} \label{eq:mult-prior-Mult-LF}
\mathrm{p}(y|p) = {n \choose {y_1, \ldots, y_k}} \prod_{j=1}^{k} {p_j}^{y_j} \; .
\end{equation}

In other words, the likelihood function is proportional to a product of powers of the entries of the vector $p$:

\begin{equation} \label{eq:mult-prior-Mult-LF-prop}
\mathrm{p}(y|p) \propto \prod_{j=1}^{k} {p_j}^{y_j} \; .
\end{equation}

The same is true for a Dirichlet distribution over $p$

\begin{equation} \label{eq:mult-prior-Mult-prior-s1}
\mathrm{p}(p) = \mathrm{Dir}(p; \alpha_0)
\end{equation}

the probability density function of which ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:dir-pdf})

\begin{equation} \label{eq:mult-prior-Mult-prior-s2}
\mathrm{p}(p) = \frac{\Gamma \left( \sum_{j=1}^{k} \alpha_{0j} \right)}{\prod_{j=1}^k \Gamma(\alpha_{0j})} \prod_{j=1}^{k} {p_j}^{\alpha_{0j}-1}
\end{equation}

exhibits the same proportionality

\begin{equation} \label{eq:mult-prior-Mult-prior-s3}
\mathrm{p}(p) \propto \prod_{j=1}^{k} {p_j}^{\alpha_{0j}-1}
\end{equation}

and is therefore conjugate relative to the likelihood.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Dirichlet distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-03-11; URL: \url{https://en.wikipedia.org/wiki/Dirichlet_distribution#Conjugate_to_categorical/multinomial}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P79 | shortcut: mult-prior | author: JoramSoch | date: 2020-03-11, 14:15.
\vspace{1em}



\subsubsection[\textbf{Posterior distribution}]{Posterior distribution} \label{sec:mult-post}
\setcounter{equation}{0}

\textbf{Theorem:} Let $y = [y_1, \ldots, y_k]$ be the number of observations in $k$ categories resulting from $n$ independent trials with unknown category probabilities $p = [p_1, \ldots, p_k]$, such that $y$ follows a multinomial distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mult}):

\begin{equation} \label{eq:mult-post-Mult}
y \sim \mathrm{Mult}(n,p) \; .
\end{equation}

Moreover, assume a Dirichlet prior distribution ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mult-prior}) over the model parameter $p$:

\begin{equation} \label{eq:mult-post-Mult-prior}
\mathrm{p}(p) = \mathrm{Dir}(p; \alpha_0) \; .
\end{equation}

Then, the posterior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) is also a Dirichlet distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:dir})

\begin{equation} \label{eq:mult-post-Mult-post}
\mathrm{p}(p|y) = \mathrm{Dir}(p; \alpha_n) \; .
\end{equation}

and the posterior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) are given by

\begin{equation} \label{eq:mult-post-Mult-post-par}
\alpha_{nj} = \alpha_{0j} + y_j, \; j = 1,\ldots,k \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} With the probability mass function of the multinomial distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mult-pmf}), the likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) implied by \eqref{eq:mult-post-Mult} is given by

\begin{equation} \label{eq:mult-post-Mult-LF}
\mathrm{p}(y|p) = {n \choose {y_1, \ldots, y_k}} \prod_{j=1}^{k} {p_j}^{y_j} \; .
\end{equation}

Combining the likelihood function \eqref{eq:mult-post-Mult-LF} with the prior distribution \eqref{eq:mult-post-Mult-prior}, the joint likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:jl}) of the model is given by

\begin{equation} \label{eq:mult-post-Mult-JL}
\begin{split}
\mathrm{p}(y,p) &= \mathrm{p}(y|p) \, \mathrm{p}(p) \\
&= {n \choose {y_1, \ldots, y_k}} \prod_{j=1}^{k} {p_j}^{y_j} \cdot \frac{\Gamma \left( \sum_{j=1}^{k} \alpha_{0j} \right)}{\prod_{j=1}^k \Gamma(\alpha_{0j})} \prod_{j=1}^{k} {p_j}^{\alpha_{0j}-1} \\
&= \frac{\Gamma \left( \sum_{j=1}^{k} \alpha_{0j} \right)}{\prod_{j=1}^k \Gamma(\alpha_{0j})} {n \choose {y_1, \ldots, y_k}} \prod_{j=1}^{k} {p_j}^{\alpha_{0j}+y_j-1} \; .
\end{split}
\end{equation}

Note that the posterior distribution is proportional to the joint likelihood ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:post-jl}):

\begin{equation} \label{eq:mult-post-Mult-post-s1}
\mathrm{p}(p|y) \propto \mathrm{p}(y,p) \; .
\end{equation}

Setting $\alpha_{nj} = \alpha_{0j} + y_j$, the posterior distribution is therefore proportional to

\begin{equation} \label{eq:mult-post-Mult-post-s2}
\mathrm{p}(p|y) \propto \prod_{j=1}^{k} {p_j}^{\alpha_{nj}-1}
\end{equation}

which, when normalized to one, results in the probability density function of the Dirichlet distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:dir-pdf}):

\begin{equation} \label{eq:mult-post-Mult-post-qed}
\mathrm{p}(p|y) = \frac{\Gamma \left( \sum_{j=1}^{k} \alpha_{nj} \right)}{\prod_{j=1}^k \Gamma(\alpha_{nj})} \prod_{j=1}^{k} {p_j}^{\alpha_{nj}-1} = \mathrm{Dir}(p; \alpha_n) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Dirichlet distribution"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-03-11; URL: \url{https://en.wikipedia.org/wiki/Dirichlet_distribution#Conjugate_to_categorical/multinomial}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P80 | shortcut: mult-post | author: JoramSoch | date: 2020-03-11, 14:40.
\vspace{1em}



\subsubsection[\textbf{Log model evidence}]{Log model evidence} \label{sec:mult-lme}
\setcounter{equation}{0}

\textbf{Theorem:} Let $y = [y_1, \ldots, y_k]$ be the number of observations in $k$ categories resulting from $n$ independent trials with unknown category probabilities $p = [p_1, \ldots, p_k]$, such that $y$ follows a multinomial distribution ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:mult}):

\begin{equation} \label{eq:mult-lme-Mult}
y \sim \mathrm{Mult}(n,p) \; .
\end{equation}

Moreover, assume a Dirichlet prior distribution ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mult-prior}) over the model parameter $p$:

\begin{equation} \label{eq:mult-lme-Mult-prior}
\mathrm{p}(p) = \mathrm{Dir}(p; \alpha_0) \; .
\end{equation}

Then, the log model evidence ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme}) for this model is

\begin{equation} \label{eq:mult-lme-Mult-LME}
\begin{split}
\log \mathrm{p}(y|m) &= \log \Gamma(n+1) - \sum_{j=1}^{k} \log \Gamma(k_j+1) \\
&+ \log \Gamma \left( \sum_{j=1}^{k} \alpha_{0j} \right) - \log \Gamma \left( \sum_{j=1}^{k} \alpha_{nj} \right) \\
&+ \sum_{j=1}^k \log \Gamma(\alpha_{nj}) - \sum_{j=1}^k \log \Gamma(\alpha_{0j}) \; .
\end{split}
\end{equation}

and the posterior hyperparameters ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) are given by

\begin{equation} \label{eq:mult-lme-Mult-post-par}
\alpha_{nj} = \alpha_{0j} + y_j, \; j = 1,\ldots,k \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} With the probability mass function of the multinomial distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:mult-pmf}), the likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) implied by \eqref{eq:mult-lme-Mult} is given by

\begin{equation} \label{eq:mult-lme-Mult-LF}
\mathrm{p}(y|p) = {n \choose {y_1, \ldots, y_k}} \prod_{j=1}^{k} {p_j}^{y_j} \; .
\end{equation}

Combining the likelihood function \eqref{eq:mult-lme-Mult-LF} with the prior distribution \eqref{eq:mult-lme-Mult-prior}, the joint likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:jl}) of the model is given by

\begin{equation} \label{eq:mult-lme-Mult-JL}
\begin{split}
\mathrm{p}(y,p) &= \mathrm{p}(y|p) \, \mathrm{p}(p) \\
&= {n \choose {y_1, \ldots, y_k}} \prod_{j=1}^{k} {p_j}^{y_j} \cdot \frac{\Gamma \left( \sum_{j=1}^{k} \alpha_{0j} \right)}{\prod_{j=1}^k \Gamma(\alpha_{0j})} \prod_{j=1}^{k} {p_j}^{\alpha_{0j}-1} \\
&= {n \choose {y_1, \ldots, y_k}} \frac{\Gamma \left( \sum_{j=1}^{k} \alpha_{0j} \right)}{\prod_{j=1}^k \Gamma(\alpha_{0j})} \prod_{j=1}^{k} {p_j}^{\alpha_{0j}+y_j-1} \; .
\end{split}
\end{equation}

Note that the model evidence is the marginal density of the joint likelihood:

\begin{equation} \label{eq:mult-lme-Mult-ME-s1}
\mathrm{p}(y) = \int \mathrm{p}(y,p) \, \mathrm{d}p \; .
\end{equation}

Setting $\alpha_{nj} = \alpha_{0j} + y_j$, the joint likelihood can also be written as

\begin{equation} \label{eq:mult-lme-Mult-JL-s2}
\mathrm{p}(y,p) = {n \choose {y_1, \ldots, y_k}} \frac{\Gamma \left( \sum_{j=1}^{k} \alpha_{0j} \right)}{\prod_{j=1}^k \Gamma(\alpha_{0j})} \, \frac{\prod_{j=1}^k \Gamma(\alpha_{nj})} {\Gamma \left( \sum_{j=1}^{k} \alpha_{nj} \right)} \, \frac{\Gamma \left( \sum_{j=1}^{k} \alpha_{nj} \right)}{\prod_{j=1}^k \Gamma(\alpha_{nj})} \prod_{j=1}^{k} {p_j}^{\alpha_{nj}-1} \; .
\end{equation}

Using the probability density function of the Dirichlet distribution ($\rightarrow$ Proof \ref{sec:Probability Distributions}/\ref{sec:dir-pdf}), $p$ can now be integrated out easily

\begin{equation} \label{eq:mult-lme-Mult-ME-s2}
\begin{split}
\mathrm{p}(y) &= \int {n \choose {y_1, \ldots, y_k}} \frac{\Gamma \left( \sum_{j=1}^{k} \alpha_{0j} \right)}{\prod_{j=1}^k \Gamma(\alpha_{0j})} \, \frac{\prod_{j=1}^k \Gamma(\alpha_{nj})}{\Gamma \left( \sum_{j=1}^{k} \alpha_{nj} \right)} \, \frac{\Gamma \left( \sum_{j=1}^{k} \alpha_{nj} \right)}{\prod_{j=1}^k \Gamma(\alpha_{nj})} \prod_{j=1}^{k} {p_j}^{\alpha_{nj}-1} \, \mathrm{d}p \\
&= {n \choose {y_1, \ldots, y_k}} \frac{\Gamma \left( \sum_{j=1}^{k} \alpha_{0j} \right)}{\prod_{j=1}^k \Gamma(\alpha_{0j})} \, \frac{\prod_{j=1}^k \Gamma(\alpha_{nj})}{\Gamma \left( \sum_{j=1}^{k} \alpha_{nj} \right)} \int \mathrm{Dir}(p; \alpha_n) \, \mathrm{d}p \\
&= {n \choose {y_1, \ldots, y_k}} \frac{\Gamma \left( \sum_{j=1}^{k} \alpha_{0j} \right)}{\Gamma \left( \sum_{j=1}^{k} \alpha_{nj} \right)} \, \frac{\prod_{j=1}^k \Gamma(\alpha_{nj})}{\prod_{j=1}^k \Gamma(\alpha_{0j})} \; ,
\end{split}
\end{equation}

such that the log model evidence ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme}) (LME) is shown to be

\begin{equation} \label{eq:mult-lme-Mult-LME-s1}
\begin{split}
\log \mathrm{p}(y|m) = \log {n \choose {y_1, \ldots, y_k}} &+ \log \Gamma \left( \sum_{j=1}^{k} \alpha_{0j} \right) - \log \Gamma \left( \sum_{j=1}^{k} \alpha_{nj} \right) \\
&+ \sum_{j=1}^k \log \Gamma(\alpha_{nj}) - \sum_{j=1}^k \log \Gamma(\alpha_{0j}) \; .
\end{split}
\end{equation}

With the definition of the multinomial coefficient

\begin{equation} \label{eq:mult-lme-mult-coeff}
{n \choose {k_1, \ldots, k_m}} = \frac{n!}{k_1! \cdot \ldots \cdot k_m!}
\end{equation}

and the definition of the gamma function

\begin{equation} \label{eq:mult-lme-gam-fct}
\Gamma(n) = (n-1)! \; ,
\end{equation}

the LME finally becomes

\begin{equation} \label{eq:mult-lme-Mult-LME-s2}
\begin{split}
\log \mathrm{p}(y|m) &= \log \Gamma(n+1) - \sum_{j=1}^{k} \log \Gamma(k_j+1) \\
&+ \log \Gamma \left( \sum_{j=1}^{k} \alpha_{0j} \right) - \log \Gamma \left( \sum_{j=1}^{k} \alpha_{nj} \right) \\
&+ \sum_{j=1}^k \log \Gamma(\alpha_{nj}) - \sum_{j=1}^k \log \Gamma(\alpha_{0j}) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P81 | shortcut: mult-lme | author: JoramSoch | date: 2020-03-11, 15:17.
\vspace{1em}





% Chapter 4 %
\chapter{Model Selection} \label{sec:Model Selection} \newpage

\pagebreak
\section{Goodness-of-fit measures}

\subsection{Residual variance}

\subsubsection[\textit{Definition}]{Definition} \label{sec:resvar}
\setcounter{equation}{0}

\textbf{Definition:} Let there be a linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr})

\begin{equation} \label{eq:resvar-mlr}
y = X\beta + \varepsilon, \; \varepsilon \sim \mathcal{N}(0, \sigma^2 V)
\end{equation}

with measured data $y$, known design matrix $X$ and covariance structure $V$ as well as unknown regression coefficients $\beta$ and noise variance $\sigma^2$.

Then, an estimate of the noise variance $\sigma^2$ is called the "residual variance" $\hat{\sigma}^2$, e.g. obtained via maximum likelihood estimation ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mle}).


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D20 | shortcut: resvar | author: JoramSoch | date: 2020-02-25, 11:21.
\vspace{1em}



\subsubsection[\textbf{Maximum likelihood estimator is biased}]{Maximum likelihood estimator is biased} \label{sec:resvar-bias}
\setcounter{equation}{0}

\textbf{Theorem:} Let $x = \left\lbrace x_1, \ldots, x_n \right\rbrace$ be a set of independent normally distributed ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}) observations with unknown mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) $\mu$ and variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) $\sigma^2$:

\begin{equation} \label{eq:resvar-bias-ug}
x_i \overset{\text{i.i.d.}}{\sim} \mathcal{N}(\mu, \sigma^2), \quad i = 1,\ldots,n \; .
\end{equation}

Then,

1) the maximum likelihood estimator ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mle}) of $\sigma^2$ is

\begin{equation} \label{eq:resvar-bias-resvar-mle}
\hat{\sigma}^2 = \frac{1}{n} \sum_{i=1}^{n} \left( x_i - \bar{x} \right)^2
\end{equation}

where

\begin{equation} \label{eq:resvar-bias-mean-mle}
\bar{x} = \frac{1}{n} \sum_{i=1}^{n} x_i
\end{equation}

2) and $\hat{\sigma}^2$ is a biased estimator ($\rightarrow$ Definition "est-unb") of $\sigma^2$

\begin{equation} \label{eq:resvar-bias-resvar-var}
\mathbb{E}\left[ \hat{\sigma}^2 \right] \neq \sigma^2 \; ,
\end{equation}

more precisely:

\begin{equation} \label{eq:resvar-bias-resvar-bias}
\mathbb{E}\left[ \hat{\sigma}^2 \right] = \frac{n-1}{n} \sigma^2 \; .
\end{equation}


\vspace{1em}
\textbf{Proof:}

1) This is equivalent to the maximum likelihood estimator for the univariate Gaussian with unknown variance ($\rightarrow$ Proof "ug-mle") and a special case of the maximum likelihood estimator for multiple linear regression ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mlr-mle}) in which $y = x$, $X = 1_n$ and $\hat{\beta} = \bar{x}$:

\begin{equation} \label{eq:resvar-bias-resvar-mle-qed}
\begin{split}
\hat{\sigma}^2 &= \frac{1}{n} (y-X\hat{\beta})^\mathrm{T} (y-X\hat{\beta}) \\
&= \frac{1}{n} (x - 1_n \bar{x})^\mathrm{T} (x - 1_n \bar{x}) \\
&= \frac{1}{n} \sum_{i=1}^{n} \left( x_i - \bar{x} \right)^2 \; .
\end{split}
\end{equation}

2) The expectation ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of the maximum likelihood estimator ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mle}) can be developed as follows:

\begin{equation} \label{eq:resvar-bias-E-resvar-mle-s1}
\begin{split}
\mathbb{E}\left[ \hat{\sigma}^2 \right] &= \mathbb{E}\left[ \frac{1}{n} \sum_{i=1}^{n} \left( x_i - \bar{x} \right)^2 \right] \\
&= \frac{1}{n} \mathbb{E}\left[ \sum_{i=1}^{n} \left( x_i - \bar{x} \right)^2 \right] \\
&= \frac{1}{n} \mathbb{E}\left[ \sum_{i=1}^{n} \left( x_i^2 - 2 x_i \bar{x} + \bar{x}^2 \right) \right] \\
&= \frac{1}{n} \mathbb{E}\left[ \sum_{i=1}^{n} x_i^2 - 2 \sum_{i=1}^{n} x_i \bar{x} + \sum_{i=1}^{n} \bar{x}^2 \right] \\
&= \frac{1}{n} \mathbb{E}\left[ \sum_{i=1}^{n} x_i^2 - 2 n \bar{x}^2 + n \bar{x}^2 \right] \\
&= \frac{1}{n} \mathbb{E}\left[ \sum_{i=1}^{n} x_i^2 - n \bar{x}^2 \right] \\
&= \frac{1}{n} \left( \sum_{i=1}^{n} \mathbb{E} \left[ x_i^2 \right] - n \mathbb{E}\left[ \bar{x}^2 \right] \right) \\
&= \frac{1}{n} \sum_{i=1}^{n} \mathbb{E} \left[ x_i^2 \right] - \mathbb{E}\left[ \bar{x}^2 \right] \\
\end{split}
\end{equation}

Due to the partition of variance into expected values ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:var-mean})

\begin{equation} \label{eq:resvar-bias-var-mean}
\mathrm{Var}(X) = \mathbb{E}(X^2) - \mathbb{E}(X)^2 \; ,
\end{equation}

we have

\begin{equation} \label{eq:resvar-bias-Var-xi-xb}
\begin{split}
\mathrm{Var}(x_i) &= \mathbb{E}(x_i^2) - \mathbb{E}(x_i)^2 \\
\mathrm{Var}(\bar{x}) &= \mathbb{E}(\bar{x}^2) - \mathbb{E}(\bar{x})^2 \; ,
\end{split}
\end{equation}

such that \eqref{eq:resvar-bias-E-resvar-mle-s1} becomes

\begin{equation} \label{eq:resvar-bias-E-resvar-mle-s2}
\mathbb{E}\left[ \hat{\sigma}^2 \right] = \frac{1}{n} \sum_{i=1}^{n} \left( \mathrm{Var}(x_i) + \mathbb{E}(x_i)^2 \right) - \left( \mathrm{Var}(\bar{x}) + \mathbb{E}(\bar{x})^2 \right) \; .
\end{equation}

From \eqref{eq:resvar-bias-ug}, it follows that

\begin{equation} \label{eq:resvar-bias-E-Var-xi}
\mathbb{E}(x_i) = \mu \quad \text{and} \quad \mathrm{Var}(x_i) = \sigma^2 \; .
\end{equation}

The expectation ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) of $\bar{x}$ given by \eqref{eq:resvar-bias-mean-mle} is

\begin{equation} \label{eq:resvar-bias-E-mean-mle}
\begin{split}
\mathbb{E}\left[ \bar{x} \right] &= \mathbb{E}\left[ \frac{1}{n} \sum_{i=1}^{n} x_i \right] = \frac{1}{n} \sum_{i=1}^{n} \mathbb{E}\left[ x_i \right] \\
&\overset{\eqref{eq:resvar-bias-E-Var-xi}}{=} \frac{1}{n} \sum_{i=1}^{n} \mu = \frac{1}{n} \cdot n \cdot \mu \\
&= \mu \; .
\end{split}
\end{equation}

The variance of $\bar{x}$ given by \eqref{eq:resvar-bias-mean-mle} is

\begin{equation} \label{eq:resvar-bias-Var-mean-mle}
\begin{split}
\mathrm{Var}\left[ \bar{x} \right] &= \mathrm{Var}\left[ \frac{1}{n} \sum_{i=1}^{n} x_i \right] = \frac{1}{n^2} \sum_{i=1}^{n} \mathrm{Var}\left[ x_i \right] \\
&\overset{\eqref{eq:resvar-bias-E-Var-xi}}{=} \frac{1}{n^2} \sum_{i=1}^{n} \sigma^2 = \frac{1}{n^2} \cdot n \cdot \sigma^2 \\
&= \frac{1}{n} \sigma^2 \; .
\end{split}
\end{equation}

Plugging \eqref{eq:resvar-bias-E-Var-xi}, \eqref{eq:resvar-bias-E-mean-mle} and \eqref{eq:resvar-bias-Var-mean-mle} into \eqref{eq:resvar-bias-E-resvar-mle-s2}, we have

\begin{equation} \label{eq:resvar-bias-E-resvar-mle-s3}
\begin{split}
\mathbb{E}\left[ \hat{\sigma}^2 \right] &= \frac{1}{n} \sum_{i=1}^{n} \left( \sigma^2 + \mu^2 \right) - \left( \frac{1}{n} \sigma^2 + \mu^2 \right) \\
\mathbb{E}\left[ \hat{\sigma}^2 \right] &= \frac{1}{n} \cdot n \cdot \left( \sigma^2 + \mu^2 \right) - \left( \frac{1}{n} \sigma^2 + \mu^2 \right) \\
\mathbb{E}\left[ \hat{\sigma}^2 \right] &= \sigma^2 + \mu^2 - \frac{1}{n} \sigma^2 - \mu^2 \\
\mathbb{E}\left[ \hat{\sigma}^2 \right] &= \frac{n-1}{n} \sigma^2
\end{split}
\end{equation}

which proves the bias ($\rightarrow$ Definition "est-unb") given by \eqref{eq:resvar-bias-resvar-bias}.



\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Liang, Dawen (????): "Maximum Likelihood Estimator for Variance is Biased: Proof", retrieved on 2020-02-24; URL: \url{https://dawenl.github.io/files/mle_biased.pdf}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P61 | shortcut: resvar-bias | author: JoramSoch | date: 2020-02-24, 23:44.
\vspace{1em}



\subsubsection[\textbf{Construction of unbiased estimator}]{Construction of unbiased estimator} \label{sec:resvar-unb}
\setcounter{equation}{0}

\textbf{Theorem:} Let $x = \left\lbrace x_1, \ldots, x_n \right\rbrace$ be a set of independent normally distributed ($\rightarrow$ Definition \ref{sec:Probability Distributions}/\ref{sec:norm}) observations with unknown mean ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mean}) $\mu$ and variance ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:var}) $\sigma^2$:

\begin{equation} \label{eq:resvar-unb-ug}
x_i \overset{\text{i.i.d.}}{\sim} \mathcal{N}(\mu, \sigma^2), \quad i = 1,\ldots,n \; .
\end{equation}

An unbiased estimator ($\rightarrow$ Definition "est-unb") of $\sigma^2$ is given by

\begin{equation} \label{eq:resvar-unb-resvar-unb}
\hat{\sigma}^2_{\mathrm{unb}} = \frac{1}{n-1} \sum_{i=1}^{n} \left( x_i - \bar{x} \right)^2 \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} It can be shown that ($\rightarrow$ Proof \ref{sec:Model Selection}/\ref{sec:resvar-bias}) the maximum likelihood estimator ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mle}) of $\sigma^2$

\begin{equation} \label{eq:resvar-unb-resvar-mle}
\hat{\sigma}^2_{\mathrm{MLE}} = \frac{1}{n} \sum_{i=1}^{n} \left( x_i - \bar{x} \right)^2
\end{equation}

is a biased estimator ($\rightarrow$ Definition "est-unb") in the sense that

\begin{equation} \label{eq:resvar-unb-resvar-bias}
\mathbb{E}\left[ \hat{\sigma}^2_{\mathrm{MLE}} \right] = \frac{n-1}{n} \sigma^2 \; .
\end{equation}

From \eqref{eq:resvar-unb-resvar-bias}, it follows that

\begin{equation} \label{eq:resvar-unb-resvar-bias-adj}
\begin{split}
\mathbb{E}\left[ \frac{n}{n-1} \hat{\sigma}^2_{\mathrm{MLE}} \right] &= \frac{n}{n-1} \mathbb{E}\left[ \hat{\sigma}^2_{\mathrm{MLE}} \right] \\
&\overset{\eqref{eq:resvar-unb-resvar-bias}}{=} \frac{n}{n-1} \cdot \frac{n-1}{n} \sigma^2 \\
&= \sigma^2 \; ,
\end{split}
\end{equation}

such that an unbiased estimator ($\rightarrow$ Definition "est-unb") can be constructed as

\begin{equation} \label{eq:resvar-unb-resvar-unb-qed}
\begin{split}
\hat{\sigma}^2_{\mathrm{unb}} &= \frac{n}{n-1} \hat{\sigma}^2_{\mathrm{MLE}} \\
&\overset{\eqref{eq:resvar-unb-resvar-mle}}{=} \frac{n}{n-1} \cdot \frac{1}{n} \sum_{i=1}^{n} \left( x_i - \bar{x} \right)^2 \\
&= \frac{1}{n-1} \sum_{i=1}^{n} \left( x_i - \bar{x} \right)^2 \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Liang, Dawen (????): "Maximum Likelihood Estimator for Variance is Biased: Proof", retrieved on 2020-02-25; URL: \url{https://dawenl.github.io/files/mle_biased.pdf}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P62 | shortcut: resvar-unb | author: JoramSoch | date: 2020-02-25, 15:38.
\vspace{1em}



\subsection{R-squared}

\subsubsection[\textit{Definition}]{Definition} \label{sec:rsq}
\setcounter{equation}{0}

\textbf{Definition:} Let there be a linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}) with independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}) observations

\begin{equation} \label{eq:rsq-mlr}
y = X\beta + \varepsilon, \; \varepsilon_i \overset{\mathrm{i.i.d.}}{\sim} \mathcal{N}(0, \sigma^2)
\end{equation}

with measured data $y$, known design matrix $X$ as well as unknown regression coefficients $\beta$ and noise variance $\sigma^2$.

Then, the proportion of the variance of the dependent variable $y$ ("total variance ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:tss})") that can be predicted from the independent variables $X$ ("explained variance ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:ess})") is called "coefficient of determination", "R-squared" or $R^2$.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2020): "Coefficient of determination"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2020-02-25; URL: \url{https://en.wikipedia.org/wiki/Mean_squared_error#Proof_of_variance_and_bias_relationship}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D21 | shortcut: rsq | author: JoramSoch | date: 2020-02-25, 11:41.
\vspace{1em}



\subsubsection[\textbf{Derivation of R² and adjusted R²}]{Derivation of R² and adjusted R²} \label{sec:rsq-der}
\setcounter{equation}{0}

\textbf{Theorem:} Given a linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr})

\begin{equation} \label{eq:rsq-der-rsq-mlr}
y = X\beta + \varepsilon, \; \varepsilon_i \overset{\mathrm{i.i.d.}}{\sim} \mathcal{N}(0, \sigma^2)
\end{equation}

with $n$ independent observations and $p$ independent variables,

1) the coefficient of determination ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:rsq}) is given by

\begin{equation} \label{eq:rsq-der-R2}
R^2 = 1 - \frac{\mathrm{RSS}}{\mathrm{TSS}}
\end{equation}

2) the adjusted coefficient of determination is

\begin{equation} \label{eq:rsq-der-R2-adj}
R^2_{\mathrm{adj}} = 1 - \frac{\mathrm{RSS}/(n-p)}{\mathrm{TSS}/(n-1)}
\end{equation}

where the residual ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:rss}) and total sum of squares ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:tss}) are

\begin{equation} \label{eq:rsq-der-SS}
\begin{split}
\mathrm{RSS} &= \sum_{i=1}^{n} (y_i - \hat{y}_i)^2, \quad \hat{y} = X\hat{\beta} \\
\mathrm{TSS} &= \sum_{i=1}^{n} (y_i - \bar{y})^2\;, \quad \bar{y} = \frac{1}{n} \sum_{i=1}^n y_i \\
\end{split}
\end{equation}

where $X$ is the $n \times p$ design matrix and $\hat{\beta}$ are the ordinary least squares ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mlr-ols}) estimates.


\vspace{1em}
\textbf{Proof:} The coefficient of determination $R^2$ is defined as ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:rsq}) the proportion of the variance explained by the independent variables, relative to the total variance in the data.

\vspace{1em}
1) If we define the explained sum of squares ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:ess}) as

\begin{equation} \label{eq:rsq-der-ESS}
\mathrm{ESS} = \sum_{i=1}^{n} (\hat{y}_i - \bar{y})^2 \; ,
\end{equation}

then $R^2$ is given by

\begin{equation} \label{eq:rsq-der-R2-s1}
R^2 = \frac{\mathrm{ESS}}{\mathrm{TSS}} \; .
\end{equation}

which is equal to

\begin{equation} \label{eq:rsq-der-R2-s2}
R^2 = \frac{\mathrm{TSS}-\mathrm{RSS}}{\mathrm{TSS}} = 1 - \frac{\mathrm{RSS}}{\mathrm{TSS}} \; ,
\end{equation}

because ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mlr-pss}) $\mathrm{TSS} = \mathrm{ESS} + \mathrm{RSS}$.

\vspace{1em}
2) Using \eqref{eq:rsq-der-SS}, the coefficient of determination can be also written as:

\begin{equation} \label{eq:rsq-der-R2'}
R^2 = 1 - \frac{\sum_{i=1}^{n} (y_i - \hat{y}_i)^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2} = 1 - \frac{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}{\frac{1}{n} \sum_{i=1}^{n} (y_i - \bar{y})^2} \; .
\end{equation}

If we replace the variance estimates by their unbiased estimators ($\rightarrow$ Proof \ref{sec:Model Selection}/\ref{sec:resvar-unb}), we obtain

\begin{equation} \label{eq:rsq-der-R2-adj'}
R^2_{\mathrm{adj}} = 1 - \frac{\frac{1}{n-p} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}{\frac{1}{n-1} \sum_{i=1}^{n} (y_i - \bar{y})^2} = 1 - \frac{\mathrm{RSS}/\mathrm{df}_r}{\mathrm{TSS}/\mathrm{df}_t}
\end{equation}

where $\mathrm{df}_r = n-p$ and $\mathrm{df}_t = n-1$ are the residual and total degrees of freedom ($\rightarrow$ Definition "dof").

\vspace{1em}
This gives the adjusted $R^2$ which adjusts $R^2$ for the number of explanatory variables.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Wikipedia (2019): "Coefficient of determination"; in: \textit{Wikipedia, the free encyclopedia}, retrieved on 2019-12-06; URL: \url{https://en.wikipedia.org/wiki/Coefficient_of_determination#Adjusted_R2}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P8 | shortcut: rsq-der | author: JoramSoch | date: 2019-12-06, 11:19.
\vspace{1em}



\subsubsection[\textbf{Relationship to maximum log-likelihood}]{Relationship to maximum log-likelihood} \label{sec:rsq-mll}
\setcounter{equation}{0}

\textbf{Theorem:} Given a linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}) with independent observations

\begin{equation} \label{eq:rsq-mll-MLR}
y = X\beta + \varepsilon, \; \varepsilon_i \overset{\mathrm{i.i.d.}}{\sim} \mathcal{N}(0, \sigma^2) \; ,
\end{equation}

the coefficient of determination ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:rsq}) can be expressed in terms of the maximum log-likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mll}) as

\begin{equation} \label{eq:rsq-mll-R2-MLL}
R^2 = 1 - \left( \exp[\Delta\mathrm{MLL}] \right)^{-2/n}
\end{equation}

where $n$ is the number of observations and $\Delta\mathrm{MLL}$ is the difference in maximum log-likelihood between the model given by \eqref{eq:rsq-mll-MLR} and a linear regression model with only a constant regressor.


\vspace{1em}
\textbf{Proof:} First, we express the maximum log-likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mll}) (MLL) of a linear regression model in terms of its residual sum of squares ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:rss}) (RSS). The model in \eqref{eq:rsq-mll-MLR} implies the following log-likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:llf})

\begin{equation} \label{eq:rsq-mll-MLR-LL}
\mathrm{LL}(\beta,\sigma^2) = \log p(y|\beta,\sigma^2) = - \frac{n}{2} \log(2\pi\sigma^2) - \frac{1}{2\sigma^2} (y - X\beta)^\mathrm{T} (y - X\beta) \; ,
\end{equation}

such that maximum likelihood estimates are ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mlr-mle})

\begin{equation} \label{eq:rsq-mll-MLR-MLE-beta}
\hat{\beta} = (X^\mathrm{T} X)^{-1} X^\mathrm{T} y
\end{equation}

\begin{equation} \label{eq:rsq-mll-MLR-MLE-sigma2}
\hat{\sigma}^2 = \frac{1}{n} (y - X\hat{\beta})^\mathrm{T} (y - X\hat{\beta})
\end{equation}

and the residual sum of squares ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:rss}) is

\begin{equation} \label{eq:rsq-mll-RSS}
\mathrm{RSS} = \sum_{i=1}^n \hat{\varepsilon}_i = \hat{\varepsilon}^\mathrm{T} \hat{\varepsilon} = (y - X\hat{\beta})^\mathrm{T} (y - X\hat{\beta}) = n \cdot \hat{\sigma}^2 \; .
\end{equation}

Since $\hat{\beta}$ and $\hat{\sigma}^2$ are maximum likelihood estimates ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mle}), plugging them into the log-likelihood function gives the maximum log-likelihood:

\begin{equation} \label{eq:rsq-mll-MLR-MLL}
\mathrm{MLL} = \mathrm{LL}(\hat{\beta},\hat{\sigma}^2) = - \frac{n}{2} \log(2\pi\hat{\sigma}^2) - \frac{1}{2\hat{\sigma}^2} (y - X\hat{\beta})^\mathrm{T} (y - X\hat{\beta}) \; .
\end{equation}

With \eqref{eq:rsq-mll-RSS} for the first $\hat{\sigma}^2$ and \eqref{eq:rsq-mll-MLR-MLE-sigma2} for the second $\hat{\sigma}^2$, the MLL becomes

\begin{equation} \label{eq:rsq-mll-MLR-MLL-RSS}
\mathrm{MLL} = - \frac{n}{2} \log(\mathrm{RSS}) - \frac{n}{2} \log \left( \frac{2\pi}{n} \right) - \frac{n}{2} \; .
\end{equation}

Second, we establish the relationship between maximum log-likelihood (MLL) and coefficient of determination (R²). Consider the two models

\begin{equation} \label{eq:rsq-mll-m0-m1}
\begin{split}
m_0: \; X_0 &= 1_n \\
m_1: \; X_1 &= X
\end{split}
\end{equation}

For $m_1$, the residual sum of squares is given by \eqref{eq:rsq-mll-RSS}; and for $m_0$, the residual sum of squares is equal to the total sum of squares ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:tss}):

\begin{equation} \label{eq:rsq-mll-TSS}
\mathrm{TSS} = \sum_{i=1}^n (y_i - \bar{y})^2 \; .
\end{equation}

Using \eqref{eq:rsq-mll-MLR-MLL-RSS}, we can therefore write

\begin{equation} \label{eq:rsq-mll-MLR-DMLL}
\Delta\mathrm{MLL} = \mathrm{MLL}(m_1) - \mathrm{MLL}(m_0) = - \frac{n}{2} \log(\mathrm{RSS}) + \frac{n}{2} \log(\mathrm{TSS}) \; .
\end{equation}

Exponentiating both sides of the equation, we have:

\begin{equation} \label{eq:rsq-mll-MLR-DMLL-RTSS}
\begin{split}
\exp[\Delta\mathrm{MLL}] &= \exp\left[ - \frac{n}{2} \log(\mathrm{RSS}) + \frac{n}{2} \log(\mathrm{TSS}) \right] \\
&= \left( \exp\left[ \log(\mathrm{RSS}) - \log(\mathrm{TSS}) \right] \right)^{-n/2} \\
&= \left( \frac{\exp[\log(\mathrm{RSS})]}{\exp[\log(\mathrm{TSS})]} \right)^{-n/2} \\
&= \left( \frac{\mathrm{RSS}}{\mathrm{TSS}} \right)^{-n/2} \; .
\end{split}
\end{equation}

Taking both sides to the power of $-2/n$ and subtracting from 1, we have

\begin{equation} \label{eq:rsq-mll-MLR-DMLL-R2}
\begin{split}
\left( \exp[\Delta\mathrm{MLL}] \right)^{-2/n} &= \frac{\mathrm{RSS}}{\mathrm{TSS}} \\
1 - \left( \exp[\Delta\mathrm{MLL}] \right)^{-2/n} &= 1 - \frac{\mathrm{RSS}}{\mathrm{TSS}} = R^2
\end{split}
\end{equation}

which proves the identity given above.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P14 | shortcut: rsq-mll | author: JoramSoch | date: 2020-01-08, 04:46.
\vspace{1em}



\subsection{Signal-to-noise ratio}

\subsubsection[\textit{Definition}]{Definition} \label{sec:snr}
\setcounter{equation}{0}

\textbf{Definition:} Let there be a linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}) with independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}) observations

\begin{equation} \label{eq:snr-mlr}
y = X\beta + \varepsilon, \; \varepsilon_i \overset{\mathrm{i.i.d.}}{\sim} \mathcal{N}(0, \sigma^2)
\end{equation}

with measured data $y$, known design matrix $X$ as well as unknown regression coefficients $\beta$ and noise variance $\sigma^2$.

Given estimated regression coefficients ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mlr-mle}) $\hat{\beta}$ and residual variance ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:resvar}) $\hat{\sigma}^2$, the signal-to-noise ratio (SNR) is defined as the ratio of estimated signal variance to estimated noise variance:

\begin{equation} \label{eq:snr-SNR}
\mathrm{SNR} = \frac{\mathrm{Var}(X\hat{\beta})}{\hat{\sigma}^2} \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Soch J, Allefeld C (2018): "MACS – a new SPM toolbox for model assessment, comparison and selection"; in: \textit{Journal of Neuroscience Methods}, vol. 306, pp. 19-31, eq. 6; URL: \url{https://www.sciencedirect.com/science/article/pii/S0165027018301468}; DOI: 10.1016/j.jneumeth.2018.05.017.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D22 | shortcut: snr | author: JoramSoch | date: 2020-02-25, 12:01.
\vspace{1em}



\subsubsection[\textbf{Relationship with R²}]{Relationship with R²} \label{sec:snr-rsq}
\setcounter{equation}{0}

\textbf{Theorem:} Let there be a linear regression model ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:mlr}) with independent ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ind}) observations

\begin{equation} \label{eq:snr-rsq-mlr}
y = X\beta + \varepsilon, \; \varepsilon_i \overset{\mathrm{i.i.d.}}{\sim} \mathcal{N}(0, \sigma^2)
\end{equation}

and parameter estimates ($\rightarrow$ Definition "est") obtained with ordinary least squares ($\rightarrow$ Proof \ref{sec:Statistical Models}/\ref{sec:mlr-ols})

\begin{equation} \label{eq:snr-rsq-OLS}
\hat{\beta} = (X^\mathrm{T} X)^{-1} X^\mathrm{T} y \; .
\end{equation}

Then, the signal-to noise ratio ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:snr}) can be expressed in terms of the coefficient of determination ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:rsq})

\begin{equation} \label{eq:snr-rsq-SNR-R2}
\mathrm{SNR} = \frac{R^2}{\mathrm{1-R^2}}
\end{equation}

and vice versa

\begin{equation} \label{eq:snr-rsq-R2-SNR}
R^2 = \frac{\mathrm{SNR}}{\mathrm{1+\mathrm{SNR}}} \; ,
\end{equation}

if the predicted signal mean is equal to the actual signal mean.


\vspace{1em}
\textbf{Proof:} The signal-to-noise ratio (SNR) is defined as ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:snr})

\begin{equation} \label{eq:snr-rsq-SNR}
\mathrm{SNR} = \frac{\mathrm{Var}(X\hat{\beta})}{\hat{\sigma}^2} = \frac{\mathrm{Var}(\hat{y})}{\hat{\sigma}^2} \; .
\end{equation}

Writing out the variances, we have

\begin{equation} \label{eq:snr-rsq-SNR-s1}
\mathrm{SNR} = \frac{\frac{1}{n} \sum_{i=1}^{n} (\hat{y}_i - \bar{\hat{y}})^2}{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2} = \frac{\sum_{i=1}^{n} (\hat{y}_i - \bar{\hat{y}})^2}{\sum_{i=1}^{n} (y_i - \hat{y}_i)^2} \; .
\end{equation}

Note that it is irrelevant whether we use the biased estimator of the variance ($\rightarrow$ Proof \ref{sec:Model Selection}/\ref{sec:resvar-bias}) (dividing by $n$) or the unbiased estimator fo the variance ($\rightarrow$ Proof \ref{sec:Model Selection}/\ref{sec:resvar-unb}) (dividing by $n-1$), because the relevant terms cancel out.

If the predicted signal mean is equal to the actual signal mean -- which is the case when variable regressors in $X$ have mean zero, such that they are orthogonal to a constant regressor in $X$ --, this means that $\bar{\hat{y}} = \bar{y}$, such that

\begin{equation} \label{eq:snr-rsq-SNR-s2}
\mathrm{SNR} = \frac{\sum_{i=1}^{n} (\hat{y}_i - \bar{y})^2}{\sum_{i=1}^{n} (y_i - \hat{y}_i)^2} \; .
\end{equation}

Then, the SNR can be written in terms of the explained ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:ess}), residual ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:rss}) and total sum of squares ($\rightarrow$ Definition \ref{sec:Statistical Models}/\ref{sec:tss}):

\begin{equation} \label{eq:snr-rsq-SNR-s3}
\mathrm{SNR} = \frac{\mathrm{ESS}}{\mathrm{RSS}} = \frac{\mathrm{ESS}/\mathrm{TSS}}{\mathrm{RSS}/\mathrm{TSS}} \; .
\end{equation}

With the derivation of the coefficient of determination ($\rightarrow$ Proof \ref{sec:Model Selection}/\ref{sec:rsq-der}), this becomes

\begin{equation} \label{eq:snr-rsq-SNR-R2-qed}
\mathrm{SNR} = \frac{R^2}{1-R^2} \; .
\end{equation}

Rearranging this equation for the coefficient of determination ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:rsq}), we have

\begin{equation} \label{eq:snr-rsq-R2-SNR-qed}
R^2 = \frac{\mathrm{SNR}}{\mathrm{1+\mathrm{SNR}}} \; ,
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P63 | shortcut: snr-rsq | author: JoramSoch | date: 2020-02-26, 10:37.
\vspace{1em}



\pagebreak
\section{Classical information criteria}

\subsection{Akaike information criterion}

\subsubsection[\textit{Definition}]{Definition} \label{sec:aic}
\setcounter{equation}{0}

\textbf{Definition:} Let $m$ be a generative model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) with likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) $p(y \vert \theta, m)$ and maximum likelihood estimates ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mle})

\begin{equation} \label{eq:aic-MLE}
\hat{\theta} = \operatorname*{arg\,max}_\theta \log p(y | \theta, m) \; .
\end{equation}

Then, the Akaike information criterion (AIC) of this model is defined as

\begin{equation} \label{eq:aic-AIC}
\mathrm{AIC}(m) = -2 \log p(y | \hat{\theta}, m) + 2 \, p
\end{equation}

where $p$ is the number of free parameters estimated via \eqref{eq:aic-MLE}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Akaike H (1974): "A New Look at the Statistical Model Identification"; in: \textit{IEEE Transactions on Automatic Control}, vol. AC-19, no. 6, pp. 716-723; URL: \url{https://ieeexplore.ieee.org/document/1100705}; DOI: 10.1109/TAC.1974.1100705.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D23 | shortcut: aic | author: JoramSoch | date: 2020-02-25, 12:31.
\vspace{1em}



\subsection{Bayesian information criterion}

\subsubsection[\textit{Definition}]{Definition} \label{sec:bic}
\setcounter{equation}{0}

\textbf{Definition:} Let $m$ be a generative model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) with likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) $p(y \vert \theta, m)$ and maximum likelihood estimates ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mle})

\begin{equation} \label{eq:bic-MLE}
\hat{\theta} = \operatorname*{arg\,max}_\theta \log p(y | \theta, m) \; .
\end{equation}

Then, the Bayesian information criterion (BIC) of this model is defined as

\begin{equation} \label{eq:bic-BIC}
\mathrm{BIC}(m) = -2 \log p(y | \hat{\theta}, m) + p \log n
\end{equation}

where $n$ is the number of data points and $p$ is the number of free parameters estimated via \eqref{eq:bic-MLE}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Schwarz G (1978): "Estimating the Dimension of a Model"; in: \textit{The Annals of Statistics}, vol. 6, no. 2, pp. 461-464; URL: \url{https://www.jstor.org/stable/2958889}.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D24 | shortcut: bic | author: JoramSoch | date: 2020-02-25, 12:21.
\vspace{1em}



\subsubsection[\textbf{Derivation}]{Derivation} \label{sec:bic-der}
\setcounter{equation}{0}

\textbf{Theorem:} Let $p(y \vert \theta, m)$ be the likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) of a generative model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) $m \in \mathcal{M}$ with model parameters $\theta \in \Theta$ describing measured data $y \in \mathbb{R}^n$. Let $p(\theta \vert m)$ be a prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) on the model parameters. Assume that likelihood function and prior density are twice differentiable.

Then, as the number of data points goes to infinity, an approximation to the log-marginal likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ml}) $\log p(y \vert m)$, up to constant terms not depending on the model, is given by the Bayesian information criterion ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:bic}) (BIC) as

\begin{equation} \label{eq:bic-der-BIC}
-2 \log p(y|m) \approx \mathrm{BIC}(m) = -2 \log p(y|\hat{\theta}, m) + p \log n
\end{equation}

where $\hat{\theta}$ is the maximum likelihood estimator ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:mle}) (MLE) of $\theta$, $n$ is the number of data points and $p$ is the number of model parameters.


\vspace{1em}
\textbf{Proof:} Let $\mathrm{LL}(\theta)$ be the log-likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:llf})

\begin{equation} \label{eq:bic-der-LL}
\mathrm{LL}(\theta) = \log p(y|\theta,m)
\end{equation}

and define the functions $g$ and $h$ as follows:

\begin{equation} \label{eq:bic-der-gh}
\begin{split}
g(\theta) &= p(\theta|m) \\
h(\theta) &= \frac{1}{n} \, \mathrm{LL}(\theta) \; .
\end{split}
\end{equation}

Then, the marginal likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ml}) can be written as follows:

\begin{equation} \label{eq:bic-der-ML}
\begin{split}
p(y|m) &= \int_{\Theta} p(y|\theta,m) \, p(\theta|m) \, \mathrm{d}\theta \\
&= \int_{\Theta} \exp\left[n \, h(\theta)\right] \, g(\theta) \, \mathrm{d}\theta \; .
\end{split}
\end{equation}

This is an integral suitable for Laplace approximation which states that

\begin{equation} \label{eq:bic-der-LA}
\int_{\Theta} \exp\left[n \, h(\theta)\right] \, g(\theta) \, \mathrm{d}\theta = \left( \sqrt{\frac{2 \pi}{n}} \right)^p \exp\left[n \, h(\theta_0)\right] \left( g(\theta_0) \left| J(\theta_0) \right|^{-1/2} + O(1/n) \right)
\end{equation}

where $\theta_0$ is the value that maximizes $h(\theta)$ and $J(\theta_0)$ is the Hessian matrix evaluated at $\theta_0$. In our case, we have $h(\theta) = 1/n \, \mathrm{LL}(\theta)$ such that $\theta_0$ is the maximum likelihood estimator $\hat{\theta}$:

\begin{equation} \label{eq:bic-der-MLE}
\hat{\theta} = \operatorname*{arg\,max}_\theta \mathrm{LL}(\theta) \; .
\end{equation}

With this, \eqref{eq:bic-der-LA} can be applied to \eqref{eq:bic-der-ML} using \eqref{eq:bic-der-gh} to give:

\begin{equation} \label{eq:bic-der-ML-approx}
p(y|m) \approx \left( \sqrt{\frac{2 \pi}{n}} \right)^p p(y|\hat{\theta},m) \, p(\hat{\theta}|m) \, \left| J(\hat{\theta}) \right|^{-1/2} \; .
\end{equation}

Logarithmizing and multiplying with $-2$, we have:

\begin{equation} \label{eq:bic-der-LME-approx}
-2 \log p(y|m) \approx -2 \, \mathrm{LL}(\hat{\theta}) + p \log n - p \log(2 \pi) - 2 \log p(\hat{\theta}|m) + \log \left| J(\hat{\theta}) \right| \; .
\end{equation}

As $n \to \infty$, the last three terms are $O_p(1)$ and can therefore be ignored when comparing between models $\mathcal{M} = \left\lbrace m_1, \ldots, m_M \right\rbrace$ and using $p(y \vert m_j)$ to compute posterior model probabilies ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:pmp}) $p(m_j \vert y)$. With that, the BIC is given as

\begin{equation} \label{eq:bic-der-BIC-qed}
\mathrm{BIC}(m) = -2 \log p(y|\hat{\theta}, m) + p \log n \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Claeskens G, Hjort NL (2008): "The Bayesian information criterion"; in: \textit{Model Selection and Model Averaging}, ch. 3.2, pp. 78-81; URL: \url{https://www.cambridge.org/core/books/model-selection-and-model-averaging/E6F1EC77279D1223423BB64FC3A12C37}; DOI: 10.1017/CBO9780511790485.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P32 | shortcut: bic-der | author: JoramSoch | date: 2020-01-26, 23:36.
\vspace{1em}



\subsection{Deviance information criterion}

\subsubsection[\textit{Definition}]{Definition} \label{sec:dic}
\setcounter{equation}{0}

\textbf{Definition:} Let $m$ be a generative model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) with likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) $p(y \vert \theta, m)$ and prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) $p(\theta \vert m)$. Together, likelihood function and prior distribution imply a posterior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) $p(\theta \vert y, m)$.

Define the posterior expected log-likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:llf}) (PLL)

\begin{equation} \label{eq:dic-PLL}
\mathrm{PLL}(m) = \left\langle \log p(y|\theta,m) \right\rangle_{\theta|y}
\end{equation}

and the log-likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:llf}) at the posterior expectation (LLP)

\begin{equation} \label{eq:dic-LLP}
\mathrm{LLP}(m) = \log p(y|\left\langle \theta \right\rangle_{\theta|y},m)
\end{equation}

where $\left\langle \cdot \right\rangle_{\theta \vert y}$ denotes an expectation across the posterior distribution.

Then, the deviance information criterion (DIC) of the model is defined as

\begin{equation} \label{eq:dic-DIC}
\mathrm{DIC}(m) = -2 \, \mathrm{LLP}(m) + 2 \, p_D \quad \text{or} \quad \mathrm{DIC}(m) = -2 \, \mathrm{PLL}(m) + p_D
\end{equation}

where the "effective number of parameters" $p_D$ is given by

\begin{equation} \label{eq:dic-DIC-pD}
p_D = -2 \, \mathrm{PLL}(m) +2 \, \mathrm{LLP}(m) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Spiegelhalter DJ, Best NG, Carlin BP, Van Der Linde A (2002): "Bayesian measures of model complexity and fit"; in: \textit{Journal of the Royal Statistical Society, Series B: Statistical Methodology}, vol. 64, iss. 4, pp. 583-639; URL: \url{https://rss.onlinelibrary.wiley.com/doi/10.1111/1467-9868.00353}; DOI: 10.1111/1467-9868.00353.
\item Soch J, Allefeld C (2018): "MACS – a new SPM toolbox for model assessment, comparison and selection"; in: \textit{Journal of Neuroscience Methods}, vol. 306, pp. 19-31, eqs. 10-12; URL: \url{https://www.sciencedirect.com/science/article/pii/S0165027018301468}; DOI: 10.1016/j.jneumeth.2018.05.017.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D25 | shortcut: dic | author: JoramSoch | date: 2020-02-25, 12:46.
\vspace{1em}



\pagebreak
\section{Bayesian model selection}

\subsection{Log model evidence}

\subsubsection[\textit{Definition}]{Definition} \label{sec:lme}
\setcounter{equation}{0}

\textbf{Definition:} Let $m$ be a generative model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) with likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) $p(y \vert \theta, m)$ and prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) $p(\theta \vert m)$. Then, the log model evidence (LME) of this model is defined as the logarithm of the marginal likelihood ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ml}):

\begin{equation} \label{eq:lme-LME}
\mathrm{LME}(m) = \log p(y|m) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Soch J, Allefeld C (2018): "MACS – a new SPM toolbox for model assessment, comparison and selection"; in: \textit{Journal of Neuroscience Methods}, vol. 306, pp. 19-31, eq. 13; URL: \url{https://www.sciencedirect.com/science/article/pii/S0165027018301468}; DOI: 10.1016/j.jneumeth.2018.05.017.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D26 | shortcut: lme | author: JoramSoch | date: 2020-02-25, 12:56.
\vspace{1em}



\subsubsection[\textbf{Derivation}]{Derivation} \label{sec:lme-der}
\setcounter{equation}{0}

\textbf{Theorem:} Let $p(y \vert \theta,m)$ be a likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf}) of a generative model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) $m$ for making inferences on model parameters $\theta$ given measured data $y$. Moreover, let $p(\theta \vert m)$ be a prior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) on model parameters $\theta$. Then, the log model evidence ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme}) (LME), also called marginal log-likelihood,

\begin{equation} \label{eq:lme-der-LME-term}
\mathrm{LME}(m) = \log p(y|m) \; ,
\end{equation}

can be expressed

1) as

\begin{equation} \label{eq:lme-der-LME-marg}
\mathrm{LME}(m) = \log \int p(y|\theta,m) \, p(\theta|m) \, \mathrm{d}\theta
\end{equation}

2) or

\begin{equation} \label{eq:lme-der-LME-bayes}
\mathrm{LME}(m) = \log p(y|\theta,m) + \log p(\theta|m) - \log p(\theta|y,m) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:}

1) The first expression is a simple consequence of the law of marginal probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}) for continuous variables according to which

\begin{equation} \label{eq:lme-der-ME}
p(y|m) = \int p(y|\theta,m) \, p(\theta|m) \, \mathrm{d}\theta
\end{equation}

which, when logarithmized, gives

\begin{equation} \label{eq:lme-der-LME-marg-qed}
\mathrm{LME}(m) = \log p(y|m) = \log \int p(y|\theta,m) \, p(\theta|m) \, \mathrm{d}\theta \; .
\end{equation}

2) The second expression can be derived from Bayes' theorem ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:bayes-th}) which makes a statement about the posterior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}):

\begin{equation} \label{eq:lme-der-BT}
p(\theta|y,m) = \frac{p(y|\theta,m) \, p(\theta|m)}{p(y|m)} \; .
\end{equation}

Rearranging for $p(y \vert m)$ and logarithmizing, we have:

\begin{equation} \label{eq:lme-der-LME-bayes-qed}
\begin{split}
\mathrm{LME}(m) = \log p(y|m) & = \log \frac{p(y|\theta,m) \, p(\theta|m)}{p(\theta|y,m)} \\
&= \log p(y|\theta,m) + \log p(\theta|m) - \log p(\theta|y,m) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P13 | shortcut: lme-der | author: JoramSoch | date: 2020-01-06, 21:27.
\vspace{1em}



\subsubsection[\textbf{Partition into accuracy and complexity}]{Partition into accuracy and complexity} \label{sec:lme-anc}
\setcounter{equation}{0}

\textbf{Theorem:} The log model evidence ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme}) can be partitioned into accuracy and complexity

\begin{equation} \label{eq:lme-anc-LME}
\mathrm{LME}(m) = \mathrm{Acc}(m) - \mathrm{Com}(m)
\end{equation}

where the accuracy term is the posterior expectation of the log-likelihood function ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:lf})

\begin{equation} \label{eq:lme-anc-Acc}
\mathrm{Acc}(m) = \left\langle p(y|\theta,m) \right\rangle_{p(\theta|y,m)}
\end{equation}

and the complexity penalty is the Kullback-Leibler divergence ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:kl}) of posterior ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) from prior ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior})

\begin{equation} \label{eq:lme-anc-Com}
\mathrm{Com}(m) = \mathrm{KL} \left[ p(\theta|y,m) \, || \, p(\theta|m) \right] \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} We consider Bayesian inference on data $y$ using model $m$ with parameters $\theta$. Then, Bayes' theorem ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:bayes-th}) makes a statement about the posterior distribution, i.e. the probability of parameters, given the data and the model:

\begin{equation} \label{eq:lme-anc-AnC-s1}
p(\theta|y,m) = \frac{p(y|\theta,m) \, p(\theta|m)}{p(y|m)} \; .
\end{equation}

Rearranging this for the model evidence ($\rightarrow$ Proof \ref{sec:Model Selection}/\ref{sec:lme-der}), we have:

\begin{equation} \label{eq:lme-anc-AnC-s2}
p(y|m) = \frac{p(y|\theta,m) \, p(\theta|m)}{p(\theta|y,m)} \; .
\end{equation}

Logarthmizing both sides of the equation, we obtain:

\begin{equation} \label{eq:lme-anc-AnC-s3}
\log p(y|m) = \log p(y|\theta,m) - \log \frac{p(\theta|y,m)}{p(\theta|m)} \; .
\end{equation}

Now taking the expectation over the posterior distribution yields:

\begin{equation} \label{eq:lme-anc-AnC-s4}
\log p(y|m) = \int p(\theta|y,m) \log p(y|\theta,m) \, \mathrm{d}\theta - \int p(\theta|y,m) \log \frac{p(\theta|y,m)}{p(\theta|m)} \, \mathrm{d}\theta \; .
\end{equation}

By definition, the left-hand side is the log model evidence and the terms on the right-hand side correspond to the posterior expectation of the log-likelihood function and the Kullback-Leibler divergence of posterior from prior

\begin{equation} \label{eq:lme-anc-LME-AnC}
\mathrm{LME}(m) = \left\langle p(y|\theta,m) \right\rangle_{p(\theta|y,m)} - \mathrm{KL} \left[ p(\theta|y,m) \, || \, p(\theta|m) \right]
\end{equation}

which proofs the partition given by \eqref{eq:lme-anc-LME}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Penny et al. (2007): "Bayesian Comparison of Spatially Regularised General Linear Models"; in: \textit{Human Brain Mapping}, vol. 28, pp. 275–293; URL: \url{https://onlinelibrary.wiley.com/doi/full/10.1002/hbm.20327}; DOI: 10.1002/hbm.20327.
\item Soch et al. (2016): "How to avoid mismodelling in GLM-based fMRI data analysis: cross-validated Bayesian model selection"; in: \textit{NeuroImage}, vol. 141, pp. 469–489; URL: \url{https://www.sciencedirect.com/science/article/pii/S1053811916303615}; DOI: 10.1016/j.neuroimage.2016.07.047.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P3 | shortcut: lme-anc | author: JoramSoch | date: 2019-09-27, 16:13.
\vspace{1em}



\subsection{Log family evidence}

\subsubsection[\textit{Definition}]{Definition} \label{sec:lfe}
\setcounter{equation}{0}

\textbf{Definition:} Let $f$ be a family of $M$ generative models ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) $m_1, \ldots, m_M$, such that the following statement holds true:

\begin{equation} \label{eq:lfe-fam}
f \Leftrightarrow m_1 \vee \ldots \vee m_M \; .
\end{equation}

Then, the family evidence of $f$ is the weighted average of the model evidences ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ml}) of $m_1, \ldots, m_M$ where the weights are the within-family prior model probabilities ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior})

\begin{equation} \label{eq:lfe-fe}
p(y|f) = \sum_{i=1}^M p(y|m_i) \, p(m_i|f) \; .
\end{equation}

The log family evidence is given by the logarithm of the family evidence:

\begin{equation} \label{eq:lfe-lfe}
\mathrm{LFE}(f) = \log p(y|f) = \log \sum_{i=1}^M p(y|m_i) \, p(m_i|f) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Soch J, Allefeld C (2018): "MACS – a new SPM toolbox for model assessment, comparison and selection"; in: \textit{Journal of Neuroscience Methods}, vol. 306, pp. 19-31, eq. 16; URL: \url{https://www.sciencedirect.com/science/article/pii/S0165027018301468}; DOI: 10.1016/j.jneumeth.2018.05.017.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D80 | shortcut: lfe | author: JoramSoch | date: 2020-07-13, 22:31.
\vspace{1em}



\subsubsection[\textbf{Derivation}]{Derivation} \label{sec:lfe-der}
\setcounter{equation}{0}

\textbf{Theorem:} Let $f$ be a family of $M$ generative models ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) $m_1, \ldots, m_M$ with model evidences ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ml}) $p(y \vert m_1), \ldots, p(y \vert m_M)$. Then, the log family evidence ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lfe})

\begin{equation} \label{eq:lfe-der-LFE-term}
\mathrm{LFE}(f) = \log p(y|f)
\end{equation}

can be expressed as

\begin{equation} \label{eq:lfe-der-LFE-marg}
\mathrm{LFE}(f) = \log \sum_{i=1}^M p(y|m_i) \, p(m_i|f)
\end{equation}

where $p(m_i \vert f)$ are the within-family ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lfe}) prior ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) probabilities ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob}).


\vspace{1em}
\textbf{Proof:} We will assume "prior addivivity"

\begin{equation} \label{eq:lfe-der-fam-prior}
p(f) = \sum_{i=1}^M p(m_i)
\end{equation}

and "posterior additivity" for family probabilities:

\begin{equation} \label{eq:lfe-der-fam-post}
p(f|y) = \sum_{i=1}^M p(m_i|y)
\end{equation}

Bayes' theorem ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:bayes-th}) for the family evidence ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lfe}) gives

\begin{equation} \label{eq:lfe-der-fe-bayes-th}
p(y|f) = \frac{p(f|y) \, p(y)}{p(f)} \; .
\end{equation}

Applying \eqref{eq:lfe-der-fam-prior} and \eqref{eq:lfe-der-fam-post}, we have

\begin{equation} \label{eq:lfe-der-fe-me}
p(y|f) = \frac{\sum_{i=1}^M p(m_i|y) \, p(y)}{\sum_{i=1}^M p(m_i)} \; .
\end{equation}

Bayes' theorem ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:bayes-th}) for the model evidence ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lfe}) gives

\begin{equation} \label{eq:lfe-der-me-bayes-th}
p(y|m_i) = \frac{p(m_i|y) \, p(y)}{p(m_i)}
\end{equation}

which can be rearranged into

\begin{equation} \label{eq:lfe-der-me-bayes-th-dev}
p(m_i|y) \, p(y) = p(y|m_i) \, p(m_i) \; .
\end{equation}

Plugging \eqref{eq:lfe-der-me-bayes-th-dev} into \eqref{eq:lfe-der-fe-me}, we have

\begin{equation} \label{eq:lfe-der-fe-marg-qed}
\begin{split}
p(y|f) &= \frac{\sum_{i=1}^M p(y|m_i) \, p(m_i)}{\sum_{i=1}^M p(m_i)} \\
&= \sum_{i=1}^M p(y|m_i) \cdot \frac{p(m_i)}{\sum_{i=1}^M p(m_i)} \\
&= \sum_{i=1}^M p(y|m_i) \cdot \frac{p(m_i,f)}{p(f)} \\
&= \sum_{i=1}^M p(y|m_i) \cdot p(m_i|f) \; .
\end{split}
\end{equation}

Equation \eqref{eq:lfe-der-LFE-marg} follows by logarithmizing both sides of \eqref{eq:lfe-der-fe-marg-qed}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P132 | shortcut: lfe-der | author: JoramSoch | date: 2020-07-13, 22:58.
\vspace{1em}



\subsubsection[\textbf{Calculation from log model evidences}]{Calculation from log model evidences} \label{sec:lfe-lme}
\setcounter{equation}{0}

\textbf{Theorem:} Let $m_1, \ldots, m_M$ be $M$ statistical models with log model evidences ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme}) $\mathrm{LME}(m_1), \ldots, \mathrm{LME}(m_M)$ and belonging to $F$ mutually exclusive model families $f_1, \ldots, f_F$. Then, the log family evidences ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lfe}) are given by:

\begin{equation} \label{eq:lfe-lme-LFE-LME}
\mathrm{LFE}(f_j) = \log \sum_{m_i \in f_j} \left[ \exp[\mathrm{LME}(m_i)] \cdot p(m_i|f_j) \right], \quad j = 1, \ldots, F,
\end{equation}

where $p(m_i \vert f_j)$ are within-family ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lfe}) prior ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) model ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) probabilities ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob}).


\vspace{1em}
\textbf{Proof:} Let us consider the (unlogarithmized) family evidence $p(y \vert f_j)$. According to the law of marginal probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}), this conditional probability is given by

\begin{equation} \label{eq:lfe-lme-FE-ME-s1}
p(y|f_j) = \sum_{m_i \in f_j} \left[ p(y|m_i,f_j) \cdot p(m_i|f_j) \right] \; .
\end{equation}

Because model families are mutually exclusive, it holds that $p(y \vert m_i,f_j) = p(y \vert m_i)$, such that

\begin{equation} \label{eq:lfe-lme-FE-ME-s2}
p(y|f_j) = \sum_{m_i \in f_j} \left[ p(y|m_i) \cdot p(m_i|f_j) \right] \; .
\end{equation}

Logarithmizing transforms the family evidence $p(y \vert f_j)$ into the log family evidence $\mathrm{LFE}(f_j)$:

\begin{equation} \label{eq:lfe-lme-LFE-LME-s1}
\mathrm{LFE}(f_j) = \log \sum_{m_i \in f_j} \left[ p(y|m_i) \cdot p(m_i|f_j) \right] \; .
\end{equation}

The definition of the log model evidence ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme})

\begin{equation} \label{eq:lfe-lme-LME}
\mathrm{LME}(m) = \log p(y|m)
\end{equation}

can be exponentiated to then read

\begin{equation} \label{eq:lfe-lme-ME}
\exp\left[ \mathrm{LME}(m) \right] = p(y|m)
\end{equation}

and applying \eqref{eq:lfe-lme-ME} to \eqref{eq:lfe-lme-LFE-LME-s1}, we finally have:

\begin{equation} \label{eq:lfe-lme-LFE-LME-s2}
\mathrm{LFE}(f_j) = \log \sum_{m_i \in f_j} \left[ \exp[\mathrm{LME}(m_i)] \cdot p(m_i|f_j) \right] \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Soch J, Allefeld C (2018): "MACS – a new SPM toolbox for model assessment, comparison and selection"; in: \textit{Journal of Neuroscience Methods}, vol. 306, pp. 19-31, eq. 16; URL: \url{https://www.sciencedirect.com/science/article/pii/S0165027018301468}; DOI: 10.1016/j.jneumeth.2018.05.017.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P65 | shortcut: lfe-lme | author: JoramSoch | date: 2020-02-27, 21:16.
\vspace{1em}



\subsection{Log Bayes factor}

\subsubsection[\textit{Definition}]{Definition} \label{sec:lbf}
\setcounter{equation}{0}

\textbf{Definition:} Let there be two generative models ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) $m_1$ and $m_2$ which are mutually exclusive, but not necessarily collectively exhaustive:

\begin{equation} \label{eq:lbf-m12}
\neg (m_1 \land m_2)
\end{equation}

Then, the Bayes factor in favor of $m_1$ and against $m_2$ is the ratio of the model evidences ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ml}) of $m_1$ and $m_2$:

\begin{equation} \label{eq:lbf-bf}
\mathrm{BF}_{12} = \frac{p(y|m_1)}{p(y|m_2)} \; .
\end{equation}

The log Bayes factor is given by the logarithm of the Bayes factor:

\begin{equation} \label{eq:lbf-lbf}
\mathrm{LBF}_{12} = \log \mathrm{BF}_{12} = \log \frac{p(y|m_1)}{p(y|m_2)} \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Soch J, Allefeld C (2018): "MACS – a new SPM toolbox for model assessment, comparison and selection"; in: \textit{Journal of Neuroscience Methods}, vol. 306, pp. 19-31, eq. 18; URL: \url{https://www.sciencedirect.com/science/article/pii/S0165027018301468}; DOI: 10.1016/j.jneumeth.2018.05.017.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D84 | shortcut: lbf | author: JoramSoch | date: 2020-07-22, 07:02.
\vspace{1em}



\subsubsection[\textbf{Derivation}]{Derivation} \label{sec:lbf-der}
\setcounter{equation}{0}

\textbf{Theorem:} Let there be two generative models ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) $m_1$ and $m_2$ with model evidences ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ml}) $p(y \vert m_1)$ and $p(y \vert m_2)$. Then, the log Bayes factor ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lbf})

\begin{equation} \label{eq:lbf-der-LBF-term}
\mathrm{LBF}_{12} = \log \mathrm{BF}_{12}
\end{equation}

can be expressed as

\begin{equation} \label{eq:lbf-der-LBF-ratio}
\mathrm{LBF}_{12} = \log \frac{p(y|m_1)}{p(y|m_2)} \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The Bayes factor ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lbf}) is defined as the posterior ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) odds ratio ($\rightarrow$ Definition "odds") when both models ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) are equally likely apriori ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}):

\begin{equation} \label{eq:lbf-der-BF-s1}
\mathrm{BF}_{12} = \frac{p(m_1|y)}{p(m_2|y)}
\end{equation}

Plugging in the posterior odds ratio according to Bayes' rule ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:bayes-rule}), we have

\begin{equation} \label{eq:lbf-der-BF-s2}
\mathrm{BF}_{12} = \frac{p(y|m_1)}{p(y|m_2)} \cdot \frac{p(m_1)}{p(m_2)} \; .
\end{equation}

When both models are equally likely apriori, the prior ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) odds ratio ($\rightarrow$ Definition "odds") is one, such that

\begin{equation} \label{eq:lbf-der-BF-s3}
\mathrm{BF}_{12} = \frac{p(y|m_1)}{p(y|m_2)} \; .
\end{equation}

Equation \eqref{eq:lbf-der-LBF-ratio} follows by logarithmizing both sides of \eqref{eq:lbf-der-BF-s3}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P137 | shortcut: lbf-der | author: JoramSoch | date: 2020-07-22, 07:27.
\vspace{1em}



\subsubsection[\textbf{Calculation from log model evidences}]{Calculation from log model evidences} \label{sec:lbf-lme}
\setcounter{equation}{0}

\textbf{Theorem:} Let $m_1$ and $m_2$ be two statistical models with log model evidences ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme}) $\mathrm{LME}(m_1)$ and $\mathrm{LME}(m_2)$. Then, the log Bayes factor ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lbf}) in favor of model $m_1$ and against model $m_2$ is the difference of the log model evidences:

\begin{equation} \label{eq:lbf-lme-LBF-LME}
\mathrm{LBF}_{12} = \mathrm{LME}(m_1) - \mathrm{LME}(m_2) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} The Bayes factor ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lbf}) is defined as the ratio of the model evidences ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ml}) of $m_1$ and $m_2$

\begin{equation} \label{eq:lbf-lme-BF}
\mathrm{BF}_{12} = \frac{p(y|m_1)}{p(y|m_2)}
\end{equation}

and the log Bayes factor ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lbf}) is defined as the logarithm of the Bayes factor

\begin{equation} \label{eq:lbf-lme-LBF}
\mathrm{LBF}_{12} = \log \mathrm{BF}_{12} = \log \frac{p(y|m_1)}{p(y|m_2)} \; .
\end{equation}

With the definition of the log model evidence ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme})

\begin{equation} \label{eq:lbf-lme-LME}
\mathrm{LME}(m) = \log p(y|m)
\end{equation}

the log Bayes factor can be expressed as:

Resolving the logarithm and applying the definition of the log model evidence ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme}), we finally have:

\begin{equation} \label{eq:lbf-lme-LBF-LME-qed}
\begin{split}
\mathrm{LBF}_{12} &= \log p(y|m_1) - \log p(y|m_2) \\
&= \mathrm{LME}(m_1) - \mathrm{LME}(m_2) \; .
\end{split}
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Soch J, Allefeld C (2018): "MACS – a new SPM toolbox for model assessment, comparison and selection"; in: \textit{Journal of Neuroscience Methods}, vol. 306, pp. 19-31, eq. 18; URL: \url{https://www.sciencedirect.com/science/article/pii/S0165027018301468}; DOI: 10.1016/j.jneumeth.2018.05.017.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P64 | shortcut: lbf-lme | author: JoramSoch | date: 2020-02-27, 20:51.
\vspace{1em}



\subsection{Posterior model probability}

\subsubsection[\textit{Definition}]{Definition} \label{sec:pmp}
\setcounter{equation}{0}

\textbf{Definition:} Let $m_1, \ldots, m_M$ be $M$ statistical models ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:fpm}) with model evidences ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ml}) $p(y \vert m_1), \ldots, p(y \vert m_M)$ and prior probabilities ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior})  $p(m_1), \ldots, p(m_M)$. Then, the conditional probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-cond}) of model $m_i$, given the data $y$, is called the posterior probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) of model $m_i$:

\begin{equation} \label{eq:pmp-PMP}
\mathrm{PP}(m_i) = p(m_i|y) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Soch J, Allefeld C (2018): "MACS – a new SPM toolbox for model assessment, comparison and selection"; in: \textit{Journal of Neuroscience Methods}, vol. 306, pp. 19-31, eq. 23; URL: \url{https://www.sciencedirect.com/science/article/pii/S0165027018301468}; DOI: 10.1016/j.jneumeth.2018.05.017.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D87 | shortcut: pmp | author: JoramSoch | date: 2020-07-28, 03:30.
\vspace{1em}



\subsubsection[\textbf{Derivation}]{Derivation} \label{sec:pmp-der}
\setcounter{equation}{0}

\textbf{Theorem:} Let there be a set of generative models ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:gm}) $m_1, \ldots, m_M$ with model evidences ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:ml}) $p(y \vert m_1), \ldots, p(y \vert m_M)$ and prior probabilities ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior})  $p(m_1), \ldots, p(m_M)$. Then, the posterior probability ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:pmp}) of model $m_i$ is given by

\begin{equation} \label{eq:pmp-der-PMP}
p(m_i|y) = \frac{p(y|m_i) \, p(m_i)}{\sum_{j=1}^{M} p(y|m_j) \, p(m_j)}, \; i = 1, \ldots, M \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} From Bayes' theorem ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:bayes-th}), the posterior model probability ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:pmp}) of the $i$-th model can be derived as

\begin{equation} \label{eq:pmp-der-PMP-s1}
p(m_i|y) = \frac{p(y|m_i) \, p(m_i)}{p(y)} \; .
\end{equation}

Using the law of marginal probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}), the denominator can be rewritten, such that

\begin{equation} \label{eq:pmp-der-PMP-s2}
p(m_i|y) = \frac{p(y|m_i) \, p(m_i)}{\sum_{j=1}^{M} p(y,m_j)} \; .
\end{equation}

Finally, using the law of conditional probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-cond}), we have

\begin{equation} \label{eq:pmp-der-PMP-s3}
p(m_i|y) = \frac{p(y|m_i) \, p(m_i)}{\sum_{j=1}^{M} p(y|m_j) \, p(m_j)} \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P139 | shortcut: pmp-der | author: JoramSoch | date: 2020-07-28, 03:58.
\vspace{1em}



\subsubsection[\textbf{Calculation from Bayes factors}]{Calculation from Bayes factors} \label{sec:pmp-bf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $m_0, m_1, \ldots, m_M$ be $M+1$ statistical models with model evidences ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme}) $p(y \vert m_0), p(y \vert m_1), \ldots, p(y \vert m_M)$. Then, the posterior model probabilities ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:pmp}) of the models $m_1, \ldots, m_M$ are given by:

\begin{equation} \label{eq:pmp-bf-PMP-BF}
p(m_i|y) = \frac{\mathrm{BF}_{i,0} \cdot \alpha_i}{\sum_{j=1}^{M} \mathrm{BF}_{j,0} \cdot \alpha_j}, \quad i = 1,\ldots,M \; ,
\end{equation}

where $\mathrm{BF}_{i,0}$ is the Bayes factor ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lbf}) comparing model $m_i$ with $m_0$ and $\alpha_i$ is the prior ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) odds ratio ($\rightarrow$ Definition "odds") of model $m_i$ against $m_0$.


\vspace{1em}
\textbf{Proof:} Define the Bayes factor ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lbf}) for $m_i$

\begin{equation} \label{eq:pmp-bf-BF-i0}
\mathrm{BF}_{i,0} = \frac{p(y|m_i)}{p(y|m_0)}
\end{equation}

and prior odds ratio of $m_i$ against $m_0$

\begin{equation} \label{eq:pmp-bf-prior-i0}
\alpha_i = \frac{p(m_i)}{p(m_0)} \; .
\end{equation}

The posterior model probability ($\rightarrow$ Proof \ref{sec:Model Selection}/\ref{sec:pmp-der}) of $m_i$ is given by

\begin{equation} \label{eq:pmp-bf-PMP-s1}
p(m_i|y) = \frac{p(y|m_i) \cdot p(m_i)}{\sum_{j=1}^{M} p(y|m_j) \cdot p(m_j)} \; .
\end{equation}

Now applying \eqref{eq:pmp-bf-BF-i0} and \eqref{eq:pmp-bf-prior-i0} to \eqref{eq:pmp-bf-PMP-s1}, we have

\begin{equation} \label{eq:pmp-bf-PMP-s2}
\begin{split}
p(m_i|y) &= \frac{ \mathrm{BF}_{i,0} \, p(y|m_0) \cdot \alpha_i \, p(m_0)}{\sum_{j=1}^{M} \mathrm{BF}_{j,0} \, p(y|m_0) \cdot \alpha_j \, p(m_0)} \\
&= \frac{\left[ p(y|m_0) \, p(m_0) \right] \mathrm{BF}_{i,0} \cdot \alpha_i}{\left[ p(y|m_0) \, p(m_0) \right] \sum_{j=1}^{M} \mathrm{BF}_{j,0} \cdot \alpha_j} \; ,
\end{split}
\end{equation}

such that

\begin{equation} \label{eq:pmp-bf-PMP-BF-qed}
p(m_i|y)= \frac{\mathrm{BF}_{i,0} \cdot \alpha_i}{\sum_{j=1}^{M} \mathrm{BF}_{j,0} \cdot \alpha_j} \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Hoeting JA, Madigan D, Raftery AE, Volinsky CT (1999): "Bayesian Model Averaging: A Tutorial"; in: \textit{Statistical Science}, vol. 14, no. 4, pp. 382–417, eq. 9; URL: \url{https://projecteuclid.org/euclid.ss/1009212519}; DOI: 10.1214/ss/1009212519.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P74 | shortcut: pmp-bf | author: JoramSoch | date: 2020-03-03, 13:13.
\vspace{1em}



\subsubsection[\textbf{Calculation from log Bayes factor}]{Calculation from log Bayes factor} \label{sec:pmp-lbf}
\setcounter{equation}{0}

\textbf{Theorem:} Let $m_1$ and $m_2$ be two statistical models with the log Bayes factor ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lbf}) $\mathrm{LBF}_{12}$ in favor of model $m_1$ and against model $m_2$. Then, if both models are equally likely apriori ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}), the posterior model probability ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:pmp}) of $m_1$ is

\begin{equation} \label{eq:pmp-lbf-PMP-LBF}
p(m_1|y) = \frac{\exp(\mathrm{LBF}_{12})}{\exp(\mathrm{LBF}_{12}) + 1} \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} From Bayes' rule ($\rightarrow$ Proof \ref{sec:General Theorems}/\ref{sec:bayes-rule}), the posterior odds ratio ($\rightarrow$ Definition "odds") is

\begin{equation} \label{eq:pmp-lbf-post-odds-s1}
\frac{p(m_1|y)}{p(m_2|y)} = \frac{p(y|m_1)}{p(y|m_2)} \cdot \frac{p(m_1)}{p(m_2)} \; .
\end{equation}

When both models are equally likely apriori ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}), the prior odds ratio ($\rightarrow$ Definition "odds") is one, such that

\begin{equation} \label{eq:pmp-lbf-post-odds-s2}
\frac{p(m_1|y)}{p(m_2|y)} = \frac{p(y|m_1)}{p(y|m_2)} \; .
\end{equation}

Now the right-hand side corresponds to the Bayes factor ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lbf}), therefore

\begin{equation} \label{eq:pmp-lbf-post-odds-s4}
\frac{p(m_1|y)}{p(m_2|y)} = \mathrm{BF}_{12} \; .
\end{equation}

Because the two posterior model probabilities ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:pmp}) add up to 1, we have

\begin{equation} \label{eq:pmp-lbf-post-odds-s3}
\frac{p(m_1|y)}{1-p(m_1|y)} = \mathrm{BF}_{12} \; .
\end{equation}

Now rearranging for the posterior probability ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:pmp}), this gives

\begin{equation} \label{eq:pmp-lbf-post-s1}
p(m_1|y) = \frac{\mathrm{BF}_{12}}{\mathrm{BF}_{12} + 1} \; .
\end{equation}

Because the log Bayes factor is the logarithm of the Bayes factor ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lbf}), we finally have

\begin{equation} \label{eq:pmp-lbf-post-s2}
p(m_1|y) = \frac{\exp(\mathrm{LBF}_{12})}{\exp(\mathrm{LBF}_{12}) + 1} \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Soch J, Allefeld C (2018): "MACS – a new SPM toolbox for model assessment, comparison and selection"; in: \textit{Journal of Neuroscience Methods}, vol. 306, pp. 19-31, eq. 21; URL: \url{https://www.sciencedirect.com/science/article/pii/S0165027018301468}; DOI: 10.1016/j.jneumeth.2018.05.017.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P73 | shortcut: pmp-lbf | author: JoramSoch | date: 2020-03-03, 12:27.
\vspace{1em}



\subsubsection[\textbf{Calculation from log model evidences}]{Calculation from log model evidences} \label{sec:pmp-lme}
\setcounter{equation}{0}

\textbf{Theorem:} Let $m_1, \ldots, m_M$ be $M$ statistical models with log model evidences ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme}) $\mathrm{LME}(m_1), \ldots, \mathrm{LME}(m_M)$. Then, the posterior model probabilities ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:pmp}) are given by:

\begin{equation} \label{eq:pmp-lme-PMP-LME}
p(m_i|y) = \frac{\exp[\mathrm{LME}(m_i)] \, p(m_i)}{\sum_{j=1}^{M} \exp[\mathrm{LME}(m_j)] \, p(m_j)}, \quad i = 1,\ldots,M \; ,
\end{equation}

where $p(m_i)$ are prior ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prior}) model probabilities.


\vspace{1em}
\textbf{Proof:} The posterior model probability ($\rightarrow$ Proof \ref{sec:Model Selection}/\ref{sec:pmp-der}) can be derived as

\begin{equation} \label{eq:pmp-lme-PMP-s1}
p(m_i|y) = \frac{p(y|m_i) \, p(m_i)}{\sum_{j=1}^{M} p(y|m_j) \, p(m_j)} \; .
\end{equation}

The definition of the log model evidence ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme})

\begin{equation} \label{eq:pmp-lme-LME}
\mathrm{LME}(m) = \log p(y|m)
\end{equation}

can be exponentiated to then read

\begin{equation} \label{eq:pmp-lme-ME}
\exp\left[ \mathrm{LME}(m) \right] = p(y|m)
\end{equation}

and applying \eqref{eq:pmp-lme-ME} to \eqref{eq:pmp-lme-PMP-s1}, we finally have:

\begin{equation} \label{eq:pmp-lme-PMP-s2}
p(m_i|y) = \frac{\exp[\mathrm{LME}(m_i)] \, p(m_i)}{\sum_{j=1}^{M} \exp[\mathrm{LME}(m_j)] \, p(m_j)} \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Soch J, Allefeld C (2018): "MACS – a new SPM toolbox for model assessment, comparison and selection"; in: \textit{Journal of Neuroscience Methods}, vol. 306, pp. 19-31, eq. 23; URL: \url{https://www.sciencedirect.com/science/article/pii/S0165027018301468}; DOI: 10.1016/j.jneumeth.2018.05.017.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P66 | shortcut: pmp-lme | author: JoramSoch | date: 2020-02-27, 21:33.
\vspace{1em}



\subsection{Bayesian model averaging}

\subsubsection[\textit{Definition}]{Definition} \label{sec:bma}
\setcounter{equation}{0}

\textbf{Definition:} Let $m_1, \ldots, m_M$ be $M$ statistical models ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:fpm}) with posterior model probabilities ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:pmp}) $p(m_1 \vert y), \ldots, p(m_M \vert y)$ and posterior distributions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) $p(\theta \vert y, m_1), \ldots, p(\theta \vert y, m_M)$. Then, Bayesian model averaging (BMA) consists in finding the marginal ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-marg}) posterior ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) density ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}), conditional ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-cond}) on the measured data $y$, but unconditional ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}) on the modelling approach $m$:

\begin{equation} \label{eq:bma-BMA}
p(\theta|y) = \sum_{i=1}^{M} p(\theta|y,m_i) \cdot p(m_i|y) \; .
\end{equation}


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Hoeting JA, Madigan D, Raftery AE, Volinsky CT (1999): "Bayesian Model Averaging: A Tutorial"; in: \textit{Statistical Science}, vol. 14, no. 4, pp. 382–417, eq. 1; URL: \url{https://projecteuclid.org/euclid.ss/1009212519}; DOI: 10.1214/ss/1009212519.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: D89 | shortcut: bma | author: JoramSoch | date: 2020-08-03, 21:34.
\vspace{1em}



\subsubsection[\textbf{Derivation}]{Derivation} \label{sec:bma-der}
\setcounter{equation}{0}

\textbf{Theorem:} Let $m_1, \ldots, m_M$ be $M$ statistical models ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:fpm}) with posterior model probabilities ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:pmp}) $p(m_1 \vert y), \ldots, p(m_M \vert y)$ and posterior distributions ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) $p(\theta \vert y, m_1), \ldots, p(\theta \vert y, m_M)$. Then, the marginal ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:dist-marg}) posterior ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) density ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:pdf}), conditional ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-cond}) on the measured data $y$, but unconditional ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}) on the modelling approach $m$, is given by:

\begin{equation} \label{eq:bma-der-BMA}
p(\theta|y) = \sum_{i=1}^{M} p(\theta|y,m_i) \cdot p(m_i|y) \; .
\end{equation}


\vspace{1em}
\textbf{Proof:} Using the law of marginal probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}), the probability distribution of the shared parameters $\theta$ conditional ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-cond}) on the measured data $y$ can be obtained by marginalizing ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}) over the discrete random variable ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:rvar}) model $m$:

\begin{equation} \label{eq:bma-der-BMA-s1}
p(\theta|y) = \sum_{i=1}^{M} p(\theta,m_i|y) \; .
\end{equation}

Using the law of the conditional probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-cond}), the summand can be expanded to give

\begin{equation} \label{eq:bma-der-BMA-s2}
p(\theta|y) = \sum_{i=1}^{M} p(\theta|y,m_i) \cdot p(m_i|y)
\end{equation}

where $p(\theta \vert y,m_i)$ is the posterior distribution ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:post}) of the $i$-th model and $p(m_i \vert y)$ happens to be the posterior probability ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:pmp}) of the $i$-th model.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item original work\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P143 | shortcut: bma-der | author: JoramSoch | date: 2020-08-03, 22:05.
\vspace{1em}



\subsubsection[\textbf{Calculation from log model evidences}]{Calculation from log model evidences} \label{sec:bma-lme}
\setcounter{equation}{0}

\textbf{Theorem:} Let $m_1, \ldots, m_M$ be $M$ statistical models ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:fpm}) describing the same measured data $y$ with log model evidences ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:lme}) $\mathrm{LME}(m_1), \ldots, \mathrm{LME}(m_M)$ and shared model parameters $\theta$. Then, Bayesian model averaging ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:bma}) determines the following posterior distribution over $\theta$:

\begin{equation} \label{eq:bma-lme-BMA-LME}
p(\theta|y) = \sum_{i=1}^{M} p(\theta|m_i,y) \cdot \frac{\exp[\mathrm{LME}(m_i)] \, p(m_i)}{\sum_{j=1}^{M} \exp[\mathrm{LME}(m_j)] \, p(m_j)} \; ,
\end{equation}

where $p(\theta \vert m_i,y)$ is the posterior distributions over $\theta$ obtained using $m_i$.


\vspace{1em}
\textbf{Proof:} According to the law of marginal probability ($\rightarrow$ Definition \ref{sec:General Theorems}/\ref{sec:prob-marg}), the probability of the shared parameters $\theta$ conditional on the measured data $y$ can be obtained ($\rightarrow$ Definition "bma-der") by marginalizing over the discrete variable model $m$:

\begin{equation} \label{eq:bma-lme-BMA-PMP}
p(\theta|y) = \sum_{i=1}^{M} p(\theta|m_i,y) \cdot p(m_i|y) \; ,
\end{equation}

where $p(m_i \vert y)$ is the posterior probability ($\rightarrow$ Definition \ref{sec:Model Selection}/\ref{sec:pmp}) of the $i$-th model. One can express posterior model probabilities in terms of log model evidences ($\rightarrow$ Proof \ref{sec:Model Selection}/\ref{sec:pmp-lme}) as

\begin{equation} \label{eq:bma-lme-PMP-LME}
p(m_i|y) = \frac{\exp[\mathrm{LME}(m_i)] \, p(m_i)}{\sum_{j=1}^{M} \exp[\mathrm{LME}(m_j)] \, p(m_j)}
\end{equation}

and by plugging \eqref{eq:bma-lme-PMP-LME} into \eqref{eq:bma-lme-BMA-PMP}, one arrives at \eqref{eq:bma-lme-BMA-LME}.


\vspace{1em}
\textbf{Sources:}
\begin{itemize}
\item Soch J, Allefeld C (2018): "MACS – a new SPM toolbox for model assessment, comparison and selection"; in: \textit{Journal of Neuroscience Methods}, vol. 306, pp. 19-31, eq. 25; URL: \url{https://www.sciencedirect.com/science/article/pii/S0165027018301468}; DOI: 10.1016/j.jneumeth.2018.05.017.
\end{itemize}


\vspace{1em}
\textbf{Metadata:} ID: P67 | shortcut: bma-lme | author: JoramSoch | date: 2020-02-27, 21:58.
\vspace{1em}



\end{document}